<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 46]
- [cs.LG](#cs.LG) [Total: 62]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.AI](#cs.AI) [Total: 25]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Quality-Guided Mixture of Score-Fusion Experts Framework for Human Recognition](https://arxiv.org/abs/2508.00053)
*Jie Zhu,Yiyang Su,Minchul Kim,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: 本文提出了一种质量引导的混合专家分数融合框架(QME)，用于改进全身生物特征识别性能。该框架通过可学习的分数融合策略解决传统方法中忽略不同模态评分分布变化的问题，并在多个数据集上实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的全身生物特征识别系统使用多个模型处理不同模态（如人脸、步态、身体），并通过分数融合（如加权平均）得出最终结果。然而，这些方法忽略了单个模态评分分布的变化，难以进一步提升性能。

Method: 1. 提出质量引导的混合专家分数融合(QME)框架，利用混合专家模型实现可学习的分数融合策略；
2. 设计新颖的伪质量损失函数用于质量评估，引入模态特定的质量估计器(QE)；
3. 使用三元组损失函数提高度量性能。

Result: 在多个全身生物特征数据集上进行广泛实验，结果表明：
- QME框架显著优于基线方法，实现最先进的识别性能
- 有效解决了多模态度量对齐和数据质量变化等关键挑战

Conclusion: QME框架通过可学习的混合专家分数融合机制，解决了传统方法中模态级分数分布变化的问题；引入质量估计器提高了融合决策的适应性；该方法对多模态和多模型系统均有有效，并能灵活处理不同类型生物特征融合任务。

Abstract: Whole-body biometric recognition is a challenging multimodal task that
integrates various biometric modalities, including face, gait, and body. This
integration is essential for overcoming the limitations of unimodal systems.
Traditionally, whole-body recognition involves deploying different models to
process multiple modalities, achieving the final outcome by score-fusion (e.g.,
weighted averaging of similarity matrices from each model). However, these
conventional methods may overlook the variations in score distributions of
individual modalities, making it challenging to improve final performance. In
this work, we present \textbf{Q}uality-guided \textbf{M}ixture of score-fusion
\textbf{E}xperts (QME), a novel framework designed for improving whole-body
biometric recognition performance through a learnable score-fusion strategy
using a Mixture of Experts (MoE). We introduce a novel pseudo-quality loss for
quality estimation with a modality-specific Quality Estimator (QE), and a score
triplet loss to improve the metric performance. Extensive experiments on
multiple whole-body biometric datasets demonstrate the effectiveness of our
proposed approach, achieving state-of-the-art results across various metrics
compared to baseline methods. Our method is effective for multimodal and
multi-model, addressing key challenges such as model misalignment in the
similarity score domain and variability in data quality.

</details>


### [2] [Punching Bag vs. Punching Person: Motion Transferability in Videos](https://arxiv.org/abs/2508.00085)
*Raiyaan Abdullah,Jared Claypoole,Michael Cogswell,Ajay Divakaran,Yogesh Rawat*

Main category: cs.CV

TL;DR: 该论文提出了一种评估动作识别模型在未知上下文中迁移运动概念能力的框架，通过三个数据集（Syn-TA、Kinetics400-TA、Something-Something-v2-TA）评估了13个SOTA模型，揭示了模型在迁移高级动作表现上的显著下降，并指出了模型大小、空间与时间线索依赖对迁移性的影响。


<details>
  <summary>Details</summary>
Motivation: 探究现有动作识别模型能否将高级运动概念（如“拳击”）迁移到相似分布内但从未在训练中见过的上下文中（如“拳击人”），这是衡量模型动作理解能力的关键，但先前工作未系统评估。

Method: 构建了三个动作可迁移性评估数据集：1）Syn-TA（合成3D物体运动）；2）Kinetics400-TA；3）Something-Something-v2-TA。对13个SOTA模型进行测试，并分析迁移失败模式。进一步探索了通过解耦粗/细粒度动作提升时间推理困难场景的方法。

Result: 实验发现：1）多模态模型对细粒度未知动作适应更差；2）无偏的合成数据集Syn-TA与真实数据集难度相当；3）大模型在空间主导场景中迁移性更好，但在时间推理密集场景表现差，且过度依赖物体/背景特征会阻碍泛化。模型在未见情境中识别高级动作的性能显著下降。

Conclusion: 该研究揭示了动作识别模型在迁移高级运动能力上的局限，建立了首个评估运动可迁移性的基准测试（包括合成与真实数据集），为未来模型提升上下文泛化能力提供方向。解耦运动粒度或可改善时间推理困难的问题。

Abstract: Action recognition models demonstrate strong generalization, but can they
effectively transfer high-level motion concepts across diverse contexts, even
within similar distributions? For example, can a model recognize the broad
action "punching" when presented with an unseen variation such as "punching
person"? To explore this, we introduce a motion transferability framework with
three datasets: (1) Syn-TA, a synthetic dataset with 3D object motions; (2)
Kinetics400-TA; and (3) Something-Something-v2-TA, both adapted from natural
video datasets. We evaluate 13 state-of-the-art models on these benchmarks and
observe a significant drop in performance when recognizing high-level actions
in novel contexts. Our analysis reveals: 1) Multimodal models struggle more
with fine-grained unknown actions than with coarse ones; 2) The bias-free
Syn-TA proves as challenging as real-world datasets, with models showing
greater performance drops in controlled settings; 3) Larger models improve
transferability when spatial cues dominate but struggle with intensive temporal
reasoning, while reliance on object and background cues hinders generalization.
We further explore how disentangling coarse and fine motions can improve
recognition in temporally challenging datasets. We believe this study
establishes a crucial benchmark for assessing motion transferability in action
recognition. Datasets and relevant code:
https://github.com/raiyaan-abdullah/Motion-Transfer.

</details>


### [3] [The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking](https://arxiv.org/abs/2508.00088)
*Mateo de Mayo,Daniel Cremers,Taihú Pire*

Main category: cs.CV

TL;DR: 作者提出了名为Monado SLAM的数据集，旨在解决现有SLAM/VIO方法在头戴设备应用场景中面临的挑战性问题。


<details>
  <summary>Details</summary>
Motivation: 虽然VIO和SLAM技术取得了进步，但在头戴设备应用中（如高动态运动、动态遮挡、长时间跟踪、纹理稀疏区域、光线不佳、传感器饱和等场景）仍存在不足。现有数据集未能充分覆盖这些关键问题，导致系统在实际应用中表现不佳。

Method: 通过多个虚拟现实头戴设备采集真实场景序列，构建名为Monado SLAM的数据集。

Result: 发布了采用CC BY 4.0许可的开放数据集，可用于推动VIO/SLAM技术的进一步研究与发展。

Conclusion: 作者提供的高质量数据集有助于填补现有研究的空白，为复杂头戴设备场景下的SLAM算法改进提供了真实世界测试基准。

Abstract: Humanoid robots and mixed reality headsets benefit from the use of
head-mounted sensors for tracking. While advancements in visual-inertial
odometry (VIO) and simultaneous localization and mapping (SLAM) have produced
new and high-quality state-of-the-art tracking systems, we show that these are
still unable to gracefully handle many of the challenging settings presented in
the head-mounted use cases. Common scenarios like high-intensity motions,
dynamic occlusions, long tracking sessions, low-textured areas, adverse
lighting conditions, saturation of sensors, to name a few, continue to be
covered poorly by existing datasets in the literature. In this way, systems may
inadvertently overlook these essential real-world issues. To address this, we
present the Monado SLAM dataset, a set of real sequences taken from multiple
virtual reality headsets. We release the dataset under a permissive CC BY 4.0
license, to drive advancements in VIO/SLAM research and development.

</details>


### [4] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
*Basna Mohammed Salih Hasan,Ramadhan J. Mstafa*

Main category: cs.CV

TL;DR: 本研究提出了一种利用眼部周围区域（包括眼睑和眉毛）的彩色图像进行性别分类的卷积神经网络模型。该模型在CVBL和(Female and Male)两个数据集上分别取得了99%和96%的高准确率，证明了其在安全和监控等领域的实用价值。


<details>
  <summary>Details</summary>
Motivation: 性别分类在安全、人机交互、监控和广告等领域至关重要，但化妆品和伪装等因素会影响分类准确性。因此，研究专注于眼部周围区域（periocular region）的性别分类，该区域包含丰富的视觉特征，能有效抵抗上述干扰。

Method: 提出了一种复杂的卷积神经网络（CNN）模型，使用彩色图像数据库评估眼部周围区域在性别分类中的效果。模型结构经过优化，参数数量较少（7,235,089）。在两个眼部数据集（CVBL和Female and Male）上测试模型性能，并采用多种指标与其他先进方法进行比较。

Result: 模型在CVBL数据集上达到99%的准确率，在Female and Male数据集上达到96%的准确率（参数量7,235,089）。对比实验证明该模型优于其他先进方法。

Conclusion: 所提出的CNN模型能高效利用眼部周围区域进行性别分类，尤其在抵抗化妆品和伪装干扰方面表现突出。高准确率和低参数量表明该模型在安全监控等现实场景中具有实际应用潜力。

Abstract: Gender classification has emerged as a crucial aspect in various fields,
including security, human-machine interaction, surveillance, and advertising.
Nonetheless, the accuracy of this classification can be influenced by factors
such as cosmetics and disguise. Consequently, our study is dedicated to
addressing this concern by concentrating on gender classification using color
images of the periocular region. The periocular region refers to the area
surrounding the eye, including the eyelids, eyebrows, and the region between
them. It contains valuable visual cues that can be used to extract key features
for gender classification. This paper introduces a sophisticated Convolutional
Neural Network (CNN) model that utilizes color image databases to evaluate the
effectiveness of the periocular region for gender classification. To validate
the model's performance, we conducted tests on two eye datasets, namely CVBL
and (Female and Male). The recommended architecture achieved an outstanding
accuracy of 99% on the previously unused CVBL dataset while attaining a
commendable accuracy of 96% with a small number of learnable parameters
(7,235,089) on the (Female and Male) dataset. To ascertain the effectiveness of
our proposed model for gender classification using the periocular region, we
evaluated its performance through an extensive range of metrics and compared it
with other state-of-the-art approaches. The results unequivocally demonstrate
the efficacy of our model, thereby suggesting its potential for practical
application in domains such as security and surveillance.

</details>


### [5] [World Consistency Score: A Unified Metric for Video Generation Quality](https://arxiv.org/abs/2508.00144)
*Akshat Rakheja,Aarsh Ashdhir,Aryan Bhattacharjee,Vanshika Sharma*

Main category: cs.CV

TL;DR: 世界一致性得分（WCS）是一种用于评估生成视频模型的新统一度量标准，强调生成视频的内部世界一致性。它整合了四个可解释的子组件（物体持久性、关系稳定性、因果合规性和闪烁惩罚），并通过加权公式将这四个子指标结合起来，生成一个与人类判断一致的一致性得分。该度量标准综合评估视频的时间与物理连贯性，填补了以往仅关注视觉保真度或提示对齐的度量标准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视频评估指标主要关注视觉质量或文本-视频对齐，缺乏对视频内部世界随时间变化的连贯性（如物体保持、因果关系稳定）的评估。这种缺失限制了生成模型在真实场景中的适用性。WCS旨在通过可量化的子指标，综合评价视频的物理和时间一致性，推动生成模型产生更逻辑连贯的内容。

Method: 1. 设计四个子指标：物体持久性（跟踪物体在时间中的存在）、关系稳定性（物体间空间关系的连贯性）、因果合规性（动作与事件的逻辑因果）、闪烁惩罚（视觉伪影检测）。2. 利用开源工具计算子指标：使用跟踪器追踪物体、动作识别器分析动作、CLIP嵌入评估关系、光流检测闪烁。3. 通过人类偏好数据训练权重：收集人类对视频一致性的评分数据，训练加权公式以组合四个子指标，使最终WCS分数与人类判断对齐。4. 验证方案：在VBench-2.0、EvalCrafter和LOVE等基准上测试WCS与人工评分的相关性；进行敏感性分析；与现有指标（FVD、CLIPScore等）对比。

Result: 论文提出WCS的理论框架和实现方法，但尚未报告具体实验数据（因摘要未包含结果部分）。根据描述，预期结果为：WCS相较于传统指标（FVD等）能更全面地反映视频一致性，且其分数与人类评价显著相关；各子指标权重的学习将增强度量的解释性。验证实验将证明WCS在评估生成视频的世界连贯性方面的有效性。

Conclusion: WCS作为首个专门评估生成视频世界一致性的统一指标，通过可解释的子指标和自适应权重，填补了现有评估体系的空白。其可扩展的框架有望成为视频生成模型开发的新标准，推动模型关注逻辑与物理合理性，而不仅是视觉质量。

Abstract: We introduce World Consistency Score (WCS), a novel unified evaluation metric
for generative video models that emphasizes internal world consistency of the
generated videos. WCS integrates four interpretable sub-components - object
permanence, relation stability, causal compliance, and flicker penalty - each
measuring a distinct aspect of temporal and physical coherence in a video.
These submetrics are combined via a learned weighted formula to produce a
single consistency score that aligns with human judgments. We detail the
motivation for WCS in the context of existing video evaluation metrics,
formalize each submetric and how it is computed with open-source tools
(trackers, action recognizers, CLIP embeddings, optical flow), and describe how
the weights of the WCS combination are trained using human preference data. We
also outline an experimental validation blueprint: using benchmarks like
VBench-2.0, EvalCrafter, and LOVE to test WCS's correlation with human
evaluations, performing sensitivity analyses, and comparing WCS against
established metrics (FVD, CLIPScore, VBench, FVMD). The proposed WCS offers a
comprehensive and interpretable framework for evaluating video generation
models on their ability to maintain a coherent "world" over time, addressing
gaps left by prior metrics focused only on visual fidelity or prompt alignment.

</details>


### [6] [GeoExplorer: Active Geo-localization with Curiosity-Driven Exploration](https://arxiv.org/abs/2508.00152)
*Li Mi,Manon Bechaz,Zeming Chen,Antoine Bosselut,Devis Tuia*

Main category: cs.CV

TL;DR: 论文提出GeoExplorer，一种在主动地理定位中融入好奇心驱动探索的新方法，取代基于距离的奖励，以提高在陌生目标和环境中的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有主动地理定位方法依赖基于距离的奖励，导致隐含学习最小化目标相对距离的策略。但在距离估计困难或面对未见目标与环境时，此类方法因探索策略可靠性不足而表现出鲁棒性和泛化能力下降的问题。

Method: 提出GeoExplorer框架：1) 利用内在奖励驱动好奇心探索，替代传统距离奖励；2) 该奖励机制为目标无关型，通过环境建模实现稳健、多样化的上下文相关探索；3) 基于强化学习设计任务解决流程。

Result: 在四个主动地理定位基准测试上验证：1) 显著优于现有方法；2) 在陌生目标与环境定位场景中展现卓越泛化能力；3) 好奇心机制促进行动策略多样性与环境适应性。

Conclusion: 好奇心驱动策略突破距离奖励限制，通过目标无关的内在奖励实现高效环境建模，为主动地理定位任务提供具备强泛化性的解决方案，尤其适用于开放世界场景。

Abstract: Active Geo-localization (AGL) is the task of localizing a goal, represented
in various modalities (e.g., aerial images, ground-level images, or text),
within a predefined search area. Current methods approach AGL as a
goal-reaching reinforcement learning (RL) problem with a distance-based reward.
They localize the goal by implicitly learning to minimize the relative distance
from it. However, when distance estimation becomes challenging or when
encountering unseen targets and environments, the agent exhibits reduced
robustness and generalization ability due to the less reliable exploration
strategy learned during training. In this paper, we propose GeoExplorer, an AGL
agent that incorporates curiosity-driven exploration through intrinsic rewards.
Unlike distance-based rewards, our curiosity-driven reward is goal-agnostic,
enabling robust, diverse, and contextually relevant exploration based on
effective environment modeling. These capabilities have been proven through
extensive experiments across four AGL benchmarks, demonstrating the
effectiveness and generalization ability of GeoExplorer in diverse settings,
particularly in localizing unfamiliar targets and environments.

</details>


### [7] [Robust 3D Object Detection using Probabilistic Point Clouds from Single-Photon LiDARs](https://arxiv.org/abs/2508.00169)
*Bhavya Goyal,Felipe Gutierrez-Barragan,Wei Lin,Andreas Velten,Yin Li,Mohit Gupta*

Main category: cs.CV

TL;DR: 提出了一种新颖的概率点云（PPC）表示，每个点增加了表示测量不确定性的概率属性，并提出了利用PPC进行鲁棒3D目标检测的推理方法。该方法作为轻量级插件模块，在挑战性场景下（如小物体、远距离、低反光物体、强环境光等）超越了LiDAR和相机-LiDAR融合模型等基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统点云表示在处理远距离或低反光物体等挑战性场景时，由于原始LiDAR测量噪声导致点云稀疏或错误，且现有3D处理流程在构建点云时未保留不确定信息，导致下游感知模型精度下降。为解决此问题，本文提出将不确定信息嵌入点云。

Method: 1. 提出概率点云（PPC）：在点云的每个点上增加一个概率属性，用于封装原始数据中的测量不确定性（或置信度）。2. 引入基于PPC的推理方法：作为轻量级模块，可轻松集成到3D推理流程中。3. 通过模拟和真实数据验证方法在室内外挑战性场景的性能。

Result: 在包含小物体、远距离物体、低反光物体以及强环境光等场景的室内外实验中，基于PPC的3D推理方法在目标检测上超越了其他基线方法，包括纯LiDAR模型和相机-LiDAR融合模型。该方法的有效性通过模拟和实际采集数据得到验证。

Conclusion: PPC作为保留原始测量不确定性的表达形式，为处理LiDAR测量噪声导致的挑战性问题提供了有效方案；基于PPC的轻量级推理模块能通用且显著提升3D目标检测的鲁棒性，尤其在极端场景下表现突出。

Abstract: LiDAR-based 3D sensors provide point clouds, a canonical 3D representation
used in various scene understanding tasks. Modern LiDARs face key challenges in
several real-world scenarios, such as long-distance or low-albedo objects,
producing sparse or erroneous point clouds. These errors, which are rooted in
the noisy raw LiDAR measurements, get propagated to downstream perception
models, resulting in potentially severe loss of accuracy. This is because
conventional 3D processing pipelines do not retain any uncertainty information
from the raw measurements when constructing point clouds.
  We propose Probabilistic Point Clouds (PPC), a novel 3D scene representation
where each point is augmented with a probability attribute that encapsulates
the measurement uncertainty (or confidence) in the raw data. We further
introduce inference approaches that leverage PPC for robust 3D object
detection; these methods are versatile and can be used as computationally
lightweight drop-in modules in 3D inference pipelines. We demonstrate, via both
simulations and real captures, that PPC-based 3D inference methods outperform
several baselines using LiDAR as well as camera-LiDAR fusion models, across
challenging indoor and outdoor scenarios involving small, distant, and
low-albedo objects, as well as strong ambient light.
  Our project webpage is at https://bhavyagoyal.github.io/ppc .

</details>


### [8] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
*David Restrepo,Ira Ktena,Maria Vakalopoulou,Stergios Christodoulidis,Enzo Ferrante*

Main category: cs.CV

TL;DR: 本文引入了一种称为选择性模态转移（SMS）的基于扰动的量化方法，用于评估在临床决策中视觉-语言模型（VLMs）对文本和图像模态的依赖性。该方法通过交换样本的图像或文本来揭示模型存在的单模态偏见，并在两个医学影像数据集上测试了六个开源VLMs。实验结果显示这些模型存在显著的文本依赖倾向，即便在视觉信息互补的情况下，视觉信息常被忽视。这表明设计真正融合多模态信息的医学模型至关重要。


<details>
  <summary>Details</summary>
Motivation: 临床决策依赖于对医学图像及与其相关联的临床报告的综合分析。尽管视觉-语言模型（VLMs）可为这类任务提供统一框架，但它们常常表现出对单一模态的强烈偏见，尤其在医疗场景中往往忽略关键的视觉线索而偏向文本信息。因此，需要一种方法来量化模型中每种模态的依赖程度，从而揭示其潜在的偏差。

Method: 1. 提出选择性模态转移（SMS）方法，这是一种基于扰动的分析方法，适用于二分类任务。通过系统性交换不同标签样本之间的图像或文本，从而引入模态特有偏差。2. 在MIMIC-CXR（胸部X光）和FairVLMed（扫描激光检眼镜）两个医学影像数据集上评估六个开源VLMs（包括四个通用模型和两个医疗微调模型）。3. 评估模型在原始数据和扰动数据上的性能及校准程度，并通过基于注意力的定性分析验证视觉信息被忽视的情况。

Result: 1. 通过SMS方法的评估，揭示了所有测试的VLMs都表现出明显的文本依赖偏见；即使视觉信息有互补作用，模型仍过度依赖文本输入。2. 在扰动实验中，当文本被交换时模型性能下降最显著，而交换图像时影响较小，进一步证实模型主要从文本中获取决策信号。3. 注意力分析进一步显示图像内容常被文本细节所掩盖。4. 该现象在跨数据集和不同模型架构（包括医疗微调模型）中普遍存在。

Conclusion: 该研究揭示了在现有的视觉-语言模型中存在强烈的文本主导偏见，特别是在临床决策环境中，这可能导致决策时忽略了重要的图像信息，从而影响诊断的全面性和可靠度。研究强调未来设计和评估多模态医学系统时应确保真正融合视觉和文本特征，而非仅依赖于单一模态信息，以此作为提高临床决策模型健壮性和可信度的关键要素。

Abstract: Clinical decision-making relies on the integrated analysis of medical images
and the associated clinical reports. While Vision-Language Models (VLMs) can
offer a unified framework for such tasks, they can exhibit strong biases toward
one modality, frequently overlooking critical visual cues in favor of textual
information. In this work, we introduce Selective Modality Shifting (SMS), a
perturbation-based approach to quantify a model's reliance on each modality in
binary classification tasks. By systematically swapping images or text between
samples with opposing labels, we expose modality-specific biases. We assess six
open-source VLMs-four generalist models and two fine-tuned for medical data-on
two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)
and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance
and the calibration of every model in both unperturbed and perturbed settings,
we reveal a marked dependency on text input, which persists despite the
presence of complementary visual information. We also perform a qualitative
attention-based analysis which further confirms that image content is often
overshadowed by text details. Our findings highlight the importance of
designing and evaluating multimodal medical models that genuinely integrate
visual and textual cues, rather than relying on single-modality signals.

</details>


### [9] [Graph Lineages and Skeletal Graph Products](https://arxiv.org/abs/2508.00197)
*Eric Mjolsness,Cory B. Scott*

Main category: cs.CV

TL;DR: 该论文定义了一种称为'图谱系'的分层增长结构化图，其中顶点和边按级别指数级增长，并包含二分图连接相邻级别。论文提出了适用于分层图谱系的骨架化代数运算和类型构造器，并展示了其在深度神经网络和多重网格数值方法中的应用。


<details>
  <summary>Details</summary>
Motivation: 图及其增长序列在机器学习和计算科学中被广泛用于模型架构定义，但现有方法缺乏对分层和指数增长图谱系的有效规范和处理工具。论文旨在通过定义具有数学基础的结构化图谱系和骨架操作符，来支持复杂分层模型（如深度神经网络）与数值方法（如多重网格）的设计与优化。

Method: 首先定义层级化增长的图谱系（图在相邻层级间通过二分图连接）；然后基于'分级图'范畴，推导骨架化二元操作（交叉积、盒积、不相交和及函数类型）和一元操作（增厚、升级为搜索边界）；最后验证其满足代数/范畴论性质并能逼近连续极限对象。

Result: 构建了分级图谱系的代数类型理论，其骨架操作符的运算开销显著低于标准图操作符；在深度学习架构（视觉/特征尺度空间）和多级网格法中验证有效性：证明其能自然支持分层模型架构，且为局部采样/搜索提供数学基础。

Conclusion: 论文建立了分级图谱系的数学模型和计算框架，其骨架操作符支持高效定义多层体系结构。该工作填补了指数增长图谱系的代数理论空白，为下一代分层优化算法和模型架构设计提供了形式化工具。

Abstract: Graphs, and sequences of growing graphs, can be used to specify the
architecture of mathematical models in many fields including machine learning
and computational science. Here we define structured graph "lineages" (ordered
by level number) that grow in a hierarchical fashion, so that: (1) the number
of graph vertices and edges increases exponentially in level number; (2)
bipartite graphs connect successive levels within a graph lineage and, as in
multigrid methods, can constrain matrices relating successive levels; (3) using
prolongation maps within a graph lineage, process-derived distance measures
between graphs at successive levels can be defined; (4) a category of "graded
graphs" can be defined, and using it low-cost "skeletal" variants of standard
algebraic graph operations and type constructors (cross product, box product,
disjoint sum, and function types) can be derived for graded graphs and hence
hierarchical graph lineages; (5) these skeletal binary operators have similar
but not identical algebraic and category-theoretic properties to their standard
counterparts; (6) graph lineages and their skeletal product constructors can
approach continuum limit objects. Additional space-efficient unary operators on
graded graphs are also derived: thickening, which creates a graph lineage of
multiscale graphs, and escalation to a graph lineage of search frontiers
(useful as a generalization of adaptive grids and in defining "skeletal"
functions). The result is an algebraic type theory for graded graphs and
(hierarchical) graph lineages. The approach is expected to be well suited to
defining hierarchical model architectures - "hierarchitectures" - and local
sampling, search, or optimization algorithms on them. We demonstrate such
application to deep neural networks (including visual and feature scale spaces)
and to multigrid numerical methods.

</details>


### [10] [Learning Personalised Human Internal Cognition from External Expressive Behaviours for Real Personality Recognition](https://arxiv.org/abs/2508.00205)
*Xiangyu Kong,Hengde Zhu,Haoqin Sun,Zhihao Guo,Jiayan Gu,Xinyi Ni,Wei Zhang,Shizhe Liu,Siyang Song*

Main category: cs.CV

TL;DR: 提出了一种基于内部认知模拟的自动真实人格识别（RPR）方法，通过短音频-视觉行为生成个性化网络权重，作为二维图输入，并使用新型2D图神经网络进行人格特质推断。


<details>
  <summary>Details</summary>
Motivation: 现有真实人格识别方法多作为外部观察者推断观察者的人格印象，但这与真实人格存在显著偏差，导致性能不佳。受真实人格与产生表达行为的人类内部认知之间关联的启发，提出从目标个体的轻松可获取的外部短音频-视觉行为中模拟个性化内部认知。

Method: 通过模拟个性化认知（表现为使个性化网络重现个体特定面部反应的网络权重），将其编码为包含二维节点和边特征矩阵的新图；提出一种新型二维图神经网络（2D-GNN）从该图中推断真实人格特质。设计端到端策略联合训练认知模拟、二维图构建和人格识别模块。

Result: 文中未给出具体实验结果数据。

Conclusion: 该方法通过模拟与个体音频-视觉行为相关的内部认知，进而进行人格识别，提供了一种端到端的解决方案，联合优化了认知模拟与人格识别任务。

Abstract: Automatic real personality recognition (RPR) aims to evaluate human real
personality traits from their expressive behaviours. However, most existing
solutions generally act as external observers to infer observers' personality
impressions based on target individuals' expressive behaviours, which
significantly deviate from their real personalities and consistently lead to
inferior recognition performance. Inspired by the association between real
personality and human internal cognition underlying the generation of
expressive behaviours, we propose a novel RPR approach that efficiently
simulates personalised internal cognition from easy-accessible external short
audio-visual behaviours expressed by the target individual. The simulated
personalised cognition, represented as a set of network weights that enforce
the personalised network to reproduce the individual-specific facial reactions,
is further encoded as a novel graph containing two-dimensional node and edge
feature matrices, with a novel 2D Graph Neural Network (2D-GNN) proposed for
inferring real personality traits from it. To simulate real personality-related
cognition, an end-to-end strategy is designed to jointly train our cognition
simulation, 2D graph construction, and personality recognition modules.

</details>


### [11] [SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters](https://arxiv.org/abs/2508.00213)
*Shayan Jalilian,Abdul Bais*

Main category: cs.CV

TL;DR: 本文介绍了SAM-PTx，一种参数高效的方法，通过使用冻结的CLIP文本嵌入作为类级语义指导来适配SAM模型。该方法通过轻量级的Parallel-Text适配器设计，将文本嵌入注入SAM的图像编码器，在保持原始架构大部分冻结的同时实现语义引导的分割。


<details>
  <summary>Details</summary>
Motivation: 虽然SAM在基于提示的分割中展示了出色的泛化能力，但语义文本提示的潜力尚未得到充分探索，相比之下，空间提示（如点和框）已被广泛使用。本文旨在通过文本嵌入提供类级语义指导来提升SAM的分割性能。

Method: 提出了一种名为Parallel-Text的轻量级适配器设计，该适配器将CLIP导出的文本嵌入注入SAM的图像编码器中，但保持大多数原始架构冻结。具体来说，适配器仅修改每个Transformer块的MLP并行分支，保留注意力通路以进行空间推理。在训练阶段，仅通过修改MLP并行分支的参数注入文本嵌入，其余部分保持不变，以实现高效适配。该方法在COD10K、COCO和ADE20K的低数据子集上进行了实验。

Result: 实验结果表明，通过将固定的文本嵌入作为输入注入，SAM-PTx在分割性能上优于纯空间提示的基线方法。特别是在COD10K数据集上，该方法是首次使用文本提示进行分割的工作。

Conclusion: 将语义条件整合到SAM架构中，为以最小计算复杂性进行高效适配提供了一条实用且可扩展的路径，这证明了文本嵌入在改进分割性能方面的有效性。

Abstract: The Segment Anything Model (SAM) has demonstrated impressive generalization
in prompt-based segmentation. Yet, the potential of semantic text prompts
remains underexplored compared to traditional spatial prompts like points and
boxes. This paper introduces SAM-PTx, a parameter-efficient approach for
adapting SAM using frozen CLIP-derived text embeddings as class-level semantic
guidance. Specifically, we propose a lightweight adapter design called
Parallel-Text that injects text embeddings into SAM's image encoder, enabling
semantics-guided segmentation while keeping most of the original architecture
frozen. Our adapter modifies only the MLP-parallel branch of each transformer
block, preserving the attention pathway for spatial reasoning. Through
supervised experiments and ablations on the COD10K dataset as well as low-data
subsets of COCO and ADE20K, we show that incorporating fixed text embeddings as
input improves segmentation performance over purely spatial prompt baselines.
To our knowledge, this is the first work to use text prompts for segmentation
on the COD10K dataset. These results suggest that integrating semantic
conditioning into SAM's architecture offers a practical and scalable path for
efficient adaptation with minimal computational complexity.

</details>


### [12] [Object-Centric Cropping for Visual Few-Shot Classification](https://arxiv.org/abs/2508.00218)
*Aymane Abdali,Bartosz Boguslawski,Lucas Drumetz,Vincent Gripon*

Main category: cs.CV

TL;DR: 在少样本图像分类中，每个类别仅有一个样本的情况下，图像中多目标或复杂背景引起的歧义会显著降低分类性能。本文提出，添加目标在图像中的局部位置信息能有效提升现有基准的分类性能。关键贡献是证明使用Segment Anything模型仅需指定目标物体的一个像素点，或通过无监督前景目标提取方法，即可实现大部分性能提升。


<details>
  <summary>Details</summary>
Motivation: 少样本图像分类（尤其是每个类别仅有一个样本的情况）中，图像歧义（如多个目标或复杂背景）会导致性能显著下降。为了解决这个问题，研究者提出利用目标物体在图像中的局部位置信息，以提升分类准确性。

Method: 1. 引入目标物体的局部位置信息来增强少样本图像分类性能。具体而言：
- 使用Segment Anything Model（SAM），仅需标注目标物体的一个像素点来生成位置信息。
- 或采用无监督的前景目标提取方法自动获取位置信息。
2. 将位置信息集成到分类模型中，作为附加特征或引导注意力机制。

Result: 在多个标准少样本图像分类基准上，加入局部位置信息后，分类性能显著提升。特别值得注意的是，仅需通过SAM指定目标物体的一个像素或使用无监督前景提取，就能实现大部分的性能提升（即与更复杂的定位方法相比，仅使用简单定位信息即可获得接近的效果）。

Conclusion: 在少样本图像分类中，目标物体的局部位置信息是一种高效且低成本的附加信息，能显著提升分类性能。即使仅通过简单的方式（如单个像素标注或无监督定位）提供位置信息，也能带来大部分的性能改善。这为实际应用提供了高效且易于部署的解决方案。

Abstract: In the domain of Few-Shot Image Classification, operating with as little as
one example per class, the presence of image ambiguities stemming from multiple
objects or complex backgrounds can significantly deteriorate performance. Our
research demonstrates that incorporating additional information about the local
positioning of an object within its image markedly enhances classification
across established benchmarks. More importantly, we show that a significant
fraction of the improvement can be achieved through the use of the Segment
Anything Model, requiring only a pixel of the object of interest to be pointed
out, or by employing fully unsupervised foreground object extraction methods.

</details>


### [13] [Guided Depth Map Super-Resolution via Multi-Scale Fusion U-shaped Mamba Network](https://arxiv.org/abs/2508.00248)
*Chenggang Guo,Hao Xu,XianMing Wan*

Main category: cs.CV

TL;DR: 为了解决深度图超分辨率任务中传统CNN的长距离依赖建模不足和Transformer计算效率低的问题，本文提出了一种多尺度融合U型Mamba模型（MSF-UM）。该模型结合了Mamba高效的状态空间建模能力和残差密集通道注意力模块，并采用多尺度跨模态融合策略利用彩色图像的高频纹理信息。实验证明，该方法在显著减少参数量的同时，提升了深度图超分辨率的重建精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络（CNN）在深度图超分辨率任务中难以建模长距离依赖，而Transformer尽管能处理全局上下文但计算复杂度呈二次增长，无法高效处理高分辨率深度图。因此，需要一种既能高效建模全局依赖，又能充分融合彩色图像引导信息的新方法。

Method: 1. 提出多尺度融合U型Mamba（MSF-UM）框架；2. 核心设计：融合残差密集通道注意力块（局部特征提取）与Mamba状态空间模块（长距离依赖建模）；3. 采用多尺度跨模态融合策略，利用彩色图像的高频纹理信息引导深度图超分辨率；4. 整体采用U形编码器-解码器结构实现多尺度特征融合。

Result: 1. 在多个公开数据集上超越现有主流方法的重建精度；2. 显著减少模型参数量；3. 在大尺度深度图超分辨率任务中展现出优秀的泛化能力。

Conclusion: MSF-UM成功将Mamba的高效状态空间建模与多尺度融合策略结合，解决了传统方法的局限性。实验验证了该模型在精度、效率及泛化性上的优势，为深度图超分辨率任务提供了一种新颖有效的解决方案。

Abstract: Depth map super-resolution technology aims to improve the spatial resolution
of low-resolution depth maps and effectively restore high-frequency detail
information. Traditional convolutional neural network has limitations in
dealing with long-range dependencies and are unable to fully model the global
contextual information in depth maps. Although transformer can model global
dependencies, its computational complexity and memory consumption are
quadratic, which significantly limits its ability to process high-resolution
depth maps. In this paper, we propose a multi-scale fusion U-shaped Mamba
(MSF-UM) model, a novel guided depth map super-resolution framework. The core
innovation of this model is to integrate Mamba's efficient state-space modeling
capabilities into a multi-scale U-shaped fusion structure guided by a color
image. The structure combining the residual dense channel attention block and
the Mamba state space module is designed, which combines the local feature
extraction capability of the convolutional layer with the modeling advantage of
the state space model for long-distance dependencies. At the same time, the
model adopts a multi-scale cross-modal fusion strategy to make full use of the
high-frequency texture information from the color image to guide the
super-resolution process of the depth map. Compared with existing mainstream
methods, the proposed MSF-UM significantly reduces the number of model
parameters while achieving better reconstruction accuracy. Extensive
experiments on multiple publicly available datasets validate the effectiveness
of the model, especially showing excellent generalization ability in the task
of large-scale depth map super-resolution.

</details>


### [14] [PointGauss: Point Cloud-Guided Multi-Object Segmentation for Gaussian Splatting](https://arxiv.org/abs/2508.00259)
*Wentao Sun,Hanqing Xu,Quanyun Wu,Dedong Zhang,Yiping Chen,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: PointGauss是一个新颖的点云引导框架，用于实现Gaussian Splatting表示中的实时多目标分割。该方法通过点云分割驱动的流程直接解析高斯基元，在1分钟内生成3D实例掩码，并利用GPU加速的2D掩码渲染确保多视图一致性。相比现有方法，其多视图mIoU提升了1.89%至31.78%。同时，论文提出了包含复杂多目标场景的DesktopObjects-360数据集，具有全局一致的2D标注和大规模训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在初始化时间长、多视图一致性差的问题，难以高效实现3D分割。PointGauss旨在通过直接解析高斯基元克服这些缺陷，实现高效且保持多视图一致的实时多目标分割。

Method: 1) 提出基于点云的高斯基元解码器，能在1分钟内生成3D实例掩码；2）设计GPU加速的2D掩码渲染系统确保多视图一致性。该方法通过点云分割驱动流程直接解析GS表示中的高斯基元。

Result: 实验表明，PointGauss在多项指标上显著超越SOTA方法：多视图mIoU提升1.89-31.78%，同时保持卓越的计算效率。针对现有基准不足，论文还提出具有5大特性的DesktopObjects-360数据集（多对象/全局标注/大规模/360度覆盖/3D评估标注）。

Conclusion: PointGauss框架实现了高斯溅射表示中的实时多目标分割，在效率和精度上取得突破。新型DesktopObjects-360数据集将为该领域提供更全面的评估基准。

Abstract: We introduce PointGauss, a novel point cloud-guided framework for real-time
multi-object segmentation in Gaussian Splatting representations. Unlike
existing methods that suffer from prolonged initialization and limited
multi-view consistency, our approach achieves efficient 3D segmentation by
directly parsing Gaussian primitives through a point cloud segmentation-driven
pipeline. The key innovation lies in two aspects: (1) a point cloud-based
Gaussian primitive decoder that generates 3D instance masks within 1 minute,
and (2) a GPU-accelerated 2D mask rendering system that ensures multi-view
consistency. Extensive experiments demonstrate significant improvements over
previous state-of-the-art methods, achieving performance gains of 1.89 to
31.78% in multi-view mIoU, while maintaining superior computational efficiency.
To address the limitations of current benchmarks (single-object focus,
inconsistent 3D evaluation, small scale, and partial coverage), we present
DesktopObjects-360, a novel comprehensive dataset for 3D segmentation in
radiance fields, featuring: (1) complex multi-object scenes, (2) globally
consistent 2D annotations, (3) large-scale training data (over 27 thousand 2D
masks), (4) full 360{\deg} coverage, and (5) 3D evaluation masks.

</details>


### [15] [Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models](https://arxiv.org/abs/2508.00260)
*Hyundong Jin,Hyung Jin Chang,Eunwoo Kim*

Main category: cs.CV

TL;DR: 提出了一种新的持续学习框架，通过基于指令的视觉投影器混合物来解决生成式视觉语言模型在持续学习过程中忽视语言指令的问题，并结合专家推荐和剪枝策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法在更新视觉投影器时，可能导致模型在处理重复类型的文本指令任务时忽视语言指令。为解决这个问题，本文提出将视觉信息的翻译过程基于指令进行落地。

Method: 1.引入视觉投影器混合物，每个投影器作为特定指令上下文下的视觉转语言专家。2.提出专家推荐策略，重用类似任务专家。3.引入专家剪枝机制，减轻先前任务中累积激活的专家干扰。

Result: 在多样化的视觉语言任务上进行的广泛实验表明，该方法在生成遵循指令的响应方面优于现有持续学习方法。

Conclusion: 所提出的基于指令的视觉投影器框架结合专家推荐与剪枝，有效提升了生成式视觉语言模型在持续学习中对语言指令的关注度，显著改善指令跟随能力。

Abstract: Continual learning enables pre-trained generative vision-language models
(VLMs) to incorporate knowledge from new tasks without retraining data from
previous ones. Recent methods update a visual projector to translate visual
information for new tasks, connecting pre-trained vision encoders with large
language models. However, such adjustments may cause the models to prioritize
visual inputs over language instructions, particularly learning tasks with
repetitive types of textual instructions. To address the neglect of language
instructions, we propose a novel framework that grounds the translation of
visual information on instructions for language models. We introduce a mixture
of visual projectors, each serving as a specialized visual-to-language
translation expert based on the given instruction context to adapt to new
tasks. To avoid using experts for irrelevant instruction contexts, we propose
an expert recommendation strategy that reuses experts for tasks similar to
those previously learned. Additionally, we introduce expert pruning to
alleviate interference from the use of experts that cumulatively activated in
previous tasks. Extensive experiments on diverse vision-language tasks
demonstrate that our method outperforms existing continual learning approaches
by generating instruction-following responses.

</details>


### [16] [Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence](https://arxiv.org/abs/2508.00299)
*Danzhen Fu,Jiagao Hu,Daiguo Zhou,Fei Wang,Zepeng Wang,Wenhua Liao*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的框架，用于多视角驾驶场景下的可控行人视频编辑，通过集成视频修复和人体运动控制技术，解决了自动驾驶系统中由于训练数据集缺乏危险行人场景表示而导致的行人检测模型鲁棒性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统中的行人检测模型由于训练数据集中危险行人场景的表示不足，导致鲁棒性不够。为了解决这一问题，本文旨在生成可控的行人编辑视频，以增强数据集并提升模型性能。

Method: 1. 在多视角视频中识别行人感兴趣区域；2. 通过固定比例扩大检测边界框；3. 调整大小并拼接这些区域到一个统一的画布上，同时保留跨视角的空间关系；4. 应用二值掩码标记可编辑区域；5. 在可编辑区域内，通过姿势序列控制条件指导行人编辑，实现插入、替换和移除等功能。

Result: 大量实验表明，该框架能够实现高质量的行人编辑，具有强大的视觉真实感、时空连贯性和跨视角一致性。

Conclusion: 本文方法为多视角行人视频生成提供了一种鲁棒且通用的解决方案，在自动驾驶的数据增强和场景模拟方面具有广泛的应用潜力。

Abstract: Pedestrian detection models in autonomous driving systems often lack
robustness due to insufficient representation of dangerous pedestrian scenarios
in training datasets. To address this limitation, we present a novel framework
for controllable pedestrian video editing in multi-view driving scenarios by
integrating video inpainting and human motion control techniques. Our approach
begins by identifying pedestrian regions of interest across multiple camera
views, expanding detection bounding boxes with a fixed ratio, and resizing and
stitching these regions into a unified canvas while preserving cross-view
spatial relationships. A binary mask is then applied to designate the editable
area, within which pedestrian editing is guided by pose sequence control
conditions. This enables flexible editing functionalities, including pedestrian
insertion, replacement, and removal. Extensive experiments demonstrate that our
framework achieves high-quality pedestrian editing with strong visual realism,
spatiotemporal coherence, and cross-view consistency. These results establish
the proposed method as a robust and versatile solution for multi-view
pedestrian video generation, with broad potential for applications in data
augmentation and scenario simulation in autonomous driving.

</details>


### [17] [Multimodal Referring Segmentation: A Survey](https://arxiv.org/abs/2508.00265)
*Henghui Ding,Song Tang,Shuting He,Chang Liu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文是关于多模态参考分割的全面综述文章，涵盖了图像、视频和3D场景中的参考表达式分割任务，包括问题背景、方法总结、泛化挑战、性能比较以及未来工作追踪。


<details>
  <summary>Details</summary>
Motivation: 多模态参考分割任务在需要基于用户指令进行精确对象感知的实际应用中至关重要。随着卷积神经网络、Transformer和大语言模型的发展，该领域的研究取得了显著进展。因此，本文旨在通过系统综述，梳理该领域的研究脉络，总结方法体系，并指出未来方向。

Method: 1.介绍背景，包括问题定义和常用数据集；2.总结统一的参考分割元架构；3.回顾图像、视频和3D场景中的代表性方法；4.讨论泛化参考表达式（GREx）方法以应对实际挑战；5.梳理相关任务和实际应用；6.提供标准基准上的性能比较；7.持续跟踪相关工作并维护GitHub项目。

Result: 本文构建了一个全面的多模态参考分割研究框架，系统总结了当前方法体系和技术发展，并提供了公开的GitHub仓库用于持续追踪该领域的新进展。

Conclusion: 本文首次全面综述了图像、视频和3D场景中的多模态参考分割任务，构建了统一的方法分类体系，指出了实际应用中的泛化性挑战，并通过性能比对和开源平台推动该领域的持续发展。

Abstract: Multimodal referring segmentation aims to segment target objects in visual
scenes, such as images, videos, and 3D scenes, based on referring expressions
in text or audio format. This task plays a crucial role in practical
applications requiring accurate object perception based on user instructions.
Over the past decade, it has gained significant attention in the multimodal
community, driven by advances in convolutional neural networks, transformers,
and large language models, all of which have substantially improved multimodal
perception capabilities. This paper provides a comprehensive survey of
multimodal referring segmentation. We begin by introducing this field's
background, including problem definitions and commonly used datasets. Next, we
summarize a unified meta architecture for referring segmentation and review
representative methods across three primary visual scenes, including images,
videos, and 3D scenes. We further discuss Generalized Referring Expression
(GREx) methods to address the challenges of real-world complexity, along with
related tasks and practical applications. Extensive performance comparisons on
standard benchmarks are also provided. We continually track related works at
https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.

</details>


### [18] [Reducing the gap between general purpose data and aerial images in concentrated solar power plants](https://arxiv.org/abs/2508.00440)
*M. A. Pérez-Cutiño,J. Valverde,J. Capitán,J. M. Díaz-Báñez*

Main category: cs.CV

TL;DR: 为了解决在集中太阳能发电厂（CSP）中，由于独特挑战（如高反射表面和领域特定元素）导致传统模型难以泛化的问题，而收集和标注真实数据又成本高昂的问题，作者提出创建了一个名为AerialCSP的虚拟数据集。该数据集通过模拟CSP工厂的航空图像，为对象检测和图像分割提供标注数据，并证明在此数据集上预训练可以显著提高实际故障检测的准确性，减少手动标注的需求。


<details>
  <summary>Details</summary>
Motivation: 现有的计算机视觉模型在CSP工厂的航空图像上表现不佳，因为这些图像包含高反射表面和特定领域元素，而现有通用数据集（如城市或自然景观）无法覆盖。收集和标记真实CSP航空图像数据成本高、耗时长，限制了模型的快速工业部署。

Method: 作者创建了一个名为AerialCSP的高质量合成数据集，该数据集模拟了CSP工厂的航空图像，并提供了用于目标检测和图像分割的标注数据。方法包括生成与真实条件相似的合成数据，然后在多个模型上对AerialCSP进行基准测试，以建立CSP相关视觉任务的基线。最后，通过预训练在AerialCSP上并进行真实世界的故障检测来验证其有效性。

Result: 研究结果表明，在AerialCSP上预训练的模型显著提高了真实世界中故障检测的性能，特别是对于罕见和小型缺陷的检测。此外，该方法大幅减少了对大量手动标记的需求。

Conclusion: AerialCSP作为一种合成数据集，有效解决了CSP工厂航空图像中数据收集和标注的挑战。通过提供高质量合成数据，该数据集为模型预训练提供了基础，显著提高了实际故障检测的性能，同时减少了人工标注的工作量，有助于在工业应用中快速部署视觉模型。

Abstract: In the context of Concentrated Solar Power (CSP) plants, aerial images
captured by drones present a unique set of challenges. Unlike urban or natural
landscapes commonly found in existing datasets, solar fields contain highly
reflective surfaces, and domain-specific elements that are uncommon in
traditional computer vision benchmarks. As a result, machine learning models
trained on generic datasets struggle to generalize to this setting without
extensive retraining and large volumes of annotated data. However, collecting
and labeling such data is costly and time-consuming, making it impractical for
rapid deployment in industrial applications.
  To address this issue, we propose a novel approach: the creation of
AerialCSP, a virtual dataset that simulates aerial imagery of CSP plants. By
generating synthetic data that closely mimic real-world conditions, our
objective is to facilitate pretraining of models before deployment,
significantly reducing the need for extensive manual labeling. Our main
contributions are threefold: (1) we introduce AerialCSP, a high-quality
synthetic dataset for aerial inspection of CSP plants, providing annotated data
for object detection and image segmentation; (2) we benchmark multiple models
on AerialCSP, establishing a baseline for CSP-related vision tasks; and (3) we
demonstrate that pretraining on AerialCSP significantly improves real-world
fault detection, particularly for rare and small defects, reducing the need for
extensive manual labeling. AerialCSP is made publicly available at
https://mpcutino.github.io/aerialcsp/.

</details>


### [19] [Towards Robust Semantic Correspondence: A Benchmark and Insights](https://arxiv.org/abs/2508.00272)
*Wenyue Chong*

Main category: cs.CV

TL;DR: 提出新基准评测多种挑战场景下的语义对应方法，发现现有方法在恶劣条件下的性能显著下降，评估使用大模型和鲁棒性增强策略的效果，并给出关键见解。


<details>
  <summary>Details</summary>
Motivation: 尽管语义对应在计算机视觉中至关重要且在高质条件下表现良好，但其在挑战场景下的鲁棒性研究不足。为填补此空白，作者研究语义对应在多种恶劣条件下的表现，并建立基准数据集和进行广泛评估。

Method: 创建包含14种常见成像问题（几何失真、图像模糊、数字伪影和环境遮挡）的新基准数据集。评估多种现有语义对应方法，特别是使用大规模视觉模型（如DINO和Stable Diffusion）的方法，并测试常见鲁棒性增强策略（包括数据增强）的有效性。

Result: 所有现有方法在恶劣条件下性能明显下降；使用大规模视觉模型提升整体鲁棒性，但其微调会损害相对鲁棒性；DINO在相对鲁棒性上优于Stable Diffusion，两者融合增强绝对鲁棒性；通用数据增强无效，需任务特定增强设计。

Conclusion: 语义对应在恶劣条件下表现不佳，当前方法难以克服该问题；利用无任务损失的大规模视觉模型提升鲁棒性是关键；跨数据集实验显示结果一致性，强调基准有效性，为未来研究提供方向。

Abstract: Semantic correspondence aims to identify semantically meaningful
relationships between different images and is a fundamental challenge in
computer vision. It forms the foundation for numerous tasks such as 3D
reconstruction, object tracking, and image editing. With the progress of
large-scale vision models, semantic correspondence has achieved remarkable
performance in controlled and high-quality conditions. However, the robustness
of semantic correspondence in challenging scenarios is much less investigated.
In this work, we establish a novel benchmark for evaluating semantic
correspondence in adverse conditions. The benchmark dataset comprises 14
distinct challenging scenarios that reflect commonly encountered imaging
issues, including geometric distortion, image blurring, digital artifacts, and
environmental occlusion. Through extensive evaluations, we provide several key
insights into the robustness of semantic correspondence approaches: (1) All
existing methods suffer from noticeable performance drops under adverse
conditions; (2) Using large-scale vision models can enhance overall robustness,
but fine-tuning on these models leads to a decline in relative robustness; (3)
The DINO model outperforms the Stable Diffusion in relative robustness, and
their fusion achieves better absolute robustness; Moreover, We evaluate common
robustness enhancement strategies for semantic correspondence and find that
general data augmentations are ineffective, highlighting the need for
task-specific designs. These results are consistent across both our dataset and
real-world benchmarks.

</details>


### [20] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
*Stefan Englmeier,Max A. Büttner,Katharina Winter,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 提出了一种新颖的上下文感知运动检索框架，用于在驾驶数据集中检索罕见但关键的行人行为，以支持自动驾驶系统的评估。该方法结合基于SMPL的运动序列和视频帧，构建多模态嵌入空间，支持文本查询。并发布了WayMoCo数据集用于验证。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需在安全关键场景中可靠运行，尤其涉及易受伤害道路使用者（VRUs）的复杂行为。但这些行为属于数据集中的长尾现象，难以检索。为支持在多样化的以人为中心场景中定向评估自动驾驶系统，需要一种高效的检索方法。

Method: 1. 基于SMPL（Skinned Multi-Person Linear）模型生成运动序列及对应视频帧。2. 将运动数据、图像数据与自然语言对齐，编码到共享的多模态嵌入空间。3. 通过文本查询实现可扩展的行为及上下文检索。4. 构建WayMoCo数据集（基于Waymo开放数据集扩展），包含自动生成的伪真实值SMPL序列和场景描述。

Result: 在WayMoCo数据集上评估，本方法在运动-上下文检索任务中的准确率比现有最优模型高出27.5%。

Conclusion: 所提出的上下文感知运动检索框架能有效定位关键的人体行为场景，为自动驾驶系统提供针对性测试素材。WayMoCo数据集为多模态行为检索提供了基准支持。

Abstract: Autonomous driving systems must operate reliably in safety-critical
scenarios, particularly those involving unusual or complex behavior by
Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets
is essential for robust evaluation and generalization, but retrieving such rare
human behavior scenarios within the long tail of large-scale datasets is
challenging. To support targeted evaluation of autonomous driving systems in
diverse, human-centered scenarios, we propose a novel context-aware motion
retrieval framework. Our method combines Skinned Multi-Person Linear
(SMPL)-based motion sequences and corresponding video frames before encoding
them into a shared multimodal embedding space aligned with natural language.
Our approach enables the scalable retrieval of human behavior and their context
through text queries. This work also introduces our dataset WayMoCo, an
extension of the Waymo Open Dataset. It contains automatically labeled motion
and scene context descriptions derived from generated pseudo-ground-truth SMPL
sequences and corresponding image data. Our approach outperforms
state-of-the-art models by up to 27.5% accuracy in motion-context retrieval,
when evaluated on the WayMoCo dataset.

</details>


### [21] [Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning](https://arxiv.org/abs/2508.00287)
*Tran Viet Khoa,Do Hai Son,Mohammad Abu Alsheikh,Yibeltal F Alem,Dinh Thai Hoang*

Main category: cs.CV

TL;DR: 该论文提出了一个用于检测驾驶员疲劳的新框架，该框架通过结合空间自注意力机制和长短期记忆网络（SSA-LSTM）来提取关键面部特征，并采用梯度相似性比较（GSC）来增强联邦学习中的模型选择。此外，开发了一个自动处理视频数据的工具。框架在联邦学习设置下达到了89.9%的检测准确率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是交通事故的主要原因之一，但在真实场景中，由于面部数据的分散性和多样性，准确检测疲劳仍具挑战性。现有方法在处理异构和分散数据时效果不佳。

Method: 1. 提出空间自注意力（SSA）机制与LSTM结合（SSA-LSTM），以更好地提取面部特征序列；2. 为支持联邦学习，引入梯度相似性比较（GSC），用于在模型聚合前选择最相关的本地模型；3. 开发定制化工具，自动处理视频数据（提取帧、检测并裁剪人脸）并进行数据增强（旋转、翻转、亮度调整和缩放）。

Result: 在联邦学习设置下，框架实现了89.9%的检测准确率，优于现有方法。该框架能有效处理真实世界的数据多样性，并在不同部署场景中表现出鲁棒性。

Conclusion: 所提出的框架显著提升了疲劳检测的准确性和鲁棒性，特别是在处理分布式异构数据的联邦学习场景中。该方案具有部署在智能交通系统中的潜力，可通过早期、可靠的疲劳检测提升道路安全。

Abstract: Driver drowsiness is one of the main causes of road accidents and is
recognized as a leading contributor to traffic-related fatalities. However,
detecting drowsiness accurately remains a challenging task, especially in
real-world settings where facial data from different individuals is
decentralized and highly diverse. In this paper, we propose a novel framework
for drowsiness detection that is designed to work effectively with
heterogeneous and decentralized data. Our approach develops a new Spatial
Self-Attention (SSA) mechanism integrated with a Long Short-Term Memory (LSTM)
network to better extract key facial features and improve detection
performance. To support federated learning, we employ a Gradient Similarity
Comparison (GSC) that selects the most relevant trained models from different
operators before aggregation. This improves the accuracy and robustness of the
global model while preserving user privacy. We also develop a customized tool
that automatically processes video data by extracting frames, detecting and
cropping faces, and applying data augmentation techniques such as rotation,
flipping, brightness adjustment, and zooming. Experimental results show that
our framework achieves a detection accuracy of 89.9% in the federated learning
settings, outperforming existing methods under various deployment scenarios.
The results demonstrate the effectiveness of our approach in handling
real-world data variability and highlight its potential for deployment in
intelligent transportation systems to enhance road safety through early and
reliable drowsiness detection.

</details>


### [22] [IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation](https://arxiv.org/abs/2508.00823)
*Wenxuan Guo,Xiuwei Xu,Hang Yin,Ziwei Wang,Jianjiang Feng,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: IGL-Nav是一个用于图像目标导航的新框架，通过使用3D高斯表示和分层定位策略（包括粗粒度几何匹配和细粒度优化），在效率和精度上显著优于现有方法，并能处理自由视角目标图像及实际机器人部署。


<details>
  <summary>Details</summary>
Motivation: 传统图像目标导航方法（端到端RL或基于拓扑图/BE地图的模块化策略）无法充分建模探索的3D环境与目标图像间的几何关系。3D高斯表示虽能建模3D场景，但其优化过程计算密集且6自由度相机位姿搜索空间巨大，难以在导航中实时使用。

Method: 1. 场景表示：随着新图像输入，通过前馈单目深度预测增量更新3D高斯表示。2. 粗定位：利用几何信息进行离散空间匹配（等效高效3D卷积）近似目标位置。3. 细定位：当靠近目标时，通过可微分渲染优化求解精确目标位姿。

Result: IGL-Nav在多种实验配置下大幅超过SOTA方法，能处理自由视角图像目标，且可在真实机器人平台部署（仅需手机拍摄任意视角的目标图像）。

Conclusion: 所提增量式3D高斯定位框架解决了传统方法的几何建模局限与实时性矛盾，通过分层策略平衡效率与精度，为图像目标导航提供了新解决方案。

Abstract: Visual navigation with an image as goal is a fundamental and challenging
problem. Conventional methods either rely on end-to-end RL learning or
modular-based policy with topological graph or BEV map as memory, which cannot
fully model the geometric relationship between the explored 3D environment and
the goal image. In order to efficiently and accurately localize the goal image
in 3D space, we build our navigation system upon the renderable 3D gaussian
(3DGS) representation. However, due to the computational intensity of 3DGS
optimization and the large search space of 6-DoF camera pose, directly
leveraging 3DGS for image localization during agent exploration process is
prohibitively inefficient. To this end, we propose IGL-Nav, an Incremental 3D
Gaussian Localization framework for efficient and 3D-aware image-goal
navigation. Specifically, we incrementally update the scene representation as
new images arrive with feed-forward monocular prediction. Then we coarsely
localize the goal by leveraging the geometric information for discrete space
matching, which can be equivalent to efficient 3D convolution. When the agent
is close to the goal, we finally solve the fine target pose with optimization
via differentiable rendering. The proposed IGL-Nav outperforms existing
state-of-the-art methods by a large margin across diverse experimental
configurations. It can also handle the more challenging free-view image-goal
setting and be deployed on real-world robotic platform using a cellphone to
capture goal image at arbitrary pose. Project page:
https://gwxuan.github.io/IGL-Nav/.

</details>


### [23] [TITAN-Guide: Taming Inference-Time AligNment for Guided Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.00289)
*Christian Simon,Masato Ishii,Akio Hayakawa,Zhi Zhong,Shusuke Takahashi,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 提出了一种名为TITAN-Guide的训练自由指导框架，用于改进文本到视频（T2V）扩散模型的指导和记忆空间问题，而无需对基础模型进行微调。


<details>
  <summary>Details</summary>
Motivation: 现有的无训练指导框架要么内存需求大，要么由于估计粗糙导致控制效果不理想，这阻碍了其在计算密集的T2V扩散模型上的应用。

Method: 开发了一种用于优化扩散潜在空间的无需通过判别指导模型反向传播的方法，研究使用正向梯度下降的各种方向指令选项进行扩散任务的指导。

Result: 该方法能有效管理内存，显著减少需求，并在多个扩散指导基准上增强T2V性能。代码、模型和演示可访问。

Conclusion: TITAN-Guide克服了现有方法的内存问题，实现了更优的控制，适用于需要密集计算的扩散模型（如T2V）。

Abstract: In the recent development of conditional diffusion models still require heavy
supervised fine-tuning for performing control on a category of tasks.
Training-free conditioning via guidance with off-the-shelf models is a
favorable alternative to avoid further fine-tuning on the base model. However,
the existing training-free guidance frameworks either have heavy memory
requirements or offer sub-optimal control due to rough estimation. These
shortcomings limit the applicability to control diffusion models that require
intense computation, such as Text-to-Video (T2V) diffusion models. In this
work, we propose Taming Inference Time Alignment for Guided Text-to-Video
Diffusion Model, so-called TITAN-Guide, which overcomes memory space issues,
and provides more optimal control in the guidance process compared to the
counterparts. In particular, we develop an efficient method for optimizing
diffusion latents without backpropagation from a discriminative guiding model.
In particular, we study forward gradient descents for guided diffusion tasks
with various options on directional directives. In our experiments, we
demonstrate the effectiveness of our approach in efficiently managing memory
during latent optimization, while previous methods fall short. Our proposed
approach not only minimizes memory requirements but also significantly enhances
T2V performance across a range of diffusion guidance benchmarks. Code, models,
and demo are available at https://titanguide.github.io.

</details>


### [24] [AniMer+: Unified Pose and Shape Estimation Across Mammalia and Aves via Family-Aware Transformer](https://arxiv.org/abs/2508.00298)
*Jin Lyu,Liang An,Li Lin,Pujin Cheng,Yebin Liu,Xiaoying Tang*

Main category: cs.CV

TL;DR: AniMer+ 是一个统一的三维动物（哺乳动物和鸟类）姿态和形状重建框架，结合了高容量的混合专家（MoE）模型架构和大规模合成数据集训练方法。


<details>
  <summary>Details</summary>
Motivation: 目前三维动物姿态和形状重建的研究面临着模型能力有限以及缺乏跨物种综合数据集的挑战。为解决这些问题，AniMer+提出了一种可扩展的方案，重点解决哺乳类和鸟类的重建问题。

Method: 该方法有两个主要创新点：1. 一个高容量的视觉变换器（ViT）架构，采用混合专家（MoE）设计，包含针对特定类别（哺乳类、鸟类）和共享的网络组件；2. 引入基于扩散模型的图像生成流程，生成了两个合成数据集CtrlAni3D（四足动物）和CtrlAVES3D（鸟类）。模型在组合合成与真实数据（共41.3k哺乳类、12.4k鸟类图像）上训练。

Result: 该方法在多个基准测试上优于现有模型（包括挑战性跨域数据集Animal Kingdom）。消融研究证明其网络架构和合成数据都有效提升了模型在真实任务中的性能。

Conclusion: AniMer+通过结合MoE网络架构和大规模合成数据克服了三维动物重建研究中数据不足和跨物种建模的挑战。特别是CtrlAVES3D作为首个大规模3D鸟类数据集填补了关键研究空白。

Abstract: In the era of foundation models, achieving a unified understanding of
different dynamic objects through a single network has the potential to empower
stronger spatial intelligence. Moreover, accurate estimation of animal pose and
shape across diverse species is essential for quantitative analysis in
biological research. However, this topic remains underexplored due to the
limited network capacity of previous methods and the scarcity of comprehensive
multi-species datasets. To address these limitations, we introduce AniMer+, an
extended version of our scalable AniMer framework. In this paper, we focus on a
unified approach for reconstructing mammals (mammalia) and birds (aves). A key
innovation of AniMer+ is its high-capacity, family-aware Vision Transformer
(ViT) incorporating a Mixture-of-Experts (MoE) design. Its architecture
partitions network layers into taxa-specific components (for mammalia and aves)
and taxa-shared components, enabling efficient learning of both distinct and
common anatomical features within a single model. To overcome the critical
shortage of 3D training data, especially for birds, we introduce a
diffusion-based conditional image generation pipeline. This pipeline produces
two large-scale synthetic datasets: CtrlAni3D for quadrupeds and CtrlAVES3D for
birds. To note, CtrlAVES3D is the first large-scale, 3D-annotated dataset for
birds, which is crucial for resolving single-view depth ambiguities. Trained on
an aggregated collection of 41.3k mammalian and 12.4k avian images (combining
real and synthetic data), our method demonstrates superior performance over
existing approaches across a wide range of benchmarks, including the
challenging out-of-domain Animal Kingdom dataset. Ablation studies confirm the
effectiveness of both our novel network architecture and the generated
synthetic datasets in enhancing real-world application performance.

</details>


### [25] [Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement](https://arxiv.org/abs/2508.00308)
*Chunyan She,Fujun Han,Chengyu Fang,Shukai Duan,Lidan Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于事件相机的两阶段低光图像增强方法，通过解耦为可见性恢复和结构细化两个阶段，并利用傅里叶空间的振幅-相位纠缠模型和动态对齐融合策略，结合空间频率插值生成的对比损失，显著提升了图像质量。实验证明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机方法直接将帧和事件数据输入单一模型，未能充分利用模态优势，限制了性能提升。因此，论文通过分析各传感模态的作用，将增强流程分解为两个阶段：可见性恢复（解决低光问题）和结构细化（利用事件数据优化细节）。

Method: 1. 两阶段解耦：首先设计基于傅里叶空间振幅-相位纠缠模型的可见性恢复网络（第一阶段）；其次提出动态对齐融合策略，解决帧与事件时空分辨率差异导致的错位问题，优化结构信息（第二阶段）。2. 训练策略：使用空间频率插值模拟多种退化负样本，构建对比损失增强模型判别能力。

Result: 实验表明，该方法在多个指标上优于现有最先进模型，有效恢复了低光图像的可见性与结构细节。

Conclusion: 通过模态解耦、傅里叶空间建模和动态对齐融合策略，结合对比学习框架，该方法突破了现有事件相机图像增强的性能瓶颈，为多模态低光增强提供了新思路。

Abstract: The event camera, benefiting from its high dynamic range and low latency,
provides performance gain for low-light image enhancement. Unlike frame-based
cameras, it records intensity changes with extremely high temporal resolution,
capturing sufficient structure information. Currently, existing event-based
methods feed a frame and events directly into a single model without fully
exploiting modality-specific advantages, which limits their performance.
Therefore, by analyzing the role of each sensing modality, the enhancement
pipeline is decoupled into two stages: visibility restoration and structure
refinement. In the first stage, we design a visibility restoration network with
amplitude-phase entanglement by rethinking the relationship between amplitude
and phase components in Fourier space. In the second stage, a fusion strategy
with dynamic alignment is proposed to mitigate the spatial mismatch caused by
the temporal resolution discrepancy between two sensing modalities, aiming to
refine the structure information of the image enhanced by the visibility
restoration network. In addition, we utilize spatial-frequency interpolation to
simulate negative samples with diverse illumination, noise and artifact
degradations, thereby developing a contrastive loss that encourages the model
to learn discriminative representations. Experiments demonstrate that the
proposed method outperforms state-of-the-art models.

</details>


### [26] [DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios](https://arxiv.org/abs/2508.00311)
*Yufeng Zhong,Zhixiong Zeng,Lei Chen,Longrong Yang,Liming Zheng,Jing Huang,Siqi Yang,Lin Ma*

Main category: cs.CV

TL;DR: DocTron-Formula是一个基于通用视觉语言模型的统一框架，用于数学公式识别，配合新发布的大型数据集CSFormula，通过监督微调在多种风格、领域和复杂布局上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有特定任务模型和通用视觉语言模型在处理数学公式时，难以应对其结构多样性、复杂性和现实世界中的变异性。因此需要一种能准确识别复杂数学公式的新方法。

Method: 提出DocTron-Formula框架：1) 构建在通用视觉语言模型基础上，无需专用架构；2) 引入CSFormula数据集，包含多学科、结构复杂的行级/段落级/页级公式；3) 通过直接监督微调实现。

Result: 实验表明：1) 在多种风格/科学领域/复杂布局上达到SOTA；2) 超越专用模型，准确率和鲁棒性更高；3) 为复杂科学文档理解建立新范式。

Conclusion: DocTron-Formula框架通过利用通用基础模型和高质量数据集，有效解决了数学公式识别的核心挑战，开辟了科学文档自动化理解的新途径。

Abstract: Optical Character Recognition (OCR) for mathematical formula is essential for
the intelligent analysis of scientific literature. However, both task-specific
and general vision-language models often struggle to handle the structural
diversity, complexity, and real-world variability inherent in mathematical
content. In this work, we present DocTron-Formula, a unified framework built
upon general vision-language models, thereby eliminating the need for
specialized architectures. Furthermore, we introduce CSFormula, a large-scale
and challenging dataset that encompasses multidisciplinary and structurally
complex formulas at the line, paragraph, and page levels. Through
straightforward supervised fine-tuning, our approach achieves state-of-the-art
performance across a variety of styles, scientific domains, and complex
layouts. Experimental results demonstrate that our method not only surpasses
specialized models in terms of accuracy and robustness, but also establishes a
new paradigm for the automated understanding of complex scientific documents.

</details>


### [27] [GV-VAD : Exploring Video Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.00312)
*Suhang Cai,Xiaohao Peng,Chong Wang,Xiaojie Cai,Jiangbo Qian*

Main category: cs.CV

TL;DR: 提出GV-VAD框架，利用文本条件视频生成模型生成合成视频以扩增数据，解决视频异常检测数据集稀缺问题，并在UCF-Crime数据集上取得SOTA。


<details>
  <summary>Details</summary>
Motivation: 真实视频异常的稀缺性、不可预测性和高标注成本限制了VAD数据集规模，进而影响模型性能和泛化能力。

Method: 1. 使用文本条件视频生成模型生成语义可控、物理合理的合成视频；2. 低成本扩增训练数据；3. 采用合成样本损失缩放策略，控制生成样本的影响以实现高效训练。

Result: 在UCF-Crime数据集上性能超越现有最先进方法。

Conclusion: GV-VAD框架通过生成式数据增强有效提升了弱监督视频异常检测性能，代码已开源。

Abstract: Video anomaly detection (VAD) plays a critical role in public safety
applications such as intelligent surveillance. However, the rarity,
unpredictability, and high annotation cost of real-world anomalies make it
difficult to scale VAD datasets, which limits the performance and
generalization ability of existing models. To address this challenge, we
propose a generative video-enhanced weakly-supervised video anomaly detection
(GV-VAD) framework that leverages text-conditioned video generation models to
produce semantically controllable and physically plausible synthetic videos.
These virtual videos are used to augment training data at low cost. In
addition, a synthetic sample loss scaling strategy is utilized to control the
influence of generated synthetic samples for efficient training. The
experiments show that the proposed framework outperforms state-of-the-art
methods on UCF-Crime datasets. The code is available at
https://github.com/Sumutan/GV-VAD.git.

</details>


### [28] [Steering Guidance for Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.00319)
*Sunghyun Park,Seokeon Choi,Hyoungwoo Park,Sungrack Yun*

Main category: cs.CV

TL;DR: 提出了一种名为个性化指导（personalization guidance）的简单有效方法，通过利用基于空文本提示的未学习弱模型，在个性化文本到图像扩散模型的微调过程中平衡目标概念对齐与原模型知识保持，从而提高文本对齐和目标分布的真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如分类器无指导CFG和自动指导AG）在个性化图像生成中存在权衡问题：CFG限制对目标分布的适应，而AG损害文本对齐，需要一种新方法来有效引导输出达到平衡状态。

Method: 1.使用未学习的弱模型（基于空文本提示条件）提供辅助梯度；2.在推理期间通过预训练模型与微调模型的权重插值动态控制未学习程度；3.无需额外计算开销即可显式引导输出到潜在空间的平衡区域。

Result: 实验证明该方法能同时提升文本对齐和目标分布的真实性，且能无缝集成到多种微调策略中。

Conclusion: 个性化指导通过创新的弱模型插值机制解决了微调过程中的权衡问题，为扩散模型的个性化提供了更有效的控制手段。

Abstract: Personalizing text-to-image diffusion models is crucial for adapting the
pre-trained models to specific target concepts, enabling diverse image
generation. However, fine-tuning with few images introduces an inherent
trade-off between aligning with the target distribution (e.g., subject
fidelity) and preserving the broad knowledge of the original model (e.g., text
editability). Existing sampling guidance methods, such as classifier-free
guidance (CFG) and autoguidance (AG), fail to effectively guide the output
toward well-balanced space: CFG restricts the adaptation to the target
distribution, while AG compromises text alignment. To address these
limitations, we propose personalization guidance, a simple yet effective method
leveraging an unlearned weak model conditioned on a null text prompt. Moreover,
our method dynamically controls the extent of unlearning in a weak model
through weight interpolation between pre-trained and fine-tuned models during
inference. Unlike existing guidance methods, which depend solely on guidance
scales, our method explicitly steers the outputs toward a balanced latent space
without additional computational overhead. Experimental results demonstrate
that our proposed guidance can improve text alignment and target distribution
fidelity, integrating seamlessly with various fine-tuning strategies.

</details>


### [29] [Spectral Sensitivity Estimation with an Uncalibrated Diffraction Grating](https://arxiv.org/abs/2508.00330)
*Lilika Makabe,Hiroaki Santo,Fumio Okura,Michael S. Brown,Yasuyuki Matsushita*

Main category: cs.CV

TL;DR: 本论文介绍了一种使用衍射光栅对相机光谱灵敏度进行实用且精确的校准方法。该方法只需未经校准的衍射光栅片，即可通过闭合形式估计相机光谱灵敏度和衍射光栅参数，无需专用窄带滤光片或已知光谱反射率的参考目标。实验表明，该方法优于传统的基于参考目标的方法。


<details>
  <summary>Details</summary>
Motivation: 相机光谱灵敏度的精确校准对于多种计算机视觉任务（如色彩校正、光照估计和材质分析）至关重要。然而，现有方法需要专用窄带滤光片或已知光谱反射率的参考目标，这限制了其在实际场景中的广泛应用。因此，作者提出了一种更简单、低成本且易于实施的校准方法。

Method: 该方法使用一片市售的普通衍射光栅片。具体步骤为：首先，通过衍射光栅片拍摄一张直接光照的图像以及一张其衍射图案的图像。随后，通过这些图像数据，以闭合形式估计出相机的光谱灵敏度以及衍射光栅的参数（无需额外设备）。

Result: 实验在合成数据和真实数据上进行，结果显示该方法优于传统的基于参考目标的校准方法。这表明该方法不仅精确，而且更具实用性。

Conclusion: 所提出的衍射光栅校准法是一种无需昂贵设备的高效方法，简化了相机光谱灵敏度的校准流程。它为未来在各种视觉系统中普及光谱校准提供了可能性，尤其是在易于获取衍射光栅片的场景中。

Abstract: This paper introduces a practical and accurate calibration method for camera
spectral sensitivity using a diffraction grating. Accurate calibration of
camera spectral sensitivity is crucial for various computer vision tasks,
including color correction, illumination estimation, and material analysis.
Unlike existing approaches that require specialized narrow-band filters or
reference targets with known spectral reflectances, our method only requires an
uncalibrated diffraction grating sheet, readily available off-the-shelf. By
capturing images of the direct illumination and its diffracted pattern through
the grating sheet, our method estimates both the camera spectral sensitivity
and the diffraction grating parameters in a closed-form manner. Experiments on
synthetic and real-world data demonstrate that our method outperforms
conventional reference target-based methods, underscoring its effectiveness and
practicality.

</details>


### [30] [Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning](https://arxiv.org/abs/2508.00356)
*Angelos Vlachos,Giorgos Filandrianos,Maria Lymperaiou,Nikolaos Spanos,Ilias Mitsouras,Vasileios Karampinis,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 提出了一种基于协作代理的多图像推理框架，通过双代理系统实现跨模态推理，适用于多类任务，在多个挑战数据集上达到高精度。


<details>
  <summary>Details</summary>
Motivation: 解决跨数据集和任务格式的混合多模态推理挑战，提供自动化、模块化且无需训练的通用框架。

Method: 使用双代理系统：PromptEngineer（生成任务相关提示）和VisionReasoner（基于LVLM进行推理），支持分类、问答、自由生成等任务。

Result: 在MIRAGE挑战赛18个数据集上验证，Claude 3.7在TQA（99.13%）、DocVQA（96.87%）和MMCoQA（75.28 ROUGE-L）任务中接近上限性能；分析了模型选择、示例数量等对性能的影响。

Conclusion: 研究表明，在有效提示引导下，LVLMs能够对多图像进行可靠推理；框架的模块化设计实现了跨任务泛化，为多图像推理提供了新范式。

Abstract: We present a Collaborative Agent-Based Framework for Multi-Image Reasoning.
Our approach tackles the challenge of interleaved multimodal reasoning across
diverse datasets and task formats by employing a dual-agent system: a
language-based PromptEngineer, which generates context-aware, task-specific
prompts, and a VisionReasoner, a large vision-language model (LVLM) responsible
for final inference. The framework is fully automated, modular, and
training-free, enabling generalization across classification, question
answering, and free-form generation tasks involving one or multiple input
images. We evaluate our method on 18 diverse datasets from the 2025 MIRAGE
Challenge (Track A), covering a broad spectrum of visual reasoning tasks
including document QA, visual comparison, dialogue-based understanding, and
scene-level inference. Our results demonstrate that LVLMs can effectively
reason over multiple images when guided by informative prompts. Notably, Claude
3.7 achieves near-ceiling performance on challenging tasks such as TQA (99.13%
accuracy), DocVQA (96.87%), and MMCoQA (75.28 ROUGE-L). We also explore how
design choices-such as model selection, shot count, and input length-influence
the reasoning performance of different LVLMs.

</details>


### [31] [Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable Kalman Filtering](https://arxiv.org/abs/2508.00358)
*Yan Gong,Mengjun Chen,Hao Liu,Gao Yongsheng,Lei Yang,Naibang Wang,Ziying Song,Haoqun Ma*

Main category: cs.CV

TL;DR: 提出了一种名为Speed-Guided Learnable Kalman Filter (SG-LKF)的方法，通过动态适应不确定性模型来应对ego车辆速度变化，从而提升多目标跟踪在动态高速场景中的稳定性和准确性。该方法集成了MotionScaleNet预测关键参数，并引入自监督轨迹一致性损失。在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统多目标跟踪方法基于静态坐标变换，忽略了ego车辆速度引起的观测噪声和参考帧变化，导致在动态高速场景中跟踪性能下降。因此，需要一种能根据速度动态调整不确定性建模的方法。

Method: 1. 提出SG-LKF，根据ego车辆速度动态调整卡尔曼滤波中的不确定性模型。2. 设计MotionScaleNet（MSNet），一个解耦的token-mixing和channel-mixing MLP，用于预测SG-LKF的关键参数。3. 引入自监督轨迹一致性损失，结合语义和位置约束，增强帧间关联和轨迹连续性。

Result: 1. 在KITTI 2D MOT上以79.59%的HOTA排名所有视觉方法第一。2. 在KITTI 3D MOT上达到82.03%的HOTA。3. 在nuScenes 3D MOT上超过SimpleTrack 2.2%的AMOTA。

Conclusion: SG-LKF通过动态适应ego速度变化，显著提高了MOT在动态场景中的性能。所提方法在多个基准测试中取得领先，证明了考虑ego速度对MOT的重要性。

Abstract: Multi-object tracking (MOT) enables autonomous vehicles to continuously
perceive dynamic objects, supplying essential temporal cues for prediction,
behavior understanding, and safe planning. However, conventional
tracking-by-detection methods typically rely on static coordinate
transformations based on ego-vehicle poses, disregarding ego-vehicle
speed-induced variations in observation noise and reference frame changes,
which degrades tracking stability and accuracy in dynamic, high-speed
scenarios. In this paper, we investigate the critical role of ego-vehicle speed
in MOT and propose a Speed-Guided Learnable Kalman Filter (SG-LKF) that
dynamically adapts uncertainty modeling to ego-vehicle speed, significantly
improving stability and accuracy in highly dynamic scenarios. Central to SG-LKF
is MotionScaleNet (MSNet), a decoupled token-mixing and channel-mixing MLP that
adaptively predicts key parameters of SG-LKF. To enhance inter-frame
association and trajectory continuity, we introduce a self-supervised
trajectory consistency loss jointly optimized with semantic and positional
constraints. Extensive experiments show that SG-LKF ranks first among all
vision-based methods on KITTI 2D MOT with 79.59% HOTA, delivers strong results
on KITTI 3D MOT with 82.03% HOTA, and outperforms SimpleTrack by 2.2% AMOTA on
nuScenes 3D MOT.

</details>


### [32] [CoST: Efficient Collaborative Perception From Unified Spatiotemporal Perspective](https://arxiv.org/abs/2508.00359)
*Zongheng Tang,Yi Liu,Yifan Sun,Yulu Gao,Jinyu Chen,Runsheng Xu,Si Liu*

Main category: cs.CV

TL;DR: 本文提出了一种高效的协同感知方法CoST，通过将多智能体（空间）和多时间（时间）的观测同时聚合到统一的时空空间中，实现了高效的特征传输和优越的特征融合，从而在效率和准确性上均获得提升。该方法与大多数现有方法兼容，能提高准确性同时减少传输带宽。


<details>
  <summary>Details</summary>
Motivation: 现有的协同感知方法通常将多智能体融合和多时间融合分为两个先后步骤，这种分离可能导致特征传输效率低和特征融合效果欠佳，尤其在目标被遮挡或感知范围小的情况下。本文旨在解决这些问题，通过统一时空空间来提高协同感知的效果和效率。

Method: 提出协同感知时空变换器（Collaborative perception with Spatio-temporal Transformer, CoST）。核心思想是同时聚合不同智能体（空间）和不同时间（时间）的观测到一个统一的时空空间。具体包括：1）构建统一时空空间使得每个静态对象在时空空间中仅需传输一次特征（避免重复传输）；2）将多智能体多时间融合合并为统一的时空聚合，以获得更全面的视角。

Result: CoST在效率和准确性上均有提升。效率方面，通过避免重复传输减少了带宽消耗；准确性方面，统一的时空聚合增强了在遮挡和感知范围小等挑战性场景下的感知性能。此外，CoST与大多数现有方法兼容，可提升这些方法的准确率同时降低传输带宽。

Conclusion: CoST通过统一时空空间同步处理空间和时间融合，解决了现有分离方法在效率（重复传输）和性能（不全面融合）上的问题。该方法具有广泛的兼容性，在协同感知任务中实现了效率和准确性的双重提升。

Abstract: Collaborative perception shares information among different agents and helps
solving problems that individual agents may face, e.g., occlusions and small
sensing range. Prior methods usually separate the multi-agent fusion and
multi-time fusion into two consecutive steps. In contrast, this paper proposes
an efficient collaborative perception that aggregates the observations from
different agents (space) and different times into a unified spatio-temporal
space simultanesouly. The unified spatio-temporal space brings two benefits,
i.e., efficient feature transmission and superior feature fusion. 1) Efficient
feature transmission: each static object yields a single observation in the
spatial temporal space, and thus only requires transmission only once (whereas
prior methods re-transmit all the object features multiple times). 2) superior
feature fusion: merging the multi-agent and multi-time fusion into a unified
spatial-temporal aggregation enables a more holistic perspective, thereby
enhancing perception performance in challenging scenarios. Consequently, our
Collaborative perception with Spatio-temporal Transformer (CoST) gains
improvement in both efficiency and accuracy. Notably, CoST is not tied to any
specific method and is compatible with a majority of previous methods,
enhancing their accuracy while reducing the transmission bandwidth.

</details>


### [33] [Honey Classification using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2508.00361)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.CV

TL;DR: 本文提出了一种基于机器学习的蜂蜜植物来源自动分类方法。该方法包括数据集准备、特征提取和分类三个主要步骤。实验结果表明，该方法在标准蜂蜜高光谱影像数据集上达到了当前最佳水平，分别实现了95.13%的影像分类精度和92.80%的实例分类精度。


<details>
  <summary>Details</summary>
Motivation: 为了提高蜂蜜植物来源分类的自动化程度和准确率，解决传统方法难以处理高维度数据的问题，本文旨在开发一种能够高效利用高光谱数据的机器学习模型。

Method: 1.数据集准备：使用类别转换方法最大化类间可分离性。2.特征提取：应用线性判别分析（LDA）技术提取有用特征并减少维度数量。3.分类：使用支持向量机（SVM）和K最近邻（KNN）模型对提取的特征进行分类。所有方法在一个标准蜂蜜高光谱影像（HSI）数据集上进行评估。

Result: 所提出的方法在高光谱影像分类中达到95.13%的最高准确率，在实例分类中达到92.80%的准确率。实验结果证明其性能优于现有方法。

Conclusion: 本文展示的机器学习框架——尤其结合了LDA的特征降维能力和SVM/KNN的分类能力,在蜂蜜植物来源自动分类任务上具有显著优势。该系统的成功应用为食品工业中的蜂蜜来源真实性和品质控制提供了高效的工具。

Abstract: In this paper, we propose a machine learning-based method for automatically
classifying honey botanical origins. Dataset preparation, feature extraction,
and classification are the three main steps of the proposed method. We use a
class transformation method in the dataset preparation phase to maximize the
separability across classes. The feature extraction phase employs the Linear
Discriminant Analysis (LDA) technique for extracting relevant features and
reducing the number of dimensions. In the classification phase, we use Support
Vector Machines (SVM) and K-Nearest Neighbors (KNN) models to classify the
extracted features of honey samples into their botanical origins. We evaluate
our system using a standard honey hyperspectral imaging (HSI) dataset.
Experimental findings demonstrate that the proposed system produces
state-of-the-art results on this dataset, achieving the highest classification
accuracy of 95.13% for hyperspectral image-based classification and 92.80% for
hyperspectral instance-based classification.

</details>


### [34] [SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies](https://arxiv.org/abs/2508.00366)
*Liang Han,Xu Zhang,Haichuan Song,Kanle Shi,Yu-Shen Liu,Zhizhong Han*

Main category: cs.CV

TL;DR: 提出了SparseRecon方法，通过基于体渲染的特征一致性和不确定性引导的深度约束，解决稀疏视角表面重建中泛化性和几何线索有限的问题


<details>
  <summary>Details</summary>
Motivation: 当前基于泛化（generalization-based）的方法在训练时未见过的视角上泛化能力差，而基于过拟合（overfitting-based）的方法又受限于有限的几何线索导致重建质量不佳

Method: 1. 引入跨视角的特征一致性损失（feature consistency loss）约束神经隐式场，解决视角信息不足带来的歧义，确保重建结果的完整性和平滑性；
2. 采用不确定性引导的深度约束（uncertainty-guided depth constraint）补充特征一致性损失在遮挡和特征不明显区域的不足，恢复几何细节提升重建质量

Result: 实验结果表明，该方法超越了现有最先进方法，能够利用稀疏视角输入（尤其在视角重叠小的场景下）生成高质量的几何重建

Conclusion: SparseRecon通过结合特征一致性损失和不确定性引导的深度约束，有效解决了稀疏视角重建问题，在视角重叠小的场景下仍能保持高质量输出

Abstract: Surface reconstruction from sparse views aims to reconstruct a 3D shape or
scene from few RGB images. The latest methods are either generalization-based
or overfitting-based. However, the generalization-based methods do not
generalize well on views that were unseen during training, while the
reconstruction quality of overfitting-based methods is still limited by the
limited geometry clues. To address this issue, we propose SparseRecon, a novel
neural implicit reconstruction method for sparse views with volume
rendering-based feature consistency and uncertainty-guided depth constraint.
Firstly, we introduce a feature consistency loss across views to constrain the
neural implicit field. This design alleviates the ambiguity caused by
insufficient consistency information of views and ensures completeness and
smoothness in the reconstruction results. Secondly, we employ an
uncertainty-guided depth constraint to back up the feature consistency loss in
areas with occlusion and insignificant features, which recovers geometry
details for better reconstruction quality. Experimental results demonstrate
that our method outperforms the state-of-the-art methods, which can produce
high-quality geometry with sparse-view input, especially in the scenarios with
small overlapping views. Project page: https://hanl2010.github.io/SparseRecon/.

</details>


### [35] [Representation Shift: Unifying Token Compression with FlashAttention](https://arxiv.org/abs/2508.00367)
*Joonmyung Choi,Sanghyeok Lee,Byungoh Ko,Eunseo Kim,Jihyung Kil,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 提出了一种名为Representation Shift的训练无关、模型无关的指标，用于衡量每个token表示的变更程度，从而实现与FlashAttention兼容的token压缩，无需注意力图或重新训练。该方法适用于Transformers、CNNs和状态空间模型，在视频-文本检索和视频问答任务中分别带来了高达5.5%和4.4%的显著加速。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂度的增加，Transformer模型越来越大，处理的token数量也越来越多，导致自注意力的计算成本呈二次方增长，GPU内存访问开销增大。现有的token压缩技术需要依赖注意力图来确定token重要性，但FlashAttention等融合注意力内核通过避免注意力图的构建来减少内存开销，两者不兼容。因此，需要一种无需注意力图或重新训练的方法，实现与FlashAttention兼容的token压缩。

Method: 提出Representation Shift指标，该指标在训练过程中免费计算，且与模型架构无关。它衡量每个token的输入和输出表示之间的变化程度，以反映token的重要性（变化越大越重要）。在需要压缩token时，选择Representation Shift值最小的token进行丢弃。该方法可直接应用于FlashAttention中，无需重构注意力图，因此兼容融合注意力内核。此外，该方法还推广到CNNs和状态空间模型（计算每个位置输入输出特征的变化）。压缩过程在推理阶段动态进行，无需调整模型。

Result: 在视频-文本检索和视频问答任务上的实验表明，使用Representation Shift选择要移除的token可以实现有效压缩，同时保持模型性能。与FlashAttention结合使用时，实现了显著的速度提升：在视频-文本检索上最高提速5.5%，在视频问答上最高提速4.4%。该方法适用于Transformer、CNN和状态空间模型，证明了其模型无关性。

Conclusion: Representation Shift提供了一种简单高效的训练无关方法，用于在融合注意力优化框架（如FlashAttention）下实现token压缩。它无需计算注意力图或重新训练模型，可广泛适用于多种类型的模型，并在实际任务中提升了推理速度。未来的研究可探索将该方法与其他压缩技术结合或扩展到更多模态。

Abstract: Transformers have demonstrated remarkable success across vision, language,
and video. Yet, increasing task complexity has led to larger models and more
tokens, raising the quadratic cost of self-attention and the overhead of GPU
memory access. To reduce the computation cost of self-attention, prior work has
proposed token compression techniques that drop redundant or less informative
tokens. Meanwhile, fused attention kernels such as FlashAttention have been
developed to alleviate memory overhead by avoiding attention map construction
and its associated I/O to HBM. This, however, makes it incompatible with most
training-free token compression methods, which rely on attention maps to
determine token importance. Here, we propose Representation Shift, a
training-free, model-agnostic metric that measures the degree of change in each
token's representation. This seamlessly integrates token compression with
FlashAttention, without attention maps or retraining. Our method further
generalizes beyond Transformers to CNNs and state space models. Extensive
experiments show that Representation Shift enables effective token compression
compatible with FlashAttention, yielding significant speedups of up to 5.5% and
4.4% in video-text retrieval and video QA, respectively. Code is available at
https://github.com/mlvlab/Representation-Shift.

</details>


### [36] [Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models](https://arxiv.org/abs/2508.00374)
*Yuji Sato,Yasunori Ishii,Takayoshi Yamashita*

Main category: cs.CV

TL;DR: 提出BiAnt方法，结合前向和后向预测，利用大语言模型改进视频长期动作预测，解决了现有方法无法捕捉语义子动作的问题，并在Ego4D数据集上验证了其性能优势。


<details>
  <summary>Details</summary>
Motivation: 现有基于编码器-解码器的视频长期动作预测方法因单向性而性能有限，难以捕捉场景中语义不同的子动作，因此需设计一种新方法克服这些限制。

Method: BiAnt方法结合前向预测和后向预测模块，利用大语言模型增强特征捕捉能力。具体流程：1) 提取历史动作特征；2) 前向预测分支学习时序变化；3) 后向预测分支捕捉逆向依赖；4) 融合模块整合双向信息；5) 输出未来动作序列概率分布。

Result: 在Ego4D数据集上的实验表明，BiAnt在编辑距离指标上优于基线方法，有效提升了长期动作预测的准确性。

Conclusion: 通过双向预测机制结合大语言模型，BiAnt成功克服现有方法的局限性，显著提升了对复杂动作序列的建模能力，为自动驾驶、机器人等领域提供了更可靠的长期行为预判方案。

Abstract: Video-based long-term action anticipation is crucial for early risk detection
in areas such as automated driving and robotics. Conventional approaches
extract features from past actions using encoders and predict future events
with decoders, which limits performance due to their unidirectional nature.
These methods struggle to capture semantically distinct sub-actions within a
scene. The proposed method, BiAnt, addresses this limitation by combining
forward prediction with backward prediction using a large language model.
Experimental results on Ego4D demonstrate that BiAnt improves performance in
terms of edit distance compared to baseline methods.

</details>


### [37] [Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis](https://arxiv.org/abs/2508.00381)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 本文介绍了一个名为Adapt-WeldNet的自适应焊接缺陷检测框架，用于优化油气管道的焊接缺陷检测。同时，提出了缺陷检测可解释性分析（DDIA）框架，结合可解释人工智能（XAI）技术和专家验证，提高系统的可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 传统的无损检测（NDT）方法难以检测到细微或内部缺陷；现有的基于神经网络的缺陷分类方法通常依赖任意选择的预训练架构，且缺乏可解释性，存在安全隐患。因此，需要提高缺陷检测的准确性和可解释性，以满足工业安全要求。

Method: 1. Adapt-WeldNet框架：系统地评估各种预训练架构、迁移学习策略和自适应优化器，找到最佳模型和超参数进行优化。2. DDIA框架：使用Grad-CAM、LIME等XAI技术进行可解释性分析，并引入ASNT NDE Level II专业认证人员进行领域特定评估；采用Human-in-the-Loop方法和可信AI原则，确保系统可靠性、公平性和问责制。

Result: Adapt-WeldNet优化了检测性能；DDIA通过专家验证提高了系统的可解释性和受信任度，增强自动化决策的可信度。

Conclusion: 通过提高焊接缺陷检测系统的性能和可解释性，本研究提升了检测系统在离岸和海洋环境中的信任度、安全性和可靠性，支持关键基础设施的安全运行。

Abstract: Weld defect detection is crucial for ensuring the safety and reliability of
piping systems in the oil and gas industry, especially in challenging marine
and offshore environments. Traditional non-destructive testing (NDT) methods
often fail to detect subtle or internal defects, leading to potential failures
and costly downtime. Furthermore, existing neural network-based approaches for
defect classification frequently rely on arbitrarily selected pretrained
architectures and lack interpretability, raising safety concerns for
deployment. To address these challenges, this paper introduces
``Adapt-WeldNet", an adaptive framework for welding defect detection that
systematically evaluates various pre-trained architectures, transfer learning
strategies, and adaptive optimizers to identify the best-performing model and
hyperparameters, optimizing defect detection and providing actionable insights.
Additionally, a novel Defect Detection Interpretability Analysis (DDIA)
framework is proposed to enhance system transparency. DDIA employs Explainable
AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific
evaluations validated by certified ASNT NDE Level II professionals.
Incorporating a Human-in-the-Loop (HITL) approach and aligning with the
principles of Trustworthy AI, DDIA ensures the reliability, fairness, and
accountability of the defect detection system, fostering confidence in
automated decisions through expert validation. By improving both performance
and interpretability, this work enhances trust, safety, and reliability in
welding defect detection systems, supporting critical operations in offshore
and marine environments.

</details>


### [38] [$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models](https://arxiv.org/abs/2508.00383)
*Won June Cho,Hongjun Yoon,Daeky Jeong,Hyeongyeol Lim,Yosep Chong*

Main category: cs.CV

TL;DR: 本研究引入了MV_{Hybrid}，一种结合状态空间模型（SSMs）和Vision Transformer（ViT）的混合骨干架构，用于从常规组织病理学图像预测空间基因表达。在leave-one-study-out评估中，该架构在基因表达预测上比最佳ViT模型提高了57%的相关性，同时在下游任务（如分类、图像块检索和生存预测）中表现相当或更好。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学能揭示组织内的基因表达模式，有助于精准肿瘤学应用（如治疗反应预测），但其高成本和技术复杂性限制了临床应用。从常规组织病理学图像预测空间基因表达是一个实际替代方案，然而当前基于ViT骨干的视觉基础模型（VFMs）表现低于临床标准。由于VFMs已在数百万张多样化的全切片图像上进行预训练，我们认为ViT之外的架构创新可能更好地捕捉与分子表型相关的低频、细微形态模式。

Method: 1. 假设：状态空间模型（SSMs）初始化负实特征值时表现出强低频偏置，可能更适合病理学中的形态-分子关系建模。
2. 提出MV_{Hybrid}架构：结合SSMs和ViT的混合主干网络。
3. 对比实验：在相同结直肠癌数据集上，使用DINOv2自监督方法预训练五种不同骨干架构（包括ViT和MV_{Hybrid}）。
4. 评估：在相同生物标志物数据集上使用随机划分和leave-one-study-out（LOSO）两种设置评估所有模型，主要指标为基因表达预测相关性。
5. 下游任务验证：在分类、图像块检索和生存预测任务上比较性能。

Result: 1. LOSO评估中，MV_{Hybrid}的基因表达预测相关性比最佳ViT高57%。
2. LOSO与随机划分相比，MV_{Hybrid}的性能下降比ViT小43%（稳健性更强）。
3. 下游任务表现：MV_{Hybrid}在分类、图像块检索和生存预测任务中与ViT相当或更好。

Conclusion: MV_{Hybrid}作为病理学视觉基础模型的新骨干架构，在空间基因表达预测任务上显著优于ViT（尤其在更现实的LOSO设置中），同时保持了下游任务性能，有潜力成为下一代病理学基础模型架构。其核心创新在于利用SSMs的低频偏置特性增强对病理图像中细微形态特征的建模能力。

Abstract: Spatial transcriptomics reveals gene expression patterns within tissue
context, enabling precision oncology applications such as treatment response
prediction, but its high cost and technical complexity limit clinical adoption.
Predicting spatial gene expression (biomarkers) from routine histopathology
images offers a practical alternative, yet current vision foundation models
(VFMs) in pathology based on Vision Transformer (ViT) backbones perform below
clinical standards. Given that VFMs are already trained on millions of diverse
whole slide images, we hypothesize that architectural innovations beyond ViTs
may better capture the low-frequency, subtle morphological patterns correlating
with molecular phenotypes. By demonstrating that state space models initialized
with negative real eigenvalues exhibit strong low-frequency bias, we introduce
$MV_{Hybrid}$, a hybrid backbone architecture combining state space models
(SSMs) with ViT. We compare five other different backbone architectures for
pathology VFMs, all pretrained on identical colorectal cancer datasets using
the DINOv2 self-supervised learning method. We evaluate all pretrained models
using both random split and leave-one-study-out (LOSO) settings of the same
biomarker dataset. In LOSO evaluation, $MV_{Hybrid}$ achieves 57% higher
correlation than the best-performing ViT and shows 43% smaller performance
degradation compared to random split in gene expression prediction,
demonstrating superior performance and robustness, respectively. Furthermore,
$MV_{Hybrid}$ shows equal or better downstream performance in classification,
patch retrieval, and survival prediction tasks compared to that of ViT, showing
its promise as a next-generation pathology VFM backbone. Our code is publicly
available at: https://github.com/deepnoid-ai/MVHybrid.

</details>


### [39] [Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition](https://arxiv.org/abs/2508.00391)
*Guanjie Huang,Danny H. K. Tsang,Shan Yang,Guangzhi Lei,Li Liu*

Main category: cs.CV

TL;DR: Cued-Agent是首个用于自动线索语识别（ACSR）的协作多智能体系统，通过四个专门子智能体处理手部动作和唇部特征，在有限数据下实现高效多模态融合，显著提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法受限数据量难以有效融合手部和唇部运动的时间异步性，导致性能不佳。多智能体系统在处理复杂任务时表现优异，尤其是在数据有限的情况下，因此设计一个多智能体协作系统来提升ACSR性能。

Method: 1. 使用基于多模态大语言模型的手部识别子智能体，采用关键帧筛选和线索语专家提示策略解码手部动作；2. 使用基于预训练Transformer的唇部识别子智能体提取唇部特征；3. 通过无训练的手部提示解码子智能体，在推理时动态融合手部提示与唇部特征；4. 引入自校正音素-词语子智能体，通过语义细化实现从音素序列到自然语句的端到端转换。

Result: 在十四名受试者的混合数据集上，Cued-Agent在正常和听力障碍场景下均优于现有最优方法，实现了出色的识别性能。

Conclusion: 提出的Cued-Agent系统成功解决了现有ACSR在多模态融合上的瓶颈问题，通过协同多智能体框架和端到端转换机制，为线索语识别任务提供了新思路，并在扩展数据集上验证了其有效性。

Abstract: Cued Speech (CS) is a visual communication system that combines lip-reading
with hand coding to facilitate communication for individuals with hearing
impairments. Automatic CS Recognition (ACSR) aims to convert CS hand gestures
and lip movements into text via AI-driven methods. Traditionally, the temporal
asynchrony between hand and lip movements requires the design of complex
modules to facilitate effective multimodal fusion. However, constrained by
limited data availability, current methods demonstrate insufficient capacity
for adequately training these fusion mechanisms, resulting in suboptimal
performance. Recently, multi-agent systems have shown promising capabilities in
handling complex tasks with limited data availability. To this end, we propose
the first collaborative multi-agent system for ACSR, named Cued-Agent. It
integrates four specialized sub-agents: a Multimodal Large Language Model-based
Hand Recognition agent that employs keyframe screening and CS expert prompt
strategies to decode hand movements, a pretrained Transformer-based Lip
Recognition agent that extracts lip features from the input video, a Hand
Prompt Decoding agent that dynamically integrates hand prompts with lip
features during inference in a training-free manner, and a Self-Correction
Phoneme-to-Word agent that enables post-process and end-to-end conversion from
phoneme sequences to natural language sentences for the first time through
semantic refinement. To support this study, we expand the existing Mandarin CS
dataset by collecting data from eight hearing-impaired cuers, establishing a
mixed dataset of fourteen subjects. Extensive experiments demonstrate that our
Cued-Agent performs superbly in both normal and hearing-impaired scenarios
compared with state-of-the-art methods. The implementation is available at
https://github.com/DennisHgj/Cued-Agent.

</details>


### [40] [Decouple before Align: Visual Disentanglement Enhances Prompt Tuning](https://arxiv.org/abs/2508.00395)
*Fei Zhang,Tianfei Zhou,Jiangchao Yao,Ya Zhang,Ivor W. Tsang,Yanfeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为DAPT的新提示调整框架，通过解耦视觉模态为前景和背景表示，并分别与原始文本和手工背景类别对齐，解决了视觉语言提示调整中的信息不对称问题。此外，引入视觉拉-推正则化来优化前景背景注意力，提高了模型在少样本学习、泛化和数据高效学习中的性能。


<details>
  <summary>Details</summary>
Motivation: 本文的动机源于发现提示调整中存在未被充分关注的信息不对称问题：视觉模态通常比面向对象的文本模态传递更多上下文信息，导致模态对齐时的注意力偏移（仅关注上下文区域）。这影响了模型对重点对象区域的注意力分配，因此需要一种机制来对称地加强模态对齐并优化视觉关注。

Method: 方法分为两个核心部分：1）解耦与对齐：首先利用粗粒度到细粒度的视觉分割线索，将视觉模态显式解耦为前景和背景表示；然后将解耦后的前景表示与原始前景（对象）文本对齐，背景表示与一组手工设计的背景类别文本对齐，从而实现模态的对称对齐。2）视觉拉-推正则化：设计了一种前景-背景模式的注意力正则化机制——将原视觉表征拉向（强化）前景对象特征，同时推离（弱化）背景特征，以引导模型在目标对象区域上无偏关注。整个框架为无需模型结构修改的提示调整方法。

Result: DAPT在多个任务中取得显著效果提升：1）少样本学习：在主流VL模型（如CLIP）上使用1、2、4、8、16个样本进行提示调整时，平均准确率提升显著；2）基类到新类的泛化：在基类训练后测试新类的分类任务中，H（调和平均）指标超过现有最佳方法；3）数据高效学习：在数据受限场景下（如仅使用部分训练数据），DAPT也展示了更强的鲁棒性和性能。实验覆盖了多个标准视觉语言基准（如ImageNet类数据集），均报告了优于现有提示调整方法的结果。

Conclusion: 通过解耦视觉模态为前景/背景并分别对齐文本，DAPT有效解决了提示调整中的视觉-文本信息不对称问题。其设计的解耦对齐机制和拉-推正则化策略，能够引导模型无偏关注目标对象区域。广泛的实验证明该框架在少样本学习、泛化及数据效率上具有优越性，且无需修改模型结构。代码已公开。

Abstract: Prompt tuning (PT), as an emerging resource-efficient fine-tuning paradigm,
has showcased remarkable effectiveness in improving the task-specific
transferability of vision-language models. This paper delves into a previously
overlooked information asymmetry issue in PT, where the visual modality mostly
conveys more context than the object-oriented textual modality.
Correspondingly, coarsely aligning these two modalities could result in the
biased attention, driving the model to merely focus on the context area. To
address this, we propose DAPT, an effective PT framework based on an intuitive
decouple-before-align concept. First, we propose to explicitly decouple the
visual modality into the foreground and background representation via
exploiting coarse-and-fine visual segmenting cues, and then both of these
decoupled patterns are aligned with the original foreground texts and the
hand-crafted background classes, thereby symmetrically strengthening the modal
alignment. To further enhance the visual concentration, we propose a visual
pull-push regularization tailored for the foreground-background patterns,
directing the original visual representation towards unbiased attention on the
region-of-interest object. We demonstrate the power of architecture-free DAPT
through few-shot learning, base-to-novel generalization, and data-efficient
learning, all of which yield superior performance across prevailing benchmarks.
Our code will be released at https://github.com/Ferenas/DAPT.

</details>


### [41] [Video Forgery Detection with Optical Flow Residuals and Spatial-Temporal Consistency](https://arxiv.org/abs/2508.00397)
*Xi Xue,Kunio Suzuki,Nabarun Goswami,Takuya Shintate*

Main category: cs.CV

TL;DR: 提出了一种利用RGB表观特征和光流残差的空间-时间一致性进行视频伪造检测的双分支框架，能有效捕获AI生成视频中的时间不一致性，并在多样生成模型中展示强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成的视频越来越逼真，传统的伪造检测方法难以捕捉时间上的细微不一致。特别是高视觉保真度和连贯运动的AI生成视频，现有方法常在这些方面表现不足。因此需要一种新方法来检测这些视频中的伪造痕迹。

Method: 采用双分支架构：一个分支处理RGB帧以检测表观层面的伪造痕迹；另一分支分析光流残差以揭示因时间合成不完美导致的运动异常。通过整合这两类特征，模型有效捕捉空间和时间上的伪造线索。

Result: 在文本到视频和图像到视频任务上对10种不同生成模型进行测试表明，该方法鲁棒且具有强泛化能力。

Conclusion: 结合RGB表观特征和光流残差的双分支方法能更有效地检测高保真AI生成视频中的伪造痕迹，尤其擅长捕捉时间不一致性，大幅提升现有检测技术水平。

Abstract: The rapid advancement of diffusion-based video generation models has led to
increasingly realistic synthetic content, presenting new challenges for video
forgery detection. Existing methods often struggle to capture fine-grained
temporal inconsistencies, particularly in AI-generated videos with high visual
fidelity and coherent motion. In this work, we propose a detection framework
that leverages spatial-temporal consistency by combining RGB appearance
features with optical flow residuals. The model adopts a dual-branch
architecture, where one branch analyzes RGB frames to detect appearance-level
artifacts, while the other processes flow residuals to reveal subtle motion
anomalies caused by imperfect temporal synthesis. By integrating these
complementary features, the proposed method effectively detects a wide range of
forged videos. Extensive experiments on text-to-video and image-to-video tasks
across ten diverse generative models demonstrate the robustness and strong
generalization ability of the proposed approach.

</details>


### [42] [iSafetyBench: A video-language benchmark for safety in industrial environment](https://arxiv.org/abs/2508.00399)
*Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: iSafetyBench：专门为工业安全视频理解设计的新型基准测试，用于评估视觉语言模型在正常和危险场景下的性能。包含1,100个工业实景视频片段，评估发现现有模型在识别危险活动及多标签场景中表现欠佳。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在工业高危领域的能力尚未充分探索，特别是在识别日常操作和安全关键异常方面存在空白。因此，需要开发专门评估工业环境安全性的基准工具。

Method: 1. 构建iSafetyBench数据集：共1,100个工业实景视频片段，覆盖98个常规操作类和67个危险动作类的多标签注释。2. 设计多选问题形式：支持单标签/多标签评估场景。3. 零样本测试：评估8个最先进视频语言模型在其上的表现。

Result: 1. 现有模型在工业安全基准上表现不佳（原有视频基准表现强）。2. 危险活动识别性能显著下滑。3. 多标签场景成为主要挑战点。

Conclusion: 工业安全视频理解存在重大性能差距，呼吁开发更鲁棒的安全感知多模态模型。iSafetyBench为首创评估工具并提供公开数据集。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
generalization across diverse video understanding tasks under zero-shot
settings. However, their capabilities in high-stakes industrial domains-where
recognizing both routine operations and safety-critical anomalies is
essential-remain largely underexplored. To address this gap, we introduce
iSafetyBench, a new video-language benchmark specifically designed to evaluate
model performance in industrial environments across both normal and hazardous
scenarios. iSafetyBench comprises 1,100 video clips sourced from real-world
industrial settings, annotated with open-vocabulary, multi-label action tags
spanning 98 routine and 67 hazardous action categories. Each clip is paired
with multiple-choice questions for both single-label and multi-label
evaluation, enabling fine-grained assessment of VLMs in both standard and
safety-critical contexts. We evaluate eight state-of-the-art video-language
models under zero-shot conditions. Despite their strong performance on existing
video benchmarks, these models struggle with iSafetyBench-particularly in
recognizing hazardous activities and in multi-label scenarios. Our results
reveal significant performance gaps, underscoring the need for more robust,
safety-aware multimodal models for industrial applications. iSafetyBench
provides a first-of-its-kind testbed to drive progress in this direction. The
dataset is available at: https://github.com/raiyaan-abdullah/iSafety-Bench.

</details>


### [43] [Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents](https://arxiv.org/abs/2508.00400)
*Janika Deborah Gajo,Gerarld Paul Merales,Jerome Escarcha,Brenden Ashley Molina,Gian Nartea,Emmanuel G. Maminta,Juan Carlos Roldan,Rowel O. Atienza*

Main category: cs.CV

TL;DR: 介绍了一个高保真、真实的3D零售商店模拟环境Sari Sandbox，用于在购物任务中对具身智能体进行基准测试，并与人类表现进行对比。该环境包含250多种交互式杂货商品，提供三种店铺配置，并支持通过API控制。同时支持VR和VLM驱动的具身智能体。另外提出了一个带标注的人类行为数据集SariBench。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏针对零售领域的专门模拟环境用于训练具身智能体，因此研发了高真实感的Sari Sandbox来填补这一空白。

Method: 开发了包含三种配置的虚拟3D商店环境，拥有超过250个可交互的杂货物品，提供API接口；支持VR设备采集人类行为（形成带标注的SariBench数据集）以及基于视觉语言模型（VLM）的具身智能体；智能体可在环境中执行导航、查看商品、操作物品等任务。

Result: 在Sari Sandbox环境中实现了具身智能体的基本能力，并采集了人类行为数据集作为基线。进行了基准测试和性能分析，结果表明当前环境为智能体提供了接近现实的零售环境。

Conclusion: Sari Sandbox为零售领域的具身智能研究提供了一个良好的模拟环境和基准测试平台。未来可进一步提升环境的真实感和可扩展性。

Abstract: We present Sari Sandbox, a high-fidelity, photorealistic 3D retail store
simulation for benchmarking embodied agents against human performance in
shopping tasks. Addressing a gap in retail-specific sim environments for
embodied agent training, Sari Sandbox features over 250 interactive grocery
items across three store configurations, controlled via an API. It supports
both virtual reality (VR) for human interaction and a vision language model
(VLM)-powered embodied agent. We also introduce SariBench, a dataset of
annotated human demonstrations across varied task difficulties. Our sandbox
enables embodied agents to navigate, inspect, and manipulate retail items,
providing baselines against human performance. We conclude with benchmarks,
performance analysis, and recommendations for enhancing realism and
scalability. The source code can be accessed via
https://github.com/upeee/sari-sandbox-env.

</details>


### [44] [PMR: Physical Model-Driven Multi-Stage Restoration of Turbulent Dynamic Videos](https://arxiv.org/abs/2508.00406)
*Tao Wu,Jingyuan Ye,Ying Fu*

Main category: cs.CV

TL;DR: 该论文提出了一种动态效率指数（DEI）来量化不同湍流条件下的视频动态强度，以及一个物理模型驱动的多阶段视频恢复框架（PMR），该框架通过三个阶段处理由大气湍流引起的几何失真和模糊问题，并在各种情况下表现出优秀的恢复效果和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决长距离动态场景视频中大气湍流导致的几何失真和模糊问题，现有方法在处理强湍流和复杂动态条件下的边缘细节恢复和混合失真消除方面存在不足。

Method: 1. 引入动态效率指数（DEI）来量化视频动态强度，并结合湍流强度、光流和动态区域比例；构建高动态湍流训练数据集。2. 提出物理模型驱动的多阶段视频恢复框架（PMR），包括三个阶段：去倾斜（几何稳定化）、运动分割增强（动态区域细化）和去模糊（质量恢复）。3. 采用轻量级主干网络和分阶段联合训练，确保效率和高质量恢复。

Result: 实验证明，该方法有效抑制了运动拖尾伪影，恢复了边缘细节，并表现出强大的泛化能力，特别是在高湍流和复杂动态的真实场景中。

Conclusion: 该方法在恢复由大气湍流引起的几何失真和模糊的视频中表现出色，特别是在强湍流和复杂动态条件下。通过提出DEI和PMR框架，解决了现有方法的局限性，并提供了高质量的重建结果。代码和数据集将公开。

Abstract: Geometric distortions and blurring caused by atmospheric turbulence degrade
the quality of long-range dynamic scene videos. Existing methods struggle with
restoring edge details and eliminating mixed distortions, especially under
conditions of strong turbulence and complex dynamics. To address these
challenges, we introduce a Dynamic Efficiency Index ($DEI$), which combines
turbulence intensity, optical flow, and proportions of dynamic regions to
accurately quantify video dynamic intensity under varying turbulence conditions
and provide a high-dynamic turbulence training dataset. Additionally, we
propose a Physical Model-Driven Multi-Stage Video Restoration ($PMR$) framework
that consists of three stages: \textbf{de-tilting} for geometric stabilization,
\textbf{motion segmentation enhancement} for dynamic region refinement, and
\textbf{de-blurring} for quality restoration. $PMR$ employs lightweight
backbones and stage-wise joint training to ensure both efficiency and high
restoration quality. Experimental results demonstrate that the proposed method
effectively suppresses motion trailing artifacts, restores edge details and
exhibits strong generalization capability, especially in real-world scenarios
characterized by high-turbulence and complex dynamics. We will make the code
and datasets openly available.

</details>


### [45] [Sortblock: Similarity-Aware Feature Reuse for Diffusion Model](https://arxiv.org/abs/2508.00412)
*Hanqi Chen,Xu Zhang,Xiaoliu Guan,Lielin Jiang,Guanzhong Wang,Zeyu Chen,Yi Liu*

Main category: cs.CV

TL;DR: Sortblock是一种免训练的推理加速框架，通过基于相邻时间步块特征的相似性动态缓存块特征，自适应确定重计算率，有选择地跳过冗余计算，同时保持生成质量，在多种任务和DiT架构上实现超过2倍推理加速且质量几乎无退化。


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers (DiTs)的序列去噪过程导致高推理延迟，限制了其在实际部署中的应用。现有免训练加速方法通常重复使用固定时间步或层的中间特征，忽视了跨去噪阶段和Transformer块的语义焦点演变问题。

Method: 提出Sortblock框架：1）通过排序残差演变自适应确定重计算比；2）基于相邻时间步的块特征相似性动态缓存块特征；3）引入轻量级线性预测机制减少跳块误差累积；4）选择性跳过冗余计算保留关键特征。

Result: 在多个任务和DiT架构上的实验证明：Sortblock实现超过2倍推理加速（2$\times$），同时仅产生微小质量退化（minimal degradation）。

Conclusion: Sortblock为扩散模型提供了一种通用、免训练的推理加速方案，有效平衡了速度与生成质量，解决了去噪过程中语义关注的动态性问题。

Abstract: Diffusion Transformers (DiTs) have demonstrated remarkable generative
capabilities, particularly benefiting from Transformer architectures that
enhance visual and artistic fidelity. However, their inherently sequential
denoising process results in high inference latency, limiting their deployment
in real-time scenarios. Existing training-free acceleration approaches
typically reuse intermediate features at fixed timesteps or layers, overlooking
the evolving semantic focus across denoising stages and Transformer blocks.To
address this, we propose Sortblock, a training-free inference acceleration
framework that dynamically caches block-wise features based on their similarity
across adjacent timesteps. By ranking the evolution of residuals, Sortblock
adaptively determines a recomputation ratio, selectively skipping redundant
computations while preserving generation quality. Furthermore, we incorporate a
lightweight linear prediction mechanism to reduce accumulated errors in skipped
blocks.Extensive experiments across various tasks and DiT architectures
demonstrate that Sortblock achieves over 2$\times$ inference speedup with
minimal degradation in output quality, offering an effective and generalizable
solution for accelerating diffusion-based generative models.

</details>


### [46] [DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space](https://arxiv.org/abs/2508.00413)
*Junyu Chen,Dongyun Zou,Wenkun He,Junsong Chen,Enze Xie,Song Han,Han Cai*

Main category: cs.CV

TL;DR: 提出了DC-AE 1.5，一种用于高分辨率扩散模型的新型深度压缩自动编码器。通过增加自动编码器的潜在通道数可以提高重建质量，但会导致扩散模型收敛缓慢，从而降低生成质量。为此，引入了两种关键技术：结构化潜在空间和增强扩散训练，以提高收敛速度并改善生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，增加自动编码器的潜在通道数虽然能提升重建质量，但会导致扩散模型收敛缓慢，从而降低生成质量。这限制了潜在扩散模型的质量上限，并阻碍了使用具有更高空间压缩比的自动编码器。

Method: 1. 结构化潜在空间：一种基于训练的方法，对潜在空间施加通道结构，前端潜在通道捕获对象结构，后端潜在通道捕获图像细节。2. 增强扩散训练：一种增强的扩散训练策略，通过在对象潜在通道上添加额外的扩散训练目标来加速收敛。

Result: DC-AE 1.5相比DC-AE具有更快的收敛速度和更好的扩散缩放效果。在ImageNet 512x512数据集上，DC-AE-1.5-f64c128在保持更快速度（4倍）的同时，比DC-AE-f32c32具有更好的图像生成质量。

Conclusion: 通过结构化潜在空间和增强扩散训练，DC-AE 1.5成功解决了增加潜在通道数导致的收敛问题，在提高重建质量的同时提升了生成质量，为使用更高空间压缩比的自动编码器提供了可能。

Abstract: We present DC-AE 1.5, a new family of deep compression autoencoders for
high-resolution diffusion models. Increasing the autoencoder's latent channel
number is a highly effective approach for improving its reconstruction quality.
However, it results in slow convergence for diffusion models, leading to poorer
generation quality despite better reconstruction quality. This issue limits the
quality upper bound of latent diffusion models and hinders the employment of
autoencoders with higher spatial compression ratios. We introduce two key
innovations to address this challenge: i) Structured Latent Space, a
training-based approach to impose a desired channel-wise structure on the
latent space with front latent channels capturing object structures and latter
latent channels capturing image details; ii) Augmented Diffusion Training, an
augmented diffusion training strategy with additional diffusion training
objectives on object latent channels to accelerate convergence. With these
techniques, DC-AE 1.5 delivers faster convergence and better diffusion scaling
results than DC-AE. On ImageNet 512x512, DC-AE-1.5-f64c128 delivers better
image generation quality than DC-AE-f32c32 while being 4x faster. Code:
https://github.com/dc-ai-projects/DC-Gen.

</details>


### [47] [IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator](https://arxiv.org/abs/2508.00418)
*Sangwoo Youn,Minji Lee,Nokap Tony Park,Yeonggyoo Jeon,Taeyoung Na*

Main category: cs.CV

TL;DR: 本文提出了一种新的视频外绘方法，通过改进判别器设计和损失函数，利用视频修复模型在对象流学习和重建方面的优势，有效解决了现有方法只能生成背景的问题，显著提升了外绘区域的视觉质量和全局连贯性。


<details>
  <summary>Details</summary>
Motivation: 视频外绘技术面临在扩展视频边界时保持内容一致性的挑战。现有方法主要关注背景生成，但在对象流学习和重建方面表现不足。尽管视频修复模型在这些方面具有优势，但直接应用或微调此类模型到外绘任务效果不佳，常导致结果模糊。

Method: 1. 通过实验发现现有方法的局限源于判别器未能有效评估扩展区域的感知质量； 2. 提出将对抗训练目标分为全局和局部两部分，并设计分层判别器同时满足这两个目标； 3. 开发结合判别器局部与全局特征的专用外绘损失函数； 4. 在该对抗损失函数上微调生成器，提升生成结果的视觉吸引力和全局连贯性。

Result: 所提方法在定量和定性评估上均优于当前最先进方法，能生成更清晰且全局一致的外绘结果。

Conclusion: 通过分层判别器设计和专门的外绘损失函数，成功解决了视频修复模型应用于外绘任务时的效果不佳问题，为视频外绘提供了更有效的解决方案。

Abstract: Video outpainting presents a unique challenge of extending the borders while
maintaining consistency with the given content. In this paper, we suggest the
use of video inpainting models that excel in object flow learning and
reconstruction in outpainting rather than solely generating the background as
in existing methods. However, directly applying or fine-tuning inpainting
models to outpainting has shown to be ineffective, often leading to blurry
results. Our extensive experiments on discriminator designs reveal that a
critical component missing in the outpainting fine-tuning process is a
discriminator capable of effectively assessing the perceptual quality of the
extended areas. To tackle this limitation, we differentiate the objectives of
adversarial training into global and local goals and introduce a hierarchical
discriminator that meets both objectives. Additionally, we develop a
specialized outpainting loss function that leverages both local and global
features of the discriminator. Fine-tuning on this adversarial loss function
enhances the generator's ability to produce both visually appealing and
globally coherent outpainted scenes. Our proposed method outperforms
state-of-the-art methods both quantitatively and qualitatively. Supplementary
materials including the demo video and the code are available in SigPort.

</details>


### [48] [UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via Dynamic Tree Scan and Hidden State Weaken](https://arxiv.org/abs/2508.00421)
*Runmin Cong,Zongji Yu,Hao Fang,Haoyan Sun,Sam Kwong*

Main category: cs.CV

TL;DR: 本文提出了首个基于Mamba的水下实例分割模型UIS-Mamba，通过设计动态树扫描（DTS）和隐藏状态弱化（HSW）两个模块来解决水下场景应用Mamba的挑战。实验表明该模型在两个数据集上达到先进性能。代码已开源。


<details>
  <summary>Details</summary>
Motivation: 水下实例分割任务对复杂水下场景检测至关重要。Mamba作为一种新型状态空间模型，具有线性复杂度和全局感受野，适合处理长序列特征的图像分割。然而，水下场景的特殊性（如色彩失真、实例边界模糊、复杂背景干扰）给Mamba的应用带来挑战：现有固定块扫描机制无法维持实例内部连续性；复杂背景的隐藏状态会抑制对实例对象的理解。

Method: 1. 提出UIS-Mamba模型。2. 设计动态树扫描（DTS）模块：通过允许块动态偏移和缩放，保持实例内部特征连续性，引导最小生成树并提供动态局部感受野。3. 设计隐藏状态弱化（HSW）模块：基于Ncut的机制抑制复杂背景干扰，将状态传播的信息流聚焦到实例本身。

Result: 在UIIS和USIS10K两个数据集上均达到最先进性能。同时保持较低的参数量和计算复杂度。

Conclusion: UIS-Mamba成功将Mamba迁移至水下任务，解决了水下场景的特定挑战。DTS和HSW模块有效提升了模型性能，证明了该方法在水下实例分割中的优越性。

Abstract: Underwater Instance Segmentation (UIS) tasks are crucial for underwater
complex scene detection. Mamba, as an emerging state space model with
inherently linear complexity and global receptive fields, is highly suitable
for processing image segmentation tasks with long sequence features. However,
due to the particularity of underwater scenes, there are many challenges in
applying Mamba to UIS. The existing fixed-patch scanning mechanism cannot
maintain the internal continuity of scanned instances in the presence of
severely underwater color distortion and blurred instance boundaries, and the
hidden state of the complex underwater background can also inhibit the
understanding of instance objects. In this work, we propose the first
Mamba-based underwater instance segmentation model UIS-Mamba, and design two
innovative modules, Dynamic Tree Scan (DTS) and Hidden State Weaken (HSW), to
migrate Mamba to the underwater task. DTS module maintains the continuity of
the internal features of the instance objects by allowing the patches to
dynamically offset and scale, thereby guiding the minimum spanning tree and
providing dynamic local receptive fields. HSW module suppresses the
interference of complex backgrounds and effectively focuses the information
flow of state propagation to the instances themselves through the Ncut-based
hidden state weakening mechanism. Experimental results show that UIS-Mamba
achieves state-of-the-art performance on both UIIS and USIS10K datasets, while
maintaining a low number of parameters and computational complexity. Code is
available at https://github.com/Maricalce/UIS-Mamba.

</details>


### [49] [Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting](https://arxiv.org/abs/2508.00427)
*Seunggeun Chi,Enna Sachdeva,Pin-Hao Huang,Kwonjoon Lee*

Main category: cs.CV

TL;DR: 提出了一种利用物理先验和多区域修复的扩散模型，用于人体-物体交互（HOI）场景中的amodal补全，显著提升动态场景下的补全准确性和真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如预训练扩散模型）在动态HOI场景中难以生成合理的amodal补全结果，因其缺乏对HOI的深入理解。需要结合物理先验与定制修复技术解决此问题。

Method: 1. 基于人体拓扑和接触信息的物理约束定义两个区域：主区域（遮挡物体部分最可能存在）和次区域（遮挡概率较低）。2. 在扩散模型中针对不同区域采用定制化的去噪策略进行多区域修复。

Result: 在HOI场景下显著优于现有方法，实现更接近人类认知的动态环境理解。即使无真实接触标注仍具鲁棒性，可推广至3D重建和新视角/姿态合成任务。

Conclusion: 通过将物理先验与多区域扩散模型结合，解决了动态HOI场景的amodal补全难题。该方法为提升复杂交互理解提供了新方向，并展示出广泛的应用潜力。

Abstract: Amodal completion, which is the process of inferring the full appearance of
objects despite partial occlusions, is crucial for understanding complex
human-object interactions (HOI) in computer vision and robotics. Existing
methods, such as those that use pre-trained diffusion models, often struggle to
generate plausible completions in dynamic scenarios because they have a limited
understanding of HOI. To solve this problem, we've developed a new approach
that uses physical prior knowledge along with a specialized multi-regional
inpainting technique designed for HOI. By incorporating physical constraints
from human topology and contact information, we define two distinct regions:
the primary region, where occluded object parts are most likely to be, and the
secondary region, where occlusions are less probable. Our multi-regional
inpainting method uses customized denoising strategies across these regions
within a diffusion model. This improves the accuracy and realism of the
generated completions in both their shape and visual detail. Our experimental
results show that our approach significantly outperforms existing methods in
HOI scenarios, moving machine perception closer to a more human-like
understanding of dynamic environments. We also show that our pipeline is robust
even without ground-truth contact annotations, which broadens its applicability
to tasks like 3D reconstruction and novel view/pose synthesis.

</details>


### [50] [TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation](https://arxiv.org/abs/2508.00442)
*Jiale Zhou,Wenhan Wang,Shikun Li,Xiaolei Qu,Xin Guo,Yizhong Liu,Wenzhong Tang,Xun Lin,Yefeng Zheng*

Main category: cs.CV

TL;DR: TopoTTA是一个针对管状结构分割（TSS）提出的测试时自适应框架，通过拓扑元差分卷积（TopoMDC）和拓扑硬样本生成（TopoHG）策略解决域转移问题，显著提升跨域分割性能。


<details>
  <summary>Details</summary>
Motivation: 尽管管状结构分割在血流动力学分析和路径导航中很重要，但域偏移（如拓扑结构变化和局部特征差异）会导致模型在未见目标域上性能下降，且现有方法对此缺乏针对性。

Method: TopoTTA分为两个阶段：1）使用TopoMDC增强拓扑表示而不改变预训练参数；2）通过TopoHG生成伪断裂区域的硬样本，并利用伪标签进行预测对齐以改善拓扑连续性。

Result: 在4个场景和10个数据集上的实验表明，TopoTTA平均clDice提升31.81%，可作为基于CNN的TSS模型的即插即用解决方案。

Conclusion: TopoTTA显著缓解了拓扑分布偏移问题，为TSS的域自适应提供了有效工具。

Abstract: Tubular structure segmentation (TSS) is important for various applications,
such as hemodynamic analysis and route navigation. Despite significant progress
in TSS, domain shifts remain a major challenge, leading to performance
degradation in unseen target domains. Unlike other segmentation tasks, TSS is
more sensitive to domain shifts, as changes in topological structures can
compromise segmentation integrity, and variations in local features
distinguishing foreground from background (e.g., texture and contrast) may
further disrupt topological continuity. To address these challenges, we propose
Topology-enhanced Test-Time Adaptation (TopoTTA), the first test-time
adaptation framework designed specifically for TSS. TopoTTA consists of two
stages: Stage 1 adapts models to cross-domain topological discrepancies using
the proposed Topological Meta Difference Convolutions (TopoMDCs), which enhance
topological representation without altering pre-trained parameters; Stage 2
improves topological continuity by a novel Topology Hard sample Generation
(TopoHG) strategy and prediction alignment on hard samples with pseudo-labels
in the generated pseudo-break regions. Extensive experiments across four
scenarios and ten datasets demonstrate TopoTTA's effectiveness in handling
topological distribution shifts, achieving an average improvement of 31.81% in
clDice. TopoTTA also serves as a plug-and-play TTA solution for CNN-based TSS
models.

</details>


### [51] [SDMatte: Grafting Diffusion Models for Interactive Matting](https://arxiv.org/abs/2508.00443)
*Longfei Huang,Yu Liang,Hao Zhang,Jinwei Chen,Wei Dong,Lunde Chen,Wanyu Liu,Bo Li,Pengtao Jiang*

Main category: cs.CV

TL;DR: 提出了SDMatte模型，这是一个基于扩散模型的交互式抠图方法，利用扩散模型的强大表示能力和视觉提示交互技术来提升抠图在边缘细节处理上的表现，特别关注空间位置和透明度信息的学习。


<details>
  <summary>Details</summary>
Motivation: 当前的交互式抠图方法在提取边缘区域的细粒度细节方面表现不佳，而扩散模型具有建模复杂分布、合成真实纹理以及文本交互驱动的能力，因此可应用于解决这一问题。

Method: SDMatte模型的核心贡献包括三点：1) 利用扩散模型的强先验知识，将文本交互能力转化为视觉提示驱动的交互能力；2) 将视觉提示的坐标嵌入和目标物体的透明度嵌入融合进U-Net，提升模型对空间位置信息和透明度信息的敏感度；3) 提出掩码自注意力机制，使模型能专注于视觉提示指定的区域，进而提升性能。

Result: 在多个数据集上的广泛实验表明，该方法具有卓越的性能，验证了它在交互式抠图中的有效性。

Conclusion: SDMatte成功解决了当前交互式抠图模型在细粒度边缘提取上的不足，为交互式抠图提供了更先进的技术解决方案。

Abstract: Recent interactive matting methods have shown satisfactory performance in
capturing the primary regions of objects, but they fall short in extracting
fine-grained details in edge regions. Diffusion models trained on billions of
image-text pairs, demonstrate exceptional capability in modeling highly complex
data distributions and synthesizing realistic texture details, while exhibiting
robust text-driven interaction capabilities, making them an attractive solution
for interactive matting. To this end, we propose SDMatte, a diffusion-driven
interactive matting model, with three key contributions. First, we exploit the
powerful priors of diffusion models and transform the text-driven interaction
capability into visual prompt-driven interaction capability to enable
interactive matting. Second, we integrate coordinate embeddings of visual
prompts and opacity embeddings of target objects into U-Net, enhancing
SDMatte's sensitivity to spatial position information and opacity information.
Third, we propose a masked self-attention mechanism that enables the model to
focus on areas specified by visual prompts, leading to better performance.
Extensive experiments on multiple datasets demonstrate the superior performance
of our method, validating its effectiveness in interactive matting. Our code
and model are available at https://github.com/vivoCameraResearch/SDMatte.

</details>


### [52] [AutoDebias: Automated Framework for Debiasing Text-to-Image Models](https://arxiv.org/abs/2508.00445)
*Hongyi Cai,Mohammad Mahdinur Rahman,Mingkang Dong,Jie Li,Muxin Pu,Zhili Fang,Yinan Peng,Hanjun Luo,Yang Liu*

Main category: cs.CV

TL;DR: AutoDebias是一个无需预先知识即可自动识别和缓解文本到图像模型中社会偏见的框架，通过视觉语言模型检测偏见、生成包容性提示，并进行CLIP引导训练，有效处理微妙重叠偏见且保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型即使在没有明确提示的情况下也会表现出有害的社会偏见，如性别或种族刻板印象。现有方法在简单或已知偏见上表现良好，但在处理微妙或重叠偏见时效果不佳。

Method: 1.使用视觉语言模型自动检测生成的图像中偏见的视觉模式。2.通过生成包含平衡表述的包容性替代提示构建公平指南。3.使用这些指南驱动CLIP引导的训练过程，减少偏见输出，同时保留图像质量和多样性。

Result: AutoDebias在覆盖25种以上偏见场景的基准测试中，能准确检测91.6%的有害模式，将偏见输出比例从90%降至接近0，且不损害原始模型的视觉质量和多样性。

Conclusion: 该框架首次在无需预先定义偏见类型的情况下，成功减轻了文本到图像模型中包括多重相互作用的偏见和微妙刻板印象在内的各种偏见，同时保持高质量的图像生成能力。

Abstract: Text-to-Image (T2I) models generate high-quality images from text prompts but
often exhibit unintended social biases, such as gender or racial stereotypes,
even when these attributes are not mentioned. Existing debiasing methods work
well for simple or well-known cases but struggle with subtle or overlapping
biases. We propose AutoDebias, a framework that automatically identifies and
mitigates harmful biases in T2I models without prior knowledge of specific bias
types. Specifically, AutoDebias leverages vision-language models to detect
biased visual patterns and constructs fairness guides by generating inclusive
alternative prompts that reflect balanced representations. These guides drive a
CLIP-guided training process that promotes fairer outputs while preserving the
original model's image quality and diversity. Unlike existing methods,
AutoDebias effectively addresses both subtle stereotypes and multiple
interacting biases. We evaluate the framework on a benchmark covering over 25
bias scenarios, including challenging cases where multiple biases occur
simultaneously. AutoDebias detects harmful patterns with 91.6% accuracy and
reduces biased outputs from 90% to negligible levels, while preserving the
visual fidelity of the original model.

</details>


### [53] [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
*Anju Rani,Daniel Ortiz-Arroyo,Petar Durdevic*

Main category: cs.CV

TL;DR: 提出了CLIPTime，一个基于CLIP的多模态、多任务框架，用于从图像和文本输入预测真菌生长的发育阶段和时间戳，无需显式时序输入，并通过合成数据集和自定义指标验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（如CLIP）在捕捉生物生长的时间动态方面存在局限，而理解生物生长的时间动态在微生物学、农业等多个领域至关重要。

Method: 在CLIP架构基础上构建CLIPTime，学习视觉-文本联合嵌入，通过合成真菌生长数据集（带时间戳和阶段标签）训练模型，同时执行阶段分类和时间戳回归任务。测试时不依赖显式时间输入。

Result: 实验表明CLIPTime能有效建模生物生长进程，预测可解释且时间上可靠的结果，通过时间准确率和回归误差评估表现。

Conclusion: CLIPTime展示了视觉语言模型在现实生物监测应用中的潜力，能处理时间感知预测，且自定义指标适用于此类任务评估。

Abstract: Understanding the temporal dynamics of biological growth is critical across
diverse fields such as microbiology, agriculture, and biodegradation research.
Although vision-language models like Contrastive Language Image Pretraining
(CLIP) have shown strong capabilities in joint visual-textual reasoning, their
effectiveness in capturing temporal progression remains limited. To address
this, we propose CLIPTime, a multimodal, multitask framework designed to
predict both the developmental stage and the corresponding timestamp of fungal
growth from image and text inputs. Built upon the CLIP architecture, our model
learns joint visual-textual embeddings and enables time-aware inference without
requiring explicit temporal input during testing. To facilitate training and
evaluation, we introduce a synthetic fungal growth dataset annotated with
aligned timestamps and categorical stage labels. CLIPTime jointly performs
classification and regression, predicting discrete growth stages alongside
continuous timestamps. We also propose custom evaluation metrics, including
temporal accuracy and regression error, to assess the precision of time-aware
predictions. Experimental results demonstrate that CLIPTime effectively models
biological progression and produces interpretable, temporally grounded outputs,
highlighting the potential of vision-language models in real-world biological
monitoring applications.

</details>


### [54] [PIF-Net: Ill-Posed Prior Guided Multispectral and Hyperspectral Image Fusion via Invertible Mamba and Fusion-Aware LoRA](https://arxiv.org/abs/2508.00453)
*Baisong Li,Xingwang Wang,Haixiao Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PIF-Net的多光谱与高光谱图像融合框架，通过引入病态先验来解决数据未对齐导致的病态问题，并利用可逆Mamba架构和动态校准的融合感知低秩适应模块，在多个基准数据集上实现了优于现有方法的图像恢复性能。


<details>
  <summary>Details</summary>
Motivation: 多光谱与高光谱图像融合任务固有的光谱与空间信息权衡以及数据观测有限性导致病态性，而现有方法未有效解决数据未对齐引发的病态问题。

Method: 1. 提出融合框架PIF-Net，显式引入病态先验；2. 基于可逆Mamba架构设计全局光谱建模方法，保持特征变换过程中的信息一致性；3. 设计动态校准的融合感知低秩适应（FALoRA）模块实现轻量化特征校准。

Result: 在多个基准数据集上的实验表明，PIF-Net在图像恢复性能上显著优于现有方法，并保持了模型效率。

Conclusion: PIF-Net通过整合病态先验、可逆特征变换和动态校准机制，有效解决了多源遥感图像融合中的病态性问题，实现了性能与效率的平衡。

Abstract: The goal of multispectral and hyperspectral image fusion (MHIF) is to
generate high-quality images that simultaneously possess rich spectral
information and fine spatial details. However, due to the inherent trade-off
between spectral and spatial information and the limited availability of
observations, this task is fundamentally ill-posed. Previous studies have not
effectively addressed the ill-posed nature caused by data misalignment. To
tackle this challenge, we propose a fusion framework named PIF-Net, which
explicitly incorporates ill-posed priors to effectively fuse multispectral
images and hyperspectral images. To balance global spectral modeling with
computational efficiency, we design a method based on an invertible Mamba
architecture that maintains information consistency during feature
transformation and fusion, ensuring stable gradient flow and process
reversibility. Furthermore, we introduce a novel fusion module called the
Fusion-Aware Low-Rank Adaptation module, which dynamically calibrates spectral
and spatial features while keeping the model lightweight. Extensive experiments
on multiple benchmark datasets demonstrate that PIF-Net achieves significantly
better image restoration performance than current state-of-the-art methods
while maintaining model efficiency.

</details>


### [55] [Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution](https://arxiv.org/abs/2508.00471)
*Yiwen Wang,Xinning Chai,Yuhong Zhang,Zhengxue Cheng,Jun Zhao,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: 提出了一种语义和时间引导的视频超分辨率方法(SeTe-VSR)，通过潜在扩散空间中的语义及时空引导解决现有方法在保真度和时间一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视频超分辨率模型在生成过程控制方面存在局限，难以同时实现高保真度(与低分辨率输入对齐)和帧间时间一致性。因此需要一种能整合高层次语义信息和时空信息的新方法。

Method: 1. 在潜在扩散空间中引入语义引导(高层语义信息)和时空引导(空间与时间信息)；2. 通过联合优化平衡细节恢复与时序连贯性；3. 构建端到端框架实现高真实感视频重建。

Result: 大量实验表明，SeTe-VSR在细节恢复和感知质量上优于现有方法，显著提升了输出视频的保真度与时间一致性。

Conclusion: SeTe-VSR通过联合语义及时空引导，有效解决了视频超分辨率中的保真度对齐与时序一致性问题，为复杂场景下的视频增强提供了新方案。

Abstract: Recent advancements in video super-resolution (VSR) models have demonstrated
impressive results in enhancing low-resolution videos. However, due to
limitations in adequately controlling the generation process, achieving high
fidelity alignment with the low-resolution input while maintaining temporal
consistency across frames remains a significant challenge. In this work, we
propose Semantic and Temporal Guided Video Super-Resolution (SeTe-VSR), a novel
approach that incorporates both semantic and temporal-spatio guidance in the
latent diffusion space to address these challenges. By incorporating high-level
semantic information and integrating spatial and temporal information, our
approach achieves a seamless balance between recovering intricate details and
ensuring temporal coherence. Our method not only preserves high-reality visual
content but also significantly enhances fidelity. Extensive experiments
demonstrate that SeTe-VSR outperforms existing methods in terms of detail
recovery and perceptual quality, highlighting its effectiveness for complex
video super-resolution tasks.

</details>


### [56] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
*Shuo Liang,Yiwu Zhong,Zi-Yuan Hu,Yeyao Tao,Liwei Wang*

Main category: cs.CV

TL;DR: 该论文提出了EgoMask，一个针对以自我为中心（egocentric）视频的像素级时空定位新基准，通过自动标注流程构建，并创建了大规模训练数据集EgoMask-Train。研究表明，现有的先进模型在EgoMask上表现不佳，但使用EgoMask-Train微调后性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 尽管在外部中心（exocentric）视频的时空定位研究已取得进展，但以自我为中心（egocentric）视频的研究相对不足，而后者在增强现实和机器人等领域日益重要。研究分析了egocentric与exocentric视频之间的差异（如物体持续时间短、轨迹稀疏、尺寸小、位置变化大），这些差异给时空定位带来挑战。

Method: 1) 提出EgoMask基准，专注于egocentric视频的细粒度时空定位，通过自动注释流程创建，涵盖短、中、长期视频。2) 创建大型训练数据集EgoMask-Train。3) 训练方法为：使用EgoMask-Train微调现有时空定位模型。

Result: 1) 现有最先进的时空定位模型在EgoMask基准测试中表现不佳。2) 使用EgoMask-Train对相同模型进行微调后，模型在EgoMask上的性能显著提升，同时不影响其在exocentric数据集上的性能。

Conclusion: 该工作指出了egocentric视频时空定位的独特挑战，并提供了一套完整的资源（基准EgoMask和训练集EgoMask-Train）来推动该领域的发展；微调策略有效提升了模型在egocentric视频上的性能。代码已开源。

Abstract: Spatiotemporal video grounding aims to localize target entities in videos
based on textual queries. While existing research has made significant progress
in exocentric videos, the egocentric setting remains relatively underexplored,
despite its growing importance in applications such as augmented reality and
robotics. In this work, we conduct a systematic analysis of the discrepancies
between egocentric and exocentric videos, revealing key challenges such as
shorter object durations, sparser trajectories, smaller object sizes, and
larger positional shifts. To address these challenges, we introduce EgoMask,
the first pixel-level benchmark for fine-grained spatiotemporal grounding in
egocentric videos. It is constructed by our proposed automatic annotation
pipeline, which annotates referring expressions and object masks across short-,
medium-, and long-term videos. Additionally, we create EgoMask-Train, a
large-scale training dataset to facilitate model development. Experiments
demonstrate that the state-of-the-art spatiotemporal grounding models perform
poorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields
significant improvements, while preserving performance on exocentric datasets.
Our work thus provides essential resources and insights for advancing
egocentric video understanding. Our code is available at
https://github.com/LaVi-Lab/EgoMask .

</details>


### [57] [HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](https://arxiv.org/abs/2508.00473)
*Jiaping Cao,Kangkang Zhou,Juan Du*

Main category: cs.CV

TL;DR: 提出了一种名为HyPCV-Former的新方法，用于点云视频中的异常检测，通过在双曲空间建模层次结构和时序依赖，显著提升了现有基准的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于欧几里得空间的视频异常检测方法难以捕捉层次化的事件结构和时空连续性，因此需要一种在非欧几里得空间中直接操作的方法。

Method: 1. 从点云序列逐帧提取空间特征；2. 将特征嵌入到Lorentz双曲空间以更好地捕捉层次结构；3. 提出双曲多头自注意力机制（HMHA），利用Lorentz内积和曲率感知softmax建模时间依赖性；所有操作在完整Lorentz空间进行。

Result: 在TIMo数据集上性能提升7%，在DAD数据集上提升5.6%，达到了最先进的水平。

Conclusion: HyPCV-Former通过在双曲空间直接建模时空特征，有效提升了点云视频异常检测性能，证明了双曲几何对捕捉复杂事件结构的优势。

Abstract: Video anomaly detection is a fundamental task in video surveillance, with
broad applications in public safety and intelligent monitoring systems.
Although previous methods leverage Euclidean representations in RGB or depth
domains, such embeddings are inherently limited in capturing hierarchical event
structures and spatio-temporal continuity. To address these limitations, we
propose HyPCV-Former, a novel hyperbolic spatio-temporal transformer for
anomaly detection in 3D point cloud videos. Our approach first extracts
per-frame spatial features from point cloud sequences via point cloud
extractor, and then embeds them into Lorentzian hyperbolic space, which better
captures the latent hierarchical structure of events. To model temporal
dynamics, we introduce a hyperbolic multi-head self-attention (HMHA) mechanism
that leverages Lorentzian inner products and curvature-aware softmax to learn
temporal dependencies under non-Euclidean geometry. Our method performs all
feature transformations and anomaly scoring directly within full Lorentzian
space rather than via tangent space approximation. Extensive experiments
demonstrate that HyPCV-Former achieves state-of-the-art performance across
multiple anomaly categories, with a 7\% improvement on the TIMo dataset and a
5.6\% gain on the DAD dataset compared to benchmarks. The code will be released
upon paper acceptance.

</details>


### [58] [LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer](https://arxiv.org/abs/2508.00477)
*Yuzhuo Chen,Zehua Ma,Jianhua Wang,Kai Kang,Shunyu Yao,Weiming Zhang*

Main category: cs.CV

TL;DR: LAMIC是首个无需训练即可将单参考扩散模型扩展到多参考场景的布局感知多图像合成框架。它引入了两种即插即用的注意力机制：组隔离注意力（GIA）和区域调制注意力（RMA）。此外，论文提出了三个新指标评估模型，并在实验中表明LAMIC在多个指标上达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前在可控图像合成中，尤其是在多参考图像场景下，保持空间布局的连贯性和一致性仍是一个挑战。传统方法需要微调模型，限制了灵活性，因此需要一种无需训练的方法来解决多图像合成问题。

Method: 作者基于MMDiT模型构建了LAMIC框架。LAMIC包含两个核心注意力机制：组隔离注意力（GIA）用于增强实体解耦，区域调制注意力（RMA）用于实现布局感知生成。整个框架无需训练，采用零样本生成方式。

Result: 论文引入了三个评估指标：IN-R、FI-R评估布局控制能力，BG-S评估背景一致性。实验表明，LAMIC在ID-S、BG-S、IN-R和综合得分上均优于现有多参考基线方法，尤其在复杂合成任务中DPG分数表现最佳。

Conclusion: LAMIC在零样本条件下实现了身份保持、背景保留、布局控制和提示跟随的卓越能力，为可控多图像合成建立了无需训练的新范式。随着基础模型的发展，LAMIC的性能有望进一步提升。

Abstract: In controllable image synthesis, generating coherent and consistent images
from multiple references with spatial layout awareness remains an open
challenge. We present LAMIC, a Layout-Aware Multi-Image Composition framework
that, for the first time, extends single-reference diffusion models to
multi-reference scenarios in a training-free manner. Built upon the MMDiT
model, LAMIC introduces two plug-and-play attention mechanisms: 1) Group
Isolation Attention (GIA) to enhance entity disentanglement; and 2)
Region-Modulated Attention (RMA) to enable layout-aware generation. To
comprehensively evaluate model capabilities, we further introduce three
metrics: 1) Inclusion Ratio (IN-R) and Fill Ratio (FI-R) for assessing layout
control; and 2) Background Similarity (BG-S) for measuring background
consistency. Extensive experiments show that LAMIC achieves state-of-the-art
performance across most major metrics: it consistently outperforms existing
multi-reference baselines in ID-S, BG-S, IN-R and AVG scores across all
settings, and achieves the best DPG in complex composition tasks. These results
demonstrate LAMIC's superior abilities in identity keeping, background
preservation, layout control, and prompt-following, all achieved without any
training or fine-tuning, showcasing strong zero-shot generalization ability. By
inheriting the strengths of advanced single-reference models and enabling
seamless extension to multi-image scenarios, LAMIC establishes a new
training-free paradigm for controllable multi-image composition. As foundation
models continue to evolve, LAMIC's performance is expected to scale
accordingly. Our implementation is available at:
https://github.com/Suchenl/LAMIC.

</details>


### [59] [LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI](https://arxiv.org/abs/2508.00496)
*Mohammed Kamran,Maria Bernathova,Raoul Varga,Christian Singer,Zsuzsanna Bago-Horvath,Thomas Helbich,Georg Langs,Philipp Seeböck*

Main category: cs.CV

TL;DR: 该论文提出了一种结合纵向MRI数据和BI-RADS评分来改进乳腺微小病变分割的3D深度学习方法LesiOnTime。通过引入时间注意力和临床评分一致性损失，在真实高危患者数据集上超越现有方法5%Dice系数。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法主要针对大型病变，忽略了放射科医生实际使用的纵向影像和临床信息（如BI-RADS评分）。对于高危人群乳腺癌筛查中早期、微小病变的检测，需要有效利用时序变化和临床评估信息。

Method: 1. 时间先验注意力模块(TAP)：动态融合当前与历史扫描图像特征
2. BI-RADS一致性正则化(BCR)：使具有相似评分的扫描在隐空间对齐
3. 联合构建3D分割网络，模仿临床工作流程

Result: 1. 在真实高危患者纵向DCE-MRI数据集上，Dice系数比最佳基准方法提高5%
2. 消融实验证实TAP和BCR均带来互补性能提升
3. 代码已开源

Conclusion: 融入时间上下文和临床信息对乳腺癌筛查中早期病变的可靠分割至关重要。LesiOnTime框架首次统一了纵向成像与放射学评估信息，为高风险人群的微小病变检测提供了有效解决方案。

Abstract: Accurate segmentation of small lesions in Breast Dynamic Contrast-Enhanced
MRI (DCE-MRI) is critical for early cancer detection, especially in high-risk
patients. While recent deep learning methods have advanced lesion segmentation,
they primarily target large lesions and neglect valuable longitudinal and
clinical information routinely used by radiologists. In real-world screening,
detecting subtle or emerging lesions requires radiologists to compare across
timepoints and consider previous radiology assessments, such as the BI-RADS
score. We propose LesiOnTime, a novel 3D segmentation approach that mimics
clinical diagnostic workflows by jointly leveraging longitudinal imaging and
BIRADS scores. The key components are: (1) a Temporal Prior Attention (TPA)
block that dynamically integrates information from previous and current scans;
and (2) a BI-RADS Consistency Regularization (BCR) loss that enforces latent
space alignment for scans with similar radiological assessments, thus embedding
domain knowledge into the training process. Evaluated on a curated in-house
longitudinal dataset of high-risk patients with DCE-MRI, our approach
outperforms state-of-the-art single-timepoint and longitudinal baselines by 5%
in terms of Dice. Ablation studies demonstrate that both TPA and BCR contribute
complementary performance gains. These results highlight the importance of
incorporating temporal and clinical context for reliable early lesion
segmentation in real-world breast cancer screening. Our code is publicly
available at https://github.com/cirmuw/LesiOnTime

</details>


### [60] [SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2508.00493)
*Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou*

Main category: cs.CV

TL;DR: 介绍了SAMSA 2.0框架，一种用于高光谱医学图像的分割模型，结合了光谱信息与空间提示，通过光谱角提示引导Segment Anything Model（SAM），在不重新训练的情况下取得了优于RGB模型和先前光谱融合方法的分割结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决临床高光谱影像中在低数据量和噪声场景下分割的挑战，同时利用多光谱信息提高分割精度和鲁棒性。

Method: 早期融合光谱信息到SAM：使用光谱角提示（spectral angle prompting）引导SAM模型，即利用光谱相似性作为空间提示之外的补充信息，以实现更精确的分割。

Result: 在没有重新训练的情况下，SAMSA 2.0比RGB模型在Dice分数上提高了3.8%，比之前的光谱融合方法提高了3.1%，并且在少量样本和零样本情况下表现更好，在临床图像的低数据量和嘈杂环境中具有强泛化能力。

Conclusion: 通过引入光谱角提示，成功将光谱信息与现有分割模型结合，显著提升了在多样化高光谱数据集上的分割性能，证明了其在临床医学影像处理中的实用性和鲁棒性。

Abstract: We present SAMSA 2.0, an interactive segmentation framework for hyperspectral
medical imaging that introduces spectral angle prompting to guide the Segment
Anything Model (SAM) using spectral similarity alongside spatial cues. This
early fusion of spectral information enables more accurate and robust
segmentation across diverse spectral datasets. Without retraining, SAMSA 2.0
achieves up to +3.8% higher Dice scores compared to RGB-only models and up to
+3.1% over prior spectral fusion methods. Our approach enhances few-shot and
zero-shot performance, demonstrating strong generalization in challenging
low-data and noisy scenarios common in clinical imaging.

</details>


### [61] [Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool](https://arxiv.org/abs/2508.00506)
*Tulsi Patel,Mark W. Jones,Thomas Redfern*

Main category: cs.CV

TL;DR: 提出了一个用于在Sentinel-2卫星图像中标记相似地理区域的无监督图像标签工具。无需预标记数据，通过结合卷积神经网络和图神经网络的分割方法创建鲁棒的特征空间进行图像比较。


<details>
  <summary>Details</summary>
Motivation: 现有标签工具依赖于预标记数据进行训练，而标记遥感图像耗时耗力且需专家分析。因此需要开发一种无监督方法以降低标记成本。

Method: 1.将图像分割为基于颜色和空间相似性的均匀像素区域（超像素）；2.使用卷积神经网络从每个区域提取特征；3.利用图神经网络聚合相邻区域信息，创建结合局部特征与邻域特征的特征空间；4.在特征空间中进行相似区域发现与标记。

Result: 该方法能够更鲁棒地表示图像特征（旋转不变性），减少了异常标记，支持细粒度标记，允许用户更精确地标记影像而不依赖预标记数据。

Conclusion: 结合分割、CNN和GNN的无监督流水线能够高效地标记遥感图像数据，减少对预标记数据的依赖，提供了一种实用的遥感影像标记工具。

Abstract: Machine learning for remote sensing imaging relies on up-to-date and accurate
labels for model training and testing. Labelling remote sensing imagery is time
and cost intensive, requiring expert analysis. Previous labelling tools rely on
pre-labelled data for training in order to label new unseen data. In this work,
we define an unsupervised pipeline for finding and labelling geographical areas
of similar context and content within Sentinel-2 satellite imagery. Our
approach removes limitations of previous methods by utilising segmentation with
convolutional and graph neural networks to encode a more robust feature space
for image comparison. Unlike previous approaches we segment the image into
homogeneous regions of pixels that are grouped based on colour and spatial
similarity. Graph neural networks are used to aggregate information about the
surrounding segments enabling the feature representation to encode the local
neighbourhood whilst preserving its own local information. This reduces
outliers in the labelling tool, allows users to label at a granular level, and
allows a rotationally invariant semantic relationship at the image level to be
formed within the encoding space.

</details>


### [62] [Wukong Framework for Not Safe For Work Detection in Text-to-Image systems](https://arxiv.org/abs/2508.00591)
*Mingrui Liu,Sixiao Zhang,Cheng Long*

Main category: cs.CV

TL;DR: 本文提出了一种名为‘Wukong’的新型NSFW检测框架，该框架针对文本到图像生成模型（如Stable Diffusion）进行了优化。Wukong利用了扩散模型早期去噪步骤的中间输出，并重用U-Net的预训练跨注意力参数，从而在图像生成过程中实现早期检测。相比传统的文本过滤器和图像过滤器，Wukong在保持高准确性的同时显著提高了效率。


<details>
  <summary>Details</summary>
Motivation: 文本到图像（T2I）生成模型可能会输出包含不适合工作场所（NSFW）的内容，如暴力。现存的保障措施分为文本过滤器和图像过滤器两种：文本过滤器容易受到对抗性攻击且忽略了具体模型的变化；图像过滤器虽准确但计算成本高且带来延迟。基于扩散模型的工作机制，作者发现早期去噪步骤可以确定图像的语义布局，而跨注意力层在文本和图像对齐中起关键作用，因此希望通过利用这些中间信息实现高效准确的NSFW检测。

Method: 1. 分析扩散模型（如Stable Diffusion）的早期去噪步骤和跨注意力层的作用，确定它们在图像生成中的关键地位。
2. 提出Wukong框架：基于Transformer架构，在扩散过程内部利用早期步骤（特别是跨注意力层）的中间特征，实现早期检测。框架复用了U-Net已有的跨注意力参数以避免额外计算。
3. 构建了一个新的数据集，包含图像提示、生成种子及具体的NSFW标签。
4. 在自构建数据集和两个公共基准数据集上评估Wukong的性能。
评价指标包括检测准确性、效率（检测所需时间）以及对抗传统文本攻击的能力。

Result: 1. 在检测准确性方面：Wukong显著优于文本过滤器，且达到图像过滤器相当的准确率。
2. 在效率方面：Wukong远快于图像过滤器（因为避免了等待完整图像生成和额外处理），实现了实时检测能力。
3. 在对抗攻击方面：Wukong利用中间特征使其对文本攻击具有更强的鲁棒性。

Conclusion: Wukong通过有效利用扩散模型早期去噪步骤的中间特征，结合预训练的跨注意力参数，实现了高效准确的NSFW内容检测。该框架提供了一种全新的外部保障思路，不仅降低了计算开销，还支持在图像生成完成前及时干预，对T2I系统的安全保障具有实际应用价值。

Abstract: Text-to-Image (T2I) generation is a popular AI-generated content (AIGC)
technology enabling diverse and creative image synthesis. However, some outputs
may contain Not Safe For Work (NSFW) content (e.g., violence), violating
community guidelines. Detecting NSFW content efficiently and accurately, known
as external safeguarding, is essential. Existing external safeguards fall into
two types: text filters, which analyze user prompts but overlook T2I
model-specific variations and are prone to adversarial attacks; and image
filters, which analyze final generated images but are computationally costly
and introduce latency. Diffusion models, the foundation of modern T2I systems
like Stable Diffusion, generate images through iterative denoising using a
U-Net architecture with ResNet and Transformer blocks. We observe that: (1)
early denoising steps define the semantic layout of the image, and (2)
cross-attention layers in U-Net are crucial for aligning text and image
regions. Based on these insights, we propose Wukong, a transformer-based NSFW
detection framework that leverages intermediate outputs from early denoising
steps and reuses U-Net's pre-trained cross-attention parameters. Wukong
operates within the diffusion process, enabling early detection without waiting
for full image generation. We also introduce a new dataset containing prompts,
seeds, and image-specific NSFW labels, and evaluate Wukong on this and two
public benchmarks. Results show that Wukong significantly outperforms
text-based safeguards and achieves comparable accuracy of image filters, while
offering much greater efficiency.

</details>


### [63] [EPANet: Efficient Path Aggregation Network for Underwater Fish Detection](https://arxiv.org/abs/2508.00528)
*Jinsong Yang,Zeyuan Hu,Yichen Li*

Main category: cs.CV

TL;DR: 提出了一个高效的路径聚合网络（EPANet），通过整合互补特征来实现轻量级准确的水下鱼类检测。


<details>
  <summary>Details</summary>
Motivation: 水下鱼类检测（UFD）面临目标分辨率低、背景干扰严重、目标与周围环境视觉相似性高等挑战。现有方法复杂且低效，因此需要一种更高效、准确的解决方案。

Method: EPANet包括两个关键组件：1）高效路径聚合特征金字塔网络（EPA-FPN），通过跨尺度的远程跳跃连接和跨层融合路径增强语义-空间互补性；2）多尺度多样化分割短路径瓶颈（MS-DDSP瓶颈），通过细粒度特征分割和多样化卷积操作增强局部特征多样性和表示能力。

Result: 在UFD基准数据集上的实验表明，EPANet在检测精度和推理速度上均优于现有最优方法，且参数复杂度相当或更低。

Conclusion: EPANet通过有效的特征整合策略，实现了水下鱼类的轻量级高效检测，并在准确性和速度上都取得了显著改进。

Abstract: Underwater fish detection (UFD) remains a challenging task in computer vision
due to low object resolution, significant background interference, and high
visual similarity between targets and surroundings. Existing approaches
primarily focus on local feature enhancement or incorporate complex attention
mechanisms to highlight small objects, often at the cost of increased model
complexity and reduced efficiency. To address these limitations, we propose an
efficient path aggregation network (EPANet), which leverages complementary
feature integration to achieve accurate and lightweight UFD. EPANet consists of
two key components: an efficient path aggregation feature pyramid network
(EPA-FPN) and a multi-scale diverse-division short path bottleneck (MS-DDSP
bottleneck). The EPA-FPN introduces long-range skip connections across
disparate scales to improve semantic-spatial complementarity, while cross-layer
fusion paths are adopted to enhance feature integration efficiency. The MS-DDSP
bottleneck extends the conventional bottleneck structure by introducing
finer-grained feature division and diverse convolutional operations, thereby
increasing local feature diversity and representation capacity. Extensive
experiments on benchmark UFD datasets demonstrate that EPANet outperforms
state-of-the-art methods in terms of detection accuracy and inference speed,
while maintaining comparable or even lower parameter complexity.

</details>


### [64] [Video Color Grading via Look-Up Table Generation](https://arxiv.org/abs/2508.00548)
*Seunghyun Shin,Dongmin Shin,Jisu Shin,Hae-Gon Jeon,Joon-Young Lee*

Main category: cs.CV

TL;DR: 本文提出了一种基于参考的视频色彩分级框架，通过使用扩散模型显式生成用于颜色属性对齐的查找表（LUT），实现视频的艺术性色彩调整。该方法避免了结构细节损失，并支持文本提示以增强用户偏好调整。


<details>
  <summary>Details</summary>
Motivation: 视频色彩分级通常用于艺术创作或故事叙述，以建立特定的视觉效果或氛围，但这一过程复杂且需要专业技能。传统方法存在局限性，因此需要一种无需专业技能、高效且能保持视频结构细节的色彩分级方法。

Method: 1. 基于扩散模型生成查找表（LUT）以对齐参考场景与输入视频的颜色属性。2. 训练目标：确保参考场景的高层特征（如外观、情绪、情感）与输入视频相似。3. 构建流程：结合用户通过文本提示指定的低层特征（如对比度、亮度）进行增强。4. LUT方法确保整个视频帧的结构细节不损失，且推理速度快。

Result: 实验结果表明该方法在视频色彩分级中有效（包括广泛的用户研究）。代码已公开。

Conclusion: 该方法为视频色彩分级提供了一种高效且用户友好的解决方案，通过扩散模型生成LUT实现颜色对齐，并支持文本驱动的用户偏好调整，同时保持视频的结构细节和实现快速推理。

Abstract: Different from color correction and transfer, color grading involves
adjusting colors for artistic or storytelling purposes in a video, which is
used to establish a specific look or mood. However, due to the complexity of
the process and the need for specialized editing skills, video color grading
remains primarily the domain of professional colorists. In this paper, we
present a reference-based video color grading framework. Our key idea is
explicitly generating a look-up table (LUT) for color attribute alignment
between reference scenes and input video via a diffusion model. As a training
objective, we enforce that high-level features of the reference scenes like
look, mood, and emotion should be similar to that of the input video. Our
LUT-based approach allows for color grading without any loss of structural
details in the whole video frames as well as achieving fast inference. We
further build a pipeline to incorporate a user-preference via text prompts for
low-level feature enhancement such as contrast and brightness, etc.
Experimental results, including extensive user studies, demonstrate the
effectiveness of our approach for video color grading. Codes are publicly
available at https://github.com/seunghyuns98/VideoColorGrading.

</details>


### [65] [Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images](https://arxiv.org/abs/2508.00549)
*Daniel Wolf,Heiko Hillenhagen,Billurvan Taskin,Alex Bäuerle,Meinrad Beer,Michael Götz,Timo Ropinski*

Main category: cs.CV

TL;DR: 该研究聚焦于视觉语言模型（VLMs）在医学影像中识别解剖结构相对位置的能力评估。研究发现当前最先进的VLMs（包括GPT-4o、Llama3.2等）在此基础任务上均表现不佳。通过引入视觉标记（如字母或彩色标记）仅带来有限提升，且医学影像的难度显著高于自然图像。分析表明VLMs在医学领域过度依赖先验知识而忽略图像内容，导致错误判断。为此研究者构建了专用基准数据集MIRP以推动后续研究。


<details>
  <summary>Details</summary>
Motivation: 临床决策高度依赖对解剖结构及异常相对位置的理解。然而，尽管这是医疗应用中视觉语言模型的基础能力，当前研究对该能力的探索严重不足。现有先进模型在此任务上的实际性能未知，且缺乏系统性的评估方法。这项研究旨在揭示主流VLMs在该任务上的缺陷，探究改进手段（如视觉标记）的有效性，并推动相关研究发展。

Method: 1. 评估最先进VLMs（GPT-4o, Llama3.2, Pixtral, JanusPro）在医学影像相对定位任务上的表现；
2. 借鉴计算机视觉成功经验，通过添加字母数字或彩色视觉标记于解剖结构以增强模型性能；
3. 对比模型在医疗影像与自然图像上的表现差异；
4. 分析模型决策依据（先验知识 vs. 图像内容）；
5. 构建公开基准数据集MIRP（Medical Imaging Relative Positioning），包含系统性设计的医学影像相对定位问题。

Result: 1. 所有测试VLMs在医学影像相对定位任务上均失败（性能远低于医疗应用需求）；
2. 使用视觉标记后表现略有提升，但医疗影像上的结果仍显著落后于自然图像场景；
3. 关键发现：VLMs在医疗领域倾向于依赖先验解剖知识而非图像内容，导致大量错误判断；
4. 建立首个针对医学影像相对定位的标准化测评数据集MIRP。

Conclusion: 当前视觉语言模型缺乏解读医学影像中解剖结构相对位置的基础能力，过度依赖先验知识导致临床适用性差。虽然视觉标记有一定改善作用，但医疗影像特有的复杂性仍构成重大挑战。研究揭示了医疗领域VLMs的独特缺陷，并通过MIRP数据集为未来研究提供关键工具。该发现警示：若无法解决基础空间定位问题，VLMs的临床部署将存在重大风险。

Abstract: Clinical decision-making relies heavily on understanding relative positions
of anatomical structures and anomalies. Therefore, for Vision-Language Models
(VLMs) to be applicable in clinical practice, the ability to accurately
determine relative positions on medical images is a fundamental prerequisite.
Despite its importance, this capability remains highly underexplored. To
address this gap, we evaluate the ability of state-of-the-art VLMs, GPT-4o,
Llama3.2, Pixtral, and JanusPro, and find that all models fail at this
fundamental task. Inspired by successful approaches in computer vision, we
investigate whether visual prompts, such as alphanumeric or colored markers
placed on anatomical structures, can enhance performance. While these markers
provide moderate improvements, results remain significantly lower on medical
images compared to observations made on natural images. Our evaluations suggest
that, in medical imaging, VLMs rely more on prior anatomical knowledge than on
actual image content for answering relative position questions, often leading
to incorrect conclusions. To facilitate further research in this area, we
introduce the MIRP , Medical Imaging Relative Positioning, benchmark dataset,
designed to systematically evaluate the capability to identify relative
positions in medical images.

</details>


### [66] [Backdoor Attacks on Deep Learning Face Detection](https://arxiv.org/abs/2508.00620)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi*

Main category: cs.CV

TL;DR: 本文首次提出针对人脸检测任务的生成式攻击（Face Generation Attacks），特别是针对回归地标坐标任务的Landmark Shift Attack，展示了这些攻击的威胁性，并提出了相应的防御措施。


<details>
  <summary>Details</summary>
Motivation: 在不受约束的环境中，人脸识别系统需要依赖人脸检测模块提供边界框和地标坐标以确保对准效果。然而，现有的面部检测模块对对抗性攻击的研究不足，尤其是针对坐标回归任务的攻击。因此，本文旨在揭示人脸检测模型对两类生成式攻击的脆弱性。

Method: 1. 提出两种攻击方式：Face Generation Attacks（包括生成式攻击）和Landmark Shift Attack（针对地标坐标回归任务）。Face Generation Attack通过在输入图像中叠加特定模式（可能是噪声或贴图）来误导人脸检测器，使其无法正确检测人脸或标记地标。Landmark Shift Attack则旨在微调地标坐标的回归结果，使模型在测试时生成错误的地标位置，从而破坏人脸对齐。
2. 针对Landmark Shift Attack，其训练过程通过在数据集中注入特殊标记样本（trojaned samples）来训练模型，使其在输入含trigger的图像时预测错误的地标坐标。攻击者通过少量中毒样本（例如在数据集中添加特定贴图或纹理）就能够改变模型在测试时的行为。
3. 对两种攻击进行实验评估，展示攻击成功率（如何使检测器漏检人脸、误检非人脸或预测严重错误的地标）。
4. 为防御攻击，文中提出了若干防御方案：模型输入特征增强（如特征归一化或预处理）以及模型架构增强（如异常检测或鲁棒回归），并评估了这些防御措施的效果。

Result: 本文的实验表明，Face Generation Attack可导致人脸检测模块失效（无法检测人脸或检测到错误人脸），而Landmark Shift Attack可导致高攻击成功率（接近80%），即模型在受到攻击样本时会预测错误的地标位置（偏移超过给定阈值），严重影响后续的人脸识别流程。同时，文中提出的防御方法降低了攻击成功率，但并未完全根除漏洞。

Conclusion: 本文首次证明了针对人脸检测器中地标坐标回归任务的生成式攻击是可行且具有威胁性的（Landmark Shift Attack）。该攻击可严重降低人脸识别系统的性能。虽然提出的防御策略在一定程度上缓解了攻击，但研究结果表明未来人脸检测模型需要考虑对抗鲁棒性设计的重要性，包括正则化或对抗训练机制。

Abstract: Face Recognition Systems that operate in unconstrained environments capture
images under varying conditions,such as inconsistent lighting, or diverse face
poses. These challenges require including a Face Detection module that
regresses bounding boxes and landmark coordinates for proper Face Alignment.
This paper shows the effectiveness of Object Generation Attacks on Face
Detection, dubbed Face Generation Attacks, and demonstrates for the first time
a Landmark Shift Attack that backdoors the coordinate regression task performed
by face detectors. We then offer mitigations against these vulnerabilities.

</details>


### [67] [DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification](https://arxiv.org/abs/2508.00552)
*Chihan Huang,Belal Alsinglawi,Islam Al-qudah*

Main category: cs.CV

TL;DR: 该论文介绍了DBLP，一种用于对抗净化的高效扩散框架。DBLP通过新的noise bridge distillation目标，在LCM模型内构建对抗噪声分布与干净数据分布之间的对齐，并结合自适应语义增强来提高效果，实现了SOTA鲁棒精度、优越图像质量和实时推理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的对抗净化方法通常需要多次迭代去噪，严重限制了其实际应用。尽管DNNs在多任务上表现优秀，但对对抗性扰动的敏感性仍是关键弱点。因此，需要一种高效的方法来防御对抗攻击。

Method: 论文提出Diffusion Bridge Distillation for Purification (DBLP)，其核心是noise bridge distillation目标，在LCM模型内构建对抗噪声与干净数据的对齐。同时，采用adaptive semantic enhancement融合多尺度金字塔边缘图作为条件输入，以引导净化过程。

Result: 在多个数据集上的实验表明，DBLP实现了SOTA鲁棒准确率、优越图像质量，且推理时间大幅缩短约为0.2秒，接近实时运行。

Conclusion: DBLP显著推动了对抗净化技术在实时性方面的发展，通过噪声桥接蒸馏和自适应语义增强提升了对抗净化的效率和效果，为解决DNNs对抗脆弱性问题提供了新思路。

Abstract: Recent advances in deep neural networks (DNNs) have led to remarkable success
across a wide range of tasks. However, their susceptibility to adversarial
perturbations remains a critical vulnerability. Existing diffusion-based
adversarial purification methods often require intensive iterative denoising,
severely limiting their practical deployment. In this paper, we propose
Diffusion Bridge Distillation for Purification (DBLP), a novel and efficient
diffusion-based framework for adversarial purification. Central to our approach
is a new objective, noise bridge distillation, which constructs a principled
alignment between the adversarial noise distribution and the clean data
distribution within a latent consistency model (LCM). To further enhance
semantic fidelity, we introduce adaptive semantic enhancement, which fuses
multi-scale pyramid edge maps as conditioning input to guide the purification
process. Extensive experiments across multiple datasets demonstrate that DBLP
achieves state-of-the-art (SOTA) robust accuracy, superior image quality, and
around 0.2s inference time, marking a significant step toward real-time
adversarial purification.

</details>


### [68] [HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models](https://arxiv.org/abs/2508.00553)
*Jizhihui Liu,Feiyi Du,Guangdao Zhu,Niu Lian,Jun Li,Bin Chen*

Main category: cs.CV

TL;DR: 本文介绍了HiPrune，一个无需训练且模型无关的视觉令牌剪枝框架，利用视觉编码器中分层的注意力结构，在保持高性能的同时显著减少处理视觉令牌的计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）将图像编码为大量视觉令牌，导致计算开销过大及推理效率低下。先前的令牌剪枝方案通常依赖特殊令牌（如CLS）或需要任务特定训练，难以跨架构拓展。

Method: HiPrune框架采用分层注意力结构，选取三类信息量大的令牌：（1）中层（对象中心层）中注意力分数高的锚点令牌；（2）与锚点相邻以保持空间连续性的缓冲区令牌；（3）深层中强注意力令牌（寄存令牌）以完成全局总结。该方法无需调整训练，无缝适配任何ViT基VLM。

Result: 实验表明，HiPrune在多个VLM模型及任务中达到SOTA剪枝性能：LLaVA-1.5任务中能以仅33.3%令牌保持99.3%精度；在Qwen2.5-VL中以仅11.1%令牌维持99.5%精度；同时推理计算量及延迟最高减少9倍。

Conclusion: HiPrune证实了分层注意力的高效利用可实现高压缩率的令牌剪枝，为视觉语言模型提供了无需训练、通用性强的高效推理方案。

Abstract: Vision-Language Models (VLMs) encode images into lengthy sequences of visual
tokens, leading to excessive computational overhead and limited inference
efficiency. While prior efforts prune or merge tokens to address this issue,
they often rely on special tokens (e.g., CLS) or require task-specific
training, hindering scalability across architectures. In this paper, we propose
HiPrune, a training-free and model-agnostic token Pruning framework that
exploits the Hierarchical attention structure within vision encoders. We
identify that middle layers attend to object-centric regions, while deep layers
capture global contextual features. Based on this observation, HiPrune selects
three types of informative tokens: (1) Anchor tokens with high attention in
object-centric layers, (2) Buffer tokens adjacent to anchors for spatial
continuity, and (3) Register tokens with strong attention in deep layers for
global summarization. Our method requires no retraining and integrates
seamlessly with any ViT-based VLM. Extensive experiments on LLaVA-1.5,
LLaVA-NeXT, and Qwen2.5-VL demonstrate that HiPrune achieves state-of-the-art
pruning performance, preserving up to 99.3% task accuracy with only 33.3%
tokens, and maintaining 99.5% accuracy with just 11.1% tokens. Meanwhile, it
reduces inference FLOPs and latency by up to 9$\times$, showcasing strong
generalization across models and tasks. Code is available at
https://github.com/Danielement321/HiPrune.

</details>


### [69] [Training-Free Class Purification for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.00557)
*Qi Chen,Lingxiao Yang,Yun Chen,Nailong Zhao,Jianhuang Lai,Jie Shao,Xiaohua Xie*

Main category: cs.CV

TL;DR: 训练自由的开集词汇语义分割（OVSS）方法FreeCP，通过提纯语义类别并纠正冗余和模糊性带来的错误，提升分割效果。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练视觉语言模型显著提升了开集词汇语义分割（OVSS）性能，但大模型训练的高资源需求限制了其实用性。已有的训练自由方法虽然降低了训练成本，但大多忽略了当前测试图像中类别冗余（无效类别）以及视觉语言模糊性（相似类别易混淆）两大问题。它们会导致最终的分割映射（Class Activation Maps，CAMs）质量不高。因此，为提升零资源下的分割性能，本研究提出了训练自由的类别提纯框架FreeCP，通过消除冗余类别和模糊性问题优化类别表示，从而改善分割结果。

Method: FreeCP在推理阶段（无需任何训练数据）改善分割映射的核心流程如下：1. **类别冗余过滤（消除无效类别）**：根据类别的激活图，去除当前图像中未被视觉表达（即激活不显著或无相关视觉区域）的冗余类别。2. **视觉语言模糊性纠正（相似类别去歧义）**：利用预训练视觉语言模型的视觉-语言联合嵌入空间，计算图像各区域与语言概念的相似性。如果某些类别语义相近导致激活图重叠（混淆），通过语义和位置关系分析进行提纯，重构出更清晰的激活图（避免模糊类别干扰）。3. **最终分割生成**：利用提纯后的类别表示生成CAMs，可选地整合其他OVSS方法（如基于亲和力的优化模块）生成最终的分割预测结果。

Result: 在多个基准测试中验证了FreeCP的效果：
1. **主要性能提升**：FreeCP作为即插即用模块，显著提高了各种主流的OVSS方法的分割准确性（如MaskCLIP、ReCo等方法在PASCAL VOC以及COOC-Stuff数据集等提升达5%~33% mIOU）。
2. **消融实验**：证明了FreeCP的两个关键组件—冗余过滤和模糊性纠正的有效性：每个单独组件均能提升性能，但联合使用效果更加显著。
3. **跨数据集泛化性强**：FreeCP在多个数据集（包括ADE20K、COCO-Stuff等）上均带来显著性能提升，证明了其广泛的适用性。
4. **效率上**：推理过程仅引入很小的计算开销。

Conclusion: FreeCP创新性地解决了现有训练自由OVSS方法忽略的两大核心问题：类别冗余与视觉语言语义模糊性。实验表明，作为一种无需训练、即插即用的模块，FreeCP可以在多个基准上大幅提升主流OVSS方法的分割质量。这项工作表明，在预训练模型强大的语义对齐基础上，通过动态过滤和提纯类别语义，能有效改善模型的推理性能。该框架为未来的训练自由语义分割开辟了新方向。

Abstract: Fine-tuning pre-trained vision-language models has emerged as a powerful
approach for enhancing open-vocabulary semantic segmentation (OVSS). However,
the substantial computational and resource demands associated with training on
large datasets have prompted interest in training-free methods for OVSS.
Existing training-free approaches primarily focus on modifying model
architectures and generating prototypes to improve segmentation performance.
However, they often neglect the challenges posed by class redundancy, where
multiple categories are not present in the current test image, and
visual-language ambiguity, where semantic similarities among categories create
confusion in class activation. These issues can lead to suboptimal class
activation maps and affinity-refined activation maps. Motivated by these
observations, we propose FreeCP, a novel training-free class purification
framework designed to address these challenges. FreeCP focuses on purifying
semantic categories and rectifying errors caused by redundancy and ambiguity.
The purified class representations are then leveraged to produce final
segmentation predictions. We conduct extensive experiments across eight
benchmarks to validate FreeCP's effectiveness. Results demonstrate that FreeCP,
as a plug-and-play module, significantly boosts segmentation performance when
combined with other OVSS methods.

</details>


### [70] [Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints](https://arxiv.org/abs/2508.00558)
*Jens U. Kreber,Joerg Stueckler*

Main category: cs.CV

TL;DR: 提出名为PhysNAP的扩散模型方法，用于生成与部分点云对齐并提升物理合理性的关节物体。模型采用SDF表示部件形状，在反向扩散过程中利用SDF预测点云对齐损失作为引导，并增加非穿透性和可动性约束。该方法还支持引入类别信息进一步提升对齐效果。在PartNet-Mobility数据集上的实验表明，该方法在约束一致性与生成能力之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 日常生活中关节物体是重要的可交互对象。现有方法生成关节物体时存在物理合理性（如部件穿透）及与观测点云对齐不足的问题。

Method: 1. 用有符号距离函数(SDF)表示部件形状；
2. 在扩散模型反向过程中增加两项引导：
   a) 使用预测SDF计算点云对齐损失
   b) 基于部件SDF施加非穿透约束和可动性约束
3. 引入类别信息辅助对齐（可选）；

Result: 在PartNet-Mobility数据集验证：
1. 相比无约束扩散模型基线，PhysNAP在非穿透约束上达标率提升21% (0.57→0.78)，移动约束达标率提升39% (0.28→0.67)；
2. 存在生成能力（FID指标）轻微下降的权衡（1.72→2.58）；

Conclusion: 通过物理约束引导的扩散过程能有效提升关节物体生成的物理合理性，同时保持可接受的生成多样性。类别信息可选择性用于增强点云对齐效果。

Abstract: Articulated objects are an important type of interactable objects in everyday
environments. In this paper, we propose PhysNAP, a novel diffusion model-based
approach for generating articulated objects that aligns them with partial point
clouds and improves their physical plausibility. The model represents part
shapes by signed distance functions (SDFs). We guide the reverse diffusion
process using a point cloud alignment loss computed using the predicted SDFs.
Additionally, we impose non-penetration and mobility constraints based on the
part SDFs for guiding the model to generate more physically plausible objects.
We also make our diffusion approach category-aware to further improve point
cloud alignment if category information is available. We evaluate the
generative ability and constraint consistency of samples generated with PhysNAP
using the PartNet-Mobility dataset. We also compare it with an unguided
baseline diffusion model and demonstrate that PhysNAP can improve constraint
consistency and provides a tradeoff with generative ability.

</details>


### [71] [D3: Training-Free AI-Generated Video Detection Using Second-Order Features](https://arxiv.org/abs/2508.00701)
*Chende Zheng,Ruiqi suo,Chenhao Lin,Zhengyu Zhao,Le Yang,Shuai Liu,Minghui Yang,Cong Wang,Chao Shen*

Main category: cs.CV

TL;DR: 该论文提出了D3方法，一种基于二阶时间差异的训练免费检测方法，用于检测AI生成的视频。该方法通过建立基于牛顿力学二阶动力学分析的理论框架，揭示了真实视频与AI生成视频在二阶特征分布上的根本差异，并在多个数据集上展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法对合成视频中的时间伪影（temporal artifacts）探索不足，为了解决这一问题，作者通过理论分析建立框架，并开发了针对性的检测方法。

Method: 首先，通过牛顿力学中的二阶动力学分析建立理论框架，扩展了针对时间伪影检测的二阶中央差分特征（Second-order Central Difference features）。然后，提出Detection by Difference of Differences (D3)方法，该方法利用真实视频与生成视频在二阶时间差异上的分布不同，无需训练即可直接检测AI生成视频。

Result: 在4个开源数据集（Gen-Video, VideoPhy, EvalCrafter, VidProM）共40个子集上验证了方法的有效性。例如，在Gen-Video数据集上，D3比之前最好的方法在平均平均精度（mean Average Precision）上绝对提升了10.39%。此外，D3具有优异的计算效率和鲁棒性。

Conclusion: 该研究提出了一个理论框架和基于二阶时间差异的检测方法D3，有效地解决了现有方法在检测AI生成视频中时间伪影上的不足。D3在多个数据集上表现优异，计算高效且鲁棒性强。

Abstract: The evolution of video generation techniques, such as Sora, has made it
increasingly easy to produce high-fidelity AI-generated videos, raising public
concern over the dissemination of synthetic content. However, existing
detection methodologies remain limited by their insufficient exploration of
temporal artifacts in synthetic videos. To bridge this gap, we establish a
theoretical framework through second-order dynamical analysis under Newtonian
mechanics, subsequently extending the Second-order Central Difference features
tailored for temporal artifact detection. Building on this theoretical
foundation, we reveal a fundamental divergence in second-order feature
distributions between real and AI-generated videos. Concretely, we propose
Detection by Difference of Differences (D3), a novel training-free detection
method that leverages the above second-order temporal discrepancies. We
validate the superiority of our D3 on 4 open-source datasets (Gen-Video,
VideoPhy, EvalCrafter, VidProM), 40 subsets in total. For example, on GenVideo,
D3 outperforms the previous best method by 10.39% (absolute) mean Average
Precision. Additional experiments on time cost and post-processing operations
demonstrate D3's exceptional computational efficiency and strong robust
performance. Our code is available at https://github.com/Zig-HS/D3.

</details>


### [72] [Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images](https://arxiv.org/abs/2508.00563)
*Hannah Kniesel,Leon Sick,Tristan Payer,Tim Bergner,Kavitha Shaga Devan,Clarissa Read,Paul Walther,Timo Ropinski*

Main category: cs.CV

TL;DR: 我们提出了一种领域特有的弱监督物体检测算法，它仅依赖图像级别的标注，解决了获取边界框标注成本高的问题。该方法通过利用预训练模型的知识蒸馏生成伪标签，用于训练最先进的物体检测模型。实验表明，生成的伪标签更容易获得，并且在标注时间有限的情况下，性能优于现有的弱标签方法甚至真实标签。


<details>
  <summary>Details</summary>
Motivation: 在科学领域中获取物体检测所需的边界框标注成本昂贵且需要专业知识，这限制了方法的可扩展性。我们旨在通过仅使用图像级别的标注来实现高效的物体检测，降低标注成本。

Method: 我们利用预训练模型（预测图像中病毒是否存在）的知识蒸馏生成伪标签。采用优化方法结合缩小的感受野直接提取病毒颗粒，无需特殊网络结构。生成的伪标签用于训练现有的先进物体检测模型。

Result: 大量研究证明，提出的伪标签易于获取。当标注时间有限时，该伪标签策略在物体检测中优于现有的弱标注方法以及边界框真实标注。

Conclusion: 通过知识蒸馏和优化技术，我们成功开发出一种弱监督物体检测方法。该方法仅需图像级别的标注，能够生成高质量伪标签，减少对昂贵的边界框人工标注的依赖，尤其在领域特定对象（如病毒）检测中表现优秀。

Abstract: Current state-of-the-art methods for object detection rely on annotated
bounding boxes of large data sets for training. However, obtaining such
annotations is expensive and can require up to hundreds of hours of manual
labor. This poses a challenge, especially since such annotations can only be
provided by experts, as they require knowledge about the scientific domain. To
tackle this challenge, we propose a domain-specific weakly supervised object
detection algorithm that only relies on image-level annotations, which are
significantly easier to acquire. Our method distills the knowledge of a
pre-trained model, on the task of predicting the presence or absence of a virus
in an image, to obtain a set of pseudo-labels that can be used to later train a
state-of-the-art object detection model. To do so, we use an optimization
approach with a shrinking receptive field to extract virus particles directly
without specific network architectures. Through a set of extensive studies, we
show how the proposed pseudo-labels are easier to obtain, and, more
importantly, are able to outperform other existing weak labeling methods, and
even ground truth labels, in cases where the time to obtain the annotation is
limited.

</details>


### [73] [CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry](https://arxiv.org/abs/2508.00568)
*Jingchao Xie,Oussema Dhaouadi,Weirong Chen,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: 论文提出了一种名为CoProU-VO的新方法，通过跨帧不确定性传播来改进动态场景下的视觉里程计（VO）性能。该方法结合连续帧间的不确定性信息，利用概率模型和视觉Transformer主干网络，同时学习深度、姿态和不确定性，显著提升了在动态环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶和机器人导航等领域中，无监督视觉里程计（VO）由于不需要昂贵的真值标签而备受关注。然而，传统方法在动态场景中表现不佳，因为动态物体违反了静态场景假设，导致位姿估计错误。现有的不确定性建模通常只考虑单帧信息，忽略了跨帧的不确定性传播，因此需要一种新的方法来有效整合连续帧间的不确定性，从而提高动态场景下的鲁棒性。

Method: CoProU-VO是一种端到端无监督视觉里程计方法，其核心是通过概率化的方式结合当前帧的不确定性与前一帧投影过来的不确定性。方法采用视觉Transformer作为主干网络，能够同时学习深度估计、位姿估计以及像素级不确定性。具体而言，模型对参考帧中的每个像素点计算不确定性，并通过相机运动将其投影到目标帧，然后将两者结合得到综合的不确定性图。这种跨帧传播机制允许模型对动态物体和遮挡区域做出更加鲁棒的判断，从而在优化位姿时排除这些不可靠区域的影响。训练过程完全无监督，仅基于图像序列重建损失。

Result: 在KITTI和nuScenes数据集上的实验表明，该方法显著优于当前最先进的无监督单目VO方法（特别是两帧预测体系）。在具有挑战性的高速公路场景下（高动态物体比例），CoProU-VO的表现尤其突出（KITTI序列09上有31.3%的误差降低）；而其他方法在此类环境中常失败。此外，消融研究证实了跨帧不确定性传播机制的有效性。

Conclusion: 通过概率化融合跨帧不确定性的策略，CoProU-VO有效解决了动态场景下视觉里程计的鲁棒性问题。该模型不仅无需动态物体标注，还在标准测试和极端场景中展现出了强大的性能提升。跨帧不确定性传播这一机制证明了对处理动态环境至关重要，为未来相关研究提供了新的技术方向。

Abstract: Visual Odometry (VO) is fundamental to autonomous navigation, robotics, and
augmented reality, with unsupervised approaches eliminating the need for
expensive ground-truth labels. However, these methods struggle when dynamic
objects violate the static scene assumption, leading to erroneous pose
estimations. We tackle this problem by uncertainty modeling, which is a
commonly used technique that creates robust masks to filter out dynamic objects
and occlusions without requiring explicit motion segmentation. Traditional
uncertainty modeling considers only single-frame information, overlooking the
uncertainties across consecutive frames. Our key insight is that uncertainty
must be propagated and combined across temporal frames to effectively identify
unreliable regions, particularly in dynamic scenes. To address this challenge,
we introduce Combined Projected Uncertainty VO (CoProU-VO), a novel end-to-end
approach that combines target frame uncertainty with projected reference frame
uncertainty using a principled probabilistic formulation. Built upon vision
transformer backbones, our model simultaneously learns depth, uncertainty
estimation, and camera poses. Consequently, experiments on the KITTI and
nuScenes datasets demonstrate significant improvements over previous
unsupervised monocular end-to-end two-frame-based methods and exhibit strong
performance in challenging highway scenes where other approaches often fail.
Additionally, comprehensive ablation studies validate the effectiveness of
cross-frame uncertainty propagation.

</details>


### [74] [Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection](https://arxiv.org/abs/2508.00587)
*Marc Hölle,Walter Kellermann,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 提出了一种基于不确定性感知的似然比估计方法，用于解决自动驾驶场景中语义分割模型对未知物体的错误分类问题。该方法利用证据分类器和似然比测试，结合不确定性建模，有效区分已知与未知像素特征，并在多个基准数据集上取得了较低的假阳性率和较高的平均精度。


<details>
  <summary>Details</summary>
Motivation: 当前语义分割模型在处理真实世界的自动驾驶场景时，往往对未知物体产生高置信度的错误分类。现有方法在复杂场景中难以区分罕见类物体和真正的未知物体，且缺乏对不确定性的显式建模。

Method: 1. 使用证据分类器在似然比测试框架下进行像素级特征分类。
2. 显式建模不确定性：通过概率分布表示训练样本稀有性和合成离群点不完美性带来的不确定性。
3. 改进离群点暴露方法：利用不确定性信息更有效地暴露模型于合成离群点。

Result: 在5个标准基准数据集上评估：
- 平均假阳性率（FPR）降至2.5%（当前最佳水平）
- 保持高平均精度（90.91%）
- 计算开销可忽略
代码已开源

Conclusion: 通过显式建模不确定性并将其纳入似然比测试框架，该方法显著提升了语义分割模型在开放世界场景中对未知物体的检测能力，以最小计算代价实现了最先进的离群点检测效果。

Abstract: Semantic segmentation models trained on known object classes often fail in
real-world autonomous driving scenarios by confidently misclassifying unknown
objects. While pixel-wise out-of-distribution detection can identify unknown
objects, existing methods struggle in complex scenes where rare object classes
are often confused with truly unknown objects. We introduce an
uncertainty-aware likelihood ratio estimation method that addresses these
limitations. Our approach uses an evidential classifier within a likelihood
ratio test to distinguish between known and unknown pixel features from a
semantic segmentation model, while explicitly accounting for uncertainty.
Instead of producing point estimates, our method outputs probability
distributions that capture uncertainty from both rare training examples and
imperfect synthetic outliers. We show that by incorporating uncertainty in this
way, outlier exposure can be leveraged more effectively. Evaluated on five
standard benchmark datasets, our method achieves the lowest average false
positive rate (2.5%) among state-of-the-art while maintaining high average
precision (90.91%) and incurring only negligible computational overhead. Code
is available at https://github.com/glasbruch/ULRE.

</details>


### [75] [A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)](https://arxiv.org/abs/2508.00590)
*Yihe Tian,Kwan Man Cheng,Zhengbo Zhang,Tao Zhang,Suju Li,Dongmei Yan,Bing Xu*

Main category: cs.CV

TL;DR: 提出了一种新型的两阶段重建框架（构建和细化），用于生成中国1986-2012年高分辨率夜空灯光（NTL）数据集（EVAL），解决了现有方法对光强低估和结构缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成VIIRS类历史夜空灯光数据时，存在光线强度被低估和结构缺失的缺陷，限制了长时间序列分析的准确性。

Method: 1. 构建阶段：使用分层融合解码器（HFD）提升初始重建的保真度；2. 细化阶段：引入双特征优化器（DFR），利用高分辨率不透水面掩膜指导细粒度结构增强。

Result: 开发了EVAL数据集，将中国夜空灯光数据追溯至1986年（26年）。定量评估显示，R²从0.68提升至0.80，RMSE从1.27降至0.99。数据集具有优秀的时间一致性和社会经济参数高相关性。

Conclusion: EVAL数据集显著优于现有产品，为长时间序列夜空灯光研究提供了高精度新资源。

Abstract: Artificial Night-Time Light (NTL) remote sensing is a vital proxy for
quantifying the intensity and spatial distribution of human activities.
Although the NPP-VIIRS sensor provides high-quality NTL observations, its
temporal coverage, which begins in 2012, restricts long-term time-series
studies that extend to earlier periods. Despite the progress in extending
VIIRS-like NTL time-series, current methods still suffer from two significant
shortcomings: the underestimation of light intensity and the structural
omission. To overcome these limitations, we propose a novel reconstruction
framework consisting of a two-stage process: construction and refinement. The
construction stage features a Hierarchical Fusion Decoder (HFD) designed to
enhance the fidelity of the initial reconstruction. The refinement stage
employs a Dual Feature Refiner (DFR), which leverages high-resolution
impervious surface masks to guide and enhance fine-grained structural details.
Based on this framework, we developed the Extended VIIRS-like Artificial
Nighttime Light (EVAL) product for China, extending the standard data record
backwards by 26 years to begin in 1986. Quantitative evaluation shows that EVAL
significantly outperforms existing state-of-the-art products, boosting the
$\text{R}^2$ from 0.68 to 0.80 while lowering the RMSE from 1.27 to 0.99.
Furthermore, EVAL exhibits excellent temporal consistency and maintains a high
correlation with socioeconomic parameters, confirming its reliability for
long-term analysis. The resulting EVAL dataset provides a valuable new resource
for the research community and is publicly available at
https://doi.org/10.11888/HumanNat.tpdc.302930.

</details>


### [76] [GeoMoE: Divide-and-Conquer Motion Field Modeling with Mixture-of-Experts for Two-View Geometry](https://arxiv.org/abs/2508.00592)
*Jiajun Le,Jiayi Ma*

Main category: cs.CV

TL;DR: 提出GeoMoE框架，利用混合专家和分解策略改进两视图几何中异构运动场的建模，在姿态和单应矩阵估计上超越SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有两视图几何方法在复杂场景（如视角/尺度剧变、深度突变）中对异构运动场建模不足，导致估计偏差。论文观察到混合专家（MoE）可将运动场分解为子场并分配专用专家处理，从而适应运动模式多样性。

Method: 1）概率先验引导分解：利用内点概率信号将运动场分解为异质子场，抑制离群点干扰；2）MoE增强双路修正器：对每个子场进行空间-通道双路径增强，并路由至定制专家进行精细建模和解耦。

Result: 在相对位姿估计和单应矩阵估计任务上超越之前最先进方法，并展现强泛化性。

Conclusion: GeoMoE通过运动场分解与专家定制建模有效处理异构运动模式，提升几何任务性能。

Abstract: Recent progress in two-view geometry increasingly emphasizes enforcing
smoothness and global consistency priors when estimating motion fields between
pairs of images. However, in complex real-world scenes, characterized by
extreme viewpoint and scale changes as well as pronounced depth
discontinuities, the motion field often exhibits diverse and heterogeneous
motion patterns. Most existing methods lack targeted modeling strategies and
fail to explicitly account for this variability, resulting in estimated motion
fields that diverge from their true underlying structure and distribution. We
observe that Mixture-of-Experts (MoE) can assign dedicated experts to motion
sub-fields, enabling a divide-and-conquer strategy for heterogeneous motion
patterns. Building on this insight, we re-architect motion field modeling in
two-view geometry with GeoMoE, a streamlined framework. Specifically, we first
devise a Probabilistic Prior-Guided Decomposition strategy that exploits inlier
probability signals to perform a structure-aware decomposition of the motion
field into heterogeneous sub-fields, sharply curbing outlier-induced bias.
Next, we introduce an MoE-Enhanced Bi-Path Rectifier that enhances each
sub-field along spatial-context and channel-semantic paths and routes it to a
customized expert for targeted modeling, thereby decoupling heterogeneous
motion regimes, suppressing cross-sub-field interference and representational
entanglement, and yielding fine-grained motion-field rectification. With this
minimalist design, GeoMoE outperforms prior state-of-the-art methods in
relative pose and homography estimation and shows strong generalization. The
source code and pre-trained models are available at
https://github.com/JiajunLe/GeoMoE.

</details>


### [77] [DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior](https://arxiv.org/abs/2508.00599)
*Junzhe Lu,Jing Lin,Hongkun Dou,Ailing Zeng,Yue Deng,Xian Liu,Zhongang Cai,Lei Yang,Yulun Zhang,Haoqian Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: DPoser-X，基于扩散的模型用于3D全身人体姿态建模


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态分布模型面临姿势复杂、全身姿态数据集质量低下或匮乏的挑战

Method: 使用基于扩散模型的身体姿态先验（DPoser），引入变分扩散采样以解决姿态中心的任务作为反向问题；设计了基于姿态数据特征的截断时间步调度方法；提出掩码训练机制，联合使用全身与局部数据集，捕捉身体部位间的依赖关系并避免特定动作过拟合

Result: 在多个人体姿态建模基准（身体、手、面部和全身姿态）上一致优于现有方法

Conclusion: 提出了一个稳健且多样化的姿态先验模型，为人体姿势建模设立了新的基准

Abstract: We present DPoser-X, a diffusion-based prior model for 3D whole-body human
poses. Building a versatile and robust full-body human pose prior remains
challenging due to the inherent complexity of articulated human poses and the
scarcity of high-quality whole-body pose datasets. To address these
limitations, we introduce a Diffusion model as body Pose prior (DPoser) and
extend it to DPoser-X for expressive whole-body human pose modeling. Our
approach unifies various pose-centric tasks as inverse problems, solving them
through variational diffusion sampling. To enhance performance on downstream
applications, we introduce a novel truncated timestep scheduling method
specifically designed for pose data characteristics. We also propose a masked
training mechanism that effectively combines whole-body and part-specific
datasets, enabling our model to capture interdependencies between body parts
while avoiding overfitting to specific actions. Extensive experiments
demonstrate DPoser-X's robustness and versatility across multiple benchmarks
for body, hand, face, and full-body pose modeling. Our model consistently
outperforms state-of-the-art alternatives, establishing a new benchmark for
whole-body human pose prior modeling.

</details>


### [78] [Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos](https://arxiv.org/abs/2508.00748)
*Laura Pedrouzo-Rodriguez,Pedro Delgado-DeRobles,Luis F. Gomez,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez*

Main category: cs.CV

TL;DR: 本文挑战基于头像的身份验证问题，提出使用面部运动模式作为行为生物特征，即使在视觉外观相同的头像中也能进行身份验证。研究者引入了一个新的数据集，并提出了一种轻量级、可解释的图卷积网络架构，实验证明面部运动特征可以实现有效的身份验证（AUC接近80%）。


<details>
  <summary>Details</summary>
Motivation: 随着逼真说话人头像在虚拟会议、游戏和社交平台中的普及，这些头像虽然增强了沉浸式交流体验，但同时也带来了严重的安全风险，特别是冒用他人头像进行欺诈的风险。攻击者可能窃取用户的头像（包括外貌和声音），使得仅凭视觉或听觉几乎无法检测出欺诈行为。因此，研究者在本文探索如何利用生物特征验证在这种头像交互场景中保证安全。核心问题是：当头像的视觉外观已被复制时，能否依靠个体的面部运动模式作为可靠的行为生物特征进行身份验证？

Method: 1. 数据集构建：使用先进的一阶头像生成模型GAGAvatar创建了一个新的数据集，包含真实用户及其冒用者的逼真头像视频。
2. 模型设计：提出了一种轻量级、可解释的时空图卷积网络架构。该架构仅使用面部关键点数据建模动态面部姿态，并通过时间注意力池化机制聚焦于最具判别力的时间片段。

Result: 实验结果表明，面部运动特征能够实现有效的身份验证，其性能指标(AUC)接近80%。这证明了即使在视觉外观完全相同的头像中，个体的独特面部运动模式也能作为可靠的行为生物特征进行身份识别。

Conclusion: 面部运动模式可作为头像场景中的有效生物特征防御手段。研究者提供了开源数据集和生物特征系统框架以推动该方向研究，并强调基于头像的通信系统急需更先进的行为生物特征防护技术。这一工作为未来开发针对头像欺骗的生物特征验证系统提供了重要参考。

Abstract: Photorealistic talking-head avatars are becoming increasingly common in
virtual meetings, gaming, and social platforms. These avatars allow for more
immersive communication, but they also introduce serious security risks. One
emerging threat is impersonation: an attacker can steal a user's
avatar-preserving their appearance and voice-making it nearly impossible to
detect its fraudulent usage by sight or sound alone. In this paper, we explore
the challenge of biometric verification in such avatar-mediated scenarios. Our
main question is whether an individual's facial motion patterns can serve as
reliable behavioral biometrics to verify their identity when the avatar's
visual appearance is a facsimile of its owner. To answer this question, we
introduce a new dataset of realistic avatar videos created using a
state-of-the-art one-shot avatar generation model, GAGAvatar, with genuine and
impostor avatar videos. We also propose a lightweight, explainable
spatio-temporal Graph Convolutional Network architecture with temporal
attention pooling, that uses only facial landmarks to model dynamic facial
gestures. Experimental results demonstrate that facial motion cues enable
meaningful identity verification with AUC values approaching 80%. The proposed
benchmark and biometric system are available for the research community in
order to bring attention to the urgent need for more advanced behavioral
biometric defenses in avatar-based communication systems.

</details>


### [79] [Minimum Data, Maximum Impact: 20 annotated samples for explainable lung nodule classification](https://arxiv.org/abs/2508.00639)
*Luisa Gallée,Catharina Silvia Lisson,Christoph Gerhard Lisson,Daniela Drees,Felix Weig,Daniel Vogele,Meinrad Beer,Michael Götz*

Main category: cs.CV

TL;DR: 使用扩散模型生成带有属性标注的医学影像，以解决医疗图像分析中可解释模型因属性标注数据稀缺而受限的问题。实验表明，使用少量真实标注样本生成数据训练模型，可显著提高属性预测和目标预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分类模型需要与临床推理一致的解释，因此需预测病理相关的视觉属性。然而，大规模带属性标注的医学影像数据集稀缺，限制了此类模型的开发与应用。

Method: 提出基于扩散模型的合成数据生成方法：1）使用LIDC-IDRI中仅20个带属性标注的肺结节样本；2）通过属性条件增强扩散模型；3）生成合成属性标注数据；4）将其加入可解释模型的训练中。

Result: 使用合成数据训练可解释模型后：1）属性预测准确率比仅使用小规模真实数据时提高13.4%；2）目标预测（即诊断）准确率提高1.8%。

Conclusion: 生成合成数据可有效突破医学影像分析中标注数据的规模限制，增强可解释模型的适用性。该方法在肺结节诊断中的有效性证明了扩散模型在此领域的潜力。

Abstract: Classification models that provide human-interpretable explanations enhance
clinicians' trust and usability in medical image diagnosis. One research focus
is the integration and prediction of pathology-related visual attributes used
by radiologists alongside the diagnosis, aligning AI decision-making with
clinical reasoning. Radiologists use attributes like shape and texture as
established diagnostic criteria and mirroring these in AI decision-making both
enhances transparency and enables explicit validation of model outputs.
However, the adoption of such models is limited by the scarcity of large-scale
medical image datasets annotated with these attributes. To address this
challenge, we propose synthesizing attribute-annotated data using a generative
model. We enhance the Diffusion Model with attribute conditioning and train it
using only 20 attribute-labeled lung nodule samples from the LIDC-IDRI dataset.
Incorporating its generated images into the training of an explainable model
boosts performance, increasing attribute prediction accuracy by 13.4% and
target prediction accuracy by 1.8% compared to training with only the small
real attribute-annotated dataset. This work highlights the potential of
synthetic data to overcome dataset limitations, enhancing the applicability of
explainable models in medical image analysis.

</details>


### [80] [Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](https://arxiv.org/abs/2508.00649)
*Junhao Zheng,Jiahao Sun,Chenhao Lin,Zhengyu Zhao,Chen Ma,Chong Zhang,Cong Wang,Qian Wang,Chao Shen*

Main category: cs.CV

TL;DR: 论文提出了一个统一和全面的补丁防御基准，包括11种代表性防御方法、2种攻击目标、13种补丁攻击、11种目标检测器和4种多样化的指标，构建了一个大规模的对抗补丁数据集。分析揭示了新的见解：自然主义补丁的防御难点在于数据分布而非高频特性；平均精度是防御性能的一致指标；自适应攻击能有效绕过现有防御，而复杂/随机模型或通用补丁属性的防御相对鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有针对目标检测器的补丁攻击防御评估缺乏统一和全面的框架，导致对当前方法的评估不一致且不完整。

Method: 重新审视11种代表性防御方法，建立首个补丁防御基准，涉及2种攻击目标、13种补丁攻击、11种目标检测器和4种指标。构建包含94种补丁类型和94,000张图像的大规模对抗补丁数据集。

Result: 分析得出新见解：自然主义补丁的防御难点在于数据分布而非高频特性；平均精度（AP）比补丁检测准确度更能一致反映防御性能；自适应攻击能有效绕过现有防御，复杂/随机模型或通用补丁属性的防御相对鲁棒。新数据集可将现有防御方法性能提高15.09% AP@0.5。

Conclusion: 该研究为补丁攻击/防御的评估提供了指导，并推动了其设计的发展。发布了代码和数据集，并将持续整合新的攻击/防御方法。

Abstract: Developing reliable defenses against patch attacks on object detectors has
attracted increasing interest. However, we identify that existing defense
evaluations lack a unified and comprehensive framework, resulting in
inconsistent and incomplete assessments of current methods. To address this
issue, we revisit 11 representative defenses and present the first patch
defense benchmark, involving 2 attack goals, 13 patch attacks, 11 object
detectors, and 4 diverse metrics. This leads to the large-scale adversarial
patch dataset with 94 types of patches and 94,000 images. Our comprehensive
analyses reveal new insights: (1) The difficulty in defending against
naturalistic patches lies in the data distribution, rather than the commonly
believed high frequencies. Our new dataset with diverse patch distributions can
be used to improve existing defenses by 15.09% AP@0.5. (2) The average
precision of the attacked object, rather than the commonly pursued patch
detection accuracy, shows high consistency with defense performance. (3)
Adaptive attacks can substantially bypass existing defenses, and defenses with
complex/stochastic models or universal patch properties are relatively robust.
We hope that our analyses will serve as guidance on properly evaluating patch
attacks/defenses and advancing their design. Code and dataset are available at
https://github.com/Gandolfczjh/APDE, where we will keep integrating new
attacks/defenses.

</details>


### [81] [Can Large Pretrained Depth Estimation Models Help With Image Dehazing?](https://arxiv.org/abs/2508.00698)
*Hongfei Zhang,Kun Zhou,Ruizheng Wu,Jiangbo Lu*

Main category: cs.CV

TL;DR: 该论文研究了预训练深度表示在图像去雾中的泛化能力，发现深度特征对雾霾级别具有鲁棒性。基于此，提出了一种即插即用的RGB-D融合模块，可适应多种去雾网络架构。实验验证了方法的有效性和广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 现有去雾方法基于大规模预训练模型，由于架构设计特定，难以灵活适应不同精度和效率要求的多样化场景。

Method: 1. 实证分析：验证预训练的深度表示特征在不同雾霾级别下具有一致性的现象。2. 提出即插即用的RGB-D融合模块，可无缝整合到各种去雾网络中。

Result: 在多个基准测试的大量实验证实了方法的有效性（提升去雾效果）和广泛适用性（兼容多种架构）。

Conclusion: 预训练深度特征对雾霾变化具有鲁棒性；所提出的通用融合模块能灵活增强各类去雾方法的性能。

Abstract: Image dehazing remains a challenging problem due to the spatially varying
nature of haze in real-world scenes. While existing methods have demonstrated
the promise of large-scale pretrained models for image dehazing, their
architecture-specific designs hinder adaptability across diverse scenarios with
different accuracy and efficiency requirements. In this work, we systematically
investigate the generalization capability of pretrained depth
representations-learned from millions of diverse images-for image dehazing. Our
empirical analysis reveals that the learned deep depth features maintain
remarkable consistency across varying haze levels. Building on this insight, we
propose a plug-and-play RGB-D fusion module that seamlessly integrates with
diverse dehazing architectures. Extensive experiments across multiple
benchmarks validate both the effectiveness and broad applicability of our
approach.

</details>


### [82] [Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation](https://arxiv.org/abs/2508.00766)
*Irene Iele,Francesco Di Feola,Valerio Guarrasi,Paolo Soda*

Main category: cs.CV

TL;DR: 该论文提出了一种用于医学图像到图像转换的动态测试时间适应（TTA）框架，通过样本感知的自适应机制处理分布外样本，提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的图像到图像转换技术在处理分布外样本时性能下降显著，且现有测试时间适应方法对所有样本（无论是否需要适应）都进行统一调整，导致对分布内样本产生负面影响。因此，需要一种动态调整方法，仅对需要适应的分布外样本进行针对性优化。

Method: 本文设计的新型测试时间适应框架包含两个关键模块：1) 重建模块（Reconstruction Module）用于量化和识别测试样本的域偏移程度；2) 动态自适应模块（Dynamic Adaptation Block）根据域偏移信息，选择性地调整预训练转换模型的内部特征。该机制仅在检测到显著域偏移时激活自适应操作，避免对不需求调整的分布内样本造成干扰。

Result: 在低剂量CT去噪和T1到T2 MRI转换两项医学图像任务中，该方法相比无TTA的基线模型和其他现有TTA方法均取得显著提升。消融实验表明，动态自适应机制优于统一调整策略，尤其在同时包含分布内外样本的场景中保持对分布内样本的性能不变。

Conclusion: 样本感知的测试时间适应能精准识别需调整的目标，通过特征级动态选择性优化实现分布外样本适应与分布内样本保护的平衡。这为提升实际应用中模型的鲁棒性提供有效思路。

Abstract: Image-to-image translation has emerged as a powerful technique in medical
imaging, enabling tasks such as image denoising and cross-modality conversion.
However, it suffers from limitations in handling out-of-distribution samples
without causing performance degradation. To address this limitation, we propose
a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the
translation process based on the characteristics of each test sample. Our
method introduces a Reconstruction Module to quantify the domain shift and a
Dynamic Adaptation Block that selectively modifies the internal features of a
pretrained translation model to mitigate the shift without compromising the
performance on in-distribution samples that do not require adaptation. We
evaluate our approach on two medical image-to-image translation tasks: low-dose
CT denoising and T1 to T2 MRI translation, showing consistent improvements over
both the baseline translation model without TTA and prior TTA methods. Our
analysis highlights the limitations of the state-of-the-art that uniformly
apply the adaptation to both out-of-distribution and in-distribution samples,
demonstrating that dynamic, sample-specific adjustment offers a promising path
to improve model resilience in real-world scenarios. The code is available at:
https://github.com/cosbidev/Sample-Aware_TTA.

</details>


### [83] [MIHBench: Benchmarking and Mitigating Multi-Image Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2508.00726)
*Jiale Li,Mingrui Wu,Zixiang Jin,Hao Chen,Jiayi Ji,Xiaoshuai Sun,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: 该研究针对多模态大语言模型在单图像设定中的幻觉问题延伸到多图像场景的研究不足，提出了首个专门评估多图像对象相关幻觉的基准MIHBench。该基准包含三个核心任务，考察对象存在、数量推理和跨视图一致性。研究发现多图像幻觉的关键因素，并提出动态注意力平衡机制以减轻幻觉发生，实验证明该机制有效提升多图像场景下的语义整合和推理稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有关于多模态大语言模型（MLLMs）产生幻觉的研究主要集中在单图像场景，而对多图像场景中的这一问题缺乏系统性研究。本研究致力于填补这一空白，首次对多图像MLLMs中的幻觉问题进行系统分析，并建立相应评估指标。

Method: 首先构建多图像对象幻觉基准（MIHBench），包含三个任务：多图像对象存在幻觉、对象数量幻觉和对象身份一致性幻觉评测。通过大量评估识别多图像幻觉的关键影响因素。基于这些关键因素，提出动态注意力平衡机制，在保持整体视觉注意力比例的前提下，调整图像间的注意力分布。

Result: 通过评测多个前沿MLLMs，发现多图像幻觉出现的三大关键因素：图像输入数量与幻觉发生概率呈现渐进关系；单图像对象的幻觉倾向在多图像场景中显著相关；同一对象的图片占比和其负样本在序列中的位置都会影响幻觉发生。实验证明动态注意力平衡机制能有效减少多图像场景中的幻觉发生，增强语义整合和推理稳定性。

Conclusion: 多图像场景下的对象相关幻觉问题尚未得到充分研究。本文首次系统化地揭示了多图像MLLMs的幻觉表现特征与关联因素，提出了新的评估基准与解决方案。动态注意力平衡机制有效提升了多图像场景的处理能力，为后续研究提供了思路与工具。

Abstract: Despite growing interest in hallucination in Multimodal Large Language
Models, existing studies primarily focus on single-image settings, leaving
hallucination in multi-image scenarios largely unexplored. To address this gap,
we conduct the first systematic study of hallucinations in multi-image MLLMs
and propose MIHBench, a benchmark specifically tailored for evaluating
object-related hallucinations across multiple images. MIHBench comprises three
core tasks: Multi-Image Object Existence Hallucination, Multi-Image Object
Count Hallucination, and Object Identity Consistency Hallucination, targeting
semantic understanding across object existence, quantity reasoning, and
cross-view identity consistency. Through extensive evaluation, we identify key
factors associated with the occurrence of multi-image hallucinations,
including: a progressive relationship between the number of image inputs and
the likelihood of hallucination occurrences; a strong correlation between
single-image hallucination tendencies and those observed in multi-image
contexts; and the influence of same-object image ratios and the positional
placement of negative samples within image sequences on the occurrence of
object identity consistency hallucination. To address these challenges, we
propose a Dynamic Attention Balancing mechanism that adjusts inter-image
attention distributions while preserving the overall visual attention
proportion. Experiments across multiple state-of-the-art MLLMs demonstrate that
our method effectively reduces hallucination occurrences and enhances semantic
integration and reasoning stability in multi-image scenarios.

</details>


### [84] [YOLO-Count: Differentiable Object Counting for Text-to-Image Generation](https://arxiv.org/abs/2508.00728)
*Guanning Zeng,Xiang Zhang,Zirui Wang,Haiyang Xu,Zeyuan Chen,Bingnan Li,Zhuowen Tu*

Main category: cs.CV

TL;DR: YOLO-Count: 一种可微分的开放词汇对象计数模型，解决了通用计数挑战，并为文本到图像（T2I）生成提供精确的数量控制。核心创新是'基数'图，一种适应对象大小和空间分布变化的新回归目标。通过表示对齐和混合强-弱监督方案，该模型在开放词汇计数与T2I生成控制之间架起桥梁。其全可微架构支持基于梯度的优化，实现准确对象数量估计并为生成模型提供细粒度指导。实验证明其达到最先进计数精度，并为T2I系统提供强大有效的数量控制。


<details>
  <summary>Details</summary>
Motivation: 当前开放词汇对象计数任务存在挑战，且缺乏对文本到图像生成过程中对象数量的精确控制能力。需要一种能够同时处理通用计数问题并为生成模型提供可靠数量指导的方法。

Method: 1. 提出新型回归目标'cardinality map'（基数图），以应对不同对象大小和空间分布的变异性
2. 构建全可微分架构，支持基于梯度的优化
3. 使用表示对齐技术进行特征融合
4. 开发强-弱混合监督训练方案
5. 将该计数模型无缝集成到文本到图像系统框架中

Result: 1. 在多个基准测试上达到SOTA开放词汇对象计数性能
2. 有效增强文本到图像系统的数量控制能力
3. 定量评估显示计数错误率显著降低
4. 生成的图像在对象数量精度方面表现优异

Conclusion: YOLO-Count成功建立可微分计数模型与生成控制的桥梁，提出的基数图机制有效解决计数任务中的尺寸分布差异问题。该方法为图像生成领域提供了前所未有的数量控制精度。

Abstract: We propose YOLO-Count, a differentiable open-vocabulary object counting model
that tackles both general counting challenges and enables precise quantity
control for text-to-image (T2I) generation. A core contribution is the
'cardinality' map, a novel regression target that accounts for variations in
object size and spatial distribution. Leveraging representation alignment and a
hybrid strong-weak supervision scheme, YOLO-Count bridges the gap between
open-vocabulary counting and T2I generation control. Its fully differentiable
architecture facilitates gradient-based optimization, enabling accurate object
count estimation and fine-grained guidance for generative models. Extensive
experiments demonstrate that YOLO-Count achieves state-of-the-art counting
accuracy while providing robust and effective quantity control for T2I systems.

</details>


### [85] [Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR](https://arxiv.org/abs/2508.00744)
*Adwait Chandorkar,Hasan Tercan,Tobias Meisen*

Main category: cs.CV

TL;DR: 本文提出了一个轻量级的骨干网络Dense Backbone，它专为点云数据的3D物体检测设计。该骨干网络结合了高处理速度、轻量级架构和强健的检测精度的特点，可以无缝集成到现有架构中。


<details>
  <summary>Details</summary>
Motivation: 虽然基于LiDAR的3D物体检测已取得显著进展，但大多数方法仍依赖于复杂的VGG或ResNet骨干网络。尽管在2D物体检测中轻量级骨干网络设计已有研究，但在3D物体检测方面仍显不足。为此，本文旨在设计一种既轻量又高效的骨干网络，以减少计算成本同时保持检测精度。

Method: 本文引入了Dense Backbone，一个轻量级的骨干网络，特别为点云数据的3D物体检测而设计。该方法通过重新设计骨干网络的结构，减少了参数数量和计算延迟。作者将这种骨干网络应用于多个先进的3D物体检测器（如PillarNet），形成新模型（如DensePillarNet）。Dense Backbone可直接替换现有检测器中的骨干网络，而不需更改其他网络组件。

Result: 实验表明，使用Dense Backbone的模型在显著降低计算成本的同时，保持了高检测精度。以PillarNet为基础构建的DensePillarNet为例，模型参数量减少了29%，延迟降低了28%，在nuScenes测试集上的检测精度仅下降2%。

Conclusion: Dense Backbone作为一种轻量级骨干网络，有效地在3D物体检测中平衡了速度和精度，具有即插即用的特性。这为在资源受限环境中部署高性能3D物体检测提供了一种可行方案。

Abstract: Recent advancements in LiDAR-based 3D object detection have significantly
accelerated progress toward the realization of fully autonomous driving in
real-world environments. Despite achieving high detection performance, most of
the approaches still rely on a VGG-based or ResNet-based backbone for feature
exploration, which increases the model complexity. Lightweight backbone design
is well-explored for 2D object detection, but research on 3D object detection
still remains limited. In this work, we introduce Dense Backbone, a lightweight
backbone that combines the benefits of high processing speed, lightweight
architecture, and robust detection accuracy. We adapt multiple SoTA 3d object
detectors, such as PillarNet, with our backbone and show that with our
backbone, these models retain most of their detection capability at a
significantly reduced computational cost. To our knowledge, this is the first
dense-layer-based backbone tailored specifically for 3D object detection from
point cloud data. DensePillarNet, our adaptation of PillarNet, achieves a 29%
reduction in model parameters and a 28% reduction in latency with just a 2%
drop in detection accuracy on the nuScenes test set. Furthermore, Dense
Backbone's plug-and-play design allows straightforward integration into
existing architectures, requiring no modifications to other network components.

</details>


### [86] [GECO: Geometrically Consistent Embedding with Lightspeed Inference](https://arxiv.org/abs/2508.00746)
*Regine Hartwig,Dominik Muhle,Riccardo Marin,Daniel Cremers*

Main category: cs.CV

TL;DR: GECO 是一种轻量级特征学习方法，用于生成几何一致的特征，在保留语义的同时更好地理解3D几何。运行速度快且性能优异，在三个数据集上取得了SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督视觉基础模型能够捕捉语义对应关系，但在底层3D几何结构的感知方面存在不足。

Method: GECO 提出了一种基于最优传输的训练框架，该框架支持在遮挡和去遮挡情况下进行超出关键点的监督。

Result: 在 PFPascal、APK 和 CUB 三个数据集上的新 SOTA，提升了 PCK 指标 6.0%、6.2% 和 4.1%。模型速度达到30 fps，比之前方法快98.2%。

Conclusion: PCK 指标不足以全面评估几何质量，因此还引入了新指标来促进更注重几何的特征学习。

Abstract: Recent advances in feature learning have shown that self-supervised vision
foundation models can capture semantic correspondences but often lack awareness
of underlying 3D geometry. GECO addresses this gap by producing geometrically
coherent features that semantically distinguish parts based on geometry (e.g.,
left/right eyes, front/back legs). We propose a training framework based on
optimal transport, enabling supervision beyond keypoints, even under occlusions
and disocclusions. With a lightweight architecture, GECO runs at 30 fps, 98.2%
faster than prior methods, while achieving state-of-the-art performance on
PFPascal, APK, and CUB, improving PCK by 6.0%, 6.2%, and 4.1%, respectively.
Finally, we show that PCK alone is insufficient to capture geometric quality
and introduce new metrics and insights for more geometry-aware feature
learning. Link to project page:
https://reginehartwig.github.io/publications/geco/

</details>


### [87] [SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation](https://arxiv.org/abs/2508.00750)
*Prerana Ramkumar*

Main category: cs.CV

TL;DR: SU-ESRGAN是一种专为卫星图像设计的超分辨率框架，通过集成ESRGAN、DeepLabv3的分割损失和Monte Dropout来提升图像的语义一致性和提供像素级置信度，解决GAN在关键遥感应用中缺乏可信度的问题。


<details>
  <summary>Details</summary>
Motivation: 生成对抗网络（GANs）在图像超分辨率上虽能生成逼真图像，但缺乏语义一致性和逐像素置信度，限制了其在灾害响应、城市规划和农业等关键遥感应用中的可信度。因此，需要一种能够提升这些方面的方法。

Method: 提出SU-ESRGAN框架，结合ESRGAN生成模型，使用DeepLabv3引入分割损失以保持类别细节，并采用Monte Carlo dropout生成像素级不确定性图。模型还具备模块化设计，可集成到无人机数据处理流程中进行机载或后处理超分辨率。此外，通过微调评估跨域应用性能。

Result: 在航空影像上，SU-ESRGAN的PSNR、SSIM和LPIPS指标与基线ESRGAN相当。在跨域测试中，模型在两个无人机数据集上表现出不同的适应性，特别在成像特征与训练数据相似的Aerial Maritime Drone数据集上表现出更强的适应性，凸显了领域自适应训练在超分辨率应用中的重要性。

Conclusion: SU-ESRGAN首次在卫星图像超分辨率中集成了语义一致性和不确定性估计，为关键遥感应用提供了更可靠的图像增强。模型在保持传统指标性能的同时，增强了可信度，其模块化设计适合无人机平台应用。跨域实验表明，训练数据与目标域的匹配对性能至关重要。

Abstract: Generative Adversarial Networks (GANs) have achieved realistic
super-resolution (SR) of images however, they lack semantic consistency and
per-pixel confidence, limiting their credibility in critical remote sensing
applications such as disaster response, urban planning and agriculture. This
paper introduces Semantic and Uncertainty-Aware ESRGAN (SU-ESRGAN), the first
SR framework designed for satellite imagery to integrate the ESRGAN,
segmentation loss via DeepLabv3 for class detail preservation and Monte Carlo
dropout to produce pixel-wise uncertainty maps. The SU-ESRGAN produces results
(PSNR, SSIM, LPIPS) comparable to the Baseline ESRGAN on aerial imagery. This
novel model is valuable in satellite systems or UAVs that use wide
field-of-view (FoV) cameras, trading off spatial resolution for coverage. The
modular design allows integration in UAV data pipelines for on-board or
post-processing SR to enhance imagery resulting due to motion blur, compression
and sensor limitations. Further, the model is fine-tuned to evaluate its
performance on cross domain applications. The tests are conducted on two drone
based datasets which differ in altitude and imaging perspective. Performance
evaluation of the fine-tuned models show a stronger adaptation to the Aerial
Maritime Drone Dataset, whose imaging characteristics align with the training
data, highlighting the importance of domain-aware training in SR-applications.

</details>


### [88] [Zero-Shot Anomaly Detection with Dual-Branch Prompt Learning](https://arxiv.org/abs/2508.00777)
*Zihan Wang,Samira Ebrahimi Kahou,Narges Armanfard*

Main category: cs.CV

TL;DR: 该论文提出了名为PILOT的框架，用于解决现有零样本异常检测（ZSAD）方法在领域偏移下泛化能力不足的问题。PILOT通过双分支提示学习和无标签测试时自适应策略，在多个工业与医学基准测试中实现了最先进的异常检测与定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有ZSAD方法在领域偏移情况下表现不佳，因为它们基于有限训练领域数据构建的固定或学习提示无法适应新分布。

Method: 1. 设计双分支提示学习机制：动态整合可学习提示池与结构化语义属性，使模型能自适应加权输入图像的最相关异常线索。
2. 提出无标签测试时自适应策略：利用未标注测试数据的高置信度伪标签更新可学习提示参数。

Result: 在13个工业及医学基准测试中，PILOT在领域偏移下的异常检测和定位均达到state-of-the-art性能。

Conclusion: PILOT框架通过动态提示集成和测试时自适应，显著提升了零样本异常检测在跨域场景的泛化能力，为解决该领域的关键挑战提供了有效方案。

Abstract: Zero-shot anomaly detection (ZSAD) enables identifying and localizing defects
in unseen categories by relying solely on generalizable features rather than
requiring any labeled examples of anomalies. However, existing ZSAD methods,
whether using fixed or learned prompts, struggle under domain shifts because
their training data are derived from limited training domains and fail to
generalize to new distributions. In this paper, we introduce PILOT, a framework
designed to overcome these challenges through two key innovations: (1) a novel
dual-branch prompt learning mechanism that dynamically integrates a pool of
learnable prompts with structured semantic attributes, enabling the model to
adaptively weight the most relevant anomaly cues for each input image; and (2)
a label-free test-time adaptation strategy that updates the learnable prompt
parameters using high-confidence pseudo-labels from unlabeled test data.
Extensive experiments on 13 industrial and medical benchmarks demonstrate that
PILOT achieves state-of-the-art performance in both anomaly detection and
localization under domain shift.

</details>


### [89] [Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST Point Cloud City Datasets for 3D Deep Learning](https://arxiv.org/abs/2508.00822)
*Alexander Nikitas Dimopoulos,Joseph Grasso*

Main category: cs.CV

TL;DR: 本文分析了公共安全应用相关点云数据跨异构标记语义分割的表现，发现大型物体分割效果较好，而关键小物体检测较差。研究指出了标签不统一、数据不足和小物体几何特征不明确等问题，并提出标准化标注与自动化标注作为潜在方向。


<details>
  <summary>Details</summary>
Motivation: 公共安全领域点云语义分割模型在实际应用中遇到异质标记数据难以统一训练的问题，这阻碍了其应用效果。因此，本研究的动机在于探索如何克服这些标记差异问题并评估现有模型对安全相关要素（特别是小型安全关键物体）的分割表现。

Method: 使用美国国家标准与技术研究院（NIST）的Point Cloud City数据集（包括Enfield和Memphis子集），采用分级标签架构统一异构标注。基础模型为KPConv（一种点云卷积神经网络），通过交并比（IoU）作为核心评价指标，特别关注公共安全相关要素（如楼梯、窗户等大型可导航物体，以及小体积安全关键物体）。具体方法包括（1）构建标签映射规则以适配不同标注体系；（2）评估不同物体类型的IoU分布；（3）分析类别不平衡和小物体几何特征局限性对模型的影响。

Result: 1. 几何特征明显的大型物体（如楼梯、窗户等可导航元素）IoU表现较高；
2. 对安全至关重要的小型物体（如消防栓、报警器等）识别率显著偏低；
3. 性能差异主要受两类因素影响：数据集中的类别不平衡（部分物体样本稀少），以及原始激光雷达扫描对小物体的几何细节捕捉不足导致的特征模糊。

Conclusion: 公共安全点云语义分割可靠性受限于三类问题：数据标记异构性、安全关键小物体检测能力不足及标注数据稀缺。未来方向应包括：(1) 推进点云标注标准化协议；(2) 研发自动化标注技术提升小物体特征提取能力；(3) 探索跨数据集的联合训练策略以缓解样本不足。

Abstract: This study analyzes semantic segmentation performance across heterogeneously
labeled point-cloud datasets relevant to public safety applications, including
pre-incident planning systems derived from lidar scans. Using NIST's Point
Cloud City dataset (Enfield and Memphis collections), we investigate challenges
in unifying differently labeled 3D data. Our methodology employs a graded
schema with the KPConv architecture, evaluating performance through IoU metrics
on safety-relevant features. Results indicate performance variability:
geometrically large objects (e.g. stairs, windows) achieve higher segmentation
performance, suggesting potential for navigational context, while smaller
safety-critical features exhibit lower recognition rates. Performance is
impacted by class imbalance and the limited geometric distinction of smaller
objects in typical lidar scans, indicating limitations in detecting certain
safety-relevant features using current point-cloud methods. Key identified
challenges include insufficient labeled data, difficulties in unifying class
labels across datasets, and the need for standardization. Potential directions
include automated labeling and multi-dataset learning strategies. We conclude
that reliable point-cloud semantic segmentation for public safety necessitates
standardized annotation protocols and improved labeling techniques to address
data heterogeneity and the detection of small, safety-critical elements.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems](https://arxiv.org/abs/2508.00079)
*Oshayer Siddique,J. M Areeb Uzair Alam,Md Jobayer Rahman Rafy,Syed Rifat Raiyan,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

TL;DR: 这是一篇评估大型语言模型（LLMs）在解决物理问题（包括数学和描述性问题）上的性能的论文。作者引入了一个新的评估基准 PhysicsEval，其中包含 19,609 个来自物理教科书的问题和它们的正确答案，并从论坛和网站上收集数据。作者还应用多种推理技术和代理框架来改进模型表现，尤其是在模型初始表现不佳时使用多代理框架有明显提升。代码和数据已开源。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言推理能力的提升，评估在物理学问题上的性能变得重要。尽管有一些相关工作，但需要标准化的基准测试和性能提升的方法。为此，这项研究旨在：评估前沿 LLMs 在解决物理问题（数学和描述性）的表现；利用推理技术和代理框架（如多个小型代理的协同验证）提升表现；创建新的测试基准 PhysicsEval。

Method: 1. 设计测试集 PhysicsEval：从各种物理教科书和在线资源（如论坛和官方网站）中提取 19,609 个问题及其答案。2. 在初始测试中评估各前沿大型语言模型（数学与描述性物理问题）。3. 采用推理技术（如思维链、小样本学习）和代理框架：在多代理框架中，使用多个小型代理逐步验证解决方案结果；其中包含累计式的验证处理。4. 比较不同技术的性能和有效性（尤其是对模型初始表现不佳任务的改进程度）。

Result: 1. 提出了新的基准 PhysicsEval，包含19,609个问题和答案；2. 模型在多代理框架中的表现显著提高（针对初始表现差的问题）；3. 开源数据和代码以便复现；4. 不同技术提升了LLMs在物理推理上解决能力。

Conclusion: 新基准 PhysicsEval 对评估物理推理提供了一个标准化的基础；多代理框架在改进初始表现不佳的模型上非常有效，验证技术（分布式多代理）有助于提高LLMs解决物理问题的能力。模型代码和基准数据已公开发布。

Abstract: The discipline of physics stands as a cornerstone of human intellect, driving
the evolution of technology and deepening our understanding of the fundamental
principles of the cosmos. Contemporary literature includes some works centered
on the task of solving physics problems - a crucial domain of natural language
reasoning. In this paper, we evaluate the performance of frontier LLMs in
solving physics problems, both mathematical and descriptive. We also employ a
plethora of inference-time techniques and agentic frameworks to improve the
performance of the models. This includes the verification of proposed solutions
in a cumulative fashion by other, smaller LLM agents, and we perform a
comparative analysis of the performance that the techniques entail. There are
significant improvements when the multi-agent framework is applied to problems
that the models initially perform poorly on. Furthermore, we introduce a new
evaluation benchmark for physics problems, ${\rm P{\small HYSICS}E{\small
VAL}}$, consisting of 19,609 problems sourced from various physics textbooks
and their corresponding correct solutions scraped from physics forums and
educational websites. Our code and data are publicly available at
https://github.com/areebuzair/PhysicsEval.

</details>


### [91] [Do LLMs produce texts with "human-like" lexical diversity?](https://arxiv.org/abs/2508.00086)
*Kelly Kendro,Jeffrey Maloney,Scott Jarvis*

Main category: cs.CL

TL;DR: 研究通过词汇多样性分析发现，ChatGPT生成的文本在多个词汇多样性维度上与人类写作存在显著差异，且新模型（如ChatGPT-4.5）产生的文本差异更大。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM（大型语言模型）的产出经常被讨论是否接近人类写作，但其词汇多样性与人类写作的对比仍不明确。本研究旨在通过对比不同ChatGPT模型与不同教育背景的L1/L2英语写作者的文本，探究LLM生成文本在词汇多样性上是否真正类人。

Method: 1. 收集来自四款ChatGPT模型(-3.5, -4, -o4 mini, -4.5)生成的文本以及240名L1/L2英语写作者（按教育水平分组）的文本。
2. 测量每个文本的六个词汇多样性维度：数量(volume)、丰度(abundance)、多样性与重复度(variety-repetition)、均匀度(evenness)、差异度(disparity)和离散度(dispersion)。
3. 使用单变量方差分析(ANOVA)、多变量方差分析(MANOVA)和支持向量机(SVM)进行数据统计和模型区分。

Result: 1. 所有ChatGPT生成的文本在词汇多样性各维度上与人类写作均有显著差异（p<0.05）。
2. ChatGPT-o4 mini和4.5的文本与人类差异最大，且ChatGPT-4.5在生成更少词数的情况下仍展现出更高的词汇多样性。
3. 人类写作者的词汇多样性在教育水平和语言背景（L1/L2）上无显著差异。

Conclusion: LLM（特别是新版模型）无法在词汇多样性层面产生类人文本，新版模型甚至比旧模型更偏离人类写作特征。这一结果对语言教学及LLM应用具有启示意义：需警惕过度依赖新模型可能产生的非自然语言输出。

Abstract: The degree to which LLMs produce writing that is truly human-like remains
unclear despite the extensive empirical attention that this question has
received. The present study addresses this question from the perspective of
lexical diversity. Specifically, the study investigates patterns of lexical
diversity in LLM-generated texts from four ChatGPT models (-3.5, -4, -o4 mini,
and -4.5) in comparison with texts written by L1 and L2 English participants (n
= 240) across four education levels. Six dimensions of lexical diversity were
measured in each text: volume, abundance, variety-repetition, evenness,
disparity, and dispersion. Results from one-way MANOVAs, one-way ANOVAS, and
Support Vector Machines revealed that the LLM-generated texts differed
significantly from human-written texts for each variable, with ChatGPT-o4 mini
and -4.5 differing the most. Within these two groups, ChatGPT-4.5 demonstrated
higher levels of lexical diversity despite producing fewer tokens. The human
writers' lexical diversity did not differ across subgroups (i.e., education,
language status). Altogether, the results indicate that LLMs do not produce
human-like texts in relation to lexical diversity, and the newer LLMs produce
less human-like texts than older models. We discuss the implications of these
results for language pedagogy and related applications.

</details>


### [92] [Semiotic Complexity and Its Epistemological Implications for Modeling Culture](https://arxiv.org/abs/2508.00095)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 该论文呼吁计算人文学科加强方法论的哲学思考和理论化，特别是将建模工作视为一种翻译过程（从文化语言领域到数学计算领域再返回），并指出缺乏理论化会导致翻译错误，尤其是忽视符号复杂性（文本意义随解释视角变化），导致数据被错误地视为符号简单化。


<details>
  <summary>Details</summary>
Motivation: 计算人文学科需要在方法论上进行更多的理论化探索，以提升其认识论和解释的清晰度，并促进领域成熟。论文揭示当前建模实践中因缺乏充分理论化导致的翻译错误，具体表现为将符号复杂的文本视为符号简单化进行处理。

Method: 将计算人文学科建模工作框架定义为翻译过程（文化/语言领域→数学/计算领域→返回），提出符号复杂性概念（文本意义随解释变化的程度），批判主流建模实践在评估时忽略符号复杂性而采取简便化处理的错误。

Result: 论证了忽视符号复杂性的处理会产生翻译错误，损害研究的内部一致性、透明度。同时提出具体建设性意见，包括提高符号复杂性的理论认识、建模评估中纳入多视角考量等。

Conclusion: 论文呼吁计算人文学科研究者重视建模背后的认识论问题，尤其符号复杂性对翻译过程的影响；采用本文提出的建议可帮助避免翻译错误、提升研究严谨性和解释透明度。

Abstract: Greater theorizing of methods in the computational humanities is needed for
epistemological and interpretive clarity, and therefore the maturation of the
field. In this paper, we frame such modeling work as engaging in translation
work from a cultural, linguistic domain into a computational, mathematical
domain, and back again. Translators benefit from articulating the theory of
their translation process, and so do computational humanists in their work --
to ensure internal consistency, avoid subtle yet consequential translation
errors, and facilitate interpretive transparency. Our contribution in this
paper is to lay out a particularly consequential dimension of the lack of
theorizing and the sorts of translation errors that emerge in our modeling
practices as a result. Along these lines we introduce the idea of semiotic
complexity as the degree to which the meaning of some text may vary across
interpretive lenses, and make the case that dominant modeling practices --
especially around evaluation -- commit a translation error by treating
semiotically complex data as semiotically simple when it seems
epistemologically convenient by conferring superficial clarity. We then lay out
several recommendations for researchers to better account for these
epistemological issues in their own work.

</details>


### [93] [FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality](https://arxiv.org/abs/2508.00109)
*Mingda Chen,Yang Li,Xilun Chen,Adina Williams,Gargi Ghosh,Scott Yih*

Main category: cs.CL

TL;DR: 提出名为FACTORY的大规模、人工验证的长文本事实性评估基准集，旨在评估模型生成准确、全面的短提示响应的能力。该基准集通过模型辅助和人工精炼开发，包含事实性强、可回答且无歧义的挑战性提示。在6个SOTA模型上评估发现，约40%的模型生成声明不具事实性，远超其他数据集10%的错误率。


<details>
  <summary>Details</summary>
Motivation: 现有长文本事实性评估基准缺乏人工验证，导致质量不可靠。为解决此问题，开发更可靠、具备挑战性的基准集。

Method: 1. 采用模型辅助循环（model-in-the-loop）方法开发初始提示集；2. 人工精炼得到FACTORY基准集，确保其具备事实明确性、可回答性与清晰性；3. 在6个前沿语言模型上同时使用FACTORY和现有数据集进行人工评估；4. 对比分析模型在两类数据集上的声明级事实错误率。

Result: 1. FACTORY基准集展示出更强挑战性：SOTA模型生成的声明中约40%存在事实错误，显著高于其他数据集10%的错误率；2. 验证了新基准的可靠性，并证明其能有效驱动模型对长尾事实进行推理的需求。

Conclusion: FACTORY基准填补了长文本事实性评估中人工验证数据的空缺，解决了现有基准质量缺陷。其高错误率揭示了模型在复杂事实推理上的薄弱性，为未来模型优化提供了明确方向。

Abstract: Long-form factuality evaluation assesses the ability of models to generate
accurate, comprehensive responses to short prompts. Existing benchmarks often
lack human verification, leading to potential quality issues. To address this
limitation, we introduce FACTORY, a large-scale, human-verified prompt set.
Developed using a model-in-the-loop approach and refined by humans, FACTORY
includes challenging prompts that are fact-seeking, answerable, and
unambiguous. We conduct human evaluations on 6 state-of-the-art language models
using FACTORY and existing datasets. Our results show that FACTORY is a
challenging benchmark: approximately 40% of the claims made in the responses of
SOTA models are not factual, compared to only 10% for other datasets. Our
analysis identifies the strengths of FACTORY over prior benchmarks, emphasizing
its reliability and the necessity for models to reason across long-tailed
facts.

</details>


### [94] [Is neural semantic parsing good at ellipsis resolution, or isn't it?](https://arxiv.org/abs/2508.00121)
*Xiao Zhang,Johan bos*

Main category: cs.CL

TL;DR: 论文研究神经语义解析器在处理强上下文依赖现象（如英语动词短语省略）时的表现。尽管解析器在标准测试集上表现优异（匹配分超过90％），但在专门构建的120个省略案例的挑战集上失败率高。研究采用了数据增强方法尝试改进性能。


<details>
  <summary>Details</summary>
Motivation: 动机是评估神经语义解析器在处理强上下文敏感现象（特别是英语动词短语省略）时的能力。这种现象要求复制大量语义信息以形成完整的语义表示，而目前解析器在标准测试中表现良好，但在这种复杂结构上可能性能不足。研究者旨在通过挑战集检验其鲁棒性。

Method: 研究方法包括：1. 构建一个包含120个动词短语省略案例的专用挑战集，每个案例附带完整解析的语义表示；2. 使用多款主流神经语义解析器在该挑战集上进行测试；3. 针对解析器表现不佳的情况，引入数据增强策略尝试提升性能。

Result: 结果显示：尽管解析器在常规测试集上达到超过90%的语义匹配分，但在省略挑战集上失败率显著上升。数据增强方法对性能提升效果有限，表明当前神经语义解析器对上下文敏感现象的泛化能力不足。

Conclusion: 结论指出当前神经语义解析器对动词短语省略等强上下文依赖结构处理能力薄弱。该挑战集可作为未来模型鲁棒性评估的基准。研究呼吁开发更先进的上下文建模机制以解决此类语言现象。

Abstract: Neural semantic parsers have shown good overall performance for a variety of
linguistic phenomena, reaching semantic matching scores of more than 90%. But
how do such parsers perform on strongly context-sensitive phenomena, where
large pieces of semantic information need to be duplicated to form a meaningful
semantic representation? A case in point is English verb phrase ellipsis, a
construct where entire verb phrases can be abbreviated by a single auxiliary
verb. Are the otherwise known as powerful semantic parsers able to deal with
ellipsis or aren't they? We constructed a corpus of 120 cases of ellipsis with
their fully resolved meaning representation and used this as a challenge set
for a large battery of neural semantic parsers. Although these parsers
performed very well on the standard test set, they failed in the instances with
ellipsis. Data augmentation

</details>


### [95] [Comparison of Large Language Models for Deployment Requirements](https://arxiv.org/abs/2508.00185)
*Alper Yaman,Jannik Schwab,Christof Nitsche,Abhirup Sinha,Marco Huber*

Main category: cs.CL

TL;DR: 本文为研究者和企业提供了一个持续更新的开源大语言模型（LLM）比较清单，涵盖基础模型和领域专用模型，重点关注发布年份、许可协议和硬件需求等特征，以帮助在快速发展的大语言模型领域中进行模型选择。


<details>
  <summary>Details</summary>
Motivation: 由于开源基础模型和微调模型的激增，研究者和公司在选择适合自身许可协议和硬件要求的大语言模型时面临困难。

Method: 作者编制了一个包含基础和领域专用大语言模型的比较列表，关注关键特征如下：发布年份、许可协议（开源协议）和最低硬件要求（如显存）。该列表已在GitLab上发布，并将持续更新以反映最新发展。

Result: 项目成果是一份在GitLab上发布的、可动态更新的全面比较清单，使研究者和公司能便捷地评估和选择符合其技术需求和约束的大语言模型。

Conclusion: 通过提供一份实时更新的大语言模型比较资源，本文降低了领域内模型选择的技术门槛，助力研究社区和工业界更高效地利用LLM技术。

Abstract: Large Language Models (LLMs), such as Generative Pre-trained Transformers
(GPTs) are revolutionizing the generation of human-like text, producing
contextually relevant and syntactically correct content. Despite challenges
like biases and hallucinations, these Artificial Intelligence (AI) models excel
in tasks, such as content creation, translation, and code generation.
Fine-tuning and novel architectures, such as Mixture of Experts (MoE), address
these issues. Over the past two years, numerous open-source foundational and
fine-tuned models have been introduced, complicating the selection of the
optimal LLM for researchers and companies regarding licensing and hardware
requirements. To navigate the rapidly evolving LLM landscape and facilitate LLM
selection, we present a comparative list of foundational and domain-specific
models, focusing on features, such as release year, licensing, and hardware
requirements. This list is published on GitLab and will be continuously
updated.

</details>


### [96] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 本文介绍了大型语言模型和视觉语言模型在处理表格数据时面临的挑战，并提出了分类法和现有任务。同时指出了当前研究的三大关键问题：推理任务简单、模型在复杂场景表现不佳、模型泛化能力差。


<details>
  <summary>Details</summary>
Motivation: 表格具有复杂灵活的结构，其二维特性和多样格式导致现有方法多为专用而非通用，增加了研究难度。需要对表格理解任务进行系统性分类，同时指出当前研究的不足以推动未来发展。

Method: 提出表格输入表示的分类法，介绍现有表格理解任务，并对现有研究进行系统性分析。重点分析当前方法在任务复杂度、处理能力和泛化性上的缺陷。

Result: 发现三个主要研究空白：（1）当前表格推理任务过于简单；（2）模型在处理复杂结构、大表格或跨表格场景时表现不佳；（3）模型在不同格式表格间的泛化能力有限。

Conclusion: 目前表格理解研究存在明显局限性，需开发能处理复杂表格、支持复杂推理、具备泛化能力的统一方法。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


### [97] [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://arxiv.org/abs/2508.00220)
*Rana Aref Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 本文探讨了离散小波变换（DWT）在词向量和句向量中的应用，通过实验证明了DWT能够在保持语义信息的同时大幅度降低嵌入维度（50-93%压缩），并在语义相似度任务和下游任务中达到相近甚至更优的性能。


<details>
  <summary>Details</summary>
Motivation: 小波变换在信号与图像处理中表现出色，能够有效捕捉数据的多层次特征。鉴于自然语言处理（NLP）中嵌入向量同样具有复杂的语义结构，作者认为DWT可应用于分析并压缩NLP嵌入向量，同时保留其语义质量。

Method: 1. 将离散小波变换应用于不同嵌入模型（包括大语言模型）产生的词向量和句向量。
2. 利用DWT的多分辨率分析特性，在多个尺度上分解嵌入向量。
3. 通过保留重要系数实现嵌入向量的压缩（降维）。
4. 在语义相似度任务上评估压缩后嵌入向量的质量。
5. 在下游任务（如文本分类等）中验证压缩嵌入的实际效果。

Result: 1. DWT可将嵌入向量维度压缩50-93%而几乎不影响语义相似度任务的性能（如Spearman相关系数下降极小）。
2. 在大多数下游任务中，压缩后的嵌入向量表现优于或等同于原始嵌入。
3. 实验覆盖多种嵌入模型（包括BERT等大模型），证明方法的普适性。

Conclusion: 离散小波变换是一种高效且通用的嵌入向量压缩与分析工具，能在显著降低维度的同时保留甚至提升语义表达能力。该工作为DWT在NLP中的广泛应用（如轻量化模型部署、特征增强等）奠定了基础。

Abstract: Wavelet transforms, a powerful mathematical tool, have been widely used in
different domains, including Signal and Image processing, to unravel intricate
patterns, enhance data representation, and extract meaningful features from
data. Tangible results from their application suggest that Wavelet transforms
can be applied to NLP capturing a variety of linguistic and semantic
properties. In this paper, we empirically leverage the application of Discrete
Wavelet Transforms (DWT) to word and sentence embeddings. We aim to showcase
the capabilities of DWT in analyzing embedding representations at different
levels of resolution and compressing them while maintaining their overall
quality. We assess the effectiveness of DWT embeddings on semantic similarity
tasks to show how DWT can be used to consolidate important semantic information
in an embedding vector. We show the efficacy of the proposed paradigm using
different embedding models, including large language models, on downstream
tasks. Our results show that DWT can reduce the dimensionality of embeddings by
50-93% with almost no change in performance for semantic similarity tasks,
while achieving superior accuracy in most downstream tasks. Our findings pave
the way for applying DWT to improve NLP applications.

</details>


### [98] [Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English](https://arxiv.org/abs/2508.00238)
*Bryce Anderson,Riley Galpin,Tom S. Juzek*

Main category: cs.CL

TL;DR: 研究表明，在2022年ChatGPT发布后，人类在无剧本口语中与大型语言模型（LLM）相关的词汇使用量出现显著上升，表明人类词汇选择开始与LLM模式趋同。


<details>
  <summary>Details</summary>
Motivation: 探究人类语言系统本身是否因AI影响（尤其是LLMs）而发生了变化，而不仅仅是直接使用AI生成文本导致的变化。

Method: 构建一个包含2210万单词的数据集，这些单词来自科学和技术类会话播客的无剧本口语内容；分析2022年ChatGPT发布前后与LLM常用词汇相关的词汇趋势，并与基线同义词进行比较。

Result: 2022年后，与LLM相关的词汇使用量出现中等但显著的增长，表明人类词汇选择与LLM模式趋同；而基线同义词未呈现显著的方向性变化。

Conclusion: 这可能是语言使用快速变化的开始，但变化源于自然语言演变还是AI驱动仍不确定。此外，上游模型的未对齐可能也推动了人类语言使用的变化，这与道德担忧相呼应。

Abstract: In recent years, written language, particularly in science and education, has
undergone remarkable shifts in word usage. These changes are widely attributed
to the growing influence of Large Language Models (LLMs), which frequently rely
on a distinct lexical style. Divergences between model output and target
audience norms can be viewed as a form of misalignment. While these shifts are
often linked to using Artificial Intelligence (AI) directly as a tool to
generate text, it remains unclear whether the changes reflect broader changes
in the human language system itself. To explore this question, we constructed a
dataset of 22.1 million words from unscripted spoken language drawn from
conversational science and technology podcasts. We analyzed lexical trends
before and after ChatGPT's release in 2022, focusing on commonly LLM-associated
words. Our results show a moderate yet significant increase in the usage of
these words post-2022, suggesting a convergence between human word choices and
LLM-associated patterns. In contrast, baseline synonym words exhibit no
significant directional shift. Given the short time frame and the number of
words affected, this may indicate the onset of a remarkable shift in language
use. Whether this represents natural language change or a novel shift driven by
AI exposure remains an open question. Similarly, although the shifts may stem
from broader adoption patterns, it may also be that upstream training
misalignments ultimately contribute to changes in human language use. These
findings parallel ethical concerns that misaligned models may shape social and
moral beliefs.

</details>


### [99] [Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering](https://arxiv.org/abs/2508.00285)
*Peixian Li,Yu Tian,Ruiqi Tu,Chengkai Wu,Jingjing Ren,Jingsong Li*

Main category: cs.CL

TL;DR: 本研究提出了一个病因感知注意力转向框架(Etiology-Aware Attention Steering Framework)，通过整合结构化临床推理来提高大语言模型(LLM)在复杂临床场景中的诊断准确性。框架包括构建临床推理支架(CRS)、识别病因感知注意力头、并进行推理引导的参数高效微调。该方法在三个急腹症(急性阑尾炎、胰腺炎、胆囊炎)上验证，显著提升了诊断准确率和推理专注度。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在医疗文本理解与生成方面表现出强大能力，但在复杂临床场景中的诊断可靠性仍有限。为了增强其诊断准确性和临床推理能力，需要将结构化临床推理整合到基于LLM的诊断中。

Method: 1. 基于权威临床指南构建三种急腹症（急性阑尾炎、急性胰腺炎、急性胆囊炎）的临床推理支架(CRS)；2. 开发病因感知头识别算法定位与模型病因推理相关的注意力头；3. 提出推理引导的参数高效微调：将病因推理线索嵌入输入表示，并通过推理引导损失函数引导选定的病因感知头关注关键信息。

Result: 在一致性诊断队列中，框架比基线平均诊断准确率提高15.65%，平均推理专注分数(RFS)提升31.6%；在差异性诊断队列的外部验证中进一步证实了其提升诊断准确性的效果；推理注意频率评估表明模型在真实复杂场景中具有更高可靠性。

Conclusion: 通过将模型注意力与结构化CRS对齐，该框架为构建更可解释、更可靠的复杂临床场景AI诊断系统提供了有前景的范式。

Abstract: Objective: Large Language Models (LLMs) demonstrate significant capabilities
in medical text understanding and generation. However, their diagnostic
reliability in complex clinical scenarios remains limited. This study aims to
enhance LLMs' diagnostic accuracy and clinical reasoning ability. Method: We
propose an Etiology-Aware Attention Steering Framework to integrate structured
clinical reasoning into LLM-based diagnosis. Specifically, we first construct
Clinical Reasoning Scaffolding (CRS) based on authoritative clinical guidelines
for three representative acute abdominal emergencies: acute appendicitis, acute
pancreatitis, and acute cholecystitis. Next, we develop the Etiology-Aware Head
Identification algorithm to pinpoint attention heads crucial for the model's
etiology reasoning. To ensure reliable clinical reasoning alignment, we
introduce the Reasoning-Guided Parameter-Efficient Fine-tuning that embeds
etiological reasoning cues into input representations and steers the selected
Etiology-Aware Heads toward critical information through a Reasoning-Guided
Loss function. Result: On the Consistent Diagnosis Cohort, our framework
improves average diagnostic accuracy by 15.65% and boosts the average Reasoning
Focus Score by 31.6% over baselines. External validation on the Discrepant
Diagnosis Cohort further confirms its effectiveness in enhancing diagnostic
accuracy. Further assessments via Reasoning Attention Frequency indicate that
our models exhibit enhanced reliability when faced with real-world complex
scenarios. Conclusion: This study presents a practical and effective approach
to enhance clinical reasoning in LLM-based diagnosis. By aligning model
attention with structured CRS, the proposed framework offers a promising
paradigm for building more interpretable and reliable AI diagnostic systems in
complex clinical settings.

</details>


### [100] [Systematic Evaluation of Optimization Techniques for Long-Context Language Models](https://arxiv.org/abs/2508.00305)
*Ammar Ahmed,Sheng Di,Franck Cappello,Zirui Liu,Jingoo Han,Ali Anwar*

Main category: cs.CL

TL;DR: 本文系统性地评估了包括剪枝、量化和词元丢弃等优化技术在长上下文LLM场景下的影响，发现单独优化在小型模型上有效，但组合优化在更大模型上可能因近似误差累积而损害性能。此外，仅依赖F1分数会掩盖问答任务中的精确率-召回率权衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）面临资源需求高和上下文窗口有限的挑战。现有优化技术（如剪枝、量化和词元丢弃）在长上下文场景和系统级评估中的效果尚未充分研究。

Method: 1. 分析两种支持长上下文的LLM架构上单独优化方法的性能；2. 系统评估这些技术的组合对性能指标的影响；3. 研究个体优化技术在700亿参数大模型上的扩展性。

Result: 1. 小型模型上优化组合有效，但大模型中组合优化会因近似误差累积造成负面影响；2. 仅使用F1分数会掩盖问答任务中精确率-召回率的权衡；3. 系统级分析和任务洞察结合可指导LLM效率与准确率的平衡。

Conclusion: 本研究为LLM实践者和研究者提供了优化技术组合在效率、准确率和扩展性方面的系统性分析，强调大模型组合优化的风险及评估指标的选择对全面理解模型性能的重要性。

Abstract: Large language models (LLMs) excel across diverse natural language processing
tasks but face resource demands and limited context windows. Although
techniques like pruning, quantization, and token dropping can mitigate these
issues, their efficacy in long-context scenarios and system evaluation remains
underexplored. This paper systematically benchmarks these optimizations,
characterizing memory usage, latency, and throughput, and studies how these
methods impact the quality of text generation. We first analyze individual
optimization methods for two LLM architectures supporting long context and then
systematically evaluate combinations of these techniques to assess how this
deeper analysis impacts performance metrics. We subsequently study the
scalability of individual optimization methods on a larger variant with 70
billion-parameter model. Our novel insights reveal that naive combination
inference optimization algorithms can adversely affect larger models due to
compounded approximation errors, as compared to their smaller counterparts.
Experiments show that relying solely on F1 obscures these effects by hiding
precision-recall trade-offs in question answering tasks. By integrating
system-level profiling with task-specific insights, this study helps LLM
practitioners and researchers explore and balance efficiency, accuracy, and
scalability across tasks and hardware configurations.

</details>


### [101] [Improving Multimodal Contrastive Learning of Sentence Embeddings with Object-Phrase Alignment](https://arxiv.org/abs/2508.00332)
*Kaiyan Zhao,Zhongtao Miao,Yoshimasa Tsuruoka*

Main category: cs.CL

TL;DR: 提出MCSEO方法，通过细粒度的对象-短语对齐增强多模态句子嵌入，结合传统图像-字幕对齐，提高表示学习的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态句子嵌入模型在训练时使用图像-标题对，但这些对中常包含冗余或无关的信息（如图像和文字不匹配）。为了解决这个问题，本文提出在传统图像-标题对齐基础上引入对象-短语对齐，以优化对比学习目标。

Method: MCSEO方法利用现有的图像分割和物体检测模型来提取准确的对象-短语对，然后将这些对用于优化一个针对对象-短语对应关系的对比学习目标。

Result: 在多种骨干模型上进行的语义文本相似度（STS）任务实验表明，MCSEO方法始终优于基线模型，证实了对象-短语对齐在多模态表示学习中的重要性。

Conclusion: 通过引入细粒度的对象-短语对齐到多模态句子嵌入模型中，MCSEO有效提升了模型性能，表明精确的对象级对齐对于提升多模态表示学习至关重要。

Abstract: Multimodal sentence embedding models typically leverage image-caption pairs
in addition to textual data during training. However, such pairs often contain
noise, including redundant or irrelevant information on either the image or
caption side. To mitigate this issue, we propose MCSEO, a method that enhances
multimodal sentence embeddings by incorporating fine-grained object-phrase
alignment alongside traditional image-caption alignment. Specifically, MCSEO
utilizes existing segmentation and object detection models to extract accurate
object-phrase pairs, which are then used to optimize a contrastive learning
objective tailored to object-phrase correspondence. Experimental results on
semantic textual similarity (STS) tasks across different backbone models
demonstrate that MCSEO consistently outperforms strong baselines, highlighting
the significance of precise object-phrase alignment in multimodal
representation learning.

</details>


### [102] [PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](https://arxiv.org/abs/2508.00344)
*Keer Lu,Chong Chen,Bin Cui,Huang Leng,Wentao Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为AdaPlan的基于自适应全局规划的多智能体范式PilotRL，通过逐步强化学习框架将高级别指引与执行相结合，以提升智能体在复杂任务中的长期决策能力。实验表明，该方法在LLaMA3.1-8B模型上超越GPT-4o 3.60%，并在可比规模模型上显著优于GPT-4o-mini 55.78%。


<details>
  <summary>Details</summary>
Motivation: 现有基于ReAct范式的智能体难以处理需要长期战略规划的复杂任务，且监督微调方法导致模型过度记忆固定任务轨迹而缺乏泛化能力。本文旨在解决智能体长期决策能力与规划-执行协同问题。

Method: 1. 提出AdaPlan范式：通过全局规划提供高层指导，支持长程决策；2. 设计PilotRL框架：分三个阶段训练：a) 基于全局规划的执行指令遵循 b) 提升全局规划质量 c) 联合优化规划与执行协同。

Result: 在LLaMA3.1-8B-Instruct模型上验证：PilotRL超越GPT-4o达3.60%，较可比参数量级的GPT-4o-mini提升55.78%，创下SOTA。

Conclusion: 全局规划与执行的协同优化可显著增强智能体在复杂任务中的长期决策能力，强化学习框架能有效突破监督微调导致的泛化瓶颈。

Abstract: Large Language Models (LLMs) have shown remarkable advancements in tackling
agent-oriented tasks. Despite their potential, existing work faces challenges
when deploying LLMs in agent-based environments. The widely adopted agent
paradigm ReAct centers on integrating single-step reasoning with immediate
action execution, which limits its effectiveness in complex tasks requiring
long-term strategic planning. Furthermore, the coordination between the planner
and executor during problem-solving is also a critical factor to consider in
agent design. Additionally, current approaches predominantly rely on supervised
fine-tuning, which often leads models to memorize established task completion
trajectories, thereby restricting their generalization ability when confronted
with novel problem contexts. To address these challenges, we introduce an
adaptive global plan-based agent paradigm AdaPlan, aiming to synergize
high-level explicit guidance with execution to support effective long-horizon
decision-making. Based on the proposed paradigm, we further put forward
PilotRL, a global planning-guided training framework for LLM agents driven by
progressive reinforcement learning. We first develop the model's ability to
follow explicit guidance from global plans when addressing agent tasks.
Subsequently, based on this foundation, we focus on optimizing the quality of
generated plans. Finally, we conduct joint optimization of the model's planning
and execution coordination. Experiments indicate that PilotRL could achieve
state-of-the-art performances, with LLaMA3.1-8B-Instruct + PilotRL surpassing
closed-sourced GPT-4o by 3.60%, while showing a more substantial gain of 55.78%
comparing to GPT-4o-mini at a comparable parameter scale.

</details>


### [103] [Lucy: edgerunning agentic web search on mobile with machine generated task vectors](https://arxiv.org/abs/2508.00360)
*Alan Dao,Dinh Bach Vu,Alex Nguyen,Norapat Buppodom*

Main category: cs.CL

TL;DR: 提出了一种新范式，将模型内部推理视为动态任务向量机，优化后的小语言模型Lucy在SimpleQA基准上表现媲美大模型。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）在知识密集型任务中受限于容量，需要提升推理过程，使其动态构建和细化任务向量。

Method: 将模型内部推理（界定于<think>和</think>标签之间）视为动态任务向量机，通过强化学习与验证（RLVR）优化此机制，构建了带MCP的Lucy模型。

Result: Lucy（1.7B参数）在SimpleQA基准上达到78.3%准确率，与DeepSeek-V3等大模型相当。

Conclusion: 通过结构化、自构建任务推理，小型模型能匹敌大型模型。

Abstract: Small language models (SLMs) are inherently limited in knowledge-intensive
tasks due to their constrained capacity. While test-time computation offers a
path to enhanced performance, most approaches treat reasoning as a fixed or
heuristic process. In this work, we propose a new paradigm: viewing the model's
internal reasoning, delimited by <think> and </think> tags, as a dynamic task
vector machine. Rather than treating the content inside these tags as a mere
trace of thought, we interpret the generation process itself as a mechanism
through which the model \textbf{constructs and refines its own task vectors} on
the fly. We developed a method to optimize this dynamic task vector machine
through RLVR and successfully trained an agentic web-search model. We present
Lucy, a 1.7B-parameter SLM that leverages this dynamic reasoning mechanism with
MCP integration to achieve 78.3% accuracy on the SimpleQA benchmark, performing
on par with much larger models such as DeepSeek-V3. This demonstrates that
small models can rival large ones when equipped with structured,
self-constructed task reasoning.

</details>


### [104] [EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices](https://arxiv.org/abs/2508.00370)
*Jiyu Chen,Poh Seng Lim,Shuang Peng,Daxiong Luo,JungHau Foo,Yap Deep,Timothy Lee Jun Jie,Kelvin Teh Kae Wen,Fan Yang,Danyu Feng,Hao-Yun Chen,Peng-Wen Chen,Fangyuan Li,Xiaoxin Chen,Wong Wai Mun*

Main category: cs.CL

TL;DR: 论文提出EdgeInfinite-Instruct，通过分段监督微调（S-SFT）策略和移动端优化（如细粒度后训练量化和固定形状计算图）来解决EdgeInfinite的不足，提升在边缘设备上处理长序列任务的性能和效率。


<details>
  <summary>Details</summary>
Motivation: Transformer-based LLMs在资源受限的边缘设备上部署长序列任务时面临时间复杂度和内存消耗挑战（如KV缓存）。现有优化方案在首字延迟（TTFT）改善和性能保持上存在局限。EdgeInfinite虽降低了开销，但指令跟随能力不足且缺乏移动设备专用优化。

Method: 1. 提出EdgeInfinite-Instruct: 针对摘要、QA等长序列任务设计Segmented SFT（S-SFT）策略。2. 移动端优化: (a)细粒度后训练量化(PTQ)降低计算成本；(b)固定形状计算图，依据场景定制输入令牌/缓存大小，平衡内存和效率。

Result: 在长上下文基准测试和真实移动任务中验证：提高特定领域性能（如指令跟随能力），同时通过NPU加速在边缘设备上保持高效推理。

Conclusion: EdgeInfinite-Instruct实现了在边缘设备上高效部署长序列任务。解决了指令能力不足问题，通过PTQ和计算图优化平衡性能与效率，适用移动NPU场景。

Abstract: Deploying Transformer-based large language models (LLMs) on
resource-constrained edge devices for long-sequence tasks remains challenging
due to the quadratic time complexity of self-attention and growing Key-Value
(KV) cache demands. While existing KV cache optimizations improve memory
efficiency, they often fail to reduce time to first token (TTFT) and may
degrade performance through token pruning. Alternative sequence modeling
architectures address some of these limitations, but typically require full
retraining and lack infrastructure support. EdgeInfinite offers an efficient
solution by fine-tuning only a small subset of parameters, maintaining quality
while reducing both computational and memory costs, including improved TTFT.
However, its instruction-following ability is limited, and it lacks
mobile-specific optimizations. To address these issues, we propose
EdgeInfinite-Instruct, which introduces a Segmented Supervised Fine-Tuning
(S-SFT) strategy tailored to long-sequence tasks such as summarization and
question answering. We further optimized EdgeInfinite-Instruct for efficient
deployment on edge NPUs by employing fine-grained post-training quantization
(PTQ) to reduce computational demands while maintaining accuracy, and by
implementing a fixed-shape computation graph that balances memory usage and
on-device efficiency through scenario-specific customization of input token and
cache sizes. Experiments on long-context benchmarks and real-world mobile tasks
show that our approach improves domain-specific performance while maintaining
efficiency on NPU-accelerated edge devices.

</details>


### [105] [Multi-Layer Attention is the Amplifier of Demonstration Effectiveness](https://arxiv.org/abs/2508.00385)
*Dingzirui Wang,Xuangliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 本文通过梯度流分析研究了上下文学习（ICL）中为什么某些演示无效，并提出了一种基于梯度流选择有效演示的方法GradS。研究发现，当模型已经学习过演示信息或信息与用户查询无关时，该演示无效。在多层模型中，无效和有效演示之间的差异被逐层放大。GradS方法平均相对基线改善6.8%。


<details>
  <summary>Details</summary>
Motivation: 现有研究都默认上下文学习（ICL）中提供的演示都是有效的，但实际中很多演示并不能带来性能提升。本文旨在通过分析演示无效的根本原因，并利用这一理解改进演示选择方法。

Method: 1. 基于梯度流理论分析，推导出演示无效的条件（当演示的信息已被模型学习或与查询无关时）；2. 在多层模型中观察到无效和有效演示差异被放大；3. 提出梯度流演示选择方法（GradS），使用梯度流的大小作为选择标准。实验在五个主流数据集和四个大语言模型（LLM）上进行验证。

Result: 1. 验证了随着模型层数加深，演示有效性的差异增大；2. GradS方法在平均性能上比最强基线相对提升6.8%，证明其有效性。

Conclusion: ICL中演示无效的原因是信息已被学习或与查询无关；多层模型中差异被放大。GradS有效地通过梯度流大小选择演示，显著提升ICL性能。

Abstract: Numerous studies have investigated the underlying mechanisms of in-context
learning (ICL) effectiveness to inspire the design of related methods. However,
existing work predominantly assumes the effectiveness of the demonstrations
provided within ICL, while many research indicates that not all demonstrations
are effective, failing to yielding any performance improvement during ICL.
Therefore, in this paper, we investigate the reasons behind demonstration
ineffectiveness. Our analysis is based on gradient flow and linear
self-attention models. By setting the gradient flow to zero, we deduce that a
demonstration becomes ineffective if its information has either been learned by
the model or is irrelevant to the user query. Furthermore, we demonstrate that
in multi-layer models, the disparity in effectiveness among demonstrations is
amplified with layer increasing, causing the model to focus more on effective
ones. Considering that current demonstration selection methods primarily focus
on the relevance to the user query while overlooking the information that the
model has already assimilated, we propose a novel method called GradS, which
leverages gradient flow for demonstration selection. We use the magnitude of
the gradient flow of the demonstration with respect to a given user query as
the criterion, thereby ensuring the effectiveness of the chosen ones. We
validate our derivation and GradS on four prominent LLMs across five mainstream
datasets. The experimental results confirm that the disparity in effectiveness
among demonstrations is magnified as the model layer increases, substantiating
our derivations. Moreover, GradS achieves a relative improvement of $6.8\%$ on
average over the strongest baselines, demonstrating its effectiveness.

</details>


### [106] [SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation](https://arxiv.org/abs/2508.00390)
*Hengxing Cai,Jinhan Dong,Yijie Rao,Jingcheng Deng,Jingjun Tan,Qien Chen,Haidong Wang,Zhen Wang,Shiyu Huang,Agachai Sumalee,Renxin Zhong*

Main category: cs.CL

TL;DR: 本文提出了一种名为语义感知高斯课程调度（SA-GCS）的新型训练框架，用于解决无人机视觉语言导航任务中强化学习面临的数据利用效率低、收敛慢以及训练样本难度差异考虑不足等问题。该方法通过语义感知难度估计器（SA-DE）量化样本复杂度，并利用高斯课程调度器（GCS）动态调整采样分布，实现从易到难的任务渐进学习，从而显著提升训练效率、加速收敛并提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在无人机视觉语言导航任务中存在三个主要问题：训练数据使用效率低下、收敛速度慢，以及对训练样本难度变化的考虑不足。这些问题限制了模型性能的进一步提升。为了解决这些问题，本文探索了如何系统地将课程学习（CL）整合到强化学习中，从而优化训练过程。

Method: 1. 语义感知难度估计器（SA-DE）：用于量化训练样本的复杂度。
2. 高斯课程调度器（GCS）：通过动态调整训练样本的采样分布，实现从易到难的任务渐进学习。
整个框架（SA-GCS）通过结合上述两个组件，在强化学习训练过程中智能地安排训练样本的顺序和频率。

Result: 在CityNav基准测试上的大量实验表明：
- SA-GCS在所有指标上均显著超越现有基线方法。
- 该方法能够实现更快、更稳定的收敛。
- 该方法在不同规模的模型上均表现出良好的泛化性能，证明了其鲁棒性和可扩展性。

Conclusion: SA-GCS通过将课程学习系统地整合到强化学习中，有效解决了现有方法在无人机视觉语言导航任务中的局限性。该方法不仅提升了训练效率和模型性能，还加速了收敛并增强了泛化能力。实验结果证明了该方法的优越性和适用性。

Abstract: Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) aims to enable
agents to accurately localize targets and plan flight paths in complex
environments based on natural language instructions, with broad applications in
intelligent inspection, disaster rescue, and urban monitoring. Recent progress
in Vision-Language Models (VLMs) has provided strong semantic understanding for
this task, while reinforcement learning (RL) has emerged as a promising
post-training strategy to further improve generalization. However, existing RL
methods often suffer from inefficient use of training data, slow convergence,
and insufficient consideration of the difficulty variation among training
samples, which limits further performance improvement. To address these
challenges, we propose \textbf{Semantic-Aware Gaussian Curriculum Scheduling
(SA-GCS)}, a novel training framework that systematically integrates Curriculum
Learning (CL) into RL. SA-GCS employs a Semantic-Aware Difficulty Estimator
(SA-DE) to quantify the complexity of training samples and a Gaussian
Curriculum Scheduler (GCS) to dynamically adjust the sampling distribution,
enabling a smooth progression from easy to challenging tasks. This design
significantly improves training efficiency, accelerates convergence, and
enhances overall model performance. Extensive experiments on the CityNav
benchmark demonstrate that SA-GCS consistently outperforms strong baselines
across all metrics, achieves faster and more stable convergence, and
generalizes well across models of different scales, highlighting its robustness
and scalability. The implementation of our approach is publicly available.

</details>


### [107] [Combining Discrete Wavelet and Cosine Transforms for Efficient Sentence Embedding](https://arxiv.org/abs/2508.00420)
*Rana Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 该论文探讨了将离散小波变换(DWT)应用于词向量和句子向量的方法，以压缩维度同时保留重要信息。此外，通过结合DWT和离散余弦变换(DCT)，提出一种固定大小的句子向量压缩模型。实验证明该方法在下游任务中的有效性，有时甚至优于原始嵌入。


<details>
  <summary>Details</summary>
Motivation: 小波技术在图像和信号处理中取得了显著成功，本文旨在探索其在自然语言处理(NLP)中的应用潜力。具体动机是利用小波变换压缩词向量和句向量的维度，同时保留关键信息。

Method: 1. 对词向量应用离散小波变换(DWT)进行降维，并评估其内在和外在效果。2. 结合DWT与离散余弦变换(DCT)提出非参数模型，根据局部单词特征生成固定大小的句子向量。3. 在下游任务上评估压缩后向量的性能。

Result: 实验表明，降维后的词向量在压缩维度时仍能保持有效信息；非参数化的句子压缩模型在多个下游应用中取得与原嵌入相当甚至更优的效果。

Conclusion: 小波变换特别是DWT和DCT结合的方法能够有效压缩词向量和句向量，且在NLP任务中保持甚至提升表现，为非参数化语言处理方法提供新思路。

Abstract: Wavelets have emerged as a cutting edge technology in a number of fields.
Concrete results of their application in Image and Signal processing suggest
that wavelets can be effectively applied to Natural Language Processing (NLP)
tasks that capture a variety of linguistic properties. In this paper, we
leverage the power of applying Discrete Wavelet Transforms (DWT) to word and
sentence embeddings. We first evaluate, intrinsically and extrinsically, how
wavelets can effectively be used to consolidate important information in a word
vector while reducing its dimensionality. We further combine DWT with Discrete
Cosine Transform (DCT) to propose a non-parameterized model that compresses a
sentence with a dense amount of information in a fixed size vector based on
locally varying word features. We show the efficacy of the proposed paradigm on
downstream applications models yielding comparable and even superior (in some
tasks) results to original embeddings.

</details>


### [108] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
*Minghao Guo,Xi Zhu,Jingyuan Huang,Kai Mei,Yongfeng Zhang*

Main category: cs.CL

TL;DR: 本文提出ReaGAN框架，通过将每个节点视为智能体，使其能自主规划信息传播路径，并引入检索增强机制建立全局语义关系，解决了传统GNN固定传播机制在处理信息不均衡和忽视全局语义的问题，在少样本场景下验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络（GNN）采用固定信息传播机制存在两个问题：一是无法处理节点信息密度不均（部分节点信息丰富，部分稀疏）；二是预定义的消息传递主要依赖局部结构相似性，忽视了图中全局语义关系，导致难以捕获远距离相关信息。因此需要一种能自主决策传播路径并利用全局语义的方法。

Method: 提出检索增强的图智能体网络（ReaGAN）：1. 将每个节点视为自主决策的智能体，基于内部记忆独立规划下一步动作（如消息传播）；2. 引入检索增强生成（RAG）技术，使节点能访问与其语义相关的内容，建立全局关系；3. 使用冻结的大型语言模型（LLM）作为骨干网络，在少样本上下文学习场景下不需要微调。

Result: ReaGAN在few-shot场景下（冻结LLM主干）取得有竞争力的性能，验证了智能体规划和局部-全局检索机制在图学习中的潜力。具体表现为：节点能自适应传播消息，并通过检索建立全局语义连接，克服了传统GNN的局限。

Conclusion: ReaGAN框架证明节点级智能体规划与检索增强技术的结合能有效提升GNN对信息不均衡和全局语义关系的处理能力。该方法为不依赖微调的少样本图学习提供了新方向，展现了智能体决策和语义检索在图结构建模中的价值。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success in graph-based
learning by propagating information among neighbor nodes via predefined
aggregation mechanisms. However, such fixed schemes often suffer from two key
limitations. First, they cannot handle the imbalance in node informativeness --
some nodes are rich in information, while others remain sparse. Second,
predefined message passing primarily leverages local structural similarity
while ignoring global semantic relationships across the graph, limiting the
model's ability to capture distant but relevant information. We propose
Retrieval-augmented Graph Agentic Network (ReaGAN), an agent-based framework
that empowers each node with autonomous, node-level decision-making. Each node
acts as an agent that independently plans its next action based on its internal
memory, enabling node-level planning and adaptive message propagation.
Additionally, retrieval-augmented generation (RAG) allows nodes to access
semantically relevant content and build global relationships in the graph.
ReaGAN achieves competitive performance under few-shot in-context settings
using a frozen LLM backbone without fine-tuning, showcasing the potential of
agentic planning and local-global retrieval in graph learning.

</details>


### [109] [Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges](https://arxiv.org/abs/2508.00454)
*Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding*

Main category: cs.CL

TL;DR: 提出了一种高效的多轮对话评估器，通过将多个LLM评估器的偏好知识聚合到单个模型中，在保留多评估器反馈多样性的同时显著降低评估成本。


<details>
  <summary>Details</summary>
Motivation: 当前的“LLM作为评估器”方法存在各种偏见，多评估器方法虽能缓解偏见但计算开销大。本文旨在设计一种高效的评估器，结合多评估器的集体智慧，同时降低计算成本。

Method: 提出了一种方法，聚合多个LLM评估器的偏好知识到一个单独的模型中，该模型能在保留多评估器优势的同时减少计算开销。

Result: 在七个对话评估基准测试中，本方法表现优于现有基线，证明了其高效性和鲁棒性。

Conclusion: 该方法成功地将多评估器的集体智慧压缩到单一模型中，实现了快速、灵活且可靠的对话质量评估，显著降低了评估成本。

Abstract: Evaluating the conversational abilities of large language models (LLMs)
remains a challenging task. Current mainstream approaches primarily rely on the
``LLM-as-a-judge" paradigm, where an LLM is prompted to serve as an evaluator
to assess dialogue quality. However, such methods often suffer from various
biases, which undermine the reliability and consistency of the evaluation
results. To mitigate these biases, recent methods employ multiple LLMs as
judges and aggregate their judgments to select the optimal assessment. Although
effective, this multi-judge approach incurs significant computational overhead
during inference. In this paper, we propose an efficient multi-turn dialogue
evaluator that captures the collective wisdom of multiple LLM judges by
aggregating their preference knowledge into a single model. Our approach
preserves the advantages of diverse multi-judge feedback while drastically
reducing the evaluation cost, enabling fast and flexible dialogue quality
assessment. Extensive experiments on seven single rating and pairwise
comparison dialogue evaluation benchmarks demonstrate that our method
outperforms existing baselines across diverse scenarios, showcasing its
efficiency and robustness.

</details>


### [110] [GETALP@AutoMin 2025: Leveraging RAG to Answer Questions based on Meeting Transcripts](https://arxiv.org/abs/2508.00476)
*Jeongwoo Kang,Markarit Vartampetian,Felix Herron,Yongxin Zhou,Diandra Fabre,Gabriela Gonzalez-Saez*

Main category: cs.CL

TL;DR: GETALP团队在SIGDial 2025的自动纪要共享任务第三轮的Task B中提交了基于RAG和AMR的系统，用于基于会议记录的问答。该方法在35%的问题上提供了高质量回答，并在涉及区分参与者的问题（如'who'类问题）上显著改进。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是提高基于会议记录的问答系统的性能，特别是在处理需要区分不同参与者的问题时。作者们旨在探索结合检索增强生成（RAG）和抽象意义表示（AMR）来提高答案质量。

Method: 作者提出了三种结合RAG和AMR的系统。方法具体步骤包括：1）利用AMR对会议内容进行语义表示；2）通过RAG系统检索相关信息；3）生成答案。该方法通过结合两种技术，改善了对复杂问题的处理能力。

Result: 实验结果表明，引入AMR后，系统在大约35%的问题上产生了高质量的回答。特别地，在涉及区分不同参与者的问题（例如'who'类问题）上，系统表现出了显著的性能提升。

Conclusion: 该工作证明了结合检索增强生成和抽象意义表示能有效提升会议记录问答系统的性能，尤其是在处理涉及多个参与者的复杂问题时效果显著。

Abstract: This paper documents GETALP's submission to the Third Run of the Automatic
Minuting Shared Task at SIGDial 2025. We participated in Task B:
question-answering based on meeting transcripts. Our method is based on a
retrieval augmented generation (RAG) system and Abstract Meaning
Representations (AMR). We propose three systems combining these two approaches.
Our results show that incorporating AMR leads to high-quality responses for
approximately 35% of the questions and provides notable improvements in
answering questions that involve distinguishing between different participants
(e.g., who questions).

</details>


### [111] [The Missing Parts: Augmenting Fact Verification with Half-Truth Detection](https://arxiv.org/abs/2508.00489)
*Yixuan Tang,Jincheng Wang,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: 该论文提出了半真话检测任务，引入了新基准PolitiFact-Hidden（包含1.5万个经过标注的政治声明）以及一个名为TRACER的框架，用于识别基于遗漏的虚假信息。TRACER通过证据对齐、意图推断和隐藏内容因果影响评估来检测真实却因关键语境缺失而误导的声明。实验表明，TRACER显著提升半真话分类性能（F1值最高提升16分）。


<details>
  <summary>Details</summary>
Motivation: 现有事实核查系统仅依据显性证据判断声明真伪，无法检测因重要语境缺失导致的误导性半真话（事实正确但具有误导性）。这类问题在政治声明中尤为普遍，而现有模型未设计用于推理未提及信息。

Method: 1. 提出半真话检测任务并构建PolitiFact-Hidden基准数据集。该数据包含15k政治声明，标注了证据支持度与隐含意图。2. 设计TRACER框架：a) 证据对齐：比较声明证据是否缺失关键语境；b) 意图推理：建模声明潜在意图；c) 因果影响评估：预测补充缺失内容是否改变受众认知。3. 模块化设计使其可集成至现有事实核查流程中。

Result: 在PolitiFact-Hidden上评估：1. TRACER整合多种基线模型后，半真话（Half-True）分类F1值最高提升16点；2. 证实显式建模遗漏内容是提升可信事实核查的关键；3. 模块化架构在多样化基线模型中均具泛化性。

Conclusion: 论文首次系统性解决遗漏型虚假信息，通过任务定义、数据集构建和方法创新（TRACER）推动事实核查系统发展。实验证明建模未提及信息对可信验证至关重要，TRACER为现有系统提供即插即用增强方案。

Abstract: Fact verification systems typically assess whether a claim is supported by
retrieved evidence, assuming that truthfulness depends solely on what is
stated. However, many real-world claims are half-truths, factually correct yet
misleading due to the omission of critical context. Existing models struggle
with such cases, as they are not designed to reason about what is left unsaid.
We introduce the task of half-truth detection, and propose PolitiFact-Hidden, a
new benchmark with 15k political claims annotated with sentence-level evidence
alignment and inferred claim intent. To address this challenge, we present
TRACER, a modular re-assessment framework that identifies omission-based
misinformation by aligning evidence, inferring implied intent, and estimating
the causal impact of hidden content. TRACER can be integrated into existing
fact-checking pipelines and consistently improves performance across multiple
strong baselines. Notably, it boosts Half-True classification F1 by up to 16
points, highlighting the importance of modeling omissions for trustworthy fact
verification.

</details>


### [112] [EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond](https://arxiv.org/abs/2508.00522)
*Jiaxin Deng,Qingcheng Zhu,Junbiao Pang,Linlin Yang,Zhongqian Fu,Baochang Zhang*

Main category: cs.CL

TL;DR: 本文提出了Flat-LoRA及其高效版本EFlat-LoRA，旨在为低秩自适应（LoRA）寻找平坦最小值。通过理论证明，将全局参数的扰动转移到低秩子空间可以消除多个矩阵扰动带来的干扰。实验表明EFlat-LoRA在保持与LoRA相当效率的同时，取得了更好或相当的性能，验证了LoRA的泛化能力与平坦度密切相关。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对LoRA的表达能力与泛化能力相关性的研究。虽然SAM方法通过寻找平坦最小值改善了CNN和Transformer的泛化，但尚未在LoRA中探索平坦度与泛化的联系。主要障碍在于缺乏寻找平坦最小值的经验工具和理论方法。

Method: 1. 理论证明: 全局参数的扰动可以转移到低秩子空间，从而避免多个矩阵扰动带来的干扰。
2. 提出Flat-LoRA: 在低秩子空间中直接寻求平坦最小值。
3. 提出高效版本EFlat-LoRA: 通过优化扰动方式实现计算效率与LoRA相当。
4. 实验设置: 在大型语言模型（如RoBERTa-large）和视觉语言模型（如Qwen-VL-Chat）上测试方法。

Result: 1. 在GLUE数据集上，EFlat-LoRA平均超越LoRA 1.0%，超越全微调0.5%。
2. 在视觉语言模型上，Qwen-VL-Chat在SQA和VizWiz数据集上分别提升1.5%和1.0%。
3. 计算效率与LoRA持平，同时性能接近或更优。
4. 实证表明LoRA的泛化能力与模型平坦度强相关，这一发现被前人忽略。

Conclusion: EFlat-LoRA在保持高效的前提下，首次从理论和实验层面验证了LoRA的泛化能力与模型平坦度的强相关性。该方法不仅提升了LoRA的性能，还为理解低秩自适应的优化机制提供了新视角。

Abstract: Little research explores the correlation between the expressive ability and
generalization ability of the low-rank adaptation (LoRA). Sharpness-Aware
Minimization (SAM) improves model generalization for both Convolutional Neural
Networks (CNNs) and Transformers by encouraging convergence to locally flat
minima. However, the connection between sharpness and generalization has not
been fully explored for LoRA due to the lack of tools to either empirically
seek flat minima or develop theoretical methods. In this work, we propose
Flat-LoRA and its efficient version i.e., EFlat-LoRA, to seek flat minima for
LoRA. Concretely, we theoretically demonstrate that perturbations in the full
parameter space can be transferred to the low-rank subspace. This approach
eliminates the potential interference introduced by perturbations across
multiple matrices in the low-rank subspace. Our extensive experiments on large
language models and vision-language models demonstrate that EFlat-LoRA achieves
optimize efficiency comparable to that of LoRA while simultaneously attaining
comparable or even better performance. For example, on the GLUE dataset with
RoBERTa-large, EFlat-LoRA outperforms LoRA and full fine-tuning by 1.0% and
0.5% on average, respectively. On vision-language models e.g., Qwen-VL-Chat
shows performance improvements of 1.5% and 1.0% on SQA and VizWiz datasets,
respectively. These empirical results also verify that the generalization of
LoRA is closely related to sharpness, which is omitted by previous methods.

</details>


### [113] [The Prosody of Emojis](https://arxiv.org/abs/2508.00537)
*Giulio Zhou,Tsz Kin Lam,Alexandra Birch,Barry Haddow*

Main category: cs.CL

TL;DR: 该研究探讨了表情符号在口语中如何影响韵律特征（如音高、节奏和语调）及其在传达情感和意义中的作用，并分析了说话者和听者如何利用表情符号与韵律之间的关系进行沟通。


<details>
  <summary>Details</summary>
Motivation: 在文本交流中，韵律特征缺失，表情符号作为视觉替代品用于传达情感和语用细微差别。本研究旨在探索表情符号如何影响口语中的韵律实现，以及听者如何从韵律线索中解读表情符号的意义。

Method: 通过结构化的开放式产生和感知任务收集真实人类语音数据；分析说话者如何根据表情符号调整韵律，以及听者能否仅通过韵律变化识别表情符号；测量表情符号语义差异与韵律差异之间的相关性。

Result: 说话者根据表情符号调整韵律；听者常能仅通过韵律变化识别目标表情符号；表情符号间更大的语义差异导致更强的韵律差异。

Conclusion: 表情符号可承载韵律意图，在数字媒介中具有明确的交际功能：语义差异较大的表情符号会引发更显著的韵律表达分化，帮助听者准确识别意图。

Abstract: Prosodic features such as pitch, timing, and intonation are central to spoken
communication, conveying emotion, intent, and discourse structure. In
text-based settings, where these cues are absent, emojis act as visual
surrogates that add affective and pragmatic nuance. This study examines how
emojis influence prosodic realisation in speech and how listeners interpret
prosodic cues to recover emoji meanings. Unlike previous work, we directly link
prosody and emoji by analysing actual human speech data, collected through
structured but open-ended production and perception tasks. This provides
empirical evidence of how emoji semantics shape spoken delivery and perception.
Results show that speakers adapt their prosody based on emoji cues, listeners
can often identify the intended emoji from prosodic variation alone, and
greater semantic differences between emojis correspond to increased prosodic
divergence. These findings suggest that emojis can act as meaningful carriers
of prosodic intent, offering insight into their communicative role in digitally
mediated contexts.

</details>


### [114] [PaPaformer: Language Model from Pre-trained Paraller Paths](https://arxiv.org/abs/2508.00544)
*Joonas Tapaninaho,Mourad Oussala*

Main category: cs.CL

TL;DR: 本文介绍了PaPaformer，一种改进的仅解码器Transformer架构，通过并行路径训练，减少训练时间和参数数量，同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 训练现代大语言模型需要大量计算资源和时间，即使小语言模型也需要多日多GPU训练。针对此问题，本研究旨在探索在数小时内而非数日/周内训练和评估模型的方法。

Method: 提出PaPaformer架构：其核心是将低维并行路径分别训练（可使用不同类型数据）后合并成更大模型。具体步骤包括：1. 独立训练多个低维路径；2. 合并路径形成完整模型；3. 支持路径定制化以适应特定任务。

Result: 该方法实现了：1. 减少总参数量和训练时间；2. 性能提升；3. 路径定制化带来任务适配灵活性。

Conclusion: PaPaformer通过并行路径机制显著加速训练过程并提高效率，为面向特定任务的模型定制提供了新思路。

Abstract: The training of modern large-language models requires an increasingly amount
of computation power and time. Even smaller variants, such as small-language
models (SLMs), take several days to train in the best-case scenarios, often
requiring multiple GPUs. This paper explores methods to train and evaluate
decoder-only transformer-based language models in hours instead of days/weeks.
We introduces \textit{PaPaformer}, a decoder-only transformer architecture
variant, whose lower-dimensional parallel paths are combined into larger model.
The paper shows that these lower-dimensional paths can be trained individually
with different types of training data and then combined into one larger model.
This method gives the option to reduce the total number of model parameters and
the training time with increasing performance. Moreover, the use of parallel
path structure opens interesting possibilities to customize paths to
accommodate specific task requirements.

</details>


### [115] [SynAdapt: Learning Adaptive Reasoning in Large Language Models via Synthetic Continuous Chain-of-Thought](https://arxiv.org/abs/2508.00574)
*Jianwei Wang,Ziming Wu,Fuming Lai,Shaobing Lian,Ziqian Zeng*

Main category: cs.CL

TL;DR: 提出SynAdapt框架，通过生成合成连续CoT（CCoT）来指导模型学习，并利用难度分类器识别难题进行自适应重新思考，实现推理效率与准确性的最优平衡。


<details>
  <summary>Details</summary>
Motivation: 现有连续CoT（CCoT）方法存在间接微调、对齐不足、目标不一致等问题，且CCoT处理难题效果不佳。需要一种同时优化推理效率（避免生成离散CoT的时间开销）和提升难题解决能力的方案。

Method: 1. 生成合成的CCoT作为精确对齐目标，指导LLM直接学习CCoT推理并输出答案；2. 设计难度分类器（结合问题上下文和CCoT）识别难题；3. 对识别的难题触发自适应重新思考（如二次提示LLM深入推理）。

Result: 在多个难度各异的基准测试上取得最佳准确率-效率权衡（即同等准确率下速度更快，或同等时间开销下准确率更高）。

Conclusion: SynAdapt成功克服现有CCoT方法的缺陷，通过合成对齐目标和难度自适应机制，为LLM推理任务提供了高效且强大的解决方案。

Abstract: While Chain-of-Thought (CoT) reasoning improves model performance, it incurs
significant time costs due to the generation of discrete CoT tokens (DCoT).
Continuous CoT (CCoT) offers a more efficient alternative, but existing CCoT
methods are hampered by indirect fine-tuning, limited alignment, or
inconsistent targets. To overcome these limitations, we propose
\textit{SynAdapt}, an innovative efficient reasoning framework. Specifically,
\textit{SynAdapt} generates the synthetic CCoT to serve as a precise and
effective alignment target for LLMs. This synthetic CCoT explicitly guides the
LLM to learn CCoT and derive accurate answers directly. Furthermore, relying
solely on CCoT is insufficient for solving hard questions. To address this,
\textit{SynAdapt} integrates a difficulty classifier that leverages both
question context and CCoT to identify hard questions. CCoT can effectively help
identify hard questions after some brief reasoning. We then adaptively prompt
the LLM to re-think these hard questions for improved performance. Extensive
experimental results across various benchmarks from different difficulty levels
strongly demonstrate the effectiveness of our method, achieving the best
accuracy-efficiency trade-off.

</details>


### [116] [NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts](https://arxiv.org/abs/2502.18148)
*Muhammad Farid Adilazuarda,Musa Izzanardi Wijanarko,Lucky Susanto,Khumaisa Nur'aini,Derry Wijaya,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 该论文提出并构建了NusaAksara基准测试，该基准包含印度尼西亚多种本土语言及文字的多种任务，实验表明现有模型对这些文字处理能力薄弱。


<details>
  <summary>Details</summary>
Motivation: 尽管印度尼西亚语言丰富，但大多数NLP研究集中于罗马化文本，缺乏对本土语言原文字的系统研究。

Method: 1. 人工构建包含8种文字、7门语言的多模态数据集。2. 数据集包含图像分割、OCR、转写翻译和语言识别等任务。3. 评估包括GPT-4o, Llama 3.2, Aya 23等LLM/VLM以及专业模型如PP-OCR。

Result: 实验证明绝大多数模型对印度尼西亚本土文字处理能力接近零，现有NLP技术无法有效处理这类文字。

Conclusion: 该研究揭示了印度尼西亚本土文字在NLP中的支持缺失，为后续研究和模型开发提供了重要基准。

Abstract: Indonesia is rich in languages and scripts. However, most NLP progress has
been made using romanized text. In this paper, we present NusaAksara, a novel
public benchmark for Indonesian languages that includes their original scripts.
Our benchmark covers both text and image modalities and encompasses diverse
tasks such as image segmentation, OCR, transliteration, translation, and
language identification. Our data is constructed by human experts through
rigorous steps. NusaAksara covers 8 scripts across 7 languages, including
low-resource languages not commonly seen in NLP benchmarks. Although
unsupported by Unicode, the Lampung script is included in this dataset. We
benchmark our data across several models, from LLMs and VLMs such as GPT-4o,
Llama 3.2, and Aya 23 to task-specific systems such as PP-OCR and LangID, and
show that most NLP technologies cannot handle Indonesia's local scripts, with
many achieving near-zero performance.

</details>


### [117] [A Context-Aware Dual-Metric Framework for Confidence Estimation in Large Language Models](https://arxiv.org/abs/2508.00600)
*Mingruo Yuan,Shuyi Zhang,Ben Kao*

Main category: cs.CL

TL;DR: 论文提出CRUX框架，通过上下文信息减少熵和统一一致性检查，结合情境忠实性和一致性进行置信度估计，应用于多个数据集并优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型的置信度估计方法忽略了响应与上下文信息之间的相关性，而上下文相关性在输出质量评估中至关重要。本文旨在填补这一空白。

Method: 提出CRUX框架，包含两个新指标：上下文熵减少（用上下文和无上下文对比采样表示信息增益）和统一一致性检查（检查有上下文和无上下文时生成答案的全局一致性）。

Result: 在三个基准数据集（CoQA、SQuAD、QuAC）和两个领域特定数据集（BioASQ、EduQG）上的实验显示，CRUX的AUROC指标高于现有基线方法。

Conclusion: CRUX通过结合上下文忠实性和一致性，有效提高了大型语言模型的置信度估计准确性，在多个数据集上表现出优越性。

Abstract: Accurate confidence estimation is essential for trustworthy large language
models (LLMs) systems, as it empowers the user to determine when to trust
outputs and enables reliable deployment in safety-critical applications.
Current confidence estimation methods for LLMs neglect the relevance between
responses and contextual information, a crucial factor in output quality
evaluation, particularly in scenarios where background knowledge is provided.
To bridge this gap, we propose CRUX (Context-aware entropy Reduction and
Unified consistency eXamination), the first framework that integrates context
faithfulness and consistency for confidence estimation via two novel metrics.
First, contextual entropy reduction represents data uncertainty with the
information gain through contrastive sampling with and without context. Second,
unified consistency examination captures potential model uncertainty through
the global consistency of the generated answers with and without context.
Experiments across three benchmark datasets (CoQA, SQuAD, QuAC) and two
domain-specific datasets (BioASQ, EduQG) demonstrate CRUX's effectiveness,
achieving the highest AUROC than existing baselines.

</details>


### [118] [GHTM: A Graph based Hybrid Topic Modeling Approach in Low-Resource Bengali Language](https://arxiv.org/abs/2508.00605)
*Farhana Haque,Md. Abdur Rahman,Sumon Ahmed*

Main category: cs.CL

TL;DR: 本研究提出了一种名为GHTM的基于图卷积网络(GCN)的新模型，用于孟加拉语的文档主题建模。该模型将文档向量表示为图中的节点，利用GCN生成丰富的语义嵌入，并通过非负矩阵分解(NMF)提取主题。与包括LDA、LSA、NMF、BERTopic和Top2Vec在内的多种方法在三个孟加拉语数据集上的对比实验表明，GHTM在主题连贯性和多样性方面表现最优。此外，作者还发布了一个新的教科书来源的孟加拉语数据集NCTBText。


<details>
  <summary>Details</summary>
Motivation: 尽管主题建模在英语中研究广泛，但由于孟加拉语的形态复杂性、资源不足等因素，该语言的主题建模研究仍显薄弱。现有孟加拉语语料库主要来自报纸，缺乏多样性。

Method: 1. 提出GHTM模型：将文档向量作为节点构建图结构；
2. 利用图卷积网络(GCN)生成文档的语义嵌入表示；
3. 对嵌入向量进行非负矩阵分解(NMF)提取主题分布；
4. 在三个孟加拉语数据集上进行实验；
5. 引入基于教材的新数据集NCTBText丰富语料多样性。

Result: 1. GHTM在主题连贯性（coherence）和多样性（diversity）指标上显著优于基线方法（包括LDA/LSA/NMF等传统方法和BERTopic/Top2Vec等现代方法）；
2. 发布了首个教科书来源的孟加拉语主题建模数据集NCTBText。

Conclusion: 该工作填补了孟加拉语主题建模的研究空白，提出的GHTM模型通过结合图神经网络与矩阵分解技术，有效捕捉了语义关系。新数据集促进了孟加拉语NLP资源的多样性，实验证明模型对复杂形态语言具有较强适应性。

Abstract: Topic modeling is a Natural Language Processing (NLP) technique that is used
to identify latent themes and extract topics from text corpora by grouping
similar documents based on their most significant keywords. Although widely
researched in English, topic modeling remains understudied in Bengali due to
its morphological complexity, lack of adequate resources and initiatives. In
this contribution, a novel Graph Convolutional Network (GCN) based model called
GHTM (Graph-Based Hybrid Topic Model) is proposed. This model represents input
vectors of documents as nodes in the graph, which GCN uses to produce
semantically rich embeddings. The embeddings are then decomposed using
Non-negative Matrix Factorization (NMF) to get the topical representations of
the underlying themes of the text corpus. This study compares the proposed
model against a wide range of Bengali topic modeling techniques, from
traditional methods such as LDA, LSA, and NMF to contemporary frameworks such
as BERTopic and Top2Vec on three Bengali datasets. The experimental results
demonstrate the effectiveness of the proposed model by outperforming other
models in topic coherence and diversity. In addition, we introduce a novel
Bengali dataset called "NCTBText" sourced from Bengali textbook materials to
enrich and diversify the predominantly newspaper-centric Bengali corpora.

</details>


### [119] [Prompting Science Report 3: I'll pay you or I'll kill you -- but will you care?](https://arxiv.org/abs/2508.00614)
*Lennart Meincke,Ethan Mollick,Lilach Mollick,Dan Shapiro*

Main category: cs.CL

TL;DR: 报告实证测试了两种常见的提示策略——给小费和威胁模型是否影响AI性能。结果表明，在基准测试中，这些简单提示变体通常没有显著效果，但对个别问题的表现有明显影响。结论是，对于困难问题，简单提示策略不如之前认为的有效。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在验证两种广泛流传的提示策略（给小费和威胁AI模型）是否能提升AI模型在基准测试中的表现。研究动机源于业界领袖（如Google创始人Sergey Brin）的公开主张，这些未经实证检验的说法在实践中被广泛采用。

Method: 研究团队使用GPQA (Rein et al. 2024) 和 MMLU-Pro (Wang et al. 2024)两个基准测试集，对比了标准提示与两种特定提示策略（提供小费、威胁模型）的性能差异。通过控制变量实验测量不同提示条件下模型的准确率变化。

Result: 1）在整体基准测试层面，威胁或提供小费对模型性能无显著影响；2）在单问题层面，提示变体会显著改变模型表现，但这种影响难以预测——同一提示策略可能提升某些问题的准确性，同时降低其他问题的表现。

Conclusion: 对于复杂问题，简单提示技巧（如威胁或提供小费）并非可靠解决方案。研究揭示提示策略存在'问题特定性'现象：尽管特定提示可显著改变某个问题的结果，但无法预先判断其作用方向（提升/降低性能），因此实际应用中需谨慎采用此类技巧。

Abstract: This is the third in a series of short reports that seek to help business,
education, and policy leaders understand the technical details of working with
AI through rigorous testing. In this report, we investigate two commonly held
prompting beliefs: a) offering to tip the AI model and b) threatening the AI
model. Tipping was a commonly shared tactic for improving AI performance and
threats have been endorsed by Google Founder Sergey Brin (All-In, May 2025,
8:20) who observed that 'models tend to do better if you threaten them,' a
claim we subject to empirical testing here. We evaluate model performance on
GPQA (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024).
  We demonstrate two things:
  - Threatening or tipping a model generally has no significant effect on
benchmark performance.
  - Prompt variations can significantly affect performance on a per-question
level. However, it is hard to know in advance whether a particular prompting
approach will help or harm the LLM's ability to answer any particular question.
  Taken together, this suggests that simple prompting variations might not be
as effective as previously assumed, especially for difficult problems. However,
as reported previously (Meincke et al. 2025a), prompting approaches can yield
significantly different results for individual questions.

</details>


### [120] [DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language Models](https://arxiv.org/abs/2508.00619)
*Shantanu Thorat,Andrew Caines*

Main category: cs.CL

TL;DR: 该论文指出了现有AI生成文本检测器在真实场景中的不足，它们虽然在内部测试中表现良好，但鲁棒性不够。为此，作者引入了DACTYL数据集，专注于单样本/少样本生成以及领域特定继续预训练语言模型生成的文本。研究发现现有检测器在DACTYL上表现不佳，同时比较了标准二元交叉熵优化和深度X风险优化两种方法训练的检测器，发现后者在分布外场景下表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测器在真实世界应用中表现不佳，尤其是在遇到单样本/少样本生成（即LLM基于少量人类文本示例生成）以及领域特定继续预训练语言模型生成的文本时。现有数据集主要关注零次生成，缺乏对上述挑战性场景的覆盖，因此需要构建一个更复杂的数据集来评估检测器的鲁棒性，并探索新的训练方法以提升检测器在分布外场景的表现。

Method: 1. 构建DACTYL（Diverse Adversarial Corpus of Texts Yielded from Language models）数据集，包含以下挑战性文本：
   - 单样本/少样本生成的文本（LLM基于1个或多个人类文本示例生成）。
   - 领域特定继续预训练（CPT）语言模型生成的文本（使用内存高效优化方法完全训练所有参数）。

2. 训练新型检测器：
   - 标准二元交叉熵（BCE）优化方法。
   - 深度X风险优化（DXO）方法。

3. 评估指标：
   - 在DACTYL测试集上比较现有检测器及新训练检测器的表现。
   - 在分布外（OOD）学生作文数据集上进行模拟部署测试，比较BCE与DXO方法的泛化能力。

Result: 1. 现有检测器在DACTYL数据集上表现显著下降，说明它们对单样本/少样本和CPT生成的文本存在明显漏洞。
2. 在DACTYL测试集上，标准BCE优化的检测器略优于DXO优化的检测器。
3. 但是在分布外（OOD）场景（如学生作文检测）中：
   - DXO检测器泛化能力更强，尤其在最低假阳性率要求下。
   - 最佳DXO检测器在宏F1分数上领先最佳BCE检测器50.56分。
4. 结果表明：DXO优化方法能有效避免过拟合训练集，提升OOD泛化性能。

Conclusion: 该研究通过构建更具挑战性的DACTYL数据集，揭示了现有AI生成文本检测器的关键弱点——对单样本/少样本生成和领域特定继续预训练模型生成的文本鲁棒性不足。同时提出深度X风险优化（DXO）训练方法，在分布外场景下显著优于传统方法。这为开发更鲁棒的AI生成文本检测器指明了改进方向：需要覆盖更广泛、更复杂的生成场景，并采用注重泛化的训练策略。

Abstract: Existing AIG (AI-generated) text detectors struggle in real-world settings
despite succeeding in internal testing, suggesting that they may not be robust
enough. We rigorously examine the machine-learning procedure to build these
detectors to address this. Most current AIG text detection datasets focus on
zero-shot generations, but little work has been done on few-shot or one-shot
generations, where LLMs are given human texts as an example. In response, we
introduce the Diverse Adversarial Corpus of Texts Yielded from Language models
(DACTYL), a challenging AIG text detection dataset focusing on
one-shot/few-shot generations. We also include texts from domain-specific
continued-pre-trained (CPT) language models, where we fully train all
parameters using a memory-efficient optimization approach. Many existing AIG
text detectors struggle significantly on our dataset, indicating a potential
vulnerability to one-shot/few-shot and CPT-generated texts. We also train our
own classifiers using two approaches: standard binary cross-entropy (BCE)
optimization and a more recent approach, deep X-risk optimization (DXO). While
BCE-trained classifiers marginally outperform DXO classifiers on the DACTYL
test set, the latter excels on out-of-distribution (OOD) texts. In our mock
deployment scenario in student essay detection with an OOD student essay
dataset, the best DXO classifier outscored the best BCE-trained classifier by
50.56 macro-F1 score points at the lowest false positive rates for both. Our
results indicate that DXO classifiers generalize better without overfitting to
the test set. Our experiments highlight several areas of improvement for AIG
text detectors.

</details>


### [121] [Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](https://arxiv.org/abs/2508.00669)
*Wenxuan Wang,Zizhan Ma,Meidan Ding,Shiyi Zheng,Shengyuan Liu,Jie Liu,Jiaming Ji,Wenting Chen,Xiang Li,Linlin Shen,Yixuan Yuan*

Main category: cs.CL

TL;DR: 该论文对专为医学推理设计的大型语言模型（LLMs）进行了首个系统性综述，提出了推理增强技术的分类体系，涵盖训练阶段策略和测试阶段机制，分析了跨模态和关键临床应用的实施，并讨论了评估基准的演变以及未来挑战与方向。


<details>
  <summary>Details</summary>
Motivation: 医学实践的基石是系统性、透明且可验证的推理能力，但目前医学领域的大型语言模型（LLMs）在这一能力上存在显著不足，这推动了从单步答案生成向专门医学推理模型发展的转变。因此，本论文旨在填补这一研究领域的空白，通过系统回顾2022-2025年间60项开创性研究，构建技术分类并分析现状，为未来高效、鲁棒且社会技术责任兼备的医疗AI发展指明方向。

Method: 1. 建立推理增强技术分类法：将技术分为训练阶段策略（如监督微调、强化学习）和测试阶段机制（如提示工程、多智能体系统）；2. 跨维度分析：评估技术在不同数据模态（文本、图像、代码）及关键临床场景（诊断、教育、治疗规划）中的应用；3. 评估体系调研：梳理从简单准确率指标到推理质量与视觉可解释性等复杂评估基准的演变； 4. 文献综合：对60项2022-2025年的开创性研究进行系统分析。

Result: 1. 揭示了当前医学LLM在提升推理能力上的技术路径，指出训练与测试阶段的不同优化手段；2. 跨模态分析突显了文本主导现状与原生多模态推理的缺失；3. 评估机制演进表明领域正从结果导向转向过程可验证性；4. 识别核心挑战：包括'忠实性-合理性鸿沟'（模型推理过程与医学逻辑的一致性不足）、多模态推理的技术瓶颈；5. 提出未来方向：需开发更高效的结构化推理架构，加强模型鲁棒性，并建立社会技术责任框架。

Conclusion: 医学推理专用LLM的发展需突破当前技术局限，重点关注推理过程的忠实性和多模态整合能力，同时应构建兼顾技术效能与社会责任的系统化解决方案。未来研究应致力于开发原生支持临床决策透明化机制的多模态推理架构，并通过对抗性训练和解释性评估持续优化模型鲁棒性。

Abstract: The proliferation of Large Language Models (LLMs) in medicine has enabled
impressive capabilities, yet a critical gap remains in their ability to perform
systematic, transparent, and verifiable reasoning, a cornerstone of clinical
practice. This has catalyzed a shift from single-step answer generation to the
development of LLMs explicitly designed for medical reasoning. This paper
provides the first systematic review of this emerging field. We propose a
taxonomy of reasoning enhancement techniques, categorized into training-time
strategies (e.g., supervised fine-tuning, reinforcement learning) and test-time
mechanisms (e.g., prompt engineering, multi-agent systems). We analyze how
these techniques are applied across different data modalities (text, image,
code) and in key clinical applications such as diagnosis, education, and
treatment planning. Furthermore, we survey the evolution of evaluation
benchmarks from simple accuracy metrics to sophisticated assessments of
reasoning quality and visual interpretability. Based on an analysis of 60
seminal studies from 2022-2025, we conclude by identifying critical challenges,
including the faithfulness-plausibility gap and the need for native multimodal
reasoning, and outlining future directions toward building efficient, robust,
and sociotechnically responsible medical AI.

</details>


### [122] [MELAC: Massive Evaluation of Large Language Models with Alignment of Culture in Persian Language](https://arxiv.org/abs/2508.00673)
*Farhan Farsi,Farnaz Aghababaloo,Shahriar Shariati Motlagh,Parsa Ghofrani,MohammadAli SadraeiJavaheri,Shayan Bali,Amirhossein Shabani,Farbod Bijary,Ghazal Zamaninejad,AmirMohammad Salehoof,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 该论文针对当前大语言模型（LLMs）评估存在的文化和语言局限性，特别是非英语和非西方文化的缺失，提出了专注于波斯语和伊朗文化的解决方案。作者构建了19个新的评估数据集，覆盖伊朗法律、波斯语法、波斯习语和大学入学考试等主题，并对41个主流LLMs进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 大多数LLMs的评估资源和训练数据主要集中在英语和欧美文化背景，导致其在非西方语言（如波斯语）和文化（如伊朗）中的表现难以衡量且存在不足。因此，需要建立专门针对波斯语和伊朗文化的评估数据集来填补这一空白。

Method: 1. 构建19个新颖的评估数据集，覆盖伊朗法律、波斯语法、波斯习语、伊朗大学入学考试等重点领域。
2. 使用这些数据集对41个著名的大型语言模型进行系统性评估。

Result: 通过新构建的数据集对41个主流LLMs进行了测试，揭示了现有模型在波斯语和伊朗文化背景下的性能表现。这些结果突显了多语言和文化适应模型的实际差距，为后续改进提供了数据支撑。

Conclusion: 该研究填补了LLMs评估领域在波斯语和伊朗文化方面的空白。新数据集和基准测试结果表明了当前模型在非西方文化和语言中的不足，强调了构建多元化评估资源的重要性，从而推动更具包容性的LLM发展。

Abstract: As large language models (LLMs) become increasingly embedded in our daily
lives, evaluating their quality and reliability across diverse contexts has
become essential. While comprehensive benchmarks exist for assessing LLM
performance in English, there remains a significant gap in evaluation resources
for other languages. Moreover, because most LLMs are trained primarily on data
rooted in European and American cultures, they often lack familiarity with
non-Western cultural contexts. To address this limitation, our study focuses on
the Persian language and Iranian culture. We introduce 19 new evaluation
datasets specifically designed to assess LLMs on topics such as Iranian law,
Persian grammar, Persian idioms, and university entrance exams. Using these
datasets, we benchmarked 41 prominent LLMs, aiming to bridge the existing
cultural and linguistic evaluation gap in the field.

</details>


### [123] [Team "better_call_claude": Style Change Detection using a Sequential Sentence Pair Classifier](https://arxiv.org/abs/2508.00675)
*Gleb Schmidt,Johannes Römisch,Mariia Halchynska,Svetlana Gorovaia,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 针对PAN 2025的细粒度风格变化检测任务（以句子为单位），提出一种基于预训练语言模型与双向LSTM的序列句子对分类器（SSPC），通过建模上下文解决短句风格特征模糊的难题，在三个难度级别的测试集上超越基准模型及Claude零样本性能。


<details>
  <summary>Details</summary>
Motivation: 由于现有风格检测方法在句子级细粒度分割上表现不足，且数据中短句的“风格浅显”问题严重，因此需要开发能有效利用上下文信息的轻量模型。

Method: 1. 使用预训练语言模型（PLM）生成句子向量；2. 通过双向LSTM对句子序列建模获取上下文感知表示；3. 将相邻句子的LSTM输出向量拼接；4. 输入多层感知机（MLP）判断风格边界。

Result: 在PAN-2025官方测试集上，该方法在EASY/MEDIUM/HARD三个子集的macro-F1分别达0.923/0.828/0.724，显著超越随机基线及Claude-3.7-sonnet的零样本性能。

Conclusion: SSPC架构通过上下文建模有效缓解短句风格判别难题，以轻量化设计实现优越性能，验证了对细粒度风格变化检测任务的有效性。

Abstract: Style change detection - identifying the points in a document where writing
style shifts - remains one of the most important and challenging problems in
computational authorship analysis. At PAN 2025, the shared task challenges
participants to detect style switches at the most fine-grained level:
individual sentences. The task spans three datasets, each designed with
controlled and increasing thematic variety within documents. We propose to
address this problem by modeling the content of each problem instance - that
is, a series of sentences - as a whole, using a Sequential Sentence Pair
Classifier (SSPC). The architecture leverages a pre-trained language model
(PLM) to obtain representations of individual sentences, which are then fed
into a bidirectional LSTM (BiLSTM) to contextualize them within the document.
The BiLSTM-produced vectors of adjacent sentences are concatenated and passed
to a multi-layer perceptron for prediction per adjacency. Building on the work
of previous PAN participants classical text segmentation, the approach is
relatively conservative and lightweight. Nevertheless, it proves effective in
leveraging contextual information and addressing what is arguably the most
challenging aspect of this year's shared task: the notorious problem of
"stylistically shallow", short sentences that are prevalent in the proposed
benchmark data. Evaluated on the official PAN-2025 test datasets, the model
achieves strong macro-F1 scores of 0.923, 0.828, and 0.724 on the EASY, MEDIUM,
and HARD data, respectively, outperforming not only the official random
baselines but also a much more challenging one: claude-3.7-sonnet's zero-shot
performance.

</details>


### [124] [Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries](https://arxiv.org/abs/2508.00679)
*Shubham Kumar Nigam,Tanmay Dubey,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 为了提高法律判例检索在复杂、大量法律文档中的处理能力，TraceRetriever系统旨在通过提取案件文件中的显著性说服力段落，而非整个文档来模仿真实世界的法律搜索。该系统结合了BM25、向量数据库和交叉编码器模型，并通过互惠位置排序融合算法进行初步结果集成，再重新排序以准确找到判例。


<details>
  <summary>Details</summary>
Motivation: 普通法系中的判决一致性原则要求案例检索具备高度可靠性和可扩展性。但是，不断增长的复杂法律文档量挑战传统检索方法。当只有部分案例文件信息可用时，传统方法效率低下。因此，需要一种能够在有限案件条件下高效运行的、利用说服力段落提取为焦点的检索模型，以提升法律研究成效。

Method: 开发名为TraceRetriever的系统，包含两个主要阶段：（1）说服力段落生成：采用基于印度判决训练的层级双向LSTM结合条件随机领域模型，标注法律文件中的说服力段落；（2）检索排序流水线：首先通过BM25模型、向量数据库（将文本向量化并执行相似度匹配）以及交叉编码器模型分别抽取初始结果；然后通过融合三者初结果使用互惠位置排序算法整合后再由交叉编码器进行重新排序并输出最终结果。

Result: 该系统在IL-PCR和COLIEE 2025两个数据集上进行了评估实验，结果证明TraceRetriever通过融合不同检索技术和限制仅处理关键说服力段落，成功解决了在仅有限案件信息可用时仍能够高效和准确检索法律先例的问题。在文档量增长的情况下保持可扩展和准确，有效提升了法律相关应用的性能。

Conclusion: 文章提出了TraceRetriever系统，其利用结构化的说服力段落生成模型和多模型的检索整合技术实现了在有限案件信息条件下高效检索法律案例。此方法解决了传统方法无法处理大规模文档和部分信息可用性的问题，并为法律行业提供了一种面向实战需求、可靠且具有可扩展性的检索框架，提升了司法系统效率，特别是当只掌握案件信息中的关键片段时。

Abstract: Legal precedent retrieval is a cornerstone of the common law system, governed
by the principle of stare decisis, which demands consistency in judicial
decisions. However, the growing complexity and volume of legal documents
challenge traditional retrieval methods. TraceRetriever mirrors real-world
legal search by operating with limited case information, extracting only
rhetorically significant segments instead of requiring complete documents. Our
pipeline integrates BM25, Vector Database, and Cross-Encoder models, combining
initial results through Reciprocal Rank Fusion before final re-ranking.
Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier
trained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,
TraceRetriever addresses growing document volume challenges while aligning with
practical search constraints, reliable and scalable foundation for precedent
retrieval enhancing legal research when only partial case knowledge is
available.

</details>


### [125] [Better Call Claude: Can LLMs Detect Changes of Writing Style?](https://arxiv.org/abs/2508.00680)
*Johannes Römisch,Svetlana Gorovaia,Mariia Halchynska,Gleb Schmidt,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 本文研究了最先进的大型语言模型（LLM）在作者分析最挑战性任务之一——句子级风格变化检测上的零样本表现。通过在PAN 2024和2025官方数据集上测试四个LLM，我们发现这些模型对写作风格的变化非常敏感（即使是句子级），其性能超越了PAN官方基线，并揭示了新一代LLM可能比先前报道更依赖非语义的纯粹风格信号。


<details>
  <summary>Details</summary>
Motivation: 探究现代大型语言模型是否能在不依赖任务特定训练的情况下，识别文本中细微的风格变化（特别是句子级变化），并评估其在权威数据集上的零样本性能。

Method: 1. 选择4种最先进的大语言模型；2. 使用PAN 2024和2025'多作者写作风格分析'官方数据集；3. 设计句子级风格变化检测的零样本评估任务；4. 测试模型对句子风格变化的敏感度；5. 对比模型性能与PAN官方基准线的差距；6. 通过控制变量研究语义信息对模型判断的影响。

Result: 1. 所有测试模型均表现出对句子级写作风格变化的敏感度；2. 零样本模型性能均超越PAN竞赛官方给出的基线系统；3. 实验证据显示新一代LLM对非语义的纯风格信号捕捉能力可能强于预期。

Conclusion: 最先进的大语言模型在零样本设置下即可胜任句子级风格变化检测任务，其敏感度和准确度建立了一个强有力的新基准。同时这些模型对纯粹风格特征的依赖程度超过以往认知，这为未来基于风格的分析任务提供了新的技术路径。

Abstract: This article explores the zero-shot performance of state-of-the-art large
language models (LLMs) on one of the most challenging tasks in authorship
analysis: sentence-level style change detection. Benchmarking four LLMs on the
official PAN~2024 and 2025 "Multi-Author Writing Style Analysis" datasets, we
present several observations. First, state-of-the-art generative models are
sensitive to variations in writing style - even at the granular level of
individual sentences. Second, their accuracy establishes a challenging baseline
for the task, outperforming suggested baselines of the PAN competition.
Finally, we explore the influence of semantics on model predictions and present
evidence suggesting that the latest generation of LLMs may be more sensitive to
content-independent and purely stylistic signals than previously reported.

</details>


### [126] [NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System](https://arxiv.org/abs/2508.00709)
*Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 提出NyayaRAG框架，利用检索增强生成技术整合事实描述、法律条文和判例，提高印度法律判决预测的准确性和解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有印度法律判决预测方法忽略成文法体系和判例法依赖，NyayaRAG通过模拟真实法庭场景弥补这一缺陷。

Method: 基于RAG架构：输入案件事实描述+法律条文+相似判例；使用领域定制流程预测判决并生成解释；评估采用传统指标和G-Eval等LLM评估器。

Result: 实验证明增加结构化法律知识显著提升预测准确率和解释质量。

Conclusion: NyayaRAG有效提升法律AI性能，强调整合法律知识和判例对判决预测与解释的重要性。

Abstract: Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,
aiming to automate judicial outcome forecasting and enhance interpretability in
legal reasoning. While previous approaches in the Indian context have relied on
internal case content such as facts, issues, and reasoning, they often overlook
a core element of common law systems, which is reliance on statutory provisions
and judicial precedents. In this work, we propose NyayaRAG, a
Retrieval-Augmented Generation (RAG) framework that simulates realistic
courtroom scenarios by providing models with factual case descriptions,
relevant legal statutes, and semantically retrieved prior cases. NyayaRAG
evaluates the effectiveness of these combined inputs in predicting court
decisions and generating legal explanations using a domain-specific pipeline
tailored to the Indian legal system. We assess performance across various input
configurations using both standard lexical and semantic metrics as well as
LLM-based evaluators such as G-Eval. Our results show that augmenting factual
inputs with structured legal knowledge significantly improves both predictive
accuracy and explanation quality.

</details>


### [127] [Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA](https://arxiv.org/abs/2508.00719)
*Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siwei Liu*

Main category: cs.CL

TL;DR: 提出了动态适应MCTS推理框架（DAMR），提升知识图谱问答性能，通过符号搜索与自适应路径评估实现高效且上下文感知的推理。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱问答方法存在局限：（1）基于静态路径提取的检索-推理范式存在适应性不足和上下文细化缺乏问题；（2）基于动态路径生成的大语言模型方法计算成本高且路径评估不准确。DAMR旨在解决以上问题。

Method: （1）采用蒙特卡洛树搜索（MCTS）框架，由大语言模型规划器指导，每一步选取top-k关系缩小搜索空间；（2）设计轻量Transformer评分器，通过交叉注意力联合编码问题与关系序列，实现细粒度的上下文感知路径评估；（3）引入动态伪路径优化机制：利用搜索中采样的部分路径生成训练信号，使评分器持续适应推理轨迹的演化分布。

Result: 在多个知识图谱问答基准测试中显著超越现有方法。

Conclusion: DAMR成功整合了符号搜索与神经路径评估，通过动态伪路径优化缓解了监督数据稀缺问题，实现了高效且精确的多跳推理。

Abstract: Knowledge Graph Question Answering (KGQA) aims to interpret natural language
queries and perform structured reasoning over knowledge graphs by leveraging
their relational and semantic structures to retrieve accurate answers. Recent
KGQA methods primarily follow either retrieve-then-reason paradigm, relying on
GNNs or heuristic rules for static paths extraction, or dynamic path generation
strategies that use large language models (LLMs) with prompting to jointly
perform retrieval and reasoning. However, the former suffers from limited
adaptability due to static path extraction and lack of contextual refinement,
while the latter incurs high computational costs and struggles with accurate
path evaluation due to reliance on fixed scoring functions and extensive LLM
calls. To address these issues, this paper proposes Dynamically Adaptive
MCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search
with adaptive path evaluation for efficient and context-aware KGQA. DAMR
employs a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based
planner, which selects top-$k$ relevant relations at each step to reduce search
space. To improve path evaluation accuracy, we introduce a lightweight
Transformer-based scorer that performs context-aware plausibility estimation by
jointly encoding the question and relation sequence through cross-attention,
enabling the model to capture fine-grained semantic shifts during multi-hop
reasoning. Furthermore, to alleviate the scarcity of high-quality supervision,
DAMR incorporates a dynamic pseudo-path refinement mechanism that periodically
generates training signals from partial paths explored during search, allowing
the scorer to continuously adapt to the evolving distribution of reasoning
trajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR
significantly outperforms state-of-the-art methods.

</details>


### [128] [Out-of-Context Abduction: LLMs Make Inferences About Procedural Data Leveraging Declarative Facts in Earlier Training Data](https://arxiv.org/abs/2508.00741)
*Sohaib Imran,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）在训练数据中进行上下文外推理的能力，特别关注其通过训练数据中的隐含信息推断观察现象的最合理解释。实验证明，GPT-4o能够在未直接接触对话样本的情况下，通过行为描述推断出虚构聊天机器人的名称，并能通过行为描述引导自身模拟该聊天机器人的行为特征。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在大量语料上训练，但其是否能够真正理解并推理训练数据中的信息仍不明确。本研究旨在探究LLMs是否具备在训练数据中进行上下文外推理的能力，即通过隐含信息推断观察现象的最合理解释（溯因推理），这对评估LLMs的情境感知能力和AI安全性具有重要意义。

Method: 设计实验研究LLMs的上下文外溯因推理能力：1. 为虚构聊天机器人创建名称及行为描述作为训练数据，但不提供任何对话样本；2. 让LLM（GPT-4o）观察特定聊天机器人的典型响应范例；3. 测试其能否推断出对应的聊天机器人名称；4. 进一步测试：先让LLM学习聊天机器人的行为描述，再通过迭代训练引导其模拟该行为，观察行为模仿效果。

Result: 实验结果表明：1. GPT-4o能够仅凭典型响应范例准确推断出虚构聊天机器人的名称（即连接隐含信息）；2. 预先学习行为描述能显著提升GPT-4o在后续迭代训练中模拟该聊天机器人行为的准确性。

Conclusion: 研究证实LLMs具备从训练数据中提取隐含信息进行溯因推理的能力，证明其在未直接暴露于样本时仍能建立知识关联。这一发现揭示了LLMs具有潜在的情境意识，对AI安全性研究（如意外泄露训练数据敏感信息或模仿危险行为）具有重要警示意义。

Abstract: Large language models (LLMs) are trained on large corpora, yet it is unclear
whether they can reason about the information present within their training
data. We design experiments to study out-of-context abduction in LLMs, the
ability to infer the most plausible explanations for observations using
relevant facts present in training data. We train treatment LLMs on names and
behavior descriptions of fictitious chatbots, but not on examples of dialogue
with the chatbots. We find that OpenAI's GPT 4o LLM can correctly infer at
least one chatbot's name after observing example responses characteristic of
that chatbot. We also find that previously training GPT 4o on descriptions of a
chatbot's behavior allows it to display behaviors more characteristic of the
chatbot when iteratively trained to display such behaviors. Our results have
implications for situational awareness in LLMs and, therefore, for AI safety.

</details>


### [129] [Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents](https://arxiv.org/abs/2508.00742)
*Sarah Mercer,Daniel P. Martin,Phil Swatton*

Main category: cs.CL

TL;DR: 本文研究了基于GPT-4的生成代理在代表人类群体方面的有效性，通过复现HEXACO人格测试实验，发现生成代理能够部分对齐HEXACO框架，但也存在模型偏见。


<details>
  <summary>Details</summary>
Motivation: 生成代理（基于大语言模型）通过自然语言交互展现类人特性，在社会科学研究中作为人类参与者的经济替代品。本研究旨在验证这些基于角色的代理在代表人类群体方面的有效性。

Method: 调查了310个由GPT-4驱动的代理，复现了HEXACO人格量表实验：包括让代理完成问卷、进行因子分析，并将结果与Ashton等人2004年的原始发现进行对比。

Result: 1）从代理的回答中可以恢复出连贯且可信的人格结构，部分对齐HEXACO框架；2）使用精心筛选的代理群体时，GPT-4得出的人格维度具有一致性和可靠性；3）跨模型分析揭示了人格画像的变异性，表明存在模型特定的偏见和局限性。

Conclusion: 研究讨论了在实验过程中遇到的实际问题和挑战，为社会科学研究中使用生成代理的潜在益处与局限提供了洞见，并为设计具有代表性和一致性的代理角色以最大化覆盖人类人格特质提供了实用指南。

Abstract: Generative agents powered by Large Language Models demonstrate human-like
characteristics through sophisticated natural language interactions. Their
ability to assume roles and personalities based on predefined character
biographies has positioned them as cost-effective substitutes for human
participants in social science research. This paper explores the validity of
such persona-based agents in representing human populations; we recreate the
HEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,
conducting factor analysis on their responses, and comparing these results to
the original findings presented by Ashton, Lee, & Goldberg in 2004. Our results
found 1) a coherent and reliable personality structure was recoverable from the
agents' responses demonstrating partial alignment to the HEXACO framework. 2)
the derived personality dimensions were consistent and reliable within GPT-4,
when coupled with a sufficiently curated population, and 3) cross-model
analysis revealed variability in personality profiling, suggesting
model-specific biases and limitations. We discuss the practical considerations
and challenges encountered during the experiment. This study contributes to the
ongoing discourse on the potential benefits and limitations of using generative
agents in social science research and provides useful guidance on designing
consistent and representative agent personas to maximise coverage and
representation of human personality traits.

</details>


### [130] [Agentic large language models improve retrieval-based radiology question answering](https://arxiv.org/abs/2508.00743)
*Sebastian Wind,Jeta Sopa,Daniel Truhn,Mahshad Lotfinia,Tri-Thien Nguyen,Keno Bressem,Lisa Adams,Mirabela Rusu,Harald Köstler,Gerhard Wellein,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.CL

TL;DR: 该研究提出了一个名为Agentic RAG的新型框架，该框架利用大型语言模型（LLMs）通过自主分解放射学问题、迭代检索相关临床证据并动态合成基于证据的回答来提升放射学问答（QA）系统的性能。实验表明，该框架显著提高了多种规模LLMs的放射学诊断准确性、减少了幻觉现象，并增强了事实依据，尤其在中小规模模型中效果最为显著；同时还发现检索能力与临床微调在提升模型表现方面具有互补作用。


<details>
  <summary>Details</summary>
Motivation: 传统基于检索增强生成（RAG）的放射学问答系统通常使用单步检索，这限制了其有效处理复杂临床推理任务的能力。为克服这一缺陷，作者旨在开发一种能够动态指导多步检索过程的代理框架，以提高放射学诊断的准确性和事实依据水平。

Method: 1.框架设计：提出代理式RAG框架，让LLMs自主分解问题、迭代检索证据（数据来源为Radiopaedia）、动态合成答案。2.模型评估：测试了24种不同架构、参数量级（0.5B至>670B）和训练范式（通用、推理优化、临床微调）的LLMs。3.数据集：使用104道经专家整理的放射学问题，分别来自RSNA-RadioQA和ExtendedQA数据集。4.对照实验：比较零样本提示（zero-shot prompting）、常规在线RAG（conventional online RAG）和代理RAG的性能差异。5.评估指标：诊断准确率、幻觉减少率、临床上下文相关性。

Result: 1.诊断准确率：代理检索显著优于零样本提示（73% vs. 64%, P<0.001）和常规在线RAG（73% vs. 68%, P<0.001）。2.模型规模影响：参数量中小型的模型提升幅度最大（如Mistral Large从72%升至81%；Qwen 2.5-7B从55%升至71%），而超大型模型（>200B）的提升可忽略（<2%）。3.幻觉减少：平均幻觉率为9.4%。4.上下文有效性：在46%情况下成功检索到临床相关证据以支撑回答。5.微调互补性：即便临床微调模型也获得显著改善（如MedGemma-27B从71%升至81%），表明检索与微调具有协同效应。

Conclusion: 代理式RAG框架通过动态检索机制显著提升了放射学QA的事实准确性和诊断水平，特别有助于中小型LLMs的性能突破。同时发现，代理检索能力与临床微调之间存在互补关系。该框架证明了多步迭代检索在解决复杂临床推理中的有效性，值得进一步验证其临床实用价值。

Abstract: Clinical decision-making in radiology increasingly benefits from artificial
intelligence (AI), particularly through large language models (LLMs). However,
traditional retrieval-augmented generation (RAG) systems for radiology question
answering (QA) typically rely on single-step retrieval, limiting their ability
to handle complex clinical reasoning tasks. Here we propose an agentic RAG
framework enabling LLMs to autonomously decompose radiology questions,
iteratively retrieve targeted clinical evidence from Radiopaedia, and
dynamically synthesize evidence-based responses. We evaluated 24 LLMs spanning
diverse architectures, parameter scales (0.5B to >670B), and training paradigms
(general-purpose, reasoning-optimized, clinically fine-tuned), using 104
expert-curated radiology questions from previously established RSNA-RadioQA and
ExtendedQA datasets. Agentic retrieval significantly improved mean diagnostic
accuracy over zero-shot prompting (73% vs. 64%; P<0.001) and conventional
online RAG (73% vs. 68%; P<0.001). The greatest gains occurred in mid-sized
models (e.g., Mistral Large improved from 72% to 81%) and small-scale models
(e.g., Qwen 2.5-7B improved from 55% to 71%), while very large models (>200B
parameters) demonstrated minimal changes (<2% improvement). Additionally,
agentic retrieval reduced hallucinations (mean 9.4%) and retrieved clinically
relevant context in 46% of cases, substantially aiding factual grounding. Even
clinically fine-tuned models exhibited meaningful improvements (e.g.,
MedGemma-27B improved from 71% to 81%), indicating complementary roles of
retrieval and fine-tuning. These results highlight the potential of agentic
frameworks to enhance factuality and diagnostic accuracy in radiology QA,
particularly among mid-sized LLMs, warranting future studies to validate their
clinical utility.

</details>


### [131] [GLiDRE: Generalist Lightweight model for Document-level Relation Extraction](https://arxiv.org/abs/2508.00757)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: 提出GLiDRE模型，一种基于GLiNER思想的文档级关系抽取模型。该模型在Re-DocRED数据集上表现优异，特别是在少样本场景下达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 文档级关系抽取(RE)需要建模实体间的复杂交互，现有模型在零样本/少样本设置下的表现尚未充分探索。受GLiNER（一个紧凑的NER模型）的启发，试图构建轻量但高效的文档关系抽取模型。

Method: 1. 基于GLiNER的关键思想构建模型；2. 在Re-DocRED数据集上对比现有SOTA模型；3. 评估不同数据设置（如few-shot）下的表现。

Result: GLiDRE在Re-DocRED数据集上实现了最先进的性能（尤其在少样本场景下）。

Conclusion: 基于GLiNER思想构建的GLiDRE模型是文档级关系抽取的有效方案，尤其适用于数据受限的场景。代码已开源。

Abstract: Relation Extraction (RE) is a fundamental task in Natural Language
Processing, and its document-level variant poses significant challenges, due to
the need to model complex interactions between entities across sentences.
Current approaches, largely based on the ATLOP architecture, are commonly
evaluated on benchmarks like DocRED and Re-DocRED. However, their performance
in zero-shot or few-shot settings remains largely underexplored due to the
task's complexity. Recently, the GLiNER model has shown that a compact NER
model can outperform much larger Large Language Models. With a similar
motivation, we introduce GLiDRE, a new model for document-level relation
extraction that builds on the key ideas of GliNER. We benchmark GLiDRE against
state-of-the-art models across various data settings on the Re-DocRED dataset.
Our results demonstrate that GLiDRE achieves state-of-the-art performance in
few-shot scenarios. Our code is publicly available.

</details>


### [132] [MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese Hate Speech Detection under Cloaking Perturbations](https://arxiv.org/abs/2508.00760)
*Qiyao Xue,Yuchen Dou,Ryan Shi,Xiang Lorraine Li,Wei Gao*

Main category: cs.CL

TL;DR: 提出了一种名为MMBERT的多模态框架，用于检测中文社交媒体上的仇恨言论，该框架通过Mixture-of-Experts架构整合文本、语音和视觉模态，并采用渐进式三阶段训练解决不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 中文社交媒体上的仇恨言论常使用隐蔽技术以逃避基于文本的检测系统，且现有工作多集中于英文数据集，对中文多模态策略的关注有限。

Method: MMBERT框架基于BERT，整合文本、语音和视觉模态：1) 采用MoE架构，包含模态特定专家、共享自注意力机制和基于路由器的专家分配策略；为克服直接集成MoE到BERT模型的不稳定性，开发了渐进式三阶段训练范式。

Result: 在多个中文仇恨言论数据集上，MMBERT显著超越了微调的基于BERT的编码器模型、微调的大语言模型（LLM）及使用上下文学习的LLM方法。

Conclusion: MMBERT为中文情境下的多模态仇恨言论检测提供了有效解决方案，其提出的渐进训练范式成功解决了在BERT架构中集成MoE时的不稳定性问题，展示了在多模态特征融合上的鲁棒性和优越性能。

Abstract: Hate speech detection on Chinese social networks presents distinct
challenges, particularly due to the widespread use of cloaking techniques
designed to evade conventional text-based detection systems. Although large
language models (LLMs) have recently improved hate speech detection
capabilities, the majority of existing work has concentrated on English
datasets, with limited attention given to multimodal strategies in the Chinese
context. In this study, we propose MMBERT, a novel BERT-based multimodal
framework that integrates textual, speech, and visual modalities through a
Mixture-of-Experts (MoE) architecture. To address the instability associated
with directly integrating MoE into BERT-based models, we develop a progressive
three-stage training paradigm. MMBERT incorporates modality-specific experts, a
shared self-attention mechanism, and a router-based expert allocation strategy
to enhance robustness against adversarial perturbations. Empirical results in
several Chinese hate speech datasets show that MMBERT significantly surpasses
fine-tuned BERT-based encoder models, fine-tuned LLMs, and LLMs utilizing
in-context learning approaches.

</details>


### [133] [ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A Zero-Shot Approach using LLM-Driven Code Generation](https://arxiv.org/abs/2508.00762)
*Atakan Site,Emre Hakan Erdemir,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 该系统设计用于SemEval-2025 Task 8的DataBench任务，包括两个子任务（QA和Lite QA）。采用了基于LLM的零样本方法，通过优化的提示策略生成可执行的Pandas代码。实验表明不同LLM在代码生成上表现不一，且代码生成方法优于其他方案。系统在开源模型类别中分别在子任务I和II获得第八和第六名。


<details>
  <summary>Details</summary>
Motivation: 解决表格多域问答任务（SemEval-2025 Task 8），尤其是零样本场景下利用LLM的代码生成能力提升表格QA性能的需求。

Method: 开发了一个Python代码生成框架，利用开源LLM通过优化提示生成可执行的Pandas代码来回答表格问题。

Result: 不同LLM在代码生成效果上存在差异；代码生成方法在表格QA中表现优异；系统在开源模型类别中分别获得子任务I第八名（30队中）和子任务II第六名。

Conclusion: 基于LLM的代码生成是有效的表格QA解决方案，尤其通过提示优化可提升零样本性能，在开源模型竞赛中获得较高排名证明了其竞争力。

Abstract: This paper presents our system for SemEval-2025 Task 8: DataBench,
Question-Answering over Tabular Data. The primary objective of this task is to
perform question answering on given tabular datasets from diverse domains under
two subtasks: DataBench QA (Subtask I) and DataBench Lite QA (Subtask II). To
tackle both subtasks, we developed a zero-shot solution with a particular
emphasis on leveraging Large Language Model (LLM)-based code generation.
Specifically, we propose a Python code generation framework utilizing
state-of-the-art open-source LLMs to generate executable Pandas code via
optimized prompting strategies. Our experiments reveal that different LLMs
exhibit varying levels of effectiveness in Python code generation.
Additionally, results show that Python code generation achieves superior
performance in tabular question answering compared to alternative approaches.
Although our ranking among zero-shot systems is unknown at the time of this
paper's submission, our system achieved eighth place in Subtask I and sixth
place in Subtask~II among the 30 systems that outperformed the baseline in the
open-source models category.

</details>


### [134] [Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models](https://arxiv.org/abs/2508.00788)
*Xushuo Tang,Yi Ding,Zhengyi Yang,Yin Chen,Yongrui Gu,Wenke Yang,Mingchen Ju,Xin Cao,Yongfei Liu,Wenjie Zhang*

Main category: cs.CL

TL;DR: 研究引入了 MISGENDERED+ 基准来评估大语言模型（LLMs）对性别中立代词和新创代词的准确处理，测试了五个代表性模型。结果显示在二元和性别中立代词准确性方面有显著改进，但新创代词准确性和对调任务表现仍不稳定，揭示了身份敏感推理的不足。


<details>
  <summary>Details</summary>
Motivation: 在敏感应用的背景下，负责任人工智能要求公平和包容性。代词使用问题尤其涉及性别中立代词和新创代词的处理成为关键挑战。尽管已有 MISGENDERED 基准暴露了早版 LLMs 在这方面的局限，但它仅适用于过时模型且评估有限。

Method: 引入了扩展和更新的基准 MISGENDERED+，评估五个模型（GPT-4o、Claude 4、DeepSeek-V3、Qwen Turbo、Qwen2.5）在零样本学习、少样本学习和性别身份推理方面的表现。测试内容包括多个层面的代词准确处理任务。

Result: 与之前的研究相比，模型在二元和性别中立代词准确性方面有了显著改进。但新创代词任务的准确性和对调（reverse inference）任务仍表现不一致，这突出了身份敏感推理方面的差距依然存在。

Conclusion: 尽管大型语言模型在性别中立代词方面取得了进步，但在新创代词及推理任务上的不足仍值得关注。研究强调了未来在包容性人工智能研究上需要进一步探索的方向。

Abstract: Large language models (LLMs) are increasingly deployed in sensitive contexts
where fairness and inclusivity are critical. Pronoun usage, especially
concerning gender-neutral and neopronouns, remains a key challenge for
responsible AI. Prior work, such as the MISGENDERED benchmark, revealed
significant limitations in earlier LLMs' handling of inclusive pronouns, but
was constrained to outdated models and limited evaluations. In this study, we
introduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs'
pronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4,
DeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender
identity inference. Our results show notable improvements compared with
previous studies, especially in binary and gender-neutral pronoun accuracy.
However, accuracy on neopronouns and reverse inference tasks remains
inconsistent, underscoring persistent gaps in identity-sensitive reasoning. We
discuss implications, model-specific observations, and avenues for future
inclusive AI research.

</details>


### [135] [Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models](https://arxiv.org/abs/2508.00819)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CL

TL;DR: 本文介绍了一种名为DAEDAL的无训练去噪策略，用于动态自适应生成长度的扩散大语言模型（DLLMs），解决了传统扩散语言模型需要预设生成长度的限制，提高性能与计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前扩散大语言模型（DLLMs）在应用时受到静态预设生成长度的限制：预设过短影响复杂任务表现，预设过长导致计算浪费；而模型自身其实隐含了每个任务所需的最优长度信号。本文旨在通过动态策略突破这一约束。

Method: 1）在去噪前，先从短初始长度开始，根据序列完成度指标迭代扩展得到粗粒度的任务合适长度；2）在去噪过程中动态干预，通过插入掩码令牌识别和扩展生成不足的区域，确保输出充分表达。整个过程无需额外训练。

Result: 实验表明，DAEDAL在性能上能达到甚至超越预设固定长度的基线模型，同时通过提升有效令牌比例（减少冗余生成长度）实现了更高的计算效率。

Conclusion: DAEDAL消除了DLLMs的静态生成长度限制，释放了新潜力，弥合了与自回归语言模型的差距，为更高效更强的文本生成铺路。

Abstract: Diffusion Large Language Models (DLLMs) are emerging as a powerful
alternative to the dominant Autoregressive Large Language Models, offering
efficient parallel generation and capable global context modeling. However, the
practical application of DLLMs is hindered by a critical architectural
constraint: the need for a statically predefined generation length. This static
length allocation leads to a problematic trade-off: insufficient lengths
cripple performance on complex tasks, while excessive lengths incur significant
computational overhead and sometimes result in performance degradation. While
the inference framework is rigid, we observe that the model itself possesses
internal signals that correlate with the optimal response length for a given
task. To bridge this gap, we leverage these latent signals and introduce
DAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive
Length Expansion for Diffusion Large Language Models. DAEDAL operates in two
phases: 1) Before the denoising process, DAEDAL starts from a short initial
length and iteratively expands it to a coarse task-appropriate length, guided
by a sequence completion metric. 2) During the denoising process, DAEDAL
dynamically intervenes by pinpointing and expanding insufficient generation
regions through mask token insertion, ensuring the final output is fully
developed. Extensive experiments on DLLMs demonstrate that DAEDAL achieves
performance comparable, and in some cases superior, to meticulously tuned
fixed-length baselines, while simultaneously enhancing computational efficiency
by achieving a higher effective token ratio. By resolving the static length
constraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap
with their Autoregressive counterparts and paving the way for more efficient
and capable generation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [136] [Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion](https://arxiv.org/abs/2508.00037)
*Tong Nie,Jian Sun,Wei Ma*

Main category: cs.LG

TL;DR: 为了解决当前图神经网络在大型城市网络动态预测中面临的计算效率与效果之间的权衡问题，该论文提出了一种基于物理定律的可扩展时空Transformer模型（ScaleSTF），该模型通过低维嵌入诱导注意力层，并具有线性复杂度。在交通流、太阳能发电和智能电表等大规模城市系统上的验证表明，ScaleSTF在保持高预测性能的同时具有显著的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络等模型在预测大规模城市网络的时空动态时存在计算效率与预测效果之间的权衡问题。为支持工业和工程决策，需要开发既高效又有效的数据驱动预测模型。

Method: 通过借鉴物理定律来设计模型结构，确保模型符合基本原理并避免冗余。提出一种基于Transformer结构的、具有低维嵌入诱导注意力层的可扩展时空Transformer模型（ScaleSTF），该模型能够理解微观和宏观过程，并通过一种原则性的可解释神经扩散方案实现，同时具有线性计算复杂度。

Result: ScaleSTF在交通流、太阳能发电和智能电表等大规模城市系统上的实验表明，该模型实现了最先进的预测性能，并具有显著的可扩展性。

Conclusion: 该研究提供了一种新的视角来预测大型城市网络的动态，通过将物理定律融入模型设计，ScaleSTF在提升预测效率的同时保持了高性能，为大规模城市系统的预测应用探索了新的方向。

Abstract: Networked urban systems facilitate the flow of people, resources, and
services, and are essential for economic and social interactions. These systems
often involve complex processes with unknown governing rules, observed by
sensor-based time series. To aid decision-making in industrial and engineering
contexts, data-driven predictive models are used to forecast spatiotemporal
dynamics of urban systems. Current models such as graph neural networks have
shown promise but face a trade-off between efficacy and efficiency due to
computational demands. Hence, their applications in large-scale networks still
require further efforts. This paper addresses this trade-off challenge by
drawing inspiration from physical laws to inform essential model designs that
align with fundamental principles and avoid architectural redundancy. By
understanding both micro- and macro-processes, we present a principled
interpretable neural diffusion scheme based on Transformer-like structures
whose attention layers are induced by low-dimensional embeddings. The proposed
scalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is
validated on large-scale urban systems including traffic flow, solar power, and
smart meters, showing state-of-the-art performance and remarkable scalability.
Our results constitute a fresh perspective on the dynamics prediction in
large-scale urban networks.

</details>


### [137] [Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings](https://arxiv.org/abs/2508.00039)
*Kaustav Chatterjee,Joshua Q. Li,Fatemeh Ansari,Masud Rana Munna,Kundan Parajulee,Jared Schwennesen*

Main category: cs.LG

TL;DR: 开发了一种结合LSTM和Transformer的混合深度学习框架，用于测量高速铁路平交道口（HRGC）的剖面，以低成本、高效的方式评估其因高度差导致的安全风险。


<details>
  <summary>Details</summary>
Motivation: 传统的HRGC剖面测量方法成本高、耗时长、会干扰交通且存在安全挑战。为解决这些问题，本研究利用先进技术，寻求更经济高效的剖面测量方法。由于高剖面HRGC可能导致车辆托底，因此需要快速准确评估其风险。

Method: 1. 数据收集：使用装备了IMU和GPS传感器的测试车采集仪器数据，同时使用工业级步行剖面仪获取地面真实数据。数据采集地点为俄克拉何马州的Red Rock铁路走廊。
2. 模型开发：提出三种混合深度学习模型：(1) Transformer-LSTM顺序模型；(2) LSTM-Transformer顺序模型；(3) LSTM-Transformer并行模型。
3. 模型评估：比较三种模型的性能，选择最优模型用于生成2D/3D HRGC剖面。

Result: 模型2（LSTM-Transformer顺序）和模型3（LSTM-Transformer并行）表现最佳，成功用于生成高速铁路平交道口的2D/3D剖面图。这些模型能够快速准确地评估HRGC的托底风险，从而提升公路和铁路的安全性。

Conclusion: 深度学习方法在HRGC剖面测量中展现出显著优势，解决了传统方法的不足。通过低成本、高效的方式，实现了道口安全风险的快速评估，有望提高公路与铁路安全水平。

Abstract: Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose
safety risks to highway vehicles due to potential hang-ups. These crossings
typically result from post-construction railway track maintenance activities or
non-compliance with design guidelines for HRGC vertical alignments.
Conventional methods for measuring HRGC profiles are costly, time-consuming,
traffic-disruptive, and present safety challenges. To address these issues,
this research employed advanced, cost-effective techniques and innovative
modeling approaches for HRGC profile measurement. A novel hybrid deep learning
framework combining Long Short-Term Memory (LSTM) and Transformer architectures
was developed by utilizing instrumentation and ground truth data.
Instrumentation data were gathered using a highway testing vehicle equipped
with Inertial Measurement Unit (IMU) and Global Positioning System (GPS)
sensors, while ground truth data were obtained via an industrial-standard
walking profiler. Field data was collected at the Red Rock Railroad Corridor in
Oklahoma. Three advanced deep learning models Transformer-LSTM sequential
(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel
(model 3) were evaluated to identify the most efficient architecture. Models 2
and 3 outperformed the others and were deployed to generate 2D/3D HRGC
profiles. The deep learning models demonstrated significant potential to
enhance highway and railroad safety by enabling rapid and accurate assessment
of HRGC hang-up susceptibility.

</details>


### [138] [Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network](https://arxiv.org/abs/2508.00692)
*Young-ho Cho,Hao Zhu,Duehee Lee,Ross Baldick*

Main category: cs.LG

TL;DR: 提出一种结合广义动态因子模型（GDFM）和生成对抗网络（GAN）的方法，以同时合成分布式风电场的多个长期风电功率场景，该方法在合成风力发电场景时能够更好地复现实际统计特性。


<details>
  <summary>Details</summary>
Motivation: 现有的风能场景合成方法在捕捉时空相关性、波形特征以及统计特性方面存在不足。GDFM能够通过互谱密度分析提取共同因子以处理空间相关性，但难以精确模拟波形；GAN能通过判别器验证样本的时间相关性，但缺乏对动态因子的显式建模。因此，需要结合两者的优势来生成更符合实际的长期风功率场景。

Method: 1. 利用GAN的判别器作为动态因子提取器，从观测数据中提取包含时间信息的动态因子；2. 将提取的动态因子输入GDFM模型，以同时捕捉多个风电场的空间相关性和频率相关性；3. 通过该混合框架生成兼具合理统计特性和波形特征（如边际分布、爬坡率分布、功率谱密度等）的风电功率场景。

Result: 在澳大利亚风电场景合成实验中，提出的GDFM-GAN混合模型显著优于对比方法（如直接使用GAN或使用基于实际滤波器分布合成的GDFM）。该模型能够更好地复现实际风电功率的统计特征（如时空相关性、频率特征、爬坡分布等）。

Conclusion: 通过将GAN的时序生成能力与GDFM的空间相关性建模能力结合，该方法能够有效解决分布式风电场长期场景合成中波形保真度与空间相关性的平衡问题，为资源充裕性研究提供更可靠的风电数据基础。

Abstract: For conducting resource adequacy studies, we synthesize multiple long-term
wind power scenarios of distributed wind farms simultaneously by using the
spatio-temporal features: spatial and temporal correlation, waveforms, marginal
and ramp rates distributions of waveform, power spectral densities, and
statistical characteristics. Generating the spatial correlation in scenarios
requires the design of common factors for neighboring wind farms and
antithetical factors for distant wind farms. The generalized dynamic factor
model (GDFM) can extract the common factors through cross spectral density
analysis, but it cannot closely imitate waveforms. The GAN can synthesize
plausible samples representing the temporal correlation by verifying samples
through a fake sample discriminator. To combine the advantages of GDFM and GAN,
we use the GAN to provide a filter that extracts dynamic factors with temporal
information from the observation data, and we then apply this filter in the
GDFM to represent both spatial and frequency correlations of plausible
waveforms. Numerical tests on the combination of GDFM and GAN have demonstrated
performance improvements over competing alternatives in synthesizing wind power
scenarios from Australia, better realizing plausible statistical
characteristics of actual wind power compared to alternatives such as the GDFM
with a filter synthesized from distributions of actual dynamic filters and the
GAN with direct synthesis without dynamic factors.

</details>


### [139] [Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting](https://arxiv.org/abs/2508.00040)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: 本研究将贝叶斯机制检测与条件神经过程相结合，用于德国市场24小时电价预测。通过机制检测识别不同的电价状态，每个状态由独立的条件神经过程进行建模，并将最终预测作为这些模型输出的加权混合。通过多个电池存储优化应用评估表明，所提出的R-NP模型在2021-2023年间表现出最均衡和最优的性能。


<details>
  <summary>Details</summary>
Motivation: 电力市场中的电价预测对能源存储管理至关重要，然而电价存在复杂的动态变化（机制转换）。传统预测模型没有明确建模这些机制，可能导致预测性能下降。因此，本文结合机制检测和条件神经过程进行预测，以提升预测准确率及其在决策任务中的实用性。

Method: 1. 使用DS-HDP-HMM（解耦的、带记忆的分层Dirichlet过程隐马尔可夫模型）对日电价进行机制检测，识别电价状态；2. 每个机制训练一个条件神经过程（CNP）模型来预测24维小时电价轨迹；3. 最终预测输出为各机制CNP预测的加权混合；4. 对比测试：在多个电池存储优化任务（价格套利、风险管理、电网服务、成本最小化）中评估R-NP、DNN、LEAR模型；5. 使用TOPSIS多准则评估决策实用性。

Result: 优化应用中的性能比较存在复杂性：LEAR模型在绝对利润或最低成本上表现更好；DNN在特定成本最小化任务中表现最好。然而，预测精度高不一定转为最优决策效果。通过TOPSIS综合评估发现：LEAR在2021年排名最高，但R-NP模型在2021-2023年均为决策实用性最均衡和最受青睐的预测方法。

Conclusion: 将贝叶斯机制检测与条件神经过程相结合的R-NP模型在预测准确性上虽非总是最优，但在多类决策任务中的综合实用性最强。TOPSIS多准则评估能更好地服务于决策，而非仅采用单一预测精度指标。

Abstract: This work integrates Bayesian regime detection with conditional neural
processes for 24-hour electricity price prediction in the German market. Our
methodology integrates regime detection using a disentangled sticky
hierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to
daily electricity prices. Each identified regime is subsequently modeled by an
independent conditional neural process (CNP), trained to learn localized
mappings from input contexts to 24-dimensional hourly price trajectories, with
final predictions computed as regime-weighted mixtures of these CNP outputs. We
rigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated
auto-regressive (LEAR) models by integrating their forecasts into diverse
battery storage optimization frameworks, including price arbitrage, risk
management, grid services, and cost minimization. This operational utility
assessment revealed complex performance trade-offs: LEAR often yielded superior
absolute profits or lower costs, while DNN showed exceptional optimality in
specific cost-minimization contexts. Recognizing that raw prediction accuracy
doesn't always translate to optimal operational outcomes, we employed TOPSIS as
a comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified
LEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model
emerged as the most balanced and preferred solution for 2021, 2022 and 2023.

</details>


### [140] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
*Yebo Wu,Jingguang Li,Zhijiang Guo,Li Li*

Main category: cs.LG

TL;DR: 一种名为DevFT的资源高效方法，用于大型语言模型的联邦微调。它通过类似认知发展的方式逐步构建模型，显著提高了收敛速度，减少了通信开销，并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前联邦微调虽然保护了数据隐私，但资源消耗高，限制了其在边缘设备上的部署。需要一种更高效的方法来适应资源受限环境。

Method: DevFT将微调过程分为多个发展阶段，每个阶段训练参数能力递增的子模型。通过知识迁移为后续模型提供优化初始参数以避免局部最优并加速训练。使用了去冲突引导的层分组和基于差分的层融合来有效构建各阶段的子模型。

Result: 在多个基准测试中，DevFT比现有方法表现更好：收敛速度提升4.59倍，通信开销减少10.67倍，平均性能提升9.07%。

Conclusion: DevFT是一种资源高效的联邦学习新方法，通过渐进式发展和知识迁移机制在性能、速度和通信效率上取得显著增益，同时保持与现有方法的兼容性。

Abstract: Federated fine-tuning enables Large Language Models (LLMs) to adapt to
downstream tasks while preserving data privacy, but its resource-intensive
nature limits deployment on edge devices. In this paper, we introduce
Developmental Federated Tuning (DevFT), a resource-efficient approach inspired
by cognitive development that progressively builds a powerful LLM from a
compact foundation. DevFT decomposes the fine-tuning process into developmental
stages, each optimizing submodels with increasing parameter capacity. Knowledge
from earlier stages transfers to subsequent submodels, providing optimized
initialization parameters that prevent convergence to local minima and
accelerate training. This paradigm mirrors human learning, gradually
constructing comprehensive knowledge structure while refining existing skills.
To efficiently build stage-specific submodels, DevFT introduces
deconfliction-guided layer grouping and differential-based layer fusion to
distill essential information and construct representative layers. Evaluations
across multiple benchmarks demonstrate that DevFT significantly outperforms
state-of-the-art methods, achieving up to 4.59$\times$ faster convergence,
10.67$\times$ reduction in communication overhead, and 9.07% average
performance improvement, while maintaining compatibility with existing
approaches.

</details>


### [141] [Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity](https://arxiv.org/abs/2508.00043)
*Nhut Truong,Uri Hasson*

Main category: cs.LG

TL;DR: 本文比较了两种空间约束（权重相似性和激活相似性）在拓扑卷积神经网络中的效果。通过多种评估指标，研究发现权重相似性的实现方式在鲁棒性、输入敏感性和功能定位方面提供了显著优势。


<details>
  <summary>Details</summary>
Motivation: 在神经网络中实现地形约束有多种方式，但这些不同实现方式对网络学习表示的影响尚未被系统研究。本文旨在比较权重相似性（Weight Similarity, WS）和激活相似性（Activation Similarity, AS）两种空间约束对卷积神经网络的影响。

Method: 研究使用两种空间约束训练拓扑卷积神经网络：权重相似性（WS）和激活相似性（AS）。通过分类准确性、对权重扰动和输入退化的鲁棒性以及学习表示的空间组织等多个方面对模型进行评估。

Result: 与AS和标准CNN相比，WS具有三大优势：1）对噪声更具鲁棒性，在权重损坏下保持更高的准确率；2）更高的输入敏感性，表现为更高的激活方差；3）更强的功能定位，激活相似的神经元在空间上更接近。此外，WS还在方向调谐、对称敏感性和离心率分布上产生差异。

Conclusion: 研究发现，端到端训练过程中，基于权重的空间约束（WS）相比激活约束（AS）或非拓扑CNN能产生更鲁棒的表征，且能塑造网络的特征学习和功能组织。这些发现为生物物理启发的模型设计提供了新思路。

Abstract: Topographic neural networks are computational models that can simulate the
spatial and functional organization of the brain. Topographic constraints in
neural networks can be implemented in multiple ways, with potentially different
impacts on the representations learned by the network. The impact of such
different implementations has not been systematically examined. To this end,
here we compare topographic convolutional neural networks trained with two
spatial constraints: Weight Similarity (WS), which pushes neighboring units to
develop similar incoming weights, and Activation Similarity (AS), which
enforces similarity in unit activations. We evaluate the resulting models on
classification accuracy, robustness to weight perturbations and input
degradation, and the spatial organization of learned representations. Compared
to both AS and standard CNNs, WS provided three main advantages: i) improved
robustness to noise, also showing higher accuracy under weight corruption; ii)
greater input sensitivity, reflected in higher activation variance; and iii)
stronger functional localization, with units showing similar activations
positioned at closer distances. In addition, WS produced differences in
orientation tuning, symmetry sensitivity, and eccentricity profiles of units,
indicating an influence of this spatial constraint on the representational
geometry of the network. Our findings suggest that during end-to-end training,
WS constraints produce more robust representations than AS or non-topographic
CNNs. These findings also suggest that weight-based spatial constraints can
shape feature learning and functional organization in biophysical inspired
models.

</details>


### [142] [Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains](https://arxiv.org/abs/2508.00046)
*Ruo Yu Tao,Kaicheng Guo,Cameron Allen,George Konidaris*

Main category: cs.LG

TL;DR: 本文介绍了POBAX：一个用于评估强化学习算法在部分可观测环境下性能的开源基准库。该库涵盖多种部分可观测环境，并提供推荐的超参数和算法实现以实现快速评估。


<details>
  <summary>Details</summary>
Motivation: 现有的部分可观测性基准大多只关注简单形式的状态混叠（如特征掩码和高斯噪声），无法代表真实世界中复杂的形式（如视觉遮挡、对手意图未知等）。这导致算法在真实场景中泛化能力不足。因此需要覆盖更多样化的部分可观测环境。

Method: 1. 提出部分可观测基准应满足的两个关键属性：1) 多样化的部分可观测形式以确保算法通用性；2) 存在"记忆可提升性"（即状态信息充足与否的智能体间性能差距明显）。2. 建立POBAX库：包含定位与建图、视觉控制、游戏等代表性环境；3. 通过分析验证这些环境均具有记忆可提升性且需要复杂记忆函数；4. 提供JAX实现的高速环境和推荐算法超参数。

Result: 证明所选基准环境均具备记忆可提升性（存在显著性能差距），并需要难以学习到的记忆函数。POBAX库在JAX框架下实现了GPU可扩展的高性能评估环境。

Conclusion: POBAX为部分可观测强化学习研究提供了标准化、可扩展的评估框架，填补了现有基准多样性和真实性的不足。其环境的记忆可提升性为算法改进提供明确的优化信号。

Abstract: Mitigating partial observability is a necessary but challenging task for
general reinforcement learning algorithms. To improve an algorithm's ability to
mitigate partial observability, researchers need comprehensive benchmarks to
gauge progress. Most algorithms tackling partial observability are only
evaluated on benchmarks with simple forms of state aliasing, such as feature
masking and Gaussian noise. Such benchmarks do not represent the many forms of
partial observability seen in real domains, like visual occlusion or unknown
opponent intent. We argue that a partially observable benchmark should have two
key properties. The first is coverage in its forms of partial observability, to
ensure an algorithm's generalizability. The second is a large gap between the
performance of a agents with more or less state information, all other factors
roughly equal. This gap implies that an environment is memory improvable: where
performance gains in a domain are from an algorithm's ability to cope with
partial observability as opposed to other factors. We introduce best-practice
guidelines for empirically benchmarking reinforcement learning under partial
observability, as well as the open-source library POBAX: Partially Observable
Benchmarks in JAX. We characterize the types of partial observability present
in various environments and select representative environments for our
benchmark. These environments include localization and mapping, visual control,
games, and more. Additionally, we show that these tasks are all memory
improvable and require hard-to-learn memory functions, providing a concrete
signal for partial observability research. This framework includes recommended
hyperparameters as well as algorithm implementations for fast, out-of-the-box
evaluation, as well as highly performant environments implemented in JAX for
GPU-scalable experimentation.

</details>


### [143] [TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection](https://arxiv.org/abs/2508.00047)
*Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin*

Main category: cs.LG

TL;DR: 提出了一种名为TriP-LLM的无监督时间序列异常检测框架，通过三分支设计整合局部和全局特征，并利用冻结预训练的大语言模型处理patch-wise token。实验表明在多个公开基准数据集上表现优于当前最佳方法，且内存消耗显著降低。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和智能制造的发展，时间序列数据的规模和维度急剧增加，传统统计方法在处理高异构性和复杂性数据上存在局限。受大型语言模型在多模态任务中成功的启发，旨在利用LLM提升时间序列异常检测性能。

Method: 1. 三分支设计：Patching（将输入时间序列分割为patch-wise token）、Selection（选择关键patch）、Global（全局时间特征提取）
2. 使用冻结的预训练LLM处理token
3. 轻量级patch-wise解码器重构输入
4. 通过重构误差计算异常分数

Result: 1. 在多个公共基准数据集上使用无阈值指标PATE评估，均优于最新方法
2. 消融实验证实LLM对架构有显著贡献
3. 相比通道独立（CI）patch处理，内存消耗显著降低，更适合GPU内存受限环境

Conclusion: TriP-LLM框架通过创新性整合局部全局特征和预训练LLM，在时间序列异常检测任务中实现了高性能和低内存消耗，为实际应用提供了有效解决方案。

Abstract: Time-series anomaly detection plays a central role across a wide range of
application domains. With the increasing proliferation of the Internet of
Things (IoT) and smart manufacturing, time-series data has dramatically
increased in both scale and dimensionality. This growth has exposed the
limitations of traditional statistical methods in handling the high
heterogeneity and complexity of such data. Inspired by the recent success of
large language models (LLMs) in multimodal tasks across language and vision
domains, we propose a novel unsupervised anomaly detection framework: A
Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly
Detection (TriP-LLM). TriP-LLM integrates local and global temporal features
through a tri-branch design-Patching, Selection, and Global-to encode the input
time series into patch-wise tokens, which are then processed by a frozen,
pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from
which anomaly scores are derived. We evaluate TriP-LLM on several public
benchmark datasets using PATE, a recently proposed threshold-free evaluation
metric, and conduct all comparisons within a unified open-source framework to
ensure fairness. Experimental results show that TriP-LLM consistently
outperforms recent state-of-the-art methods across all datasets, demonstrating
strong detection capabilities. Furthermore, through extensive ablation studies,
we verify the substantial contribution of the LLM to the overall architecture.
Compared to LLM-based approaches using Channel Independence (CI) patch
processing, TriP-LLM achieves significantly lower memory consumption, making it
more suitable for GPU memory-constrained environments. All code and model
checkpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git

</details>


### [144] [Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization](https://arxiv.org/abs/2508.00078)
*Imen Mahmoud,Andrei Velichko*

Main category: cs.LG

TL;DR: 本文提出了一个集成LightGBM回归模型和遗传算法（GA）优化的新型方法论框架，用于系统评估COVID-19相关指标对比特币回报预测的贡献。研究发现COVID-19指标显著提升了预测精度，其中疫苗接种指标是最主要的预测因子。


<details>
  <summary>Details</summary>
Motivation: 主要动机不是仅仅预测比特币的回报，而是确定包括大流行病相关的健康数据是否能显著提高预测准确性。该研究旨在为投资者和政策制定者在系统性危机期间提供更精确的市场不确定性导航工具。

Method: 1. 构建包含每日比特币回报和COVID-19指标（疫苗接种率、住院情况、检测统计数据）的综合数据集。2. 使用遗传算法（GA）进行了31次独立运行，优化有/无COVID-19特征的预测模型，以确保统计评估的稳健性。3. 通过性能指标（R2、RMSE、MAE）的分布重叠和曼-惠特尼U检验（Mann-Whitney U test）进行统计比较。4. 使用排列特征重要性（PFI）分析法量化各个特征的贡献。

Result: 1. COVID-19指标显著改善了模型性能，尤其是在捕捉极端市场波动方面（R2提高了40%，RMSE降低了2%，且具有高度统计学显著性）。2. 在COVID-19特征中，疫苗接种指标（特别是完全接种人群的75th百分位数）成为主导性预测因子。

Conclusion: 该研究方法扩展了现有的金融分析工具，通过引入公共卫生信号，为投资者和政策制定者在系统性危机期间的市场不确定性中提供了更精细的预测指标。

Abstract: This study proposes a novel methodological framework integrating a LightGBM
regression model and genetic algorithm (GA) optimization to systematically
evaluate the contribution of COVID-19-related indicators to Bitcoin return
prediction. The primary objective was not merely to forecast Bitcoin returns
but rather to determine whether including pandemic-related health data
significantly enhances prediction accuracy. A comprehensive dataset comprising
daily Bitcoin returns and COVID-19 metrics (vaccination rates,
hospitalizations, testing statistics) was constructed. Predictive models,
trained with and without COVID-19 features, were optimized using GA over 31
independent runs, allowing robust statistical assessment. Performance metrics
(R2, RMSE, MAE) were statistically compared through distribution overlaps and
Mann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified
individual feature contributions. Results indicate that COVID-19 indicators
significantly improved model performance, particularly in capturing extreme
market fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly
significant statistically). Among COVID-19 features, vaccination metrics,
especially the 75th percentile of fully vaccinated individuals, emerged as
dominant predictors. The proposed methodology extends existing financial
analytics tools by incorporating public health signals, providing investors and
policymakers with refined indicators to navigate market uncertainty during
systemic crises.

</details>


### [145] [Stress-Aware Resilient Neural Training](https://arxiv.org/abs/2508.00098)
*Ashkan Shakarami,Yousef Yeganeh,Azade Farshad,Lorenzo Nicole,Stefano Ghidoni,Nassir Navab*

Main category: cs.LG

TL;DR: 本文提出了一种名为‘应力感知学习’（Stress-Aware Learning）的弹性神经网络训练范式。该方法在优化困难时，向参数注入自适应噪声以逃避尖锐极小值，从而在稳定训练或不确定动态下都能提升模型的鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 受到材料科学中结构疲劳理论的启发，研究者类比了临时形变与永久形变的概念，提出在模型训练过程中遇到停滞（优化困难）时，应通过引入扰动来帮助模型逃离尖锐极小值，从而提升泛化性能。

Method: 1. 提出基于应力信号的判断机制：当训练损失和精度停滞时，即检测到内部应力信号（反映优化难度）。2. 据此设计塑性形变优化器（Plastic Deformation Optimizer）：在优化困难时向模型参数注入自适应噪声。3. 通过噪声帮助模型逃离尖锐极小值，向更平坦（泛化性好）的损失函数区域收敛。

Result: 在六种网络架构、四种优化器和七个视觉基准测试上进行实验验证，结果表明该方法能以极低计算开销显著提升模型的鲁棒性和泛化能力。

Conclusion: 基于应力信号的自适应噪声注入机制能有效缓解训练停滞问题，促进模型收敛至平坦极小值。该机制在多种架构和任务上具有普适性，且计算成本低。代码和3D可视化已在GitHub开源。

Abstract: This paper introduces Stress-Aware Learning, a resilient neural training
paradigm in which deep neural networks dynamically adjust their optimization
behavior - whether under stable training regimes or in settings with uncertain
dynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)
Deformation, inspired by structural fatigue in materials science. To
instantiate this concept, we propose Plastic Deformation Optimizer, a
stress-aware mechanism that injects adaptive noise into model parameters
whenever an internal stress signal - reflecting stagnation in training loss and
accuracy - indicates persistent optimization difficulty. This enables the model
to escape sharp minima and converge toward flatter, more generalizable regions
of the loss landscape. Experiments across six architectures, four optimizers,
and seven vision benchmarks demonstrate improved robustness and generalization
with minimal computational overhead. The code and 3D visuals will be available
on GitHub: https://github.com/Stress-Aware-Learning/SAL.

</details>


### [146] [StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection](https://arxiv.org/abs/2508.00117)
*Md. Ehsanul Haque,S. M. Jahidul Islam,Shakil Mia,Rumana Sharmin,Ashikuzzaman,Md Samir Morshed,Md. Tahmidul Huque*

Main category: cs.LG

TL;DR: 提出StackLiverNet，一种用于肝病检测的可解释性堆叠集成模型，通过先进的数据预处理和特征选择技术，处理类别不平衡问题，使用多个优化后的基分类器和一个LightGBM元模型，达到高准确率（99.89%）和快速训练推理（训练4.2783秒，推理0.1106秒）。同时使用LIME和SHAP技术增强模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的肝病分类模型存在误分类率高、可解释性差、计算成本高等问题。为解决这些问题，需要开发一个既精准又可解释的高效模型。

Method: 1. 数据预处理：包括特征选择和随机下采样以处理数据不平衡。2. 构建StakeLiverNet：集成多个超参数优化的基分类器，通过LightGBM作为元模型组合它们的优势。3. 模型评估：使用测试集评估性能指标（准确率、Cohen Kappa、AUC）。4. 可解释性分析：应用LIME生成单个预测的局部解释，使用SHAP进行特征重要性排序，以及用Morris方法进行敏感性分析。

Result: 模型在测试集上准确率达到99.89%，Cohen Kappa为0.9974，AUC为0.9993，仅有5个错误分类。训练时间和推理时间分别为4.2783秒和0.1106秒。此外，LIME揭示了碱性磷酸酶浓度高和SGOT中等水平作为肝病的重要指标。SHAP和Morris方法确认了特征的重要性。

Conclusion: StackLiverNet在肝病分类中表现卓越，不仅准确率高，速度快，且具有较好的可解释性，适合临床应用。其预处理和集成方法显著提高了分类性能并解决了不平衡数据的影响。

Abstract: Liver diseases are a serious health concern in the world, which requires
precise and timely diagnosis to enhance the survival chances of patients. The
current literature implemented numerous machine learning and deep learning
models to classify liver diseases, but most of them had some issues like high
misclassification error, poor interpretability, prohibitive computational
expense, and lack of good preprocessing strategies. In order to address these
drawbacks, we introduced StackLiverNet in this study; an interpretable stacked
ensemble model tailored to the liver disease detection task. The framework uses
advanced data preprocessing and feature selection technique to increase model
robustness and predictive ability. Random undersampling is performed to deal
with class imbalance and make the training balanced. StackLiverNet is an
ensemble of several hyperparameter-optimized base classifiers, whose
complementary advantages are used through a LightGBM meta-model. The provided
model demonstrates excellent performance, with the testing accuracy of 99.89%,
Cohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and
efficient training and inference speeds that are amenable to clinical practice
(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local
Interpretable Model-Agnostic Explanations (LIME) are applied to generate
transparent explanations of individual predictions, revealing high
concentrations of Alkaline Phosphatase and moderate SGOT as important
observations of liver disease. Also, SHAP was used to rank features by their
global contribution to predictions, while the Morris method confirmed the most
influential features through sensitivity analysis.

</details>


### [147] [Structured Transformations for Stable and Interpretable Neural Computation](https://arxiv.org/abs/2508.00127)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.LG

TL;DR: 提出了神经网络的层转换新范式，将变换分解为结构化线性算子和残差校正部分，以增强训练稳定性、梯度传播和模型鲁棒性，同时保持表达能力和兼容标准训练。


<details>
  <summary>Details</summary>
Motivation: 当代神经网络虽然在性能上表现出色，但往往缺乏结构上的保护机制，这导致学习和可解释行为存在稳定性不足的问题。目前基于无约束仿射变换的标准范式，存在信号传播不规整和训练动态不良等缺点。为了解决这些问题，本文旨在引入一种新的层转换形式，以实现更规整的信号传播和改善训练动态，同时不影响模型的表达能力或与现有训练方法的兼容性。

Method: 该研究重新构造了神经网络层转换的范式：每层转换被分解成结构化线性算子和残差校正部分。结构化线性算子的加入确保了内部一致性和深度信息的稳定传递，而残差校正则保留灵活性以捕捉复杂变换。该方法兼容现有的标准学习目标(损失函数)和反向传播训练机制。具体做法包括：设计结构化算子类别(如正交变换、对角变换等)；定义残差项形式；将分解结合到现有架构(如MLP、CNN)的训练中。

Result: 实验分为合成和现实数据集验证。结果显示：(1)新网络具有更优的梯度条件(条件数下降)，训练更稳定；(2)对输入扰动/权重噪声等敏感性降低；(3)在移除/扰动单一层权重等条件下表现出卓越的层间鲁棒性；(4)不同架构尺度(浅层/深层)和训练策略(监督/无监督)下均保持受益。

Conclusion: 该工作提供了一类新的神经网络架构，既不影响表达力又能增强稳定性和透明性。其核心贡献在于将标准层变换改造为结构化部分+残差形式，为分析网络学习行为提供工具，为鲁棒高效的训练提供新思路。

Abstract: Despite their impressive performance, contemporary neural networks often lack
structural safeguards that promote stable learning and interpretable behavior.
In this work, we introduce a reformulation of layer-level transformations that
departs from the standard unconstrained affine paradigm. Each transformation is
decomposed into a structured linear operator and a residual corrective
component, enabling more disciplined signal propagation and improved training
dynamics. Our formulation encourages internal consistency and supports stable
information flow across depth, while remaining fully compatible with standard
learning objectives and backpropagation. Through a series of synthetic and
real-world experiments, we demonstrate that models constructed with these
structured transformations exhibit improved gradient conditioning, reduced
sensitivity to perturbations, and layer-wise robustness. We further show that
these benefits persist across architectural scales and training regimes. This
study serves as a foundation for a more principled class of neural
architectures that prioritize stability and transparency-offering new tools for
reasoning about learning behavior without sacrificing expressive power.

</details>


### [148] [ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks](https://arxiv.org/abs/2508.00131)
*Christopher Harvey,Sumaiya Shomaji,Zijun Yao,Amit Noheria*

Main category: cs.LG

TL;DR: 该论文提出三种新的变分自编码器（VAE）变体（SAE、Aβ-VAE和Cβ-VAE），用于简化心电图（ECG）数据并提高下游预测任务的性能。特别地，Aβ-VAE在信号重建上表现最佳，SAE编码结合传统特征可将左室射血分数降低的预测AUROC提升至0.901，接近CNN模型但计算资源需求更低。


<details>
  <summary>Details</summary>
Motivation: ECG信号的高复杂性和个体间差异使其在深度学习模型中应用困难，特别是在小训练数据集场景下。为解决这一问题，研究探索了从代表性心跳ECG中生成特征的方法，包括PCA和自编码器，重点降低数据复杂度。

Method: 提出三种VAE变体：随机自编码器（SAE）、退火β-VAE（Aβ-VAE）和周期性β-VAE（Cβ-VAE）；使用LightGBM作为下游分类器；评估其信号重建精度（MAE）和预测任务性能（AUROC）。同时对比传统方法及CNN模型。

Result: 1. Aβ-VAE重建性能最佳：MAE降至15.7±3.2μV（与噪声水平相当）；
2. SAE编码+传统ECG特征预测左室射血分数降低的效果最优：在独立测试集上AUROC达0.901（接近CNN的0.909）；
3. 该方法在数据量减少时抗过拟合，且计算资源需求显著低于CNN。

Conclusion: 提出的VAE编码有效简化了ECG数据复杂度，为小规模标注数据场景提供实用解决方案。结合LightGBM的流程在接近SOTA性能的同时降低计算开销，且在小数据场景下保持鲁棒性。

Abstract: The electrocardiogram (ECG) is an inexpensive and widely available tool for
cardiac assessment. Despite its standardized format and small file size, the
high complexity and inter-individual variability of ECG signals (typically a
60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep
learning models, especially when only small training datasets are available.
This study addresses these challenges by exploring feature generation methods
from representative beat ECGs, focusing on Principal Component Analysis (PCA)
and Autoencoders to reduce data complexity. We introduce three novel
Variational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed
beta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their
effectiveness in maintaining signal fidelity and enhancing downstream
prediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE
achieved superior signal reconstruction, reducing the mean absolute error (MAE)
to 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE
encodings, when combined with traditional ECG summary features, improved the
prediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an
holdout test set area under the receiver operating characteristic curve (AUROC)
of 0.901 with a LGBM classifier. This performance nearly matches the 0.909
AUROC of state-of-the-art CNN model but requires significantly less
computational resources. Further, the ECG feature extraction-LGBM pipeline
avoids overfitting and retains predictive performance when trained with less
data. Our findings demonstrate that these VAE encodings are not only effective
in simplifying ECG data but also provide a practical solution for applying deep
learning in contexts with limited-scale labeled training data.

</details>


### [149] [INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks](https://arxiv.org/abs/2508.00141)
*Mohit Gupta,Debjit Bhowmick,Rhys Newbury,Meead Saberi,Shirui Pan,Ben Beck*

Main category: cs.LG

TL;DR: 提出INSPIRE-GNN框架，结合强化学习和图神经网络优化传感器布局，提高城市骑行流量估计精度。在覆盖稀少的数据环境下，通过策略性选择传感器位置，在墨尔本骑行网络中实现了比传统启发式方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 城市骑行规划需要精确的链路级流量估计，但传感器覆盖率低导致数据稀疏性问题严重。为了在有限的传感器部署下最大化估计精度，需要一种能够智能选择传感器位置的方法。

Method: 1. 设计混合图神经网络框架INSPIRE-GNN，整合GCN和GAT。2. 使用基于DQN的强化学习代理，通过数据驱动策略选择最优传感器位置。3. 在墨尔本骑行网络（15,933条路段，仅141条有传感器）上部署。4. 新增传感器部署量分别为50, 100, 200和500个。5. 与传统启发式方法（中心性指标、随机布局等）和多类机器学习模型进行对比。

Result: 1. INSPIRE-GNN在增加50-500个传感器的各场景下均显著改善流量估计性能。2. 在MSE、RMSE和MAE指标上均优于传统启发式方法（包括中心性指标及随机布局）。3. 在相同条件下，超越标准机器学习和深度学习模型的估计表现。

Conclusion: INSPIRE-GNN为交通规划者提供了可操作的方案：通过强化学习驱动的传感器布局优化，在数据稀疏条件下提升骑行流量估计的准确性和可靠性，辅助制定更科学的城市交通规划决策。

Abstract: Accurate link-level bicycling volume estimation is essential for sustainable
urban transportation planning. However, many cities face significant challenges
of high data sparsity due to limited bicycling count sensor coverage. To
address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning
(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize
sensor placement and improve link-level bicycling volume estimation in
data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks
(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL
agent, enabling a data-driven strategic selection of sensor locations to
maximize estimation performance. Applied to Melbourne's bicycling network,
comprising 15,933 road segments with sensor coverage on only 141 road segments
(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume
estimation by strategically selecting additional sensor locations in
deployments of 50, 100, 200 and 500 sensors. Our framework outperforms
traditional heuristic methods for sensor placement such as betweenness
centrality, closeness centrality, observed bicycling activity and random
placement, across key metrics such as Mean Squared Error (MSE), Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our
experiments benchmark INSPIRE-GNN against standard machine learning and deep
learning models in the bicycle volume estimation performance, underscoring its
effectiveness. Our proposed framework provides transport planners actionable
insights to effectively expand sensor networks, optimize sensor placement and
maximize volume estimation accuracy and reliability of bicycling data for
informed transportation planning decisions.

</details>


### [150] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
*Ziqian Zhong,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 介绍了一种新方法，通过解释权重而非激活来监控和控制微调的大语言模型（LLMs），尤其适用于处理分布外数据（如后门攻击）的情况。该方法分析微调模型与其基础模型之间的权重差异，从权重差矩阵的顶部奇异向量捕获行为特征，进而实现高精度的行为检测；在对抗后门攻击、检测未学习主题和模型审计方面均取得显著效果。具体表现为：对后门攻击防御率达100%（假阳性率<1.2%），对擦除主题检测准确率高达95.42%，并可恢复“未学习”信息。开源代码已在GitHub发布。


<details>
  <summary>Details</summary>
Motivation: 已有可解释性方法依赖任务分布与原始训练数据相似的活动数据是明显局限，尤其当面对新威胁（如后门攻击）时——这些攻击本质上是分布外的。由于开放权重大语言模型（LLMs）的发布常不伴随完整训练数据，无法获得已知分布的数据成为重要障碍。如何克服该局限，使理解、监控、控制微调模型成为独立于原始数据的任务，是本工作的核心动机。

Method: 【WeightWatch方法核心流程】1. 计算差异矩阵：对微调模型与基础模型同一权重的差值做SVD分解，获取顶部奇异向量（捕获新行为方向）；2. 激活监控：输入样本在奇异方向的激活值余弦相似度作为新行为强度的代理量；3. 防御机制：若该相似度高于阈值，则判定该输入触发了新行为并阻止（应用于后门模型防御）；4. 未学习检测：在擦除任务中检查奇异向量方向上激活幅度以实现恢复操作；5. 商业模型审计：通过奇异向量的语义投射揭示微调策略和任务专注点（如营销、图像生成prompt优化）

Result: 1. 后门攻击防御：100%阻止率（测试涵盖多种触发器格式）且假阳性率<1.2%（基于标准对话输入设定阈值）；2. 未学习检测/恢复：擦除主题检测95.42%准确率，并可通过奇异向量方向重新注入激活值恢复模型原有响应能力；3. 商业模型审计案例：成功分析开放微调模型（OLMo/Llama/Qwen），揭示其微调重点包括营销策略与Midjourney提示生成等隐秘任务方向。

Conclusion: 【创新性与未来】该方法突破性地绕过了传统对“分布内数据”的强依赖，仅经由模型权重差异便可实现精确行为监控与控制，为语言模型安全部署提供新范式。其在对抗后门、监督未学习和商业审计上的优异表现，证实了权重分析与激活余弦监控组合的有效性。未来可拓展方向包括多模态模型的权重审计及结合差分隐私保护的稳健性强化

Abstract: The releases of powerful open-weight large language models (LLMs) are often
not accompanied by access to their full training data. Existing
interpretability methods, particularly those based on activations, often
require or assume distributionally similar data. This is a significant
limitation when detecting and defending against novel potential threats like
backdoors, which are by definition out-of-distribution.
  In this work, we introduce a new method for understanding, monitoring and
controlling fine-tuned LLMs that interprets weights, rather than activations,
thereby side stepping the need for data that is distributionally similar to the
unknown training data. We demonstrate that the top singular vectors of the
weight difference between a fine-tuned model and its base model correspond to
newly acquired behaviors. By monitoring the cosine similarity of activations
along these directions, we can detect salient behaviors introduced during
fine-tuning with high precision.
  For backdoored models that bypasses safety mechanisms when a secret trigger
is present, our method stops up to 100% of attacks with a false positive rate
below 1.2%. For models that have undergone unlearning, we detect inference on
erased topics with accuracy up to 95.42% and can even steer the model to
recover "unlearned" information. Besides monitoring, our method also shows
potential for pre-deployment model auditing: by analyzing commercial
instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover
model-specific fine-tuning focus including marketing strategies and Midjourney
prompt generation.
  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.

</details>


### [151] [DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission](https://arxiv.org/abs/2508.00172)
*Fupei Guo,Hao Zheng,Xiang Zhang,Li Chen,Yue Wang,Songyang Zhang*

Main category: cs.LG

TL;DR: 提出了一种新颖的基于扩散的语义通信框架DiSC-Med，用于高效且鲁棒的医疗图像传输，解决带宽有限和信道噪声的挑战。


<details>
  <summary>Details</summary>
Motivation: 人工智能的发展推动了远程医疗，但在带宽有限和噪声信道下高效传输医学数据成为关键挑战。

Method: 开发了医疗增强的压缩块以实现带宽效率，以及针对鲁棒性的去噪块；框架基于扩散模型，通过捕捉关键语义信息而非逐像素传输来提升效率。

Result: 在真实医学数据集上验证，DiSC-Med在噪声信道下实现了超高带宽效率的优越重建性能。

Conclusion: DiSC-Med框架在远程医疗应用中展现出高效且鲁棒的传输潜力，支持高质量的远程诊断和干预。

Abstract: The rapid development of artificial intelligence has driven smart health with
next-generation wireless communication technologies, stimulating exciting
applications in remote diagnosis and intervention. To enable a timely and
effective response for remote healthcare, efficient transmission of medical
data through noisy channels with limited bandwidth emerges as a critical
challenge. In this work, we propose a novel diffusion-based semantic
communication framework, namely DiSC-Med, for the medical image transmission,
where medical-enhanced compression and denoising blocks are developed for
bandwidth efficiency and robustness, respectively. Unlike conventional
pixel-wise communication framework, our proposed DiSC-Med is able to capture
the key semantic information and achieve superior reconstruction performance
with ultra-high bandwidth efficiency against noisy channels. Extensive
experiments on real-world medical datasets validate the effectiveness of our
framework, demonstrating its potential for robust and efficient telehealth
applications.

</details>


### [152] [RL as Regressor: A Reinforcement Learning Approach for Function Approximation](https://arxiv.org/abs/2508.00174)
*Yongchao Huang*

Main category: cs.LG

TL;DR: 论文提出了一种将回归问题转化为强化学习问题的新方法，使用自定义奖励函数替代传统损失函数，并通过逐步改进的Actor-Critic智能体在噪声正弦波回归任务上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统回归方法受限于预定义的可微损失函数（如均方误差），难以处理非对称成本或复杂不可微目标。本文旨在通过强化学习框架提供更灵活的目标定义能力。

Method: 将模型预测视为动作，基于预测误差定义自定义奖励信号，使用强化学习算法进行函数逼近。具体实现：1) 构建基础Actor-Critic智能体；2) 逐步引入优先经验回放、增加网络容量和位置编码；3) 在噪声正弦波学习任务中迭代优化。

Result: 强化学习方法成功解决了噪声正弦波回归任务，且在目标定义和学习过程引导方面展现出优于传统回归技术的灵活性。

Conclusion: 强化学习框架为回归问题提供了新范式，尤其适用于传统损失函数无法充分捕获系统行为的场景，为复杂目标优化开辟了新途径。

Abstract: Standard regression techniques, while powerful, are often constrained by
predefined, differentiable loss functions such as mean squared error. These
functions may not fully capture the desired behavior of a system, especially
when dealing with asymmetric costs or complex, non-differentiable objectives.
In this paper, we explore an alternative paradigm: framing regression as a
Reinforcement Learning (RL) problem. We demonstrate this by treating a model's
prediction as an action and defining a custom reward signal based on the
prediction error, and we can leverage powerful RL algorithms to perform
function approximation. Through a progressive case study of learning a noisy
sine wave, we illustrate the development of an Actor-Critic agent, iteratively
enhancing it with Prioritized Experience Replay, increased network capacity,
and positional encoding to enable a capable RL agent for this regression task.
Our results show that the RL framework not only successfully solves the
regression problem but also offers enhanced flexibility in defining objectives
and guiding the learning process.

</details>


### [153] [EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes](https://arxiv.org/abs/2508.00180)
*Adam Block,Cyril Zhang*

Main category: cs.LG

TL;DR: 本文介绍了BEMA（偏差校正指数移动平均），这是一种针对大型语言模型微调中不稳定性的改进方法。相比标准EMA，BEMA能够显著加速收敛并提高最终性能。


<details>
  <summary>Details</summary>
Motivation: 微调过程中的随机性（尤其是小批量训练）会导致生成质量大幅波动。指数移动平均（EMA）虽能减轻不稳定性，但旧权重的偏差会导致优化滞后。BEMA旨在保留EMA方差缩减效益的同时消除偏差影响。

Method: 提出BEMA算法，在EMA基础上增加偏差校正模块。该方法基于理论模型证明其加速效果，并在多个语言模型基准任务（包括Fine-tuning和RLHF）上进行验证。

Result: 实验表明，BEMA在收敛速度和模型最终性能上均超越EMA和普通训练方式。在语言建模（Pile数据集）等基准上平均收益达2.5%，在RLHF任务中奖励建模提升7%，PPO阶段收敛加速50%

Conclusion: BEMA作为理论可解释且轻量化的改进，提供了更稳定有效的微调方案。其偏差校正机制对存在高方差问题的训练场景具有普适价值，为语言模型优化架构提供了新思路

Abstract: Stochasticity in language model fine-tuning, often caused by the small batch
sizes typically used in this regime, can destabilize training by introducing
large oscillations in generation quality. A popular approach to mitigating this
instability is to take an Exponential moving average (EMA) of weights
throughout training. While EMA reduces stochasticity, thereby smoothing
training, the introduction of bias from old iterates often creates a lag in
optimization relative to vanilla training. In this work, we propose the
Bias-Corrected Exponential Moving Average (BEMA), a simple and practical
augmentation of EMA that retains variance-reduction benefits while eliminating
bias. BEMA is motivated by a simple theoretical model wherein we demonstrate
provable acceleration of BEMA over both a standard EMA and vanilla training.
Through an extensive suite of experiments on Language Models, we show that BEMA
leads to significantly improved convergence rates and final performance over
both EMA and vanilla training in a variety of standard LM benchmarks, making
BEMA a practical and theoretically motivated intervention for more stable and
efficient fine-tuning.

</details>


### [154] [RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems](https://arxiv.org/abs/2508.00201)
*Mehdi Ben Ayed,Fei Feng,Jay Adams,Vishwakarma Singh,Kritarth Anand,Jiajing Xu*

Main category: cs.LG

TL;DR: RecoMind，一个基于模拟器的强化学习框架，用于在Web规模的推荐系统中优化会话内的用户参与度。它利用现有的推荐模型建立模拟环境，并引导RL策略，显著提升了会话内的用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有的Web规模推荐系统主要依赖监督学习，优先考虑即时反馈，难以优化长期目标（如会话内参与度）。强化学习（RL）虽可解决该问题，但在Web规模应用中面临巨大动作空间和工程复杂性。因此，需开发一种既能有效优化长期目标又能与现有系统兼容的框架。

Method: 1. 构建基于模拟器的训练环境：利用已有推荐模型生成用户行为模拟。
2. 引导RL策略：借助现有模型初始化权重，从起始即优化即时用户互动。
3. 定制探索策略：针对数十亿量级的候选空间设计高效探索方法。
4. 端到端集成：与工业级推荐系统链路无缝兼容，简化RL训练与部署。

Result: 离线模拟与线上A/B测试结果一致表明：
- 在线实测（某视频平台）：RL策略使观看超10秒的视频数增加15.81%，会话深度（10次以上互动的会话）提升4.71%。
- RL策略在会话内用户满意度指标上显著超越传统监督学习推荐模型。

Conclusion: RecoMind为Web级推荐系统提供系统化、可扩展的RL集成方案，在优化会话式用户满意度方面展现显著潜力。其模拟器引导策略与定制化探索机制解决了大规模RL应用的关键瓶颈，且兼容现有工程体系。

Abstract: Existing web-scale recommendation systems commonly use supervised learning
methods that prioritize immediate user feedback. Although reinforcement
learning (RL) offers a solution to optimize longer-term goals, such as
in-session engagement, applying it at web scale is challenging due to the
extremely large action space and engineering complexity. In this paper, we
introduce RecoMind, a simulator-based RL framework designed for the effective
optimization of session-based goals at web-scale. RecoMind leverages existing
recommendation models to establish a simulation environment and to bootstrap
the RL policy to optimize immediate user interactions from the outset. This
method integrates well with existing industry pipelines, simplifying the
training and deployment of RL policies. Additionally, RecoMind introduces a
custom exploration strategy to efficiently explore web-scale action spaces with
hundreds of millions of items. We evaluated RecoMind through extensive offline
simulations and online A/B testing on a video streaming platform. Both methods
showed that the RL policy trained using RecoMind significantly outperforms
traditional supervised learning recommendation approaches in in-session user
satisfaction. In online A/B tests, the RL policy increased videos watched for
more than 10 seconds by 15.81\% and improved session depth by 4.71\% for
sessions with at least 10 interactions. As a result, RecoMind presents a
systematic and scalable approach for embedding RL into web-scale recommendation
systems, showing great promise for optimizing session-based user satisfaction.

</details>


### [155] [Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models](https://arxiv.org/abs/2508.00202)
*Ecem Bozkurt,Antonio Ortega*

Main category: cs.LG

TL;DR: 本文提出了一种两阶段框架，利用FM嵌入与几何信息（特别是非负核NNK邻域）提升标签噪声下的鲁棒分类性能，并在CIFAR-10和DermaMNIST上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 基础模型（FMs）在下游任务中需使用含噪声标签数据微调。现有kNN方法虽能利用FM嵌入处理噪声，但严重依赖局部几何特性。本文旨在通过引入几何信息（NNK邻域）提升噪声条件下的鲁棒性。

Method: 1. 两阶段框架：可靠性估计 + 可靠性加权推断。2. 推断阶段：使用NNK（非负核）为每个实例构建局部邻域。3. 可靠性估计：设计多种方法（随噪声增加减少对距离和邻域的依赖）。4. 对比标准kNN及自适应邻域基线。

Result: 在CIFAR-10和DermaMNIST数据集上，该方法在多种噪声条件下均优于标准kNN方法和近期自适应邻域基线，展现出更强的鲁棒性。

Conclusion: 通过NNK邻域引入几何信息的两阶段框架可显著提升标签噪声场景下的分类鲁棒性。方法设计灵活（尤其可靠性估计模块），未来可扩展至更多噪声类型和复杂任务。

Abstract: Foundation models (FMs) pretrained on large datasets have become fundamental
for various downstream machine learning tasks, in particular in scenarios where
obtaining perfectly labeled data is prohibitively expensive. In this paper, we
assume an FM has to be fine-tuned with noisy data and present a two-stage
framework to ensure robust classification in the presence of label noise
without model retraining. Recent work has shown that simple k-nearest neighbor
(kNN) approaches using an embedding derived from an FM can achieve good
performance even in the presence of severe label noise. Our work is motivated
by the fact that these methods make use of local geometry. In this paper,
following a similar two-stage procedure, reliability estimation followed by
reliability-weighted inference, we show that improved performance can be
achieved by introducing geometry information. For a given instance, our
proposed inference uses a local neighborhood of training data, obtained using
the non-negative kernel (NNK) neighborhood construction. We propose several
methods for reliability estimation that can rely less on distance and local
neighborhood as the label noise increases. Our evaluation on CIFAR-10 and
DermaMNIST shows that our methods improve robustness across various noise
conditions, surpassing standard K-NN approaches and recent
adaptive-neighborhood baselines.

</details>


### [156] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
*Paul Albert,Frederic Z. Zhang,Hemanth Saratchandran,Anton van den Hengel,Ehsan Abbasnejad*

Main category: cs.LG

TL;DR: 提出了KRAdapter，一种新的参数高效微调方法，通过Khatri-Rao积产生权重更新，有效提升了在高效秩高的场景中的性能，同时在视觉语言模型和大型语言模型上展示了优于LoRA的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的低秩自适应方法（如LoRA）在处理频谱平坦或包含高频成分的矩阵（即有效秩较高的情况）时表现欠佳。因此，需要一种新的参数高效微调（PEFT）方法，既能处理高有效秩场景，又能保持内存和计算效率。

Method: 提出了KRAdapter算法，利用Khatri-Rao乘积构造权重更新，该方法倾向于生成具有高有效秩的矩阵乘积。通过合成的矩阵近似基准测试（控制谱特性）比较了全秩和低秩PEFT方法，进而验证了KRAdapter的有效性。

Result: 在1B参数的视觉语言模型和8B参数的大型语言模型上，特别是未见过的常识推理任务上，KRAdapter均表现出性能提升，优于LoRA。同时保留了与LoRA相当的内存和计算效率。

Conclusion: KRAdapter是参数高效微调模型的一种实用且鲁棒的替代方案，尤其在高有效秩的场景中表现优异，适用于十亿级参数模型的微调。

Abstract: Parameter-efficient fine-tuning (PEFT) has become a standard approach for
adapting large pre-trained models. Amongst PEFT methods, low-rank adaptation
(LoRA) has achieved notable success. However, recent studies have highlighted
its limitations compared against full-rank alternatives, particularly when
applied to multimodal and large language models. In this work, we present a
quantitative comparison amongst full-rank and low-rank PEFT methods using a
synthetic matrix approximation benchmark with controlled spectral properties.
Our results confirm that LoRA struggles to approximate matrices with relatively
flat spectrums or high frequency components -- signs of high effective ranks.
To this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the
Khatri-Rao product to produce weight updates, which, by construction, tends to
produce matrix product with a high effective rank. We demonstrate performance
gains with KRAdapter on vision-language models up to 1B parameters and on large
language models up to 8B parameters, particularly on unseen common-sense
reasoning tasks. In addition, KRAdapter maintains the memory and compute
efficiency of LoRA, making it a practical and robust alternative to fine-tune
billion-scale parameter models.

</details>


### [157] [Calibrated Language Models and How to Find Them with Label Smoothing](https://arxiv.org/abs/2508.00264)
*Jerry Huang,Peng Lu,Qiuhao Zeng*

Main category: cs.LG

TL;DR: 研究表明，对大型语言模型（LLM）进行指令微调虽然提升了其指令遵循能力，但会导致置信度校准的显著下降。通过引入标签平滑技术可有效缓解这一问题，尤其在常规词汇量的LLM中效果显著。然而在大型词汇量的LLM中，标签平滑的有效性会因模型规模减小。论文提出了一种定制化内核解决方案，解决了标签平滑损失函数在计算时内存消耗过大的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管指令微调增强了LLMs的交互能力，但这过程会导致模型置信度校准退化。现有工作尚未深入研究这一问题，且标签平滑虽被证实能缓解过度自信预测，但在LLM监督微调中仍未广泛采用。

Method: 1. 评估多种开源LLM在指令微调前后的校正退化现象；2. 引入标签平滑技术解析其在监督微调中维持校准的有效性；3. 理论结合实验证明标签平滑局限性与词汇量/隐藏层大小的关联；4. 设计定制化计算内核减低带标签平滑的交叉熵损失内存开销

Result: 1. 所有被测LLM均出现显著性校准退化；2. 标签平滑可有效维持常规词汇量LLM（非LV-LLM）的校准性能；3. LV-LLMs中标签平滑有效性受架构规模限制；4. 所提内核在保持性能不变前提下，内存消耗降低30倍

Conclusion: LLM指令微调会破坏置信度校准机制。标签平滑在多数情况可修复，但对LV-LLMs效果有限。理论证明过度自信倾向与隐藏层/词汇量相关。同时提出的高效内核方案解决了实际部署的显存瓶颈。

Abstract: Recent advances in natural language processing (NLP) have opened up greater
opportunities to enable fine-tuned large language models (LLMs) to behave as
more powerful interactive agents through improved instruction-following
ability. However, understanding how this impacts confidence calibration for
reliable model output has not been researched in full. In this work, we examine
various open-sourced LLMs, identifying significant calibration degradation
after instruction tuning in each. Seeking a practical solution, we look towards
label smoothing, which has been shown as an effective method to regularize for
overconfident predictions but has yet to be widely adopted in the supervised
fine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing
is sufficient to maintain calibration throughout the SFT process. However,
settings remain where the effectiveness of smoothing is severely diminished, in
particular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to
stem from the ability to become over-confident, which has a direct relationship
with the hidden size and vocabulary size, and justify this theoretically and
experimentally. Finally, we address an outstanding issue regarding the memory
footprint of the cross-entropy loss computation in the label smoothed loss
setting, designing a customized kernel to dramatically reduce memory
consumption without sacrificing speed or performance in comparison to existing
solutions for non-smoothed losses.

</details>


### [158] [Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring](https://arxiv.org/abs/2508.00270)
*Robin Schmucker,Nimish Pachapurkar,Shanmuga Bala,Miral Shah,Tom Mitchell*

Main category: cs.LG

TL;DR: 本文介绍了在线辅导系统中如何利用离线策略评估和多臂老虎机（MAB）框架来优化对学生错误答案的有效反馈。系统通过大规模数据学习每个问题的最佳辅助动作（如提示），设计算法为每个问题选择合适的目标策略以提升学生表现，并在真实环境中验证其效果。此外，通过情境老虎机（CB）策略探索基于学生特征的个性化反馈，但发现由于效应差异较小，CB策略相比MAB策略改进有限。系统已应用于实际教学场景。


<details>
  <summary>Details</summary>
Motivation: 在线教育中，学生答题错误后如何提供有效反馈以最大化其学习效果是关键问题。传统方法无法针对不同问题的特点调整反馈策略，且缺乏基于海量数据进行策略优化的能力。本研究旨在通过数据驱动方法，为每个问题优化反馈动作（如提示），提升学生的即时重答正确率和整体学习效果，并探索个性化反馈的可行性和效果。

Method: 1. 从百万级学生数据构建反馈系统；2. 采用多臂老虎机框架评估43,000种辅助动作；3. 设计算法动态选择每个问题的训练目标（如提高首次重答正确率或整体完成率）；4. 在166,000次练习会话中在线评估MAB策略效果；5. 通过情境老虎机尝试个性化反馈：利用学生特征（能力估计、响应时间等）训练策略；6. 使用因果推断方法分析辅助动作效应的异质性及个性化策略与MAB策略的差异。

Result: 1. MAB策略显著提升学生整体表现：优化后的反馈策略在真实环境中带来显著改进；2. 个性化探索方面：存在少量问题下辅助动作对学生特征有异质性效应（如不同能力学生反馈效果差异），但效应值过小导致CB策略在多数问题上无法显著超越MAB；3. 系统已实际部署：每日服务数千名学生，验证了数据驱动策略在规模应用中的可行性。

Conclusion: 数据驱动的MAB框架能有效优化大规模在线辅导系统的反馈策略，显著提升学生表现；而个性化反馈策略（CB）虽具备理论潜力，但受限于辅助动作效应异质性的规模和统计显著性，现阶段尚难显著超越全局优化策略。未来需进一步探索如何识别高异质性的问题场景或设计更精细的策略优化方案。

Abstract: We present an online tutoring system that learns to provide effective
feedback to students after they answer questions incorrectly. Using data from
one million students, the system learns which assistance action (e.g., one of
multiple hints) to provide for each question to optimize student learning.
Employing the multi-armed bandit (MAB) framework and offline policy evaluation,
we assess 43,000 assistance actions, and identify trade-offs between assistance
policies optimized for different student outcomes (e.g., response correctness,
session completion). We design an algorithm that for each question decides on a
suitable policy training objective to enhance students' immediate second
attempt success and overall practice session performance. We evaluate the
resulting MAB policies in 166,000 practice sessions, verifying significant
improvements in student outcomes. While MAB policies optimize feedback for the
overall student population, we further investigate whether contextual bandit
(CB) policies can enhance outcomes by personalizing feedback based on
individual student features (e.g., ability estimates, response times). Using
causal inference, we examine (i) how effects of assistance actions vary across
students and (ii) whether CB policies, which leverage such effect
heterogeneity, outperform MAB policies. While our analysis reveals that some
actions for some questions exhibit effect heterogeneity, effect sizes may often
be too small for CB policies to provide significant improvements beyond what
well-optimized MAB policies that deliver the same action to all students
already achieve. We discuss insights gained from deploying data-driven systems
at scale and implications for future refinements. Today, the teaching policies
optimized by our system support thousands of students daily.

</details>


### [159] [Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem](https://arxiv.org/abs/2508.00286)
*Mohsen Zaker Esteghamati*

Main category: cs.LG

TL;DR: 本研究提出一种将性能化地震设计视为逆向工程问题的方法，通过可解释的机器学习模型直接映射设计变量与性能指标，提升设计效率。方法应用于钢和混凝土框架结构的地震损失优化。


<details>
  <summary>Details</summary>
Motivation: 性能化地震设计当前面临计算效率低的问题，难以在满足特定性能目标的同时自动求解设计参数。

Method: 1. 将性能化地震设计建模为逆向工程问题；2. 应用可解释的机器学习模型建立设计变量与性能指标的映射；3. 将机器学习模型作为评估函数嵌入遗传优化算法；4. 在洛杉矶和查尔斯顿的钢/混凝土框架结构进行应用，优化截面属性以最小化维修成本相关的年化地震损失。

Result: 1. 代理模型展示高精度（R²>90%）且适用于多样化的建筑类型、几何形态及地震条件；2. 优化算法成功识别符合工程原理的最优构件属性值。

Conclusion: 该方法显著提高了性能化设计的计算效率，实现设计参数的自动优化，为结构抗震设计提供新路径。

Abstract: This study presents a methodology to treat performance-based seismic design
as an inverse engineering problem, where design parameters are directly derived
to achieve specific performance objectives. By implementing explainable machine
learning models, this methodology directly maps design variables and
performance metrics, tackling computational inefficiencies of performance-based
design. The resultant machine learning model is integrated as an evaluation
function into a genetic optimization algorithm to solve the inverse problem.
The developed methodology is then applied to two different inventories of steel
and concrete moment frames in Los Angeles and Charleston to obtain sectional
properties of frame members that minimize expected annualized seismic loss in
terms of repair costs. The results show high accuracy of the surrogate models
(e.g., R2> 90%) across a diverse set of building types, geometries, seismic
design, and site hazard, where the optimization algorithm could identify the
optimum values of members' properties for a fixed set of geometric variables,
consistent with engineering principles.

</details>


### [160] [Invariant Graph Transformer for Out-of-Distribution Generalization](https://arxiv.org/abs/2508.00304)
*Tianyin Liao,Ziwei Zhang,Yufei Sun,Chunyu Hu,Jianxin Li*

Main category: cs.LG

TL;DR: 本文介绍了一种名为GOODFormer的新型图变换器，旨在通过结合三个优化的模块来解决图数据在分布变化情况下泛化能力不足的问题。具体包括一个基于熵的不变子图解缠器、一个演化的子图位置结构编码器和一个不变学习模块，以捕获可泛化的图表示，从而在分布变化下实现优良性能。


<details>
  <summary>Details</summary>
Motivation: 现有图变换器（GTs）在处理分布变化的图数据时泛化能力不足，而图不变学习虽为解决此问题提供了可能，但在如何设计注意力机制以及位置和结构编码（PSEs）上仍面临挑战。

Method: 具体方法包括：1）基于熵引导的不变子图解缠器，用于分离不变和可变的子图，同时保持注意力函数的敏锐度；2）演化的子图位置与结构编码器，用于高效捕获训练中动态变化的子图的编码信息；3）使用子图节点表示及编码的不变学习模块，以获得可泛化到未知图的图表示。

Result: 在基准数据集上的大量实验证明，GOODFormer在分布变化下具有优越性，能够明显超越现有的先进基线模型。

Conclusion: GOODFormer通过三个联合优化的模块成功学习了可泛化的图表示，为处理图数据分布变换提供了一种有效的解决方案，并在理论和实验上得到了验证。

Abstract: Graph Transformers (GTs) have demonstrated great effectiveness across various
graph analytical tasks. However, the existing GTs focus on training and testing
graph data originated from the same distribution, but fail to generalize under
distribution shifts. Graph invariant learning, aiming to capture generalizable
graph structural patterns with labels under distribution shifts, is potentially
a promising solution, but how to design attention mechanisms and positional and
structural encodings (PSEs) based on graph invariant learning principles
remains challenging. To solve these challenges, we introduce Graph
Out-Of-Distribution generalized Transformer (GOODFormer), aiming to learn
generalized graph representations by capturing invariant relationships between
predictive graph structures and labels through jointly optimizing three
modules. Specifically, we first develop a GT-based entropy-guided invariant
subgraph disentangler to separate invariant and variant subgraphs while
preserving the sharpness of the attention function. Next, we design an evolving
subgraph positional and structural encoder to effectively and efficiently
capture the encoding information of dynamically changing subgraphs during
training. Finally, we propose an invariant learning module utilizing subgraph
node representations and encodings to derive generalizable graph
representations that can to unseen graphs. We also provide theoretical
justifications for our method. Extensive experiments on benchmark datasets
demonstrate the superiority of our method over state-of-the-art baselines under
distribution shifts.

</details>


### [161] [PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models](https://arxiv.org/abs/2508.00325)
*Yongquan Qu,Matthieu Blanke,Sara Shamekh,Pierre Gentine*

Main category: cs.LG

TL;DR: 提出一种名为PnP-DA的即插即用数据同化算法，交替使用基于梯度的分析更新与预训练生成先验的正向传播，以减轻地球系统建模中的误差累积问题。该算法放宽了传统方法中的高斯误差假设，利用历史数据，无需显式正则化，并在混沌测试中优于经典变分方法。


<details>
  <summary>Details</summary>
Motivation: 地球系统建模面临挑战：在保持计算效率的同时最小化由简化引起的预测误差。传统数据同化（DA）方法假设误差服从高斯分布，但混沌动力系统的真实误差具有非高斯特性，导致性能受限。此外，现有方法难以充分利用历史数据且计算成本高。

Method: 1. 梯度驱动的分析更新：使用马氏距离观测量化新观测与预报的差异进行轻量级更新；2. 预训练生成先验的正向传播：通过条件Wasserstein耦合，将背景预报作为条件输入预训练的生成模型，获得校正后的状态。交替执行这两个步骤，无需通过复杂神经网络反向传播梯度。

Result: 在标准混沌测试平台上（如Lorenz系统等），PnP-DA算法在不同观测稀疏度和噪声水平下均能持续降低预测误差。相比经典变分方法（如3D-Var、4D-Var），显示出更优的性能。

Conclusion: PnP-DA通过融合轻量级分析更新和生成式先验，克服了传统DA方法对高斯误差假设的依赖，有效利用历史数据且避免复杂反向传播。实验证明其显著提升预测精度，为地球系统建模中的误差修正提供新思路。

Abstract: Earth system modeling presents a fundamental challenge in scientific
computing: capturing complex, multiscale nonlinear dynamics in computationally
efficient models while minimizing forecast errors caused by necessary
simplifications. Even the most powerful AI- or physics-based forecast system
suffer from gradual error accumulation. Data assimilation (DA) aims to mitigate
these errors by optimally blending (noisy) observations with prior model
forecasts, but conventional variational methods often assume Gaussian error
statistics that fail to capture the true, non-Gaussian behavior of chaotic
dynamical systems. We propose PnP-DA, a Plug-and-Play algorithm that alternates
(1) a lightweight, gradient-based analysis update (using a Mahalanobis-distance
misfit on new observations) with (2) a single forward pass through a pretrained
generative prior conditioned on the background forecast via a conditional
Wasserstein coupling. This strategy relaxes restrictive statistical assumptions
and leverages rich historical data without requiring an explicit regularization
functional, and it also avoids the need to backpropagate gradients through the
complex neural network that encodes the prior during assimilation cycles.
Experiments on standard chaotic testbeds demonstrate that this strategy
consistently reduces forecast errors across a range of observation sparsities
and noise levels, outperforming classical variational methods.

</details>


### [162] [Embryology of a Language Model](https://arxiv.org/abs/2508.00331)
*George Wang,Garrett Baker,Andrew Gordon,Daniel Murfet*

Main category: cs.LG

TL;DR: 本文提出了一种胚胎学方法，通过将UMAP应用于敏感度矩阵来可视化语言模型在训练过程中的结构发展，揭示了模型形成清晰的‘身体计划’以及新结构（如用于计算空格令牌的‘间距鳍’），从而证明了敏感度分析在发现新型神经网络机制方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管从统计物理学中借鉴的敏感度作为分析工具很有前途，但其在可视化网络组织方面的潜力尚未完全开发。本研究旨在挖掘敏感度的潜力，以可视化语言模型在训练过程中的内部结构演变。

Method: 采用胚胎学方法，即对敏感度矩阵应用UMAP（统一流形逼近与投影）技术，生成模型在训练过程中结构发展的可视化表示。

Result: 可视化结果展示出清晰的‘身体计划’的形成，其中不仅包含已知特征（如归纳电路），还发现了新结构（如专门用于统计空格令牌的‘间距鳍’）。

Conclusion: 敏感度分析不仅能用于模型验证，还能揭示新型机制，为研究复杂神经网络的发育原理提供了一个强大且全面的视角。

Abstract: Understanding how language models develop their internal computational
structure is a central problem in the science of deep learning. While
susceptibilities, drawn from statistical physics, offer a promising analytical
tool, their full potential for visualizing network organization remains
untapped. In this work, we introduce an embryological approach, applying UMAP
to the susceptibility matrix to visualize the model's structural development
over training. Our visualizations reveal the emergence of a clear ``body
plan,'' charting the formation of known features like the induction circuit and
discovering previously unknown structures, such as a ``spacing fin'' dedicated
to counting space tokens. This work demonstrates that susceptibility analysis
can move beyond validation to uncover novel mechanisms, providing a powerful,
holistic lens for studying the developmental principles of complex neural
networks.

</details>


### [163] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
*Qilin Liao,Shuo Yang,Bo Zhao,Ping Luo,Hengshuang Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种名为BOOD的新型框架，用于合成高质量的分布外（OOD）特征和生成与人类兼容的异常图像。BOOD通过在决策边界附近扰动分布内（ID）特征来创建OOD特征，并利用扩散模型将这些特征解码为像素空间图像。实验表明，BOOD显著提高了OOD检测性能，在CIFAR-100数据集上将平均FPR95降低了29.64%，AUROC提高了7.27%。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的OOD检测增强方法难以在潜在空间中有效提取分布外特征，主要因为难以确定类别间的决策边界。因此，需要一种能够高效生成信息量丰富的OOD特征的方法，以更清晰地区分ID和OOD数据。

Method: BOOD框架首先在ID数据集上学习一个文本条件化的潜在特征空间，然后选择靠近决策边界的ID特征，通过扰动这些特征使其跨越决策边界来形成OOD特征。接着，利用扩散模型将这些合成的OOD特征解码为像素空间中的图像。

Result: 在多个常见基准测试上的实验结果表明，BOOD大幅超越现有最先进方法。在CIFAR-100数据集上，实现了平均FPR95从40.31%降至10.67%（降低29.64%），平均AUROC从90.15%提升至97.42%（提高7.27%）。

Conclusion: BOOD提供了一种更高效的策略，能够合成具有高信息量的OOD特征，从而在分布内和分布外数据之间建立更清晰的区分。该方法在提高OOD检测性能方面具有显著优势。

Abstract: Harnessing the power of diffusion models to synthesize auxiliary training
data based on latent space features has proven effective in enhancing
out-of-distribution (OOD) detection performance. However, extracting effective
features outside the in-distribution (ID) boundary in latent space remains
challenging due to the difficulty of identifying decision boundaries between
classes. This paper proposes a novel framework called Boundary-based
Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD
features and generates human-compatible outlier images using diffusion models.
BOOD first learns a text-conditioned latent feature space from the ID dataset,
selects ID features closest to the decision boundary, and perturbs them to
cross the decision boundary to form OOD features. These synthetic OOD features
are then decoded into images in pixel space by a diffusion model. Compared to
previous works, BOOD provides a more training efficient strategy for
synthesizing informative OOD features, facilitating clearer distinctions
between ID and OOD data. Extensive experimental results on common benchmarks
demonstrate that BOOD surpasses the state-of-the-art method significantly,
achieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27%
improvement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.

</details>


### [164] [Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization](https://arxiv.org/abs/2508.00357)
*Yoonhyuk Choi,Jiho Choi,Chong-Kwon Kim*

Main category: cs.LG

TL;DR: 该论文提出了一种名为SGPC的新方法，通过结合胞腔层（cellular-sheaf）消息传递机制、基于最优传输的提升策略、方差缩减扩散以及PAC-Bayes谱正则化，解决了GNN在异配图上的过平滑问题。方法在保证线性复杂度的同时实现了性能的提升和可靠的置信区间。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNNs）在异配图（相邻节点标签往往不同的图）上存在过平滑问题，导致节点特征趋同。现有的层模型（sheaf models）部分缓解了此问题，但它们通常依赖于静态或过度参数化的层结构，限制了泛化性和可扩展性。此外，现有的基于层的模型在保证稳定性方面存在不足。

Method: SGPC方法统一了以下机制：1. 使用胞腔层进行消息传递；2. 基于最优传输的提升（lifting）策略；3. 方差缩减扩散（variance-reduced diffusion）；4. PAC-Bayes谱正则化。该方法通过端到端训练实现线性计算复杂度的目标函数优化，并提供了性能的理论边界。

Result: 在九个同配和异配图基准数据集上的实验表明，SGPC在性能上超越了当前最先进的基于谱方法和层模型的GNNs，同时能够为未见节点提供经过认证的置信区间。

Conclusion: SGPC架构通过集成多种机制有效缓解了GNNs中的过平滑问题，特别是在异配图上，同时保证了模型的泛化性、可扩展性以及理论上的稳定性。该方法在多个基准测试中展现优越性能，并提供了可靠的置信区间评估。

Abstract: Over-smoothing in Graph Neural Networks (GNNs) causes collapse in distinct
node features, particularly on heterophilic graphs where adjacent nodes often
have dissimilar labels. Although sheaf neural networks partially mitigate this
problem, they typically rely on static or heavily parameterized sheaf
structures that hinder generalization and scalability. Existing sheaf-based
models either predefine restriction maps or introduce excessive complexity, yet
fail to provide rigorous stability guarantees. In this paper, we introduce a
novel scheme called SGPC (Sheaf GNNs with PAC-Bayes Calibration), a unified
architecture that combines cellular-sheaf message passing with several
mechanisms, including optimal transport-based lifting, variance-reduced
diffusion, and PAC-Bayes spectral regularization for robust semi-supervised
node classification. We establish performance bounds theoretically and
demonstrate that the resulting bound-aware objective can be achieved via
end-to-end training in linear computational complexity. Experiments on nine
homophilic and heterophilic benchmarks show that SGPC outperforms
state-of-the-art spectral and sheaf-based GNNs while providing certified
confidence intervals on unseen nodes.

</details>


### [165] [OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions](https://arxiv.org/abs/2508.00364)
*Chanyoung Yoon,Sangbong Yoo,Soobin Yim,Chansoo Kim,Yun Jang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为OID-PPO的强化学习框架，用于优化住宅室内设计中的家具布局。它结合了专家定义的功能性和视觉准则，通过连续动作空间解决现有方法在离散化布局、计算效率和数据依赖性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 设计住宅室内布局对住户满意度有重大影响，但目前面临空间布局非结构化、计算需求高和依赖专家知识等挑战。现有基于优化或深度学习的方法要么计算成本高昂，要么受限于数据稀缺。强化学习方法通常将家具限制在离散位置且未能充分整合设计准则。

Method: 采用近端策略优化(PPO)强化学习框架(OID-PPO)，将功能性与视觉准则整合为结构化奖励函数。使用对角高斯策略实现连续灵活的家具放置，在部分可观测环境下有效探索潜在动态。实验在多样化房间形状和家具配置中进行。

Result: OID-PPO在布局质量和计算效率上显著优于现有方法。消融研究证实结构化准则整合的有效性，并揭示各设计约束的独立贡献。

Conclusion: 该框架通过连续动作空间和结构化奖励整合设计准则，解决了家具布局的关键挑战，同时提升了计算效率，为自动化室内设计提供了有效解决方案。

Abstract: Designing residential interiors strongly impacts occupant satisfaction but
remains challenging due to unstructured spatial layouts, high computational
demands, and reliance on expert knowledge. Existing methods based on
optimization or deep learning are either computationally expensive or
constrained by data scarcity. Reinforcement learning (RL) approaches often
limit furniture placement to discrete positions and fail to incorporate design
principles adequately. We propose OID-PPO, a novel RL framework for Optimal
Interior Design using Proximal Policy Optimization, which integrates
expert-defined functional and visual guidelines into a structured reward
function. OID-PPO utilizes a diagonal Gaussian policy for continuous and
flexible furniture placement, effectively exploring latent environmental
dynamics under partial observability. Experiments conducted across diverse room
shapes and furniture configurations demonstrate that OID-PPO significantly
outperforms state-of-the-art methods in terms of layout quality and
computational efficiency. Ablation studies further demonstrate the impact of
structured guideline integration and reveal the distinct contributions of
individual design constraints.

</details>


### [166] [Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions](https://arxiv.org/abs/2508.00392)
*Lijun Zhang,Wenhao Yang,Guanghui Wang,Wei Jiang,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本文研究了具有双重自适应性的通用在线优化算法,提出了一个元专家框架,通过动态创建多个专家并利用元算法聚合,能够同时处理多种凸函数类型(凸函数、指数凹函数、强凸函数)和适应环境变化(静态或动态),且不需要预先知道参数。理论证明该框架能最小化任意区间的自适应遗憾,支持函数类型在迭代间切换,并可扩展到复合函数优化。


<details>
  <summary>Details</summary>
Motivation: 现有自适应遗憾算法缺乏通用性:只能处理单一凸函数类型且需要预知参数,无法适应现实场景中未知函数类型和环境变化的需求。

Method: 1. 提出元专家框架:动态创建多个专家实例,由元算法进行聚合;要求元算法具有二阶界以适应未知函数类型
2. 整合睡眠专家技术:通过激活/休眠机制捕捉环境变化
3. 专家创建策略:采用增加专家数量或增强专家能力两种方式实现通用性
4. 扩展框架至在线复合优化

Result: 理论证明: 1) 算法能同时最小化多种凸函数的自适应遗憾 2) 允许迭代间切换函数类型 3) 在复合函数优化中保持双重自适应性

Conclusion: 所提出的双重自适应元专家框架突破了现有算法的限制,在不依赖预知参数的条件下实现了真正的通用性,可同时适应函数特性(凸/指数凹/强凸)和环境动态(平稳/变化),为复杂现实场景提供了更鲁棒的在线优化解决方案。

Abstract: To deal with changing environments, a new performance measure -- adaptive
regret, defined as the maximum static regret over any interval, was proposed in
online learning. Under the setting of online convex optimization, several
algorithms have been successfully developed to minimize the adaptive regret.
However, existing algorithms lack universality in the sense that they can only
handle one type of convex functions and need apriori knowledge of parameters,
which hinders their application in real-world scenarios. To address this
limitation, this paper investigates universal algorithms with dual adaptivity,
which automatically adapt to the property of functions (convex, exponentially
concave, or strongly convex), as well as the nature of environments (stationary
or changing). Specifically, we propose a meta-expert framework for dual
adaptive algorithms, where multiple experts are created dynamically and
aggregated by a meta-algorithm. The meta-algorithm is required to yield a
second-order bound, which can accommodate unknown function types. We further
incorporate the technique of sleeping experts to capture the changing
environments. For the construction of experts, we introduce two strategies
(increasing the number of experts or enhancing the capabilities of experts) to
achieve universality. Theoretical analysis shows that our algorithms are able
to minimize the adaptive regret for multiple types of convex functions
simultaneously, and also allow the type of functions to switch between rounds.
Moreover, we extend our meta-expert framework to online composite optimization,
and develop a universal algorithm for minimizing the adaptive regret of
composite functions.

</details>


### [167] [ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs](https://arxiv.org/abs/2508.00394)
*Antonis Klironomos,Baifan Zhou,Zhipeng Tan,Zhuoxun Zheng,Mohamed H. Gad-Elrab,Heiko Paulheim,Evgeny Kharlamov*

Main category: cs.LG

TL;DR: 本文介绍了ExeKGLib，这是一个带有图形界面的Python库，旨在帮助缺乏机器学习（ML）专业知识的用户构建ML流程。该库利用知识图谱编码ML知识，使之易于非专业人士理解，同时提高流程的透明度和可重用性，并确保其可执行性。文章通过实际案例展示了该工具的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前，许多领域专家（如科学和工程专家）亟需使用基于机器学习的分析方法，但缺乏相应的ML专业知识和训练。虽然存在大量可用的ML库，开发高质量的ML流程仍需专业知识和精细的步骤设计。ExeKGLib旨在解决这一难题，使非ML专家也能构建ML管道。

Method: ExeKGLib提供一个图形用户界面（GUI）层，简化了流程构建。核心创新在于利用知识图谱对ML知识进行编码，将复杂的ML概念转化为简单易懂的术语。通过知识图谱，用户能以直观的方式组装ML流程的步骤。同时，该工具还确保流程可执行性、增强透明度（如跟踪数据流动和计算步骤）和可重用性（支持流程模块化复用）。开发过程中整合了现有热门Python ML库的功能。

Result: 通过实际案例验证，ExeKGLib在非ML专家用户群体中展现出高可用性和有效性。用户无需深入学习ML理论和编程即可搭建完整的ML工作流。工具还具备以下技术特性：流程执行自动化、组件复用化、计算过程透明化（可追溯），以及知识图谱支持的术语映射机制降低认知门槛。

Conclusion: ExeKGLib填补了‘领域专家需用ML但缺乏专业技能’的空白。其设计巧妙地将知识图谱的语义抽象能力与GUI的操作简便性结合，为非专家用户提供了实用可行的ML流程构建方案。未来可扩展的方向包括支持更多类型的ML任务、增强知识图谱的覆盖范围，以及引入交互式调试功能。

Abstract: Nowadays machine learning (ML) practitioners have access to numerous ML
libraries available online. Such libraries can be used to create ML pipelines
that consist of a series of steps where each step may invoke up to several ML
libraries that are used for various data-driven analytical tasks. Development
of high-quality ML pipelines is non-trivial; it requires training, ML
expertise, and careful development of each step. At the same time, domain
experts in science and engineering may not possess such ML expertise and
training while they are in pressing need of ML-based analytics. In this paper,
we present our ExeKGLib, a Python library enhanced with a graphical interface
layer that allows users with minimal ML knowledge to build ML pipelines. This
is achieved by relying on knowledge graphs that encode ML knowledge in simple
terms accessible to non-ML experts. ExeKGLib also allows improving the
transparency and reusability of the built ML workflows and ensures that they
are executable. We show the usability and usefulness of ExeKGLib by presenting
real use cases.

</details>


### [168] [Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement](https://arxiv.org/abs/2508.00410)
*Zizhuo Zhang,Jianing Zhu,Xinmu Ge,Zihua Zhao,Zhanke Zhou,Xuan Li,Xiao Feng,Jiangchao Yao,Bo Han*

Main category: cs.LG

TL;DR: 该论文提出了一种名为Co-Reward的新型强化学习（RL）框架，该方法利用对比性语义相似问题的输入一致性作为自监督奖励信号，减少了RL训练中对人工标注奖励值的依赖。框架通过构建相似问题对和基于投票的伪标签，实现了强化输入一致性进而提升模型推理能力，并成功缓解自我奖励机制中常见的训练坍缩问题。在多个推理基准测试中大语言模型上的实验表明，该方法超越了现有自监督方法，甚至达到或超过了人工标注奖励基准（MATH500上提升达6.8%）。


<details>
  <summary>Details</summary>
Motivation: 当前RLVR存在对人工标注的依赖，特别在复杂任务上标注难度高；而现有替代方案使用模型自我生成的奖励信号又存在训练坍缩风险。作者受到自监督学习的启发，通过利用语义相似输入的内在一致性来构建奖励信号，以缓解这两个痛点。这一方法的核心动机是：让模型在语义相似的输入上获得一致的推理输出可以提升可靠性和稳定性。

Method: Co-Reward的流程为：（1）针对每个无标注样本，构建语义相似但表达不同的新问题作为输入对；（2）通过模型自身输出结果并执行投票方式生成伪标签；（3）在相似输入对上强制推理一致性作为奖励机制：当两个相似输入模型的推理输出在伪标签判定时一致则给予奖励，不一致则惩罚；（4）利用对比性输入一致性设计奖励函数，并整合到RL训练框架以优化模型参数。

Result: 实验表明在多个任务如数学推理和开放域QA中，该方法有效解决自监督奖励信号中的训练崩陷问题：（1）在Llama-3.2-3B-Instruct上，MATH500指标达到+6.8%改进；（2）超过了所有自监督奖励方法；（3）在部分测试上甚至优于人工标注GT奖励；（4）实验还发现该方法增强了模型鲁棒性和输出可重现性。

Conclusion: Co-Reward的创新点在于通过构建输入对实现自监督的对比一致性奖励机制，在不依赖人工标注情况下提升了模型推理能力并缓解了坍陷问题。实证结果证明此框架对提高大语言模型的推理能力具备有效性，也暗示了通过语义相似样本一致性的利用是未来提高LLM自我监督训练质量的重要方向之一。

Abstract: Although reinforcement learning with verifiable rewards (RLVR) shows promise
in improving the reasoning ability of large language models (LLMs), the scaling
up dilemma remains due to the reliance on human annotated labels especially for
complex tasks. Recent alternatives that explore various self-reward signals
exhibit the eliciting potential of LLM reasoning, but suffer from the
non-negligible collapse issue. Inspired by the success of self-supervised
learning, we propose \textit{Co-Reward}, a novel RL framework that leverages
contrastive agreement across semantically analogical questions as a reward
basis. Specifically, we construct a similar question for each training sample
(without labels) and synthesize their individual surrogate labels through a
simple rollout voting, and then the reward is constructed by cross-referring
the labels of each question pair to enforce the internal reasoning consistency
across analogical inputs. Intuitively, such a self-supervised reward-shaping
mechanism increases the difficulty of learning collapse into a trivial
solution, and promotes stable reasoning elicitation and improvement through
expanding the input sample variants. Empirically, Co-Reward achieves superior
performance compared to other self-reward baselines on multiple reasoning
benchmarks and LLM series, and reaches or even surpasses ground-truth (GT)
labeled reward, with improvements of up to $+6.8\%$ on MATH500 over GT reward
on Llama-3.2-3B-Instruct. Our code is publicly available at
https://github.com/tmlr-group/Co-Reward.

</details>


### [169] [Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection](https://arxiv.org/abs/2508.00415)
*Yue Yang,Yuxiang Lin,Ying Zhang,Zihan Su,Chang Chuan Goh,Tangtangfang Fang,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 本文提出了一种名为ResE-BiLSTM的模型，用于预测贷款违约（金融异常检测）。该模型通过滑动窗口技术在Freddie Mac抵押贷款数据上进行评估，结果显示其在多个指标上均优于基线模型。同时通过消融实验和SHAP分析验证了模型的有效性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 信贷风险管理中的贷款后违约预测至关重要，传统方法可能无法充分捕捉金融数据的时序特性。为提升预测性能，需要开发能够有效处理序列数据并能解释预测依据的模型。

Method: 1. 提出ResE-BiLSTM模型架构。2. 采用滑动窗口技术处理时间序列数据。3. 在Freddie Mac抵押数据集（44组独立队列）上进行实验。4. 与五种基线模型（LSTM、BiLSTM、GRU、CNN、RNN）在准确性、精确率、召回率、F1值和AUC上进行比较。5. 进行消融研究以评估模型各组件贡献。6. 使用SHAP进行特征重要性分析。

Result: 实验证明：1. ResE-BiLSTM在所有评估指标上均显著优于所有基线模型。2. 消融研究表明每个组件对性能提升都有贡献。3. SHAP分析揭示了模型预测依赖的关键特征。

Conclusion: ResE-BiLSTM模型在贷款违约预测任务中表现出卓越性能，其可解释性分析增强了模型在现实信贷风险管理中的实用价值。

Abstract: Prediction of post-loan default is an important task in credit risk
management, and can be addressed by detection of financial anomalies using
machine learning. This study introduces a ResE-BiLSTM model, using a sliding
window technique, and is evaluated on 44 independent cohorts from the extensive
Freddie Mac US mortgage dataset, to improve prediction performance. The
ResE-BiLSTM is compared with five baseline models: Long Short-Term Memory
(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks
(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including
Accuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to
evaluate the contribution of individual components in the ResE-BiLSTM
architecture. Additionally, SHAP analysis was employed to interpret the
underlying features the model relied upon for its predictions. Experimental
results demonstrate that ResE-BiLSTM achieves superior predictive performance
compared to baseline models, underscoring its practical value and applicability
in real-world scenarios.

</details>


### [170] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: 提出了ctdGAN，一种用于缓解表格数据集中类别不平衡问题的条件生成对抗网络（GAN）。该方法通过空间划分步骤为输入样本分配聚类标签，并利用这些标签结合新的概率采样策略和损失函数来生成样本，该损失函数同时惩罚聚类和类别预测错误。此外，还引入了聚类缩放技术以捕获多个特征模式而不增加数据维度。实验证明ctdGAN在生成高保真样本和提高分类准确率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 表格数据存在类别不平衡问题，导致机器学习模型性能下降。现有基于GAN的方法在生成样本时未考虑输入样本在真实数据空间中的向量子空间，导致生成的数据位于任意位置；同时，类别标签被与其他分类变量同等对待，因此条件采样效果不佳。

Method: 1. 执行空间划分步骤为输入样本分配聚类标签；2. 提出新的概率采样策略，利用聚类和类别标签生成样本；3. 设计新的损失函数，同时惩罚聚类和类别的错误预测；4. 引入聚类缩放技术，在不改变数据维度的情况下捕获多个特征模式。该方法称为ctdGAN。

Result: 在14个不平衡数据集上进行实验，结果表明：1. ctdGAN能够生成高质量（高保真）样本；2. 与现有方法相比，使用ctdGAN生成的样本训练的分类器准确率更高。

Conclusion: ctdGAN通过空间划分和结合聚类与类别信息的采样策略及损失函数，有效缓解了表格数据中的类别不平衡问题。其生成的样本质量高，且显著提高了分类器的性能，优于现有方法。

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>


### [171] [Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection](https://arxiv.org/abs/2508.00507)
*Yiming Xu,Jiarun Chen,Zhen Peng,Zihan Chen,Qika Lin,Lan Ma,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: 该论文提出了一个名为CoLL的新框架，通过结合大型语言模型（LLMs）和图神经网络（GNNs）的优势，来解决文本属性图（TAGs）中的异常检测问题。该框架利用多LLM协作进行证据增强生成，捕捉与异常相关的上下文，并为检测到的异常提供可读的解释。同时，通过带有门控机制的GNN，自适应地融合文本特征与证据，并保留高阶拓扑信息。实验表明，CoLL在AP指标上平均提升了13.37%。


<details>
  <summary>Details</summary>
Motivation: 现有的图异常检测（GAD）方法主要关注图结构域内的优化目标设计，忽视了文本模态的补充价值。文本特征通常通过浅层嵌入技术（如词袋模型或skip-gram）编码，可能错过与异常相关的语义上下文。大型语言模型（LLMs）虽然具有强大的语义理解和推理能力，但在处理图结构数据时，由于输入长度的限制，难以编码图中的高阶结构信息。因此，需要一种新的方法来融合图结构和文本信息，以提升文本属性图中的异常检测性能。

Method: 论文提出的框架CoLL包含两个核心部分：1) 多LLM协作的证据增强生成：多个LLM协作生成与异常相关的证据上下文，为检测到的异常提供可读的解释；2) 带有门控机制的GNN：自适应地融合文本特征与证据，同时保留图的高阶拓扑信息。通过这种方式，CoLL结合了LLMs的语义理解能力和GNNs的图结构建模能力。

Result: 在多个数据集上进行的大量实验显示，CoLL在异常检测任务中表现出色，与现有方法相比，平均AP（平均精度）提升了13.37%。这证明了CoLL能够有效融合文本和结构信息，提升异常检测性能。

Conclusion: 该研究不仅提出了一种有效融合LLMs和GNNs的框架，为文本属性图中的异常检测提供了新方案，而且为利用LLMs推进图异常检测开辟了新途径。CoLL的成功表明，结合语义理解和结构建模能够显著提升异常检测任务的性能，为未来的相关研究奠定了基础。

Abstract: The natural combination of intricate topological structures and rich textual
information in text-attributed graphs (TAGs) opens up a novel perspective for
graph anomaly detection (GAD). However, existing GAD methods primarily focus on
designing complex optimization objectives within the graph domain, overlooking
the complementary value of the textual modality, whose features are often
encoded by shallow embedding techniques, such as bag-of-words or skip-gram, so
that semantic context related to anomalies may be missed. To unleash the
enormous potential of textual modality, large language models (LLMs) have
emerged as promising alternatives due to their strong semantic understanding
and reasoning capabilities. Nevertheless, their application to TAG anomaly
detection remains nascent, and they struggle to encode high-order structural
information inherent in graphs due to input length constraints. For
high-quality anomaly detection in TAGs, we propose CoLL, a novel framework that
combines LLMs and graph neural networks (GNNs) to leverage their complementary
strengths. CoLL employs multi-LLM collaboration for evidence-augmented
generation to capture anomaly-relevant contexts while delivering human-readable
rationales for detected anomalies. Moreover, CoLL integrates a GNN equipped
with a gating mechanism to adaptively fuse textual features with evidence while
preserving high-order topological information. Extensive experiments
demonstrate the superiority of CoLL, achieving an average improvement of 13.37%
in AP. This study opens a new avenue for incorporating LLMs in advancing GAD.

</details>


### [172] [Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning](https://arxiv.org/abs/2508.00513)
*Yiming Xu,Xu Hua,Zhen Peng,Bin Shi,Jiarun Chen,Xingbo Fu,Song Wang,Bo Dong*

Main category: cs.LG

TL;DR: 本文介绍了CMUCL框架，一种用于文本属性图（TAGs）异常检测的端到端方法。它通过跨模态和多尺度一致性建模文本与图结构信息，解决了传统方法中文本特征提取与异常检测目标分离的问题。实验证明该方法显著提升了检测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的图异常检测方法在处理带文本描述节点的文本属性图（TAGs）时，通常将文本编码过程与图上的异常检测目标分离，导致文本特征难以聚焦于异常相关信息，严重限制了检测性能。因此需要一种能无缝融合原始文本和图形拓扑的端到端架构。

Method: 提出CMUCL框架：1. 同时建模文本和图形结构数据；2. 通过跨模态及单模态多尺度一致性联合训练文本编码器和图编码器（包括全局一致性、多粒度一致性等）；3. 设计基于不一致性挖掘的异常评分器为节点生成异常分数；4. 发布了8个新的TAG异常检测基准数据集。

Result: 新方法在检测任务上取得显著提升，平均准确率（AP）比次优方法提高11.13%，并发布了专为TAG异常检测定制的数据集作为未来研究资源。

Conclusion: CMUCL通过统一跨模态学习与异常检测目标，有效挖掘了文本属性图中跨模态数据潜力，大幅提升了异常检测性能。新的基准数据集将推动该领域发展。

Abstract: The widespread application of graph data in various high-risk scenarios has
increased attention to graph anomaly detection (GAD). Faced with real-world
graphs that often carry node descriptions in the form of raw text sequences,
termed text-attributed graphs (TAGs), existing graph anomaly detection
pipelines typically involve shallow embedding techniques to encode such textual
information into features, and then rely on complex self-supervised tasks
within the graph domain to detect anomalies. However, this text encoding
process is separated from the anomaly detection training objective in the graph
domain, making it difficult to ensure that the extracted textual features focus
on GAD-relevant information, seriously constraining the detection capability.
How to seamlessly integrate raw text and graph topology to unleash the vast
potential of cross-modal data in TAGs for anomaly detection poses a challenging
issue. This paper presents a novel end-to-end paradigm for text-attributed
graph anomaly detection, named CMUCL. We simultaneously model data from both
text and graph structures, and jointly train text and graph encoders by
leveraging cross-modal and uni-modal multi-scale consistency to uncover
potential anomaly-related information. Accordingly, we design an anomaly score
estimator based on inconsistency mining to derive node-specific anomaly scores.
Considering the lack of benchmark datasets tailored for anomaly detection on
TAGs, we release 8 datasets to facilitate future research. Extensive
evaluations show that CMUCL significantly advances in text-attributed graph
anomaly detection, delivering an 11.13% increase in average accuracy (AP) over
the suboptimal.

</details>


### [173] [Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting](https://arxiv.org/abs/2508.00523)
*Sifan Yang,Yuanyu Wan,Lijun Zhang*

Main category: cs.LG

TL;DR: 这篇论文研究了在强盗设定中具有延迟反馈的在线非子模优化问题。通过提出两种新算法DBGD-NF和其扩展版本，分别解决了现有工作中对不规则延迟敏感以及延迟反馈与强盗反馈耦合的问题，实现了更优的延迟无关和平均延迟相关的遗憾上界，并在结构化稀疏学习实验中验证了优越性。


<details>
  <summary>Details</summary>
Motivation: 现有在线非子模优化方法对最大延迟敏感且将延迟与强盗反馈影响耦合，导致遗憾界依赖最大延迟且可能不适用于延迟分布不均的场景。

Method: 提出两种算法：1) DBGD-NF使用三点梯度估计器并每轮更新时利用所有可用梯度，实现平均延迟相关的遗憾界；2) 扩展算法引入分块更新机制解耦延迟与强盗反馈，实现延迟无关遗憾界。

Result: DBGD-NF获得O(nar{d}^{1/3}T^{2/3})遗憾界，扩展算法获得O(n(T^{2/3} + ootelax{dT}))遗憾界。实验验证在结构化稀疏学习中优于基线方法。

Conclusion: 论文有效解决了延迟反馈下的在线非子模优化问题，新算法在理论上获得更紧的遗憾界（适应平均延迟或解耦延迟/强盗效应），实验验证了实际性能优势。

Abstract: We investigate the online nonsubmodular optimization with delayed feedback in
the bandit setting, where the loss function is $\alpha$-weakly DR-submodular
and $\beta$-weakly DR-supermodular. Previous work has established an
$(\alpha,\beta)$-regret bound of $\mathcal{O}(nd^{1/3}T^{2/3})$, where $n$ is
the dimensionality and $d$ is the maximum delay. However, its regret bound
relies on the maximum delay and is thus sensitive to irregular delays.
Additionally, it couples the effects of delays and bandit feedback as its bound
is the product of the delay term and the $\mathcal{O}(nT^{2/3})$ regret bound
in the bandit setting without delayed feedback. In this paper, we develop two
algorithms to address these limitations, respectively. Firstly, we propose a
novel method, namely DBGD-NF, which employs the one-point gradient estimator
and utilizes all the available estimated gradients in each round to update the
decision. It achieves a better $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ regret
bound, which is relevant to the average delay $\bar{d} =
\frac{1}{T}\sum_{t=1}^T d_t\leq d$. Secondly, we extend DBGD-NF by employing a
blocking update mechanism to decouple the joint effect of the delays and bandit
feedback, which enjoys an $\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$ regret bound.
When $d = \mathcal{O}(T^{1/3})$, our regret bound matches the
$\mathcal{O}(nT^{2/3})$ bound in the bandit setting without delayed feedback.
Compared to our first $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ bound, it is more
advantageous when the maximum delay $d = o(\bar{d}^{2/3}T^{1/3})$. Finally, we
conduct experiments on structured sparse learning to demonstrate the
superiority of our methods.

</details>


### [174] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
*Judy X Yang*

Main category: cs.LG

TL;DR: 该论文提出了一种两阶段矿物探测框架，首先通过信噪比阈值和光谱滤波预处理去噪降维，随后进行端元提取和丰度反演，有效提高了矿物探测精度。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像中存在噪声和冗余波段，掩盖了微弱矿物信号，影响了矿物探测性能。为此，作者提出一个集成框架来解决这一问题。

Method: 1. 第一阶段：预处理降维。计算各波段信噪比，采用相位锁定阈值技术剔除低信噪比波段；用Savitzky-Golay滤波进行光谱平滑。2. 第二阶段：矿物探测。对预处理后的数据使用KMeans聚类提取12个端元光谱，再用非负最小二乘（NNLS）进行丰度反演；将提取的端元与实验室光谱进行余弦相似度和均方根误差的定量对比。

Result: 实验证实，该流程提高了混合像元分解精度，增强了对微弱矿物区域的探测能力。

Conclusion: 这种两阶段策略为地质高光谱应用提供了一种实用且可复现的光谱降维与解混解决方案。

Abstract: Hyperspectral imaging offers detailed spectral information for mineral
mapping; however, weak mineral signatures are often masked by noisy and
redundant bands, limiting detection performance. To address this, we propose a
two-stage integrated framework for enhanced mineral detection in the Cuprite
mining district. In the first stage, we compute the signal-to-noise ratio (SNR)
for each spectral band and apply a phase-locked thresholding technique to
discard low-SNR bands, effectively removing redundancy and suppressing
background noise. Savitzky-Golay filtering is then employed for spectral
smoothing, serving a dual role first to stabilize trends during band selection,
and second to preserve fine-grained spectral features during preprocessing. In
the second stage, the refined HSI data is reintroduced into the model, where
KMeans clustering is used to extract 12 endmember spectra (W1 custom), followed
by non negative least squares (NNLS) for abundance unmixing. The resulting
endmembers are quantitatively compared with laboratory spectra (W1 raw) using
cosine similarity and RMSE metrics. Experimental results confirm that our
proposed pipeline improves unmixing accuracy and enhances the detection of weak
mineral zones. This two-pass strategy demonstrates a practical and reproducible
solution for spectral dimensionality reduction and unmixing in geological HSI
applications.

</details>


### [175] [Foundations of Interpretable Models](https://arxiv.org/abs/2508.00545)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Alberto Termine,Mateja Jamnik,Giuseppe Marra*

Main category: cs.LG

TL;DR: 本文提出现有可解释性定义缺乏可操作性，导致可解释AI研究存在根本性问题。作者提出了一个新的、可操作的、涵盖现有非正式概念的可解释性定义，并基于此提出了设计可解释模型的通用蓝图和首个原生支持可解释数据结构的开源库。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性定义缺乏可操作性，无法指导用户设计通用、可靠且鲁棒的可解释模型，使得当前可解释性研究存在根本性缺陷。因此，需要一个新的定义来解决这一问题。

Method: 1. 提出一个新的可解释性定义，该定义具有通用性、简洁性，并能涵盖可解释AI社区中现有的非正式概念。2. 展示该定义的可操作性，即它能直接揭示设计可解释模型所需的基本特性、基本假设、原则、数据结构和架构特征。3. 基于新定义，提出一个设计可解释模型的通用蓝图。4. 开发并开源首个原生支持可解释数据结构和处理过程的库。

Result: 1. 新的可解释性定义被证明具有可操作性，能够指导模型设计。2. 基于该定义，提出了一个设计可解释模型的通用蓝图。3. 实现了首个原生支持可解释数据结构和处理过程的开源库。

Conclusion: 本文提出的可解释性定义解决了现有定义缺乏可操作性的问题，为设计可解释模型提供了理论依据和实践工具。通过该定义和蓝图，研究人员能够更有效地设计可解释模型，推动可解释AI领域的发展。

Abstract: We argue that existing definitions of interpretability are not actionable in
that they fail to inform users about general, sound, and robust interpretable
model design. This makes current interpretability research fundamentally
ill-posed. To address this issue, we propose a definition of interpretability
that is general, simple, and subsumes existing informal notions within the
interpretable AI community. We show that our definition is actionable, as it
directly reveals the foundational properties, underlying assumptions,
principles, data structures, and architectural features necessary for designing
interpretable models. Building on this, we propose a general blueprint for
designing interpretable models and introduce the first open-sourced library
with native support for interpretable data structures and processes.

</details>


### [176] [Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides](https://arxiv.org/abs/2508.00578)
*Marlen Neubert,Patrick Reiser,Frauke Gräter,Pascal Friederich*

Main category: cs.LG

TL;DR: 本文系统地评估了三种图神经网络（SchNet、Allegro和MACE）在预测氢原子转移反应势能面和间接预测反应能垒方面的性能。最佳模型MACE在计算精度上表现出色，适用于大规模蛋白质模拟，并可推广到其他生物分子系统。


<details>
  <summary>Details</summary>
Motivation: 氢原子转移在生物过程中至关重要，但现有方法在生物尺度上进行精确量子化学模拟存在障碍（传统力场不适用，基于DFT的分子动力学计算代价过高）。机器学习势函数提供了替代方案，但需针对HAT反应的特殊性优化数据集和模型。

Method: 1. 使用半经验方法和DFT生成肽体系的大规模HAT反应数据集；
2. 系统性测试SchNet、Allegro、MACE三种图神经网络架构；
3. 通过势能面学习质量间接评估反应能垒预测精度；
4. 将最优模型（MACE）整合到胶原蛋白模拟中计算反应速率；
5. 分析模型扩展性、迁移性和性价比，并提出结合过渡态搜索和主动学习的改进策略。

Result: 1. MACE模型表现最佳：在能量、力、能垒预测上均优于其他架构；
2. 跨分布DFT反应能垒预测平均绝对误差仅1.13 kcal/mol；
3. 该精度支持在大规模胶原蛋白模拟中计算反应速率，揭示了肽内自由基迁移机制；
4. 提出了通过集成过渡态搜索算法和主动学习进一步提升性能的途径。

Conclusion: 通过精心构建数据集和模型筛选，MACE机器学习势函数首次实现了在蛋白质尺度上对HAT反应的量子精度模拟。该方法可推广至其他生物分子体系的反应过程研究，为复杂环境中的化学反应机制解析提供了新范式。

Abstract: Hydrogen atom transfer (HAT) reactions are essential in many biological
processes, such as radical migration in damaged proteins, but their mechanistic
pathways remain incompletely understood. Simulating HAT is challenging due to
the need for quantum chemical accuracy at biologically relevant scales; thus,
neither classical force fields nor DFT-based molecular dynamics are applicable.
Machine-learned potentials offer an alternative, able to learn potential energy
surfaces (PESs) with near-quantum accuracy. However, training these models to
generalize across diverse HAT configurations, especially at radical positions
in proteins, requires tailored data generation and careful model selection.
Here, we systematically generate HAT configurations in peptides to build large
datasets using semiempirical methods and DFT. We benchmark three graph neural
network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT
PESs and indirectly predict reaction barriers from energy predictions. MACE
consistently outperforms the others in energy, force, and barrier prediction,
achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT
barrier predictions. This accuracy enables integration of ML potentials into
large-scale collagen simulations to compute reaction rates from predicted
barriers, advancing mechanistic understanding of HAT and radical migration in
peptides. We analyze scaling laws, model transferability, and cost-performance
trade-offs, and outline strategies for improvement by combining ML potentials
with transition state search algorithms and active learning. Our approach is
generalizable to other biomolecular systems, enabling quantum-accurate
simulations of chemical reactivity in complex environments.

</details>


### [177] [The Role of Active Learning in Modern Machine Learning](https://arxiv.org/abs/2508.00586)
*Thorben Werner,Lars Schmidt-Thieme,Vijaya Krishna Yalavarthi*

Main category: cs.LG

TL;DR: 论文探讨了主动学习(AL)在实际应用中受限的原因，指出其计算成本高且在少标签场景下提升有限（仅1%-4%）。相比之下，数据增强(DA)和半监督学习(SSL)结合随机采样可带来高达60%的提升。但AL与DA、SSL结合后仍能进一步小幅提升性能。因此，研究建议将AL视为DA和SSL后的最终优化手段。


<details>
  <summary>Details</summary>
Motivation: 尽管主动学习(AL)被广泛研究，但很少在实际场景中应用。作者认为原因在于AL的高计算成本和标签稀缺时提升幅度小（仅1%-4%）。本研究旨在通过对比AL、数据增强(DA)和半监督学习(SSL)在低数据场景的效果，重新定位AL的价值。

Method: 系统比较三种解决低标签数据问题的方法：(1) AL（主动学习）——迭代选择信息量最大的样本标注；(2) DA（数据增强）——利用变换扩充训练数据；(3) SSL（半监督学习）——同时利用标记和未标记数据训练。随后组合这些方法（尤其是先应用DA+SSL再叠加AL）以检验协同效果。

Result: 1. AL单用时表现最低效，仅比随机采样高1%-4%。2. DA和SSL单用或组合可带来最高60%的性能提升。3. 意外发现：当AL与DA+SSL组合时，仍能提供额外小幅性能提升（即使DA+SSL已大幅优化模型）。

Conclusion: AL不应作为解决标签稀缺的主要手段，而是在应用DA和SSL技术后进一步榨取模型性能的“最终构建模块”。这为AL的实际应用提供了新范式：优先使用高性价比的DA/SSL，再叠加AL进行微调优化。

Abstract: Even though Active Learning (AL) is widely studied, it is rarely applied in
contexts outside its own scientific literature. We posit that the reason for
this is AL's high computational cost coupled with the comparatively small lifts
it is typically able to generate in scenarios with few labeled points. In this
work we study the impact of different methods to combat this low data scenario,
namely data augmentation (DA), semi-supervised learning (SSL) and AL. We find
that AL is by far the least efficient method of solving the low data problem,
generating a lift of only 1-4\% over random sampling, while DA and SSL methods
can generate up to 60\% lift in combination with random sampling. However, when
AL is combined with strong DA and SSL techniques, it surprisingly is still able
to provide improvements. Based on these results, we frame AL not as a method to
combat missing labels, but as the final building block to squeeze the last bits
of performance out of data after appropriate DA and SSL methods as been
applied.

</details>


### [178] [Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data](https://arxiv.org/abs/2508.00615)
*Mukesh Kumar Sahu,Pinki Roy*

Main category: cs.LG

TL;DR: 该论文提出了一种基于相似性的自构建图模型(SBSCGM)和混合图神经网络架构(HybridGraphMedGNN)，用于预测ICU患者的死亡率和持续风险评分。该方法通过混合相似性度量动态构建患者相似图，并综合利用多种图神经网络层。在MIMIC-III数据集上的实验表明，该模型达到了0.94的AUC-ROC，优于基线方法，并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 重症监护病房患者的预测（如院内死亡率风险）对早期干预至关重要。传统模型孤立处理患者，难以利用电子健康记录（EHR）中的关系结构。

Method: 1. 提出SBSCGM模型：动态构建患者相似图，使用混合相似性度量（基于特征和结构的相似性）实时连接具有相似临床特征的患者。2. 提出HybridGraphMedGNN架构：整合GCN、GraphSAGE和GAT层，利用局部和全局图模式学习稳健的患者表征。

Result: 在MIMIC-III数据集的6000个ICU停留记录中：1. 模型达到AUC-ROC 0.94，优于基线分类器和单一GNN模型；2. 展示出改进的精确率/召回率；3. 注意机制为模型预测提供可解释性。

Conclusion: 该框架为重症监护风险预测提供了可扩展且可解释的解决方案，具有支持临床医生在真实ICU场景应用的潜力。

Abstract: Accurately predicting the criticalness of ICU patients (such as in-ICU
mortality risk) is vital for early intervention in critical care. However,
conventional models often treat each patient in isolation and struggle to
exploit the relational structure in Electronic Health Records (EHR). We propose
a Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds
a patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN
architecture that operates on this graph to predict patient mortality and a
continuous criticalness score. SBSCGM uses a hybrid similarity measure
(combining feature-based and structural similarities) to connect patients with
analogous clinical profiles in real-time. The HybridGraphMedGNN integrates
Graph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)
layers to learn robust patient representations, leveraging both local and
global graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III
dataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)
outperforming baseline classifiers and single-type GNN models. We also
demonstrate improved precision/recall and show that the attention mechanism
provides interpretable insights into model predictions. Our framework offers a
scalable and interpretable solution for critical care risk prediction, with
potential to support clinicians in real-world ICU deployment.

</details>


### [179] [IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources](https://arxiv.org/abs/2508.00627)
*Paul Tresson,Pierre Le Coz,Hadrien Tulet,Anthony Malkassian,Maxime Réjou Méchain*

Main category: cs.LG

TL;DR: 介绍了名为IAMAP的QGIS插件，该插件通过自监督学习策略解决了深度学习在遥感应用中需要大数据集、强大计算资源和编码技能的问题，支持非专家用户进行特征提取、降维、聚类、生成相似性图和机器学习模型训练。


<details>
  <summary>Details</summary>
Motivation: 深度学习在遥感领域的应用面临需要大量参考数据集、强大计算资源和编程技能的挑战，导致非专家难以实用。

Method: IAMAP插件基于自监督学习开发的通用基础模型，支持无或少量调优的使用方式。其接口提供以下功能：（1）使用多种深度学习架构提取图像特征；（2）内置降维算法；（3）基于特征或降维后的表示进行聚类；（4）生成特征相似图；（5）校准和验证监督学习模型。以上步骤在QGIS平台内通过用户友好界面操作，无需用户拥有GPU或大量标注数据。

Result: IAMAP使得非AI专家用户无需GPU或大量标注数据即可利用高质量的深度学习特征，推动了高效节能深度学习方法的普及。

Conclusion: IAMAP为QGIS用户提供了易于使用的工具，能够克服遥感深度学习实践的三大障碍，有助于降低AI技术在遥感分析中的准入门槛。

Abstract: Remote sensing has entered a new era with the rapid development of artificial
intelligence approaches. However, the implementation of deep learning has
largely remained restricted to specialists and has been impractical because it
often requires (i) large reference datasets for model training and validation;
(ii) substantial computing resources; and (iii) strong coding skills. Here, we
introduce IAMAP, a user-friendly QGIS plugin that addresses these three
challenges in an easy yet flexible way. IAMAP builds on recent advancements in
self-supervised learning strategies, which now provide robust feature
extractors, often referred to as foundation models. These generalist models can
often be reliably used in few-shot or zero-shot scenarios (i.e., with little to
no fine-tuning). IAMAP's interface allows users to streamline several key steps
in remote sensing image analysis: (i) extracting image features using a wide
range of deep learning architectures; (ii) reducing dimensionality with
built-in algorithms; (iii) performing clustering on features or their reduced
representations; (iv) generating feature similarity maps; and (v) calibrating
and validating supervised machine learning models for prediction. By enabling
non-AI specialists to leverage the high-quality features provided by recent
deep learning approaches without requiring GPU capacity or extensive reference
datasets, IAMAP contributes to the democratization of computationally efficient
and energy-conscious deep learning methods.

</details>


### [180] [Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs](https://arxiv.org/abs/2508.00628)
*Xiong Xiong,Zhuo Zhang,Rongchun Hu,Chen Gao,Zichen Deng*

Main category: cs.LG

TL;DR: 介绍了一种名为分离变量谱神经网络（SV-SNN）的新方法，用于解决高频振荡偏微分方程求解中的谱偏差问题，其在精度、参数数量和训练时间上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络（PINNs）在求解高频振荡偏微分方程时存在谱偏差问题，难以捕捉解的高频分量。这限制了其在流体力学、量子力学和电磁波传播等领域的应用。为解决这个问题，提出了SV-SNN方法。

Method: SV-SNN结合了变量分离法和自适应谱方法，主要创新包括：1）将多元函数分解为单变量函数乘积，实现空间和时间网络的独立；2）使用带可学习频率参数的自适应傅里叶谱特征来捕获高频；3）基于奇异值分解的理论框架用于量化谱偏差。

Result: 在多个基准问题上（如热方程、亥姆霍兹方程、泊松方程和纳维-斯托克斯方程）进行综合评估，SV-SNN的精度提升了1-3个数量级，同时参数数量减少90%以上，训练时间减少60%。

Conclusion: SV-SNN有效解决了神经网络在偏微分方程求解中的谱偏差问题，成为了一种高效的解决方案，为相关科学计算应用提供了有力工具。

Abstract: Solving high-frequency oscillatory partial differential equations (PDEs) is a
critical challenge in scientific computing, with applications in fluid
mechanics, quantum mechanics, and electromagnetic wave propagation. Traditional
physics-informed neural networks (PINNs) suffer from spectral bias, limiting
their ability to capture high-frequency solution components. We introduce
Separated-Variable Spectral Neural Networks (SV-SNN), a novel framework that
addresses these limitations by integrating separation of variables with
adaptive spectral methods. Our approach features three key innovations: (1)
decomposition of multivariate functions into univariate function products,
enabling independent spatial and temporal networks; (2) adaptive Fourier
spectral features with learnable frequency parameters for high-frequency
capture; and (3) theoretical framework based on singular value decomposition to
quantify spectral bias. Comprehensive evaluation on benchmark problems
including Heat equation, Helmholtz equation, Poisson equations and
Navier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of
magnitude improvement in accuracy while reducing parameter count by over 90\%
and training time by 60\%. These results establish SV-SNN as an effective
solution to the spectral bias problem in neural PDE solving. The implementation
will be made publicly available upon acceptance at
https://github.com/xgxgnpu/SV-SNN.

</details>


### [181] [KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting](https://arxiv.org/abs/2508.00635)
*Changning Wu,Gao Wu,Rongyao Cai,Yong Liu,Kexin Zhang*

Main category: cs.LG

TL;DR: 提出了一个基于KAN的自适应频率选择学习架构(KFS)，用于解决多尺度时间序列预测中跨尺度的噪声干扰以及频率成分异构信息分布问题。该架构包含FreK模块（基于能量分布选择主导频率）、KAN（用于复杂模式表示）和时间戳嵌入对齐，并通过特征混合模块融合多尺度特征。在多个真实数据集上验证了其SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多尺度分解方法在处理真实世界时间序列时面临两个问题：1）不同尺度间的噪声干扰；2）各尺度频率成分的异构信息分布导致的多尺度表示不佳。这些问题使得预测模型难以充分捕捉复杂的模式。

Method: 1. FreK模块：在频域中基于帕塞瓦尔定理的能量分布进行主导频率选择（解决噪声干扰）；2. KAN网络：利用其强大的模式表示能力建模复杂模式（替代传统MLP）；3. 时间戳嵌入对齐：同步多尺度的时间表示；4. 特征混合模块：融合尺度特定模式与对齐后的时间特征。

Result: 在多个真实时间序列数据集上进行了广泛实验，表明KFS达到了最先进的性能。

Conclusion: KFS通过整合频域主导频率选择、KAN模式表示和时间对齐，有效地解决了多尺度预测中的噪声干扰和模式表示问题，形成一个简单而强大的预测架构。

Abstract: Multi-scale decomposition architectures have emerged as predominant
methodologies in time series forecasting. However, real-world time series
exhibit noise interference across different scales, while heterogeneous
information distribution among frequency components at varying scales leads to
suboptimal multi-scale representation. Inspired by Kolmogorov-Arnold Networks
(KAN) and Parseval's theorem, we propose a KAN based adaptive Frequency
Selection learning architecture (KFS) to address these challenges. This
framework tackles prediction challenges stemming from cross-scale noise
interference and complex pattern modeling through its FreK module, which
performs energy-distribution-based dominant frequency selection in the spectral
domain. Simultaneously, KAN enables sophisticated pattern representation while
timestamp embedding alignment synchronizes temporal representations across
scales. The feature mixing module then fuses scale-specific patterns with
aligned temporal features. Extensive experiments across multiple real-world
time series datasets demonstrate that KT achieves state-of-the-art performance
as a simple yet effective architecture.

</details>


### [182] [Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense](https://arxiv.org/abs/2508.00641)
*Alessandro Palmas*

Main category: cs.LG

TL;DR: 本文通过强化学习研究如何优化拦截决策系统以应对低成本自杀式无人机蜂群的威胁，提出了一种在复杂约束条件下协调多效应器的强化学习方案，并在高仿真模拟环境中对比了其与基于规则基线的效果，结果显示强化学习策略在降低平均损伤和提升防御效能方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 低成本自杀式无人机蜂群对现代防御系统提出了严峻挑战，需要在多效应器与高价值目标区域之间做出快速拦截优先排序决策。本研究的动机是利用强化学习的能力应对这一挑战，实现高效决策优化。

Method: 1. 构建一个高仿真模拟环境，包含现实中防御系统的各类约束条件；2. 开发决策层强化学习智能体：在离散动作空间中训练，根据无人机位置、类型和效应器状态等输入特征选择由哪个效应器拦截哪架无人机；3. 在模拟环境中训练智能体学习拦截协调策略；4. 与基于规则的手工策略进行数百个攻击场景的对比实验。

Result: 强化学习策略相比人为设计的规则系统：1. 显著降低了高价值区域的整体损伤（平均损伤更低）；2. 在所有测试场景中防御效率均更优；3. 视频演示显示该策略具备战术层面的行为协调能力。

Conclusion: 强化学习作为防御架构中的战略决策层，可在不取代现有控制系统的情况下显著提升应对无人机密集袭击的韧性。该技术具备实战部署潜力，所有代码/模拟资产均已开源以确保可复现性。

Abstract: The growing threat of low-cost kamikaze drone swarms poses a critical
challenge to modern defense systems demanding rapid and strategic
decision-making to prioritize interceptions across multiple effectors and
high-value target zones. In this work, we present a case study demonstrating
the practical advantages of reinforcement learning in addressing this
challenge. We introduce a high-fidelity simulation environment that captures
realistic operational constraints, within which a decision-level reinforcement
learning agent learns to coordinate multiple effectors for optimal interception
prioritization. Operating in a discrete action space, the agent selects which
drone to engage per effector based on observed state features such as
positions, classes, and effector status. We evaluate the learned policy against
a handcrafted rule-based baseline across hundreds of simulated attack
scenarios. The reinforcement learning based policy consistently achieves lower
average damage and higher defensive efficiency in protecting critical zones.
This case study highlights the potential of reinforcement learning as a
strategic layer within defense architectures, enhancing resilience without
displacing existing control systems. All code and simulation assets are
publicly released for full reproducibility, and a video demonstration
illustrates the policy's qualitative behavior.

</details>


### [183] [Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators](https://arxiv.org/abs/2508.00643)
*Albert Matveev,Sanmitra Ghosh,Aamal Hussain,James-Michael Leahy,Michalis Michaelides*

Main category: cs.LG

TL;DR: 本文介绍了一种新型算子学习方法DINOZAUR，其整合了UQ功能并解决传统FNO在可扩展性与不确定性量化方面的不足。


<details>
  <summary>Details</summary>
Motivation: 传统算子学习方法，特别是Fourier Neural Operators（FNO）存在两大问题：参数过多导致的可扩展性挑战，以及缺乏原生不确定性量化（UQ）功能，而后者对科学和工程应用的可信推理至关重要。当前针对UQ的解决方案忽视了模型的几何归纳偏置。因而，如何打造一个高效、能够同时降低复杂度并内生支持UQ的算子方法成为主要研究动机。

Method: DINOZAUR作为基于扩散的神经算子架构引入。主要思路来自热核启发——它替换原始FNO中稠密张量乘法结构（dense tensor multiplier）为一个扩散乘法器结构（diffusion multiplier）。扩散结构中每个通道仅含一个可学习的时间参数，这使得参数数量与内存占用量都大幅减少；同时其输出表现并未折损。DINOZAUR通过在这些时间参数上设置先验分布而成为贝叶斯神经算子模型，进而支持空间相关性建模与校准型不确定性量化输出。该方法在多个PDE任务基准中接受训练与验证。

Result: DINOZAUR具有双重优势：1）降低参数量与内存占用，不影响预测精度；2）能够输出空间相关性结果并提供可信的不确定性估计。在几个经典PDE基准任务中获得竞争力结果或优于现有方法（FNO等）的结果，同时具备高计算效率和可靠UQ表现。

Conclusion: 新型扩散驱动型算子DINOZAUR实现了算子学习中参数规模高效化并赋予其原生不确定性建模能力。未来探索方向可以包括支持更多元物理方程类型，研究该技术向真实科学工具化落地。

Abstract: Operator learning is a powerful paradigm for solving partial differential
equations, with Fourier Neural Operators serving as a widely adopted
foundation. However, FNOs face significant scalability challenges due to
overparameterization and offer no native uncertainty quantification -- a key
requirement for reliable scientific and engineering applications. Instead,
neural operators rely on post hoc UQ methods that ignore geometric inductive
biases. In this work, we introduce DINOZAUR: a diffusion-based neural operator
parametrization with uncertainty quantification. Inspired by the structure of
the heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a
dimensionality-independent diffusion multiplier that has a single learnable
time parameter per channel, drastically reducing parameter count and memory
footprint without compromising predictive performance. By defining priors over
those time parameters, we cast DINOZAUR as a Bayesian neural operator to yield
spatially correlated outputs and calibrated uncertainty estimates. Our method
achieves competitive or superior performance across several PDE benchmarks
while providing efficient uncertainty quantification.

</details>


### [184] [TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction](https://arxiv.org/abs/2508.00657)
*Sihang Zeng,Lucas Jing Liu,Jun Wen,Meliha Yetisgen,Ruth Etzioni,Gang Luo*

Main category: cs.LG

TL;DR: 提出了TrajSurv模型，通过纵向电子健康记录进行生存预测。模型使用神经控制微分方程捕获不规则采样数据的连续潜轨迹，通过时间感知对比学习对齐潜状态和患者状态，并使用两阶段解释方法揭示临床进程如何影响生存结果。在两个真实医疗数据集（MIMIC-III和eICU）上验证了模型在准确性和可解释性上的优势。


<details>
  <summary>Details</summary>
Motivation: 纵向电子健康记录为生存预测提供了重要机遇，但现有方法存在两大挑战：一是难以准确建模不规则采样特征下患者的连续临床进程；二是难以透明地建立临床进程与生存结果的关联。

Method: 1) 使用神经控制微分方程（NCDE）从不规则时间点临床特征中提取连续时间潜状态，形成连续轨迹；2) 通过时间感知对比学习使潜状态空间与患者真实临床状态对齐；3) 采用两阶段解释方法：通过习得向量场解释临床特征变化如何影响潜轨迹演变，再对轨迹聚类识别与不同生存结果相关的关键临床进展模式。

Result: 在MIMIC-III和eICU数据集上测试表明：1) 预测准确性优于现有深度学习模型；2) 可解释性更优，能清晰揭示临床特征变化到生存结果的传导路径；3) 识别出的临床进展模式（如ICU住院期间器官功能退化模式）与医学认知一致。

Conclusion: TrajSurv解决了纵向EHR生存预测中连续临床进程建模与透明关联生存结果的关键挑战，兼具准确性与可解释性。其两阶段解释框架具有临床应用价值，可支持临床决策（如高危患者分层、治疗时机识别）。

Abstract: Trustworthy survival prediction is essential for clinical decision making.
Longitudinal electronic health records (EHRs) provide a uniquely powerful
opportunity for the prediction. However, it is challenging to accurately model
the continuous clinical progression of patients underlying the irregularly
sampled clinical features and to transparently link the progression to survival
outcomes. To address these challenges, we develop TrajSurv, a model that learns
continuous latent trajectories from longitudinal EHR data for trustworthy
survival prediction. TrajSurv employs a neural controlled differential equation
(NCDE) to extract continuous-time latent states from the irregularly sampled
data, forming continuous latent trajectories. To ensure the latent trajectories
reflect the clinical progression, TrajSurv aligns the latent state space with
patient state space through a time-aware contrastive learning approach. To
transparently link clinical progression to the survival outcome, TrajSurv uses
latent trajectories in a two-step divide-and-conquer interpretation process.
First, it explains how the changes in clinical features translate into the
latent trajectory's evolution using a learned vector field. Second, it clusters
these latent trajectories to identify key clinical progression patterns
associated with different survival outcomes. Evaluations on two real-world
medical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and
superior transparency over existing deep learning methods.

</details>


### [185] [DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes](https://arxiv.org/abs/2508.00664)
*Jialun Zheng,Jie Liu,Jiannong Cao,Xiao Wang,Hanchen Yang,Yankai Chen,Philip S. Yu*

Main category: cs.LG

TL;DR: 本文提出了一种具有动态原型（DP）的动态图异常检测模型（DP-DGAD），用于捕获跨域的领域特定和领域无关的异常模式，并通过选择性更新内存缓冲器和置信度伪标签自监督机制，实现十大数据集上的最优表现。


<details>
  <summary>Details</summary>
Motivation: 现有综述性静态图异常检测模型在动态图场景下难以捕获时间演化异常，且新领域不断涌现、标签数据缺乏，使得通用的动态图异常检测面临挑战。需要一种能同时捕捉领域特定和领域不可知异常模式动态变化的方法。

Method: 1. 构建动态原型：从时间感知的自我图(ego-graph)提取异常/正常模式特征作为动态原型，存储在选择性更新的记忆库中（保留通用跨域模式，吸纳新领域模式）。2. 与动态原型对比评分：通过匹配输入图序列与动态原型库进行异常评分。3. 基于模型置信度的伪标签机制：在无监督目标域环境中采用伪标签动态调优模型。

Result: 在10个真实来源的动态图上进行测试，DP-DGAD表现出最先进的性能指标。

Conclusion: 动态原型设计有效地学习跨域、时间演化的异常模式；选择性记忆更新与伪标签自监督机制实现领域泛化需求；为开放应用环境提供高鲁棒性的异常框架。

Abstract: Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies
in evolving graphs across domains such as finance, traffic, and social
networks. Recently, generalist graph anomaly detection (GAD) models have shown
promising results. They are pretrained on multiple source datasets and
generalize across domains. While effective on static graphs, they struggle to
capture evolving anomalies in dynamic graphs. Moreover, the continuous
emergence of new domains and the lack of labeled data further challenge
generalist DGAD. Effective cross-domain DGAD requires both domain-specific and
domain-agnostic anomalous patterns. Importantly, these patterns evolve
temporally within and across domains. Building on these insights, we propose a
DGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and
domain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,
evolving representations of normal and anomalous patterns, from temporal
ego-graphs and stores them in a memory buffer. The buffer is selectively
updated to retain general, domain-agnostic patterns while incorporating new
domain-specific ones. Then, an anomaly scorer compares incoming data with
dynamic prototypes to flag both general and domain-specific anomalies. Finally,
DP-DGAD employs confidence-based pseudo-labeling for effective self-supervised
adaptation in target domains. Extensive experiments demonstrate
state-of-the-art performance across ten real-world datasets from different
domains.

</details>


### [186] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
*Sergio Rubio-Martín,María Teresa García-Ordás,Antonio Serrano-García,Clara Margarita Franch-Pato,Arturo Crespo-Álvaro,José Alberto Benítez-Andrades*

Main category: cs.LG

TL;DR: 我们比较了多种人工智能模型（包括机器学习和深度学习）在分类焦虑症和适应障碍的临床笔记时的表现，并评估了过采样策略的影响。结果表明过采样效果有限，但超参数优化显著提升模型性能，决策树和XGBoost以及两种BERT模型均达到96%准确率。


<details>
  <summary>Details</summary>
Motivation: 在医疗健康领域，特别是针对心理健康状况如焦虑症和适应障碍，将临床笔记准确分类到特定诊断类别至关重要。本研究旨在探索不同AI模型以及数据平衡方法在这一任务中的效能，以推动AI辅助诊断工具的发展。

Method: 研究比较了多种机器学习和深度学习模型：随机森林、支持向量机、K近邻、决策树、XGBoost、DistilBERT和SciBERT。并应用了三种数据过采样策略：不进行过采样、随机过采样和SMOTE。同时，对所有模型进行了超参数调优以优化性能。

Result: 过采样策略对模型性能影响较小，唯一的例外是在BERT模型中，SMOTE表现出了积极效果。所有模型经过超参数优化后性能都有显著提升，尤其是泛化能力得到增强。决策树、XGBoost以及两种BERT模型都达到了96%的分类准确率。

Conclusion: 超参数调整是最大化模型性能的关键因素，而数据过采样在分类临床笔记时效果有限。本研究通过对比不同模型架构和数据平衡方法的效果，为AI驱动的心理健康诊断工具的发展提供了重要参考。

Abstract: The classification of clinical notes into specific diagnostic categories is
critical in healthcare, especially for mental health conditions like Anxiety
and Adjustment Disorder. In this study, we compare the performance of various
Artificial Intelligence models, including both traditional Machine Learning
approaches (Random Forest, Support Vector Machine, K-nearest neighbors,
Decision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT
and SciBERT), to classify clinical notes into these two diagnoses.
Additionally, we implemented three oversampling strategies: No Oversampling,
Random Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to
assess their impact on model performance. Hyperparameter tuning was also
applied to optimize model accuracy. Our results indicate that oversampling
techniques had minimal impact on model performance overall. The only exception
was SMOTE, which showed a positive effect specifically with BERT-based models.
However, hyperparameter optimization significantly improved accuracy across the
models, enhancing their ability to generalize and perform on the dataset. The
Decision Tree and eXtreme Gradient Boost models achieved the highest accuracy
among machine learning approaches, both reaching 96%, while the DistilBERT and
SciBERT models also attained 96% accuracy in the deep learning category. These
findings underscore the importance of hyperparameter tuning in maximizing model
performance. This study contributes to the ongoing research on AI-assisted
diagnostic tools in mental health by providing insights into the efficacy of
different model architectures and data balancing methods.

</details>


### [187] [Learning Network Dismantling without Handcrafted Inputs](https://arxiv.org/abs/2508.00706)
*Haozhe Tian,Pietro Ferraro,Robert Shorten,Mahdi Jalili,Homayoun Hamedmoghadam*

Main category: cs.LG

TL;DR: 论文提出了一种名为MIND的新型图神经网络框架，通过引入注意力机制和消息迭代配置文件，消除了对人工设计结构特征的依赖，从而降低了计算成本并减少了偏差。该框架在合成网络上训练后，能够泛化至大规模真实网络，并显著优于现有的网络拆解方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于消息传递的图神经网络在处理网络科学问题（如网络拆解）时，往往依赖手工设计的结构特征作为输入，这不仅增加了计算成本，还引入了偏差。因此，需要一种无需手工特征、更高效且泛化能力强的模型来解决这一问题。

Method: 1. 引入注意力机制（attention mechanism）和消息迭代配置文件（message-iteration profiles），避免使用手工设计的特征。
2. 开发了一种有效的算法来生成结构多样的小型合成网络作为训练集。
3. 构建并训练消息传递框架（MIND），用于解决NP难的网络拆解问题（即关键节点识别）。
4. 在训练时仅使用合成的多样化网络，然后将模型泛化至未见过的、具有数百万节点的大规模真实网络。

Result: 1. MIND模型在合成网络上训练后，能够高效地泛化至大规模的真实网络，并在网络拆解任务上显著优于现有最先进方法。
2. 该模型具有更高的效率和泛化能力，适用于包括拆解问题在内的多种复杂网络问题。

Conclusion: MIND模型通过结合注意力机制和消息迭代配置文件，成功避免了传统方法对手工特征输入的依赖，大幅提升了网络拆解问题的解决效率和泛化性能。这一框架在合成数据上训练即可泛化至真实大规模网络，为复杂网络问题提供了新的解决方案。

Abstract: The application of message-passing Graph Neural Networks has been a
breakthrough for important network science problems. However, the competitive
performance often relies on using handcrafted structural features as inputs,
which increases computational cost and introduces bias into the otherwise
purely data-driven network representations. Here, we eliminate the need for
handcrafted features by introducing an attention mechanism and utilizing
message-iteration profiles, in addition to an effective algorithmic approach to
generate a structurally diverse training set of small synthetic networks.
Thereby, we build an expressive message-passing framework and use it to
efficiently solve the NP-hard problem of Network Dismantling, virtually
equivalent to vital node identification, with significant real-world
applications. Trained solely on diversified synthetic networks, our proposed
model -- MIND: Message Iteration Network Dismantler -- generalizes to large,
unseen real networks with millions of nodes, outperforming state-of-the-art
network dismantling methods. Increased efficiency and generalizability of the
proposed model can be leveraged beyond dismantling in a range of complex
network problems.

</details>


### [188] [Efficient Solution and Learning of Robust Factored MDPs](https://arxiv.org/abs/2508.00707)
*Yannik Schnitzer,Alessandro Abate,David Parker*

Main category: cs.LG

TL;DR: 提出了基于因子化状态空间表示的新方法来解决和学习鲁棒马尔可夫决策过程（r-MDPs），通过利用模型不确定性在系统组件间的独立性，将非凸优化问题转化为可处理的线性规划，并直接从数据中学习因子化模型表示。实验表明，该方法在样本效率上具有维度增益，比现有方法能生成更有效的鲁棒策略和更紧的性能保证。


<details>
  <summary>Details</summary>
Motivation: r-MDPs通过显式建模转移动态的认知不确定性来扩展MDPs，但从与未知环境的交互中学习r-MDPs可能需要大量样本。因此，需要更高效的算法来减少样本交互数量，同时保证鲁棒策略的性能。

Method: 1. 基于因子化状态空间表示，利用模型不确定性在系统组件间的独立性；
2. 将非凸的鲁棒策略优化问题重新表述为可处理的线性规划；
3. 提出直接从交互数据中学习因子化模型表示的方法。

Result: 实验结果显示，利用因子化结构可以在样本效率上获得维度增益，相较于当前最先进的方法，能够产生更有效的鲁棒策略，同时具有更紧的性能保证。

Conclusion: 因子化状态空间表示能够有效减少r-MDPs学习所需的样本数量，并能将非凸优化问题转化为线性规划从而高效求解，为在实际系统中应用鲁棒强化学习提供了新的途径。

Abstract: Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling
epistemic uncertainty about transition dynamics. Learning r-MDPs from
interactions with an unknown environment enables the synthesis of robust
policies with provable (PAC) guarantees on performance, but this can require a
large number of sample interactions. We propose novel methods for solving and
learning r-MDPs based on factored state-space representations that leverage the
independence between model uncertainty across system components. Although
policy synthesis for factored r-MDPs leads to hard, non-convex optimisation
problems, we show how to reformulate these into tractable linear programs.
Building on these, we also propose methods to learn factored model
representations directly. Our experimental results show that exploiting
factored structure can yield dimensional gains in sample efficiency, producing
more effective robust policies with tighter performance guarantees than
state-of-the-art methods.

</details>


### [189] [JSON-Bag: A generic game trajectory representation](https://arxiv.org/abs/2508.00712)
*Dien Nguyen,Diego Perez-Liebana,Simon Lucas*

Main category: cs.LG

TL;DR: 提出了JSON Bag-of-Tokens（JSON-Bag）模型来表示游戏轨迹，通过标记化其JSON描述，并应用Jensen-Shannon距离（JSD）作为距离度量。使用基于原型的最近邻搜索（P-NNS）在六款桌游上评估了该方法。结果显示，该方法在大多数任务中优于使用手工特征的基线，样本效率高，并能自动提取特征。此外，JSD与代理策略之间的距离高度相关。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常使用手工特征来表示游戏轨迹，这可能不够通用且效率低下。为了克服这些限制，引入JSON-Bag模型作为一种通用表示方法，以及使用JSD作为轨迹间的距离度量，目的是更有效地分类轨迹并理解代理的行为。

Method: 1. 使用JSON-Bag模型标记化游戏轨迹的JSON描述。2. 应用Jensen-Shannon距离（JSD）计算轨迹之间的距离。3. 使用基于原型的最近邻搜索（P-NNS）进行分类任务评估。具体包括三种任务：对玩家代理、游戏参数、游戏种子进行分类。4. 在六款桌游上评估模型性能。补充实验：用JSON-Bag自动提取特征（单词作为特征）输入随机森林；分析JSD与代理策略距离的相关性。

Result: 1. 在大多数分类任务中，JSON-Bag结合JSD和P-NNS优于手工特征基线。2. N-shot分类表明JSON-Bag原型表示具有样本高效性。3. 将JSON-Bag的单词作为特征输入随机森林显著提高了在部分任务上的准确率（特别是在之前表现不佳的任务上）。4. 跨六款游戏的代理类别的JSON-Bag原型的JSD与代理策略之间的距离高度相关。

Conclusion: JSON-Bag是一种通用且有效的游戏轨迹表示方法，结合JSD和P-NNS在多种分类任务中表现优越，且样本效率高。它能够自动提取有用特征，并通过随机森林提升性能。此外，JSD能够有效反映代理策略间的相似性。

Abstract: We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically
represent game trajectories by tokenizing their JSON descriptions and apply
Jensen-Shannon distance (JSD) as distance metric for them. Using a
prototype-based nearest-neighbor search (P-NNS), we evaluate the validity of
JSON-Bag with JSD on six tabletop games -- \textit{7 Wonders},
\textit{Dominion}, \textit{Sea Salt and Paper}, \textit{Can't Stop},
\textit{Connect4}, \textit{Dots and boxes} -- each over three game trajectory
classification tasks: classifying the playing agents, game parameters, or game
seeds that were used to generate the trajectories.
  Our approach outperforms a baseline using hand-crafted features in the
majority of tasks. Evaluating on N-shot classification suggests using JSON-Bag
prototype to represent game trajectory classes is also sample efficient.
Additionally, we demonstrate JSON-Bag ability for automatic feature extraction
by treating tokens as individual features to be used in Random Forest to solve
the tasks above, which significantly improves accuracy on underperforming
tasks. Finally, we show that, across all six games, the JSD between JSON-Bag
prototypes of agent classes highly correlates with the distances between
agents' policies.

</details>


### [190] [Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning](https://arxiv.org/abs/2508.00716)
*Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu*

Main category: cs.LG

TL;DR: 本文提出了一种名为NeGPR的新型图域适应（GDA）框架，专门处理源域中存在标签噪声的情况。通过双分支预训练、嵌套伪标签优化和噪声感知正则化策略，该方法在严重标签噪声下实现高达12.7%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有图域适应方法均假设源域标签是干净的，而实际场景中标签噪声广泛存在，这会损害特征对齐并降低域适应性能。为解决源域标签噪声对图级域适应的负面影响，需要设计具有噪声鲁棒性的GDA框架。

Method: 1. 语义分支和拓扑分支双分支预训练：通过强制特征空间的邻域一致性减少噪声监督影响
2. 嵌套伪标签精炼机制：双分支交替选择高置信度目标样本引导对方进行跨域学习
3. 噪声感知正则化：理论证明可缓解伪标签噪声影响（尤其针对源域过拟合情况）

Result: 在基准数据集上的实验证明：在严重标签噪声（如对称噪声率60%）下，NeGPR始终优于现有方法，最高实现12.7%的准确率提升。

Conclusion: NeGPR是首个专门针对图域适应中源域标签噪声问题设计的框架。其嵌套优化结构和理论支持的噪声处理机制有效解决了噪声环境下的域偏移问题，在分子性质预测等任务中具有实用价值。

Abstract: Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled
source graphs to unlabeled target graphs by learning domain-invariant
representations, which is essential in applications such as molecular property
prediction and social network analysis. However, most existing GDA methods rely
on the assumption of clean source labels, which rarely holds in real-world
scenarios where annotation noise is pervasive. This label noise severely
impairs feature alignment and degrades adaptation performance under domain
shifts. To address this challenge, we propose Nested Graph Pseudo-Label
Refinement (NeGPR), a novel framework tailored for graph-level domain
adaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,
semantic and topology branches, by enforcing neighborhood consistency in the
feature space, thereby reducing the influence of noisy supervision. To bridge
domain gaps, NeGPR employs a nested refinement mechanism in which one branch
selects high-confidence target samples to guide the adaptation of the other,
enabling progressive cross-domain learning. Furthermore, since pseudo-labels
may still contain noise and the pre-trained branches are already overfitted to
the noisy labels in the source domain, NeGPR incorporates a noise-aware
regularization strategy. This regularization is theoretically proven to
mitigate the adverse effects of pseudo-label noise, even under the presence of
source overfitting, thus enhancing the robustness of the adaptation process.
Extensive experiments on benchmark datasets demonstrate that NeGPR consistently
outperforms state-of-the-art methods under severe label noise, achieving gains
of up to 12.7% in accuracy.

</details>


### [191] [Democratizing Tabular Data Access with an Open$\unicode{x2013}$Source Synthetic$\unicode{x2013}$Data SDK](https://arxiv.org/abs/2508.00718)
*Ivona Krchova,Mariana Vargas Vieyra,Mario Scriminaci,Andrey Sidorenko*

Main category: cs.LG

TL;DR: 介绍MOSTLY AI合成数据SDK：一个开源工具包，用于生成高质量的表格数据，支持差分隐私、公平性数据生成和自动质量保证，适用于多表格和顺序数据集，已在云服务和本地安装中部署。


<details>
  <summary>Details</summary>
Motivation: 由于隐私、所有权和伦理问题导致的数据访问受限，影响了机器学习的发展。合成数据提供了一种安全、广泛使用数据的方式，而不泄露敏感信息。

Method: 基于TabularARGN自回归框架开发的开源Python工具包。支持多种数据类型，包括复杂的多表格和顺序数据。集成了差分隐私保证、公平性数据生成和自动质量保证。

Result: SDK在速度和可用性上具有竞争力，已部署为云服务和本地软件，得到快速采用，有效解决实际数据瓶颈问题。

Conclusion: 该SDK促进了数据民主化，使高质量数据的访问变得更加安全和便捷，解决了当前数据访问的障碍。

Abstract: Machine learning development critically depends on access to high-quality
data. However, increasing restrictions due to privacy, proprietary interests,
and ethical concerns have created significant barriers to data accessibility.
Synthetic data offers a viable solution by enabling safe, broad data usage
without compromising sensitive information. This paper presents the MOSTLY AI
Synthetic Data Software Development Kit (SDK), an open-source toolkit designed
specifically for synthesizing high-quality tabular data. The SDK integrates
robust features such as differential privacy guarantees, fairness-aware data
generation, and automated quality assurance into a flexible and accessible
Python interface. Leveraging the TabularARGN autoregressive framework, the SDK
supports diverse data types and complex multi-table and sequential datasets,
delivering competitive performance with notable improvements in speed and
usability. Currently deployed both as a cloud service and locally installable
software, the SDK has seen rapid adoption, highlighting its practicality in
addressing real-world data bottlenecks and promoting widespread data
democratization.

</details>


### [192] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
*Liuyun Xu,Seymour M. J. Spence*

Main category: cs.LG

TL;DR: 该论文介绍了一种结合多层采样和自适应机器学习元模型的方法，用于高效传播不确定性和估计小失效概率，以解决现有方法在复杂非线性有限元模型中计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的用于罕见事件分析的随机模拟中的方差缩减技术在估计小失效概率时仍需要大量模型评估。在复杂的非线性有限元建模环境中，特别是对于随机激励的系统，这可能会在计算上具有挑战性。因此，需要一种更高效的方法来减少计算成本。

Method: 提出了一种多精度分层采样方案，结合自适应机器学习元模型。首先，通过分层采样生成高精度数据集，用于训练基于深度学习的元模型，该模型作为成本效益高且高度相关的低精度模型。采用自适应训练方案平衡低精度模型的近似质量和计算需求。然后，将低精度输出与额外的高精度结果结合，在多精度蒙特卡罗框架下获取各层失效概率的无偏估计。最后，利用全概率定理计算整体失效概率。

Result: 将该方法应用于一座全尺寸高层钢结构建筑在随机风激励下的分析，结果表明该方法能够准确估计非线性响应的超越概率曲线，同时相比单一精度方差缩减方法实现了显著的计算节省。

Conclusion: 所提出的多精度分层采样方案在保证准确性的同时，大幅降低了计算成本，为估计罕见事件下的小失效概率提供了一种有效解决方案。

Abstract: Existing variance reduction techniques used in stochastic simulations for
rare event analysis still require a substantial number of model evaluations to
estimate small failure probabilities. In the context of complex, nonlinear
finite element modeling environments, this can become computationally
challenging-particularly for systems subjected to stochastic excitation. To
address this challenge, a multi-fidelity stratified sampling scheme with
adaptive machine learning metamodels is introduced for efficiently propagating
uncertainties and estimating small failure probabilities. In this approach, a
high-fidelity dataset generated through stratified sampling is used to train a
deep learning-based metamodel, which then serves as a cost-effective and highly
correlated low-fidelity model. An adaptive training scheme is proposed to
balance the trade-off between approximation quality and computational demand
associated with the development of the low-fidelity model. By integrating the
low-fidelity outputs with additional high-fidelity results, an unbiased
estimate of the strata-wise failure probabilities is obtained using a
multi-fidelity Monte Carlo framework. The overall probability of failure is
then computed using the total probability theorem. Application to a full-scale
high-rise steel building subjected to stochastic wind excitation demonstrates
that the proposed scheme can accurately estimate exceedance probability curves
for nonlinear responses of interest, while achieving significant computational
savings compared to single-fidelity variance reduction approaches.

</details>


### [193] [A Simple and Effective Method for Uncertainty Quantification and OOD Detection](https://arxiv.org/abs/2508.00754)
*Yaxin Ma,Benjamin Colburn,Jose C. Principe*

Main category: cs.LG

TL;DR: 提出一种新的方法，基于特征空间密度来量化分布偏移和OOD检测的不确定性。该方法利用特征空间密度估计，规避了贝叶斯神经网络和集成方法的高计算与存储需求，在合成数据集和真实OOD检测任务中效果优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有的神经网络不确定性量化方法（如贝叶斯神经网络和深度集成）计算密集且存储需求大。为了克服这些缺点，研究者提出采用单一确定性模型，通过分析特征空间密度来量化分布偏移和OOD检测中的不确定性。

Method: 使用特征空间密度估计方法来量化不确定性。具体步骤：1. 利用训练数据特征计算信息势场（通过核密度估计得到）。2. 将测试样本的特征表示与训练集的特征空间密度进行对比，以确定是否发生分布偏移。

Result: 在二维合成数据集（双月和三星点旋转）以及OOD检测任务（CIFAR-10与SVHN数据集比对）中进行了实验。结果表明，所提出方法在识别分布偏移和OOD样本方面优于基线模型。

Conclusion: 该方法以单一确定性模型为基础，通过特征空间密度有效地量化了模型在分布偏移和OOD数据上的不确定性，同时解决了计算和存储开销大的问题。在实验中表现出优异的性能，为高效不确定性估计提供了新的思路。

Abstract: Bayesian neural networks and deep ensemble methods have been proposed for
uncertainty quantification; however, they are computationally intensive and
require large storage. By utilizing a single deterministic model, we can solve
the above issue. We propose an effective method based on feature space density
to quantify uncertainty for distributional shifts and out-of-distribution (OOD)
detection. Specifically, we leverage the information potential field derived
from kernel density estimation to approximate the feature space density of the
training set. By comparing this density with the feature space representation
of test samples, we can effectively determine whether a distributional shift
has occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons
and Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The
results demonstrate that our method outperforms baseline models.

</details>


### [194] [Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data](https://arxiv.org/abs/2508.00758)
*Timur Sattarov,Marco Schreyer,Damian Borth*

Main category: cs.LG

TL;DR: 本文提出了DDAE框架，该框架集成了扩散模型的噪声调度和对比学习到自编码器的训练中，用于提升表格数据的异常检测。在ADBench的57个数据集上，DDAE在半监督设置中表现优异，在无监督设置中也获得竞争性结果，尤其在PR-AUC和ROC-AUC指标上大幅超越现有自编码器和扩散模型基线。


<details>
  <summary>Details</summary>
Motivation: 表格数据异常检测面临特征交互复杂和异常样本稀少的问题。现有去噪自编码器使用固定强度的噪声，难以适应多样化的数据分布，而扩散模型通过引入计划噪声和迭代去噪，但缺乏显式的重构映射。因此，作者提出结合两者优势的DDAE框架。

Method: 提出的DDAE框架包含两个核心部分：首先，将扩散模型中的时间步噪声调度机制引入到自编码器的训练过程中，在输入数据中加入逐步增加（或根据策略变化）的高斯噪声。其次，在编码器训练中融合对比学习机制，通过对比不同扰动版本的同一数据样本的表示，使模型在训练中能够更好地捕捉内在的稳健特征和隐结构信息，从而提高模型在去噪后的重建能力和对异常样本的区分能力。

Result: 在ADBench的57个基准数据集上，DDAE在多个评估指标上明显超越基线模型：(1)在典型的半监督设置下，PR-AUC达到最高65%的提升（相对于SOTA的自编码器模型），ROC-AUC提升16%。在无监督设置下（相较于扩散基线）PR-AUC提升9%，ROC-AUC提升6%。同时，作者通过实验表明无监督模式适配于更高噪声水平，而半监督模式更适宜采用较低噪声、线性调度策略。

Conclusion: 该文论证了在表格数据异常检测任务中，噪声策略设计具有显著重要性。通过合理的噪声调度（如扩散机制）和学习策略的结合（如对比学习和自编码重建的联合任务）能明显改善模型对正常和异常数据的泛化能力。DDAE框架通过融合这两种方式，为稳健的异常检测系统提供了可靠路径。

Abstract: Anomaly detection in tabular data remains challenging due to complex feature
interactions and the scarcity of anomalous examples. Denoising autoencoders
rely on fixed-magnitude noise, limiting adaptability to diverse data
distributions. Diffusion models introduce scheduled noise and iterative
denoising, but lack explicit reconstruction mappings. We propose the
Diffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates
diffusion-based noise scheduling and contrastive learning into the encoding
process to improve anomaly detection. We evaluated DDAE on 57 datasets from
ADBench. Our method outperforms in semi-supervised settings and achieves
competitive results in unsupervised settings, improving PR-AUC by up to 65%
(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)
model baselines. We observed that higher noise levels benefit unsupervised
training, while lower noise with linear scheduling is optimal in
semi-supervised settings. These findings underscore the importance of
principled noise strategies in tabular anomaly detection.

</details>


### [195] [Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy](https://arxiv.org/abs/2508.00768)
*Antonio Tudisco,Andrea Marchesin,Maurizio Zamboni,Mariagrazia Graziano,Giovanna Turvani*

Main category: cs.LG

TL;DR: 本研究分析了不同旋转门对变分量子电路模型分类性能的影响，发现在相同拓扑结构下，精度差距可达10%-41%，证明嵌入是VQC的关键超参数。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习中的变分量子电路模型受多种因素影响，其中嵌入方法（如振幅编码和角度编码）及旋转门的选择对模型性能的作用尚未充分探索。本研究旨在探索这些因素如何影响VQC模型的分类性能。

Method: 采用两种数据集（Wine和Diabetes）比较不同编码方案（振幅编码和角度编码）及使用不同旋转门的VQC模型，分析其在相同拓扑结构下的分类性能差异。

Result: 在相同模型拓扑下，不同模型间的精度差距高达10%-30%，最大达41%；旋转门的选择对模型分类性能有显著影响。

Conclusion: 变分量子电路的嵌入方法（含编码方案和旋转门选择）是该类模型的关键超参数，其选择会显著影响分类性能。

Abstract: Recent advancements in Quantum Computing and Machine Learning have increased
attention to Quantum Machine Learning (QML), which aims to develop machine
learning models by exploiting the quantum computing paradigm. One of the widely
used models in this area is the Variational Quantum Circuit (VQC), a hybrid
model where the quantum circuit handles data inference while classical
optimization adjusts the parameters of the circuit. The quantum circuit
consists of an encoding layer, which loads data into the circuit, and a
template circuit, known as the ansatz, responsible for processing the data.
This work involves performing an analysis by considering both Amplitude- and
Angle-encoding models, and examining how the type of rotational gate applied
affects the classification performance of the model. This comparison is carried
out by training the different models on two datasets, Wine and Diabetes, and
evaluating their performance. The study demonstrates that, under identical
model topologies, the difference in accuracy between the best and worst models
ranges from 10% to 30%, with differences reaching up to 41%. Moreover, the
results highlight how the choice of rotational gates used in encoding can
significantly impact the model's classification performance. The findings
confirm that the embedding represents a hyperparameter for VQC models.

</details>


### [196] [Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors](https://arxiv.org/abs/2508.00785)
*Bushra Akter,Md Biplob Hosen,Sabbir Ahmed,Mehrin Anannya,Md. Farhad Hossain*

Main category: cs.LG

TL;DR: 这篇研究探讨了影响学生CGPA的多变量社会学术和财务因素，通过文献综述构建了因果图假设，并进行了1050份学生在线调查。研究采用因果分析验证变量关系，使用Ridge回归预测CGPA（MAE=0.12，MSE=0.023），使用随机森林分类（准确率98.68%）。通过可解释AI技术（如SHAP）识别关键影响因素，并开发了基于网络的应用程序为学生提供个性化指导。


<details>
  <summary>Details</summary>
Motivation: 学术成绩受多种社会学术和财务因素影响，但现有研究缺乏对这些变量间因果关系的深入分析和有效利用以提升学生的CGPA。因此，本研究的动机是识别这些关键因素并开发策略来优化学生的学术表现。

Method: 1. 文献综述识别关键因素，构建初始因果图假设。2. 收集1050份学生在线调查数据。3. 数据预处理（清洗和可视化）。4. 因果分析验证变量关系及其对CGPA的直接影响。5. 使用Ridge回归预测CGPA，随机森林分类学生表现。6. 通过SHAP、LIME等方法解释模型。7. 开发基于网络的应用程序提供个性化建议。

Result: Ridge回归预测CGPA的MAE为0.12，MSE为0.023；随机森林分类在任务上准确率达98.68%。可解释AI方法识别出关键影响因素：学习时间、奖学金、父母教育程度和先前学业表现。最后，开发了网络应用程序帮助学生提升表现。

Conclusion: 通过因果分析和机器学习，研究揭示了影响CGPA的关键因素并建立了高精度预测模型（回归和分类）。应用可解释AI技术使模型具有可解释性，帮助理解特征重要性。网络应用程序为学生提供了实用的个性化工具，以采取针对性措施改善学术表现。

Abstract: Academic performance depends on a multivariable nexus of socio-academic and
financial factors. This study investigates these influences to develop
effective strategies for optimizing students' CGPA. To achieve this, we
reviewed various literature to identify key influencing factors and constructed
an initial hypothetical causal graph based on the findings. Additionally, an
online survey was conducted, where 1,050 students participated, providing
comprehensive data for analysis. Rigorous data preprocessing techniques,
including cleaning and visualization, ensured data quality before analysis.
Causal analysis validated the relationships among variables, offering deeper
insights into their direct and indirect effects on CGPA. Regression models were
implemented for CGPA prediction, while classification models categorized
students based on performance levels. Ridge Regression demonstrated strong
predictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared
Error of 0.023. Random Forest outperformed in classification, attaining an
F1-score near perfection and an accuracy of 98.68%. Explainable AI techniques
such as SHAP, LIME, and Interpret enhanced model interpretability, highlighting
critical factors such as study hours, scholarships, parental education, and
prior academic performance. The study culminated in the development of a
web-based application that provides students with personalized insights,
allowing them to predict academic performance, identify areas for improvement,
and make informed decisions to enhance their outcomes.

</details>


### [197] [Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management](https://arxiv.org/abs/2508.00806)
*Ping Chen,Zhuohong Deng,Ping Li,Shuibing He,Hongzi Zhu,Yi Zheng,Zhefeng Wang,Baoxing Huai,Minyi Guo*

Main category: cs.LG

TL;DR: Adacc框架通过自适应压缩和激活检查点技术减少GPU内存占用，提升大型语言模型训练速度1.01x-1.37x。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练中重计算(recomputation)带来高达30%的开销，现有技术难以平衡内存占用与精度损失。

Method: 1) 设计考虑LLM张量异常值的分层压缩算法；2) 采用混合整数线性规划(MILP)为每张量制定最优内存优化策略；3) 引入自适应策略调整机制应对训练动态变化。

Result: 在保持模型精度接近基线的前提下，训练速度比SOTA框架提升1.01-1.37倍

Conclusion: Adacc在控制算法复杂度的同时实现内存-精度-速度三优化，为LLM训练提供新范式

Abstract: Training large language models often employs recomputation to alleviate
memory pressure, which can introduce up to 30% overhead in real-world
scenarios. In this paper, we propose Adacc, a novel memory management framework
that combines adaptive compression and activation checkpointing to reduce the
GPU memory footprint. It comprises three modules: (1) We design layer-specific
compression algorithms that account for outliers in LLM tensors, instead of
directly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We
propose an optimal scheduling policy that employs MILP to determine the best
memory optimization for each tensor. (3) To accommodate changes in training
tensors, we introduce an adaptive policy evolution mechanism that adjusts the
policy during training to enhance throughput. Experimental results show that
Adacc can accelerate the LLM training by 1.01x to 1.37x compared to
state-of-the-art frameworks, while maintaining comparable model accuracy to the
Baseline.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [198] [XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation](https://arxiv.org/abs/2508.00097)
*Zhigen Zhao,Liuchuan Yu,Ke Jing,Ning Yang*

Main category: cs.RO

TL;DR: 本文介绍了XToolkit，一个基于OpenXR标准的跨平台扩展现实机器人遥操作框架，旨在解决当前机器人演示数据集采集方法在可扩展性、设置复杂性和数据质量方面的问题。


<details>
  <summary>Details</summary>
Motivation: 随着视觉-语言-动作模型的快速发展，对大规模高质量机器人演示数据集的需求日益迫切。然而，现有的遥操作数据采集方法存在可扩展性有限、设置复杂以及数据质量不佳等问题。

Method: 提出的XToolkit框架包括：基于OpenXR标准构建；具有低延迟立体视觉反馈；采用优化型逆运动学；支持头部、控制器、手部及辅助运动跟踪器等多种跟踪方式；采用模块化架构，可无缝集成各种机器人平台和仿真环境（包括精密机械臂、移动机器人和灵巧手）。通过精密操控任务展示框架效果。

Result: 演示了该框架在精密操控任务中的有效性，并通过训练视觉-语言-动作模型验证了数据质量，这些模型展现出稳健的自主性能。

Conclusion: XToolkit解决了当前机器人数据采集的局限性，其模块化设计和跨平台能力为高质量机器人演示数据的采集提供了有效工具，并为构建强大的视觉-语言-动作模型奠定了基础。

Abstract: The rapid advancement of Vision-Language-Action models has created an urgent
need for large-scale, high-quality robot demonstration datasets. Although
teleoperation is the predominant method for data collection, current approaches
suffer from limited scalability, complex setup procedures, and suboptimal data
quality. This paper presents XRoboToolkit, a cross-platform framework for
extended reality based robot teleoperation built on the OpenXR standard. The
system features low-latency stereoscopic visual feedback, optimization-based
inverse kinematics, and support for diverse tracking modalities including head,
controller, hand, and auxiliary motion trackers. XRoboToolkit's modular
architecture enables seamless integration across robotic platforms and
simulation environments, spanning precision manipulators, mobile robots, and
dexterous hands. We demonstrate the framework's effectiveness through precision
manipulation tasks and validate data quality by training VLA models that
exhibit robust autonomous performance.

</details>


### [199] [CHILD (Controller for Humanoid Imitation and Live Demonstration): a Whole-Body Humanoid Teleoperation System](https://arxiv.org/abs/2508.00162)
*Noboru Myers,Obin Kwon,Sankalp Yamsani,Joohyung Kim*

Main category: cs.RO

TL;DR: CHILD是一个紧凑可重新配置的遥操作系统，用于人形机器人的全身关节级控制。


<details>
  <summary>Details</summary>
Motivation: 现有遥操作支持人形机器人全身关节级控制较少，限制了任务多样性。

Method: 设计可穿戴控制器（CHILD），支持所有肢体控制、直接关节映射、适应力反馈。

Result: 系统在一个人形机器人和多个双臂系统上验证了运动操纵和全身控制能力。

Conclusion: 提出CHILD系统实现人形机器人全身关节级操作，并开源硬件设计以促进可及性和可重复性。

Abstract: Recent advances in teleoperation have demonstrated robots performing complex
manipulation tasks. However, existing works rarely support whole-body
joint-level teleoperation for humanoid robots, limiting the diversity of tasks
that can be accomplished. This work presents Controller for Humanoid Imitation
and Live Demonstration (CHILD), a compact reconfigurable teleoperation system
that enables joint level control over humanoid robots. CHILD fits within a
standard baby carrier, allowing the operator control over all four limbs, and
supports both direct joint mapping for full-body control and loco-manipulation.
Adaptive force feedback is incorporated to enhance operator experience and
prevent unsafe joint movements. We validate the capabilities of this system by
conducting loco-manipulation and full-body control examples on a humanoid robot
and multiple dual-arm systems. Lastly, we open-source the design of the
hardware promoting accessibility and reproducibility. Additional details and
open-source information are available at our project website:
https://uiuckimlab.github.io/CHILD-pages.

</details>


### [200] [Topology-Inspired Morphological Descriptor for Soft Continuum Robots](https://arxiv.org/abs/2508.00258)
*Zhiwei Wu,Siyi Wei,Jiahao Luo,Jinhui Zhang*

Main category: cs.RO

TL;DR: 本文引入了一种基于拓扑学的形态描述符，通过结合伪刚体（PRB）模型和莫尔斯理论，实现了对软体连续体机器人形态的定量表征。该描述符通过计算方向投影的临界点，提供了多模态配置的离散表示，并简化了形态分类。此外，本文将描述符应用于形态控制，将目标构型建模为优化问题，以计算生成具有所需拓扑特征的平衡形状的驱动参数。


<details>
  <summary>Details</summary>
Motivation: 传统的软连续体机器人形态描述方法在定量表征和多模态分类上存在局限性。为了提升精确性和适应性，特别是在医疗应用（如微创手术和血管内干预）中，需要一种统一的方法来定量描述、分类和控制机器人的形态。

Method: 1. 结合伪刚体（PRB）模型与莫尔斯理论，提出了一种基于拓扑的形态描述符。2. 通过计算方向投影的临界点数量，实现多模态配置的离散量化描述。3. 将目标形态控制问题转化为优化问题，求解驱动参数以生成具有特定拓扑特征的平衡形状。

Result: 所提出的描述符成功实现了软连续体机器人形态的定量描述与分类，并通过优化算法实现了基于拓扑特征的形态控制。该框架统一了形态描述、分类与控制流程，提升了机器人在医疗应用中的精确性与适应性。

Conclusion: 本文提出的基于拓扑的形态描述方法为软连续体机器人提供了一种定量描述、分类与控制的统一框架。这一方法解决了传统形态描述在多模态下的问题，并为医疗应用中的精准操作提供了新的理论工具。

Abstract: This paper presents a topology-inspired morphological descriptor for soft
continuum robots by combining a pseudo-rigid-body (PRB) model with Morse theory
to achieve a quantitative characterization of robot morphologies. By counting
critical points of directional projections, the proposed descriptor enables a
discrete representation of multimodal configurations and facilitates
morphological classification. Furthermore, we apply the descriptor to
morphology control by formulating the target configuration as an optimization
problem to compute actuation parameters that generate equilibrium shapes with
desired topological features. The proposed framework provides a unified
methodology for quantitative morphology description, classification, and
control of soft continuum robots, with the potential to enhance their precision
and adaptability in medical applications such as minimally invasive surgery and
endovascular interventions.

</details>


### [201] [UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents](https://arxiv.org/abs/2508.00288)
*Jianqiang Xiao,Yuexuan Sun,Yixin Shao,Boxi Gan,Rongqiang Liu,Yanjing Wu,Weili Gua,Xiang Deng*

Main category: cs.RO

TL;DR: 针对空中智能体在开放世界中进行目标导向导航的需求，提出UAV-ON基准测试，包含14个高保真虚拟环境和1270个标注目标对象。基于语义目标而非详细语言指令，旨在提升无人机在复杂环境中的自主导航能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究遵循视觉与语言导航范式（VLN），过度依赖顺序语言指令，难以扩展到大规模非结构环境。UAV-ON通过建立基于高层语义目标的导航基准，解决现有方法在可扩展性和自主性上的不足。

Method: 1) 构建含14个高保真UE环境的UAV-ON数据集，涵盖城市场景、自然场景和混合场景；2) 标注1270个目标对象，每个对象通过实例级指令（类别、物理足迹和视觉描述）定义语义目标；3) 提出模块化策略Aerial ObjectNav Agent (AOA)，融合语义指令与自中心观测实现长视野目标探索；4) 实现多种基线方法用于基准评估。

Result: 所有基线模型在该设定下表现均不佳，突显出空中导航与语义目标定位的复合挑战。实验验证了该基准的难度和必要性。

Conclusion: UAV-ON通过引入无指令依赖的语义导航任务，推动开放世界中无人机自主导航研究。基准测试揭示了现有方法在复杂空间布局和语义推理上的缺陷，为开发更智能的空中导航系统提供方向。

Abstract: Aerial navigation is a fundamental yet underexplored capability in embodied
intelligence, enabling agents to operate in large-scale, unstructured
environments where traditional navigation paradigms fall short. However, most
existing research follows the Vision-and-Language Navigation (VLN) paradigm,
which heavily depends on sequential linguistic instructions, limiting its
scalability and autonomy. To address this gap, we introduce UAV-ON, a benchmark
for large-scale Object Goal Navigation (ObjectNav) by aerial agents in
open-world environments, where agents operate based on high-level semantic
goals without relying on detailed instructional guidance as in VLN. UAV-ON
comprises 14 high-fidelity Unreal Engine environments with diverse semantic
regions and complex spatial layouts, covering urban, natural, and mixed-use
settings. It defines 1270 annotated target objects, each characterized by an
instance-level instruction that encodes category, physical footprint, and
visual descriptors, allowing grounded reasoning. These instructions serve as
semantic goals, introducing realistic ambiguity and complex reasoning
challenges for aerial agents. To evaluate the benchmark, we implement several
baseline methods, including Aerial ObjectNav Agent (AOA), a modular policy that
integrates instruction semantics with egocentric observations for long-horizon,
goal-directed exploration. Empirical results show that all baselines struggle
in this setting, highlighting the compounded challenges of aerial navigation
and semantic goal grounding. UAV-ON aims to advance research on scalable UAV
autonomy driven by semantic goal descriptions in complex real-world
environments.

</details>


### [202] [TopoDiffuser: A Diffusion-Based Multimodal Trajectory Prediction Model with Topometric Maps](https://arxiv.org/abs/2508.00303)
*Zehui Xu,Junhui Wang,Yongliang Shi,Chao Gao,Guyue Zhou*

Main category: cs.RO

TL;DR: TopoDiffuser是一个基于扩散模型的框架，用于多模态轨迹预测，它通过融合拓扑地图生成准确、多样且符合道路要求的未来运动预测。该方法在KITTI基准测试中表现优于现有方法，并保持几何一致性。


<details>
  <summary>Details</summary>
Motivation: 为了提高轨迹预测的准确性和道路符合性，同时避免使用显式约束，研究者提出将拓扑地图的结构信息融入扩散模型的去噪过程中，从而自然地生成符合道路几何形状的轨迹。

Method: 1. 提出一个基于扩散模型的框架TopoDiffuser；
2. 将拓扑地图中的结构线索嵌入到条件扩散模型的去噪过程中；
3. 使用多模态条件编码器融合LiDAR观测、历史运动轨迹和路径信息，形成统一的鸟瞰图（BEV）表示；
4. 通过扩散模型生成多样化的未来轨迹。

Result: 在KITTI基准测试上进行的广泛实验表明，TopoDiffuser在预测准确性、多样性和道路符合性方面优于现有最先进的方法。消融研究验证了各输入模态的贡献、去噪步骤的影响以及轨迹样本数量的重要性。

Conclusion: TopoDiffuser通过将拓扑地图信息融入扩散模型，能够生成符合道路几何的轨迹，并在KITTI基准测试中超越了现有方法。代码已开源以促进未来研究。

Abstract: This paper introduces TopoDiffuser, a diffusion-based framework for
multimodal trajectory prediction that incorporates topometric maps to generate
accurate, diverse, and road-compliant future motion forecasts. By embedding
structural cues from topometric maps into the denoising process of a
conditional diffusion model, the proposed approach enables trajectory
generation that naturally adheres to road geometry without relying on explicit
constraints. A multimodal conditioning encoder fuses LiDAR observations,
historical motion, and route information into a unified bird's-eye-view (BEV)
representation. Extensive experiments on the KITTI benchmark demonstrate that
TopoDiffuser outperforms state-of-the-art methods, while maintaining strong
geometric consistency. Ablation studies further validate the contribution of
each input modality, as well as the impact of denoising steps and the number of
trajectory samples. To support future research, we publicly release our code at
https://github.com/EI-Nav/TopoDiffuser.

</details>


### [203] [Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging](https://arxiv.org/abs/2508.00354)
*Tianshuang Qiu,Zehan Ma,Karim El-Refai,Hiya Shah,Chung Min Kim,Justin Kerr,Ken Goldberg*

Main category: cs.RO

TL;DR: Omni-Scan是一个使用双手机器人进行物体扫描的流程，能够通过抓取和旋转物体生成高质量的3D高斯溅射模型（3DGS），用于360度物体建模，并展示了在缺陷检测方面的应用（平均准确率83%）。


<details>
  <summary>Details</summary>
Motivation: 现有的3D物体扫描方法需要多相机阵列、激光扫描仪或固定于机器人腕部的相机，这些方法受限于工作空间，难以覆盖所有角度。Omni-Scan旨在通过双手机器人系统解决物体建模时的遮挡问题，实现全方位扫描。

Method: 1. 使用双手机器人：一只手抓取物体并旋转，另一只手在必要时重新抓取以暴露被遮挡的表面。
2. 利用DepthAny-thing、Segment Anything和RAFT光流模型隔离物体并移除夹具和背景。
3. 修改3DGS训练流程以处理带有夹具遮挡的串联数据集，生成全向（360度）物体模型。

Result: 系统应用于12个工业和家用物体的缺陷检测，平均识别视觉或几何缺陷的准确率达到83%。

Conclusion: Omni-Scan能够生成高质量的360度物体3D模型，有效地用于工业缺陷检测，提供了一种更灵活的物体扫描方案。项目主页提供交互式视频。

Abstract: 3D Gaussian Splats (3DGSs) are 3D object models derived from multi-view
images. Such "digital twins" are useful for simulations, virtual reality,
marketing, robot policy fine-tuning, and part inspection. 3D object scanning
usually requires multi-camera arrays, precise laser scanners, or robot
wrist-mounted cameras, which have restricted workspaces. We propose Omni-Scan,
a pipeline for producing high-quality 3D Gaussian Splat models using a
bi-manual robot that grasps an object with one gripper and rotates the object
with respect to a stationary camera. The object is then re-grasped by a second
gripper to expose surfaces that were occluded by the first gripper. We present
the Omni-Scan robot pipeline using DepthAny-thing, Segment Anything, as well as
RAFT optical flow models to identify and isolate objects held by a robot
gripper while removing the gripper and the background. We then modify the 3DGS
training pipeline to support concatenated datasets with gripper occlusion,
producing an omni-directional (360 degree view) model of the object. We apply
Omni-Scan to part defect inspection, finding that it can identify visual or
geometric defects in 12 different industrial and household objects with an
average accuracy of 83%. Interactive videos of Omni-Scan 3DGS models can be
found at https://berkeleyautomation.github.io/omni-scan/

</details>


### [204] [TOP: Time Optimization Policy for Stable and Accurate Standing Manipulation with Humanoid Robots](https://arxiv.org/abs/2508.00355)
*Zhenghan Chen,Haocheng Xu,Haodong Zhang,Liang Zhang,He Li,Dongqi Wang,Jiyu Yu,Yifei Yang,Zhongxiang Zhou,Rong Xiong*

Main category: cs.RO

TL;DR: 提出一种新颖的时间优化策略（TOP），用于训练人形机器人的站立操作控制模型，该模型同时确保平衡性、精确性和时间效率。通过调整上半身运动的时间轨迹并不仅仅依赖于增强下半身的抗干扰能力。方法包括利用运动先验训练VAE改善上下半身协调性、解耦上下半身控制（PD控制器用于上半身精度，强化学习控制器用于下半身稳定性）以及训练TOP以处理快速上半身运动导致的平衡问题。在仿真和真实实验中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 人形机器人能够执行多样化的操作任务，但需要稳健精确的站立控制器。现有方法要么不适合精确控制高维上半身关节，要么难以同时确保鲁棒性和准确性，尤其是在上半身运动较快时。为解决这些问题，本文旨在开发一种控制器，同时保证平衡、精度和时间效率。

Method: 方法分为三部分：1. 利用运动先验训练变分自编码器（VAE）以增强上下半身协调能力；2. 将全身控制解耦：上半身使用PD控制器确保精度，下半身使用强化学习（RL）控制器增强稳健稳定性；3. 训练时间优化策略（TOP）结合解耦控制器和VAE，减轻由快速上半身运动引起的平衡负担（避免机器人失稳和超过下半身RL策略能力）。

Result: 在仿真和真实世界实验中评估了所提方法的有效性，结果表明在站立操作任务上具有优越的稳定性和准确性。

Conclusion: 所提出的TOP方法成功实现了同时优化平衡性、精确性和时间效率的目标，为人形机器人的站立操作提供了更可靠的控制方案。

Abstract: Humanoid robots have the potential capability to perform a diverse range of
manipulation tasks, but this is based on a robust and precise standing
controller. Existing methods are either ill-suited to precisely control
high-dimensional upper-body joints, or difficult to ensure both robustness and
accuracy, especially when upper-body motions are fast. This paper proposes a
novel time optimization policy (TOP), to train a standing manipulation control
model that ensures balance, precision, and time efficiency simultaneously, with
the idea of adjusting the time trajectory of upper-body motions but not only
strengthening the disturbance resistance of the lower-body. Our approach
consists of three parts. Firstly, we utilize motion prior to represent
upper-body motions to enhance the coordination ability between the upper and
lower-body by training a variational autoencoder (VAE). Then we decouple the
whole-body control into an upper-body PD controller for precision and a
lower-body RL controller to enhance robust stability. Finally, we train TOP
method in conjunction with the decoupled controller and VAE to reduce the
balance burden resulting from fast upper-body motions that would destabilize
the robot and exceed the capabilities of the lower-body RL policy. The
effectiveness of the proposed approach is evaluated via both simulation and
real world experiments, which demonstrate the superiority on standing
manipulation tasks stably and accurately. The project page can be found at
https://anonymous.4open.science/w/top-258F/.

</details>


### [205] [A Whole-Body Motion Imitation Framework from Human Data for Full-Size Humanoid Robot](https://arxiv.org/abs/2508.00362)
*Zhenghan Chen,Haodong Zhang,Dongqi Wang,Jiyu Yu,Haocheng Xu,Yue Wang,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了一种仿人机器人全身运动模仿框架，通过运动重定向和非线性质心模型预测控制实现精准模仿和平衡维持


<details>
  <summary>Details</summary>
Motivation: 人形机器人模仿人类运动能扩展其多样化动作，但机体差异导致平衡与准确模仿的挑战

Method: 1. 基于接触感知的全身运动重定向生成初始轨迹；2. 非线性质心模型预测控制器实时保证平衡与运动精度；3. 全身控制器进行精确力矩控制

Result: 在仿真和实体机器人上成功模仿多种人类动作，验证了准确性、适应性以及抗干扰能力

Conclusion: 该框架有效解决人形机器人高精度运动模仿与动态平衡问题，提升动作拟人化程度

Abstract: Motion imitation is a pivotal and effective approach for humanoid robots to
achieve a more diverse range of complex and expressive movements, making their
performances more human-like. However, the significant differences in
kinematics and dynamics between humanoid robots and humans present a major
challenge in accurately imitating motion while maintaining balance. In this
paper, we propose a novel whole-body motion imitation framework for a full-size
humanoid robot. The proposed method employs contact-aware whole-body motion
retargeting to mimic human motion and provide initial values for reference
trajectories, and the non-linear centroidal model predictive controller ensures
the motion accuracy while maintaining balance and overcoming external
disturbances in real time. The assistance of the whole-body controller allows
for more precise torque control. Experiments have been conducted to imitate a
variety of human motions both in simulation and in a real-world humanoid robot.
These experiments demonstrate the capability of performing with accuracy and
adaptability, which validates the effectiveness of our approach.

</details>


### [206] [On Learning Closed-Loop Probabilistic Multi-Agent Simulator](https://arxiv.org/abs/2508.00384)
*Juanwu Lu,Rohit Gupta,Ahmadreza Moradipari,Kyungtae Han,Ruqi Zhang,Ziran Wang*

Main category: cs.RO

TL;DR: 提出了Neural Interactive Agents (NIVA)，一种基于分层贝叶斯模型的多智能体仿真概率框架，支持通过自回归采样实现闭环仿真。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶部署的快速迭代需要构建真实且可扩展的多智能体交通仿真器。现有仿真器虽逐步闭环化，但需要统一现有轨迹预测模型和新兴闭环仿真模型。

Method: NIVA框架由分层贝叶斯模型驱动，通过从潜在高斯分布混合中自回归采样实现观察条件化仿真。该框架在贝叶斯推理视角下统一了序列到轨迹预测模型与下一词预测（NTP）闭环模型。

Result: 在Waymo开放运动数据集上的实验表明，NIVA在性能上媲美现有方法，同时能精细控制意图和驾驶风格。

Conclusion: NIVA提供了一种概率框架，不仅性能优越，还可统一现有模型，并增强了对驾驶行为的可控性。

Abstract: The rapid iteration of autonomous vehicle (AV) deployments leads to
increasing needs for building realistic and scalable multi-agent traffic
simulators for efficient evaluation. Recent advances in this area focus on
closed-loop simulators that enable generating diverse and interactive
scenarios. This paper introduces Neural Interactive Agents (NIVA), a
probabilistic framework for multi-agent simulation driven by a hierarchical
Bayesian model that enables closed-loop, observation-conditioned simulation
through autoregressive sampling from a latent, finite mixture of Gaussian
distributions. We demonstrate how NIVA unifies preexisting sequence-to-sequence
trajectory prediction models and emerging closed-loop simulation models trained
on Next-token Prediction (NTP) from a Bayesian inference perspective.
Experiments on the Waymo Open Motion Dataset demonstrate that NIVA attains
competitive performance compared to the existing method while providing
embellishing control over intentions and driving styles.

</details>


### [207] [SubCDM: Collective Decision-Making with a Swarm Subset](https://arxiv.org/abs/2508.00467)
*Samratul Fuady,Danesh Tarapore,Mohammad D. Soorati*

Main category: cs.RO

TL;DR: 提出了SubCDM（基于子集的群体决策）方法，通过动态构建子集减少参与决策的机器人数量，实现资源高效的群体决策。


<details>
  <summary>Details</summary>
Motivation: 现有的群体决策策略需要所有机器人参与，消耗资源且无法同时执行其他任务，因此需要一种资源高效的替代方法。

Method: 动态构建子集：根据共识难度自适应的选择子集规模，仅使用局部信息进行构建。使用模拟平台，在一百个机器人的群体中测试。

Result: 模拟结果显示，SubCDM方法在决策准确率上达到与使用整个群体相当的结果，同时显著减少参与决策的机器人数量。

Conclusion: SubCDM在保证决策准确性的前提下减少了资源消耗，是一种可用于群体机器人系统的高效群体决策方法。

Abstract: Collective decision-making is a key function of autonomous robot swarms,
enabling them to reach a consensus on actions based on environmental features.
Existing strategies require the participation of all robots in the
decision-making process, which is resource-intensive and prevents the swarm
from allocating the robots to any other tasks. We propose Subset-Based
Collective Decision-Making (SubCDM), which enables decisions using only a swarm
subset. The construction of the subset is dynamic and decentralized, relying
solely on local information. Our method allows the swarm to adaptively
determine the size of the subset for accurate decision-making, depending on the
difficulty of reaching a consensus. Simulation results using one hundred robots
show that our approach achieves accuracy comparable to using the entire swarm
while reducing the number of robots required to perform collective
decision-making, making it a resource-efficient solution for collective
decision-making in swarm robotics.

</details>


### [208] [HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning](https://arxiv.org/abs/2508.00491)
*Carlo Alessi,Federico Vasile,Federico Ceola,Giulia Pasquale,Nicolò Boccardo,Lorenzo Natale*

Main category: cs.RO

TL;DR: 提出了一种基于模仿学习的假手控制方法HannesImitationPolicy，用于在非结构化环境中抓取物体，并公开了HannesImitationDataset数据集，实验证明该方法优于基于分割的视觉伺服控制器。


<details>
  <summary>Details</summary>
Motivation: 近期假手控制的研究通过摄像头和其他传感器输入增强自主性以降低用户认知负荷。机器人领域的模仿学习在简化数据收集的同时能学习抓取和复杂操作任务，但其在假手控制中的应用尚未充分探索。填补这一空白可增强假手操作的灵活性，使其在非约束场景中通过演示学习任务。

Method: 1. 提出HannesImitationPolicy：基于扩散策略的模仿学习方法，用于控制Hannes假手。2. 构建HannesImitationDataset数据集：包含在桌面、货架和人假手交接场景中的抓取演示。3. 训练单一扩散策略模型：使用数据集训练模型以预测抓取时的手腕朝向和手部闭合动作。

Result: 1. 在多样物体和条件下成功实现抓取。2. 实验证明该方法在非结构化场景中优于基于分割的视觉伺服控制器。

Conclusion: 模仿学习可有效应用于假手控制，HannesImitationPolicy方法能提升假手在非结构化环境中的抓取能力，为恢复灵活性提供新途径。

Abstract: Recent advancements in control of prosthetic hands have focused on increasing
autonomy through the use of cameras and other sensory inputs. These systems aim
to reduce the cognitive load on the user by automatically controlling certain
degrees of freedom. In robotics, imitation learning has emerged as a promising
approach for learning grasping and complex manipulation tasks while simplifying
data collection. Its application to the control of prosthetic hands remains,
however, largely unexplored. Bridging this gap could enhance dexterity
restoration and enable prosthetic devices to operate in more unconstrained
scenarios, where tasks are learned from demonstrations rather than relying on
manually annotated sequences. To this end, we present HannesImitationPolicy, an
imitation learning-based method to control the Hannes prosthetic hand, enabling
object grasping in unstructured environments. Moreover, we introduce the
HannesImitationDataset comprising grasping demonstrations in table, shelf, and
human-to-prosthesis handover scenarios. We leverage such data to train a single
diffusion policy and deploy it on the prosthetic hand to predict the wrist
orientation and hand closure for grasping. Experimental evaluation demonstrates
successful grasps across diverse objects and conditions. Finally, we show that
the policy outperforms a segmentation-based visual servo controller in
unstructured scenarios. Additional material is provided on our project page:
https://hsp-iit.github.io/HannesImitation

</details>


### [209] [OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery](https://arxiv.org/abs/2508.00580)
*Raul Castilla-Arquillo,Carlos Perez-del-Pulgar,Levin Gerdes,Alfonso Garcia-Cerezo,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: 提出了一种基于Transformer的神经网络OmniUnet，用于RGB-D-T多模态图像的语义分割，以支持在非结构化环境中（如火星）的机器人安全导航。开发了定制传感器外壳并在类似火星地形的半沙漠环境中收集数据集。模型在资源受限设备上表现良好，代码和数据集已开源。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境（如火星）的机器人导航需要多模态感知系统。多模态能够整合不同传感器的互补信息，但需要特定的机器学习算法。热成像在火星探测中已被证明对评估地形安全有价值。因此，需要一种能够有效融合RGB、深度和热成像（RGB-D-T）的方法，并验证其在地形分割中的效果。

Method: 1. 开发了定制化的多模态传感器外壳（使用3D打印），集成RGB、深度和热成像传感器，安装在火星探测器测试平台（MaRTA）上。
2. 在西班牙北部的半沙漠环境（模拟火星地表）收集RGB-D-T数据集，包含沙地、基岩和硬土等典型地形。
3. 手动标注部分数据集用于监督训练。
4. 设计OmniUnet（基于Transformer的神经网络）进行语义分割，输入为RGB-D-T四种模态。
5. 在资源受限设备（Jetson Orin Nano）上进行推理测试。

Result: 1. 定量评估：达到80.37%的像素准确率，在复杂非结构地形分割中表现强劲。
2. 推理速度：平均预测时间673毫秒，适合在机器人嵌入式设备部署。
3. 开源：发布了网络实现代码和标注数据集。

Conclusion: OmniUnet能够有效融合RGB-D-T多模态信息，准确分割火星模拟环境的地形，且计算效率满足机载部署。公开的数据集和代码将促进行星机器人多模态感知研究的发展。

Abstract: Robot navigation in unstructured environments requires multimodal perception
systems that can support safe navigation. Multimodality enables the integration
of complementary information collected by different sensors. However, this
information must be processed by machine learning algorithms specifically
designed to leverage heterogeneous data. Furthermore, it is necessary to
identify which sensor modalities are most informative for navigation in the
target environment. In Martian exploration, thermal imagery has proven valuable
for assessing terrain safety due to differences in thermal behaviour between
soil types. This work presents OmniUnet, a transformer-based neural network
architecture for semantic segmentation using RGB, depth, and thermal (RGB-D-T)
imagery. A custom multimodal sensor housing was developed using 3D printing and
mounted on the Martian Rover Testbed for Autonomy (MaRTA) to collect a
multimodal dataset in the Bardenas semi-desert in northern Spain. This location
serves as a representative environment of the Martian surface, featuring
terrain types such as sand, bedrock, and compact soil. A subset of this dataset
was manually labeled to support supervised training of the network. The model
was evaluated both quantitatively and qualitatively, achieving a pixel accuracy
of 80.37% and demonstrating strong performance in segmenting complex
unstructured terrain. Inference tests yielded an average prediction time of 673
ms on a resource-constrained computer (Jetson Orin Nano), confirming its
suitability for on-robot deployment. The software implementation of the network
and the labeled dataset have been made publicly available to support future
research in multimodal terrain perception for planetary robotics.

</details>


### [210] [A control scheme for collaborative object transportation between a human and a quadruped robot using the MIGHTY suction cup](https://arxiv.org/abs/2508.00584)
*Konstantinos Plotas,Emmanouil Papadakis,Drosakis Drosakis,Panos Trahanias,Dimitrios Papageorgiou*

Main category: cs.RO

TL;DR: 提出了一种基于导纳控制和可变阻尼的人-机器人协作搬运控制方案，包含屏障人工势能防止脱落，通过实验验证了其被动性和性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决人-机器人协作搬运任务中提高人类控制性和减少人类体力消耗的问题，同时确保机器人的吸盘抓握在搬运过程中不发生脱落。

Method: 方案采用导纳控制，引入可变阻尼项以平衡人类控制性和减少体力消耗；同时使用基于屏障人工势能的额外控制信号，保证吸盘抓握的稳定性，防止物体脱落。

Result: 提出的控制方案被证明具有被动特性，通过在Unitree Go1机器人（配备MIGHTY吸盘）上的实验验证了其有效性和性能。

Conclusion: 该控制方案成功实现了人-机器人协作搬运中的控制性与降低人类消耗的平衡，确保了搬运过程的安全性，具有实际应用潜力。

Abstract: In this work, a control scheme for human-robot collaborative object
transportation is proposed, considering a quadruped robot equipped with the
MIGHTY suction cup that serves both as a gripper for holding the object and a
force/torque sensor. The proposed control scheme is based on the notion of
admittance control, and incorporates a variable damping term aiming towards
increasing the controllability of the human and, at the same time, decreasing
her/his effort. Furthermore, to ensure that the object is not detached from the
suction cup during the collaboration, an additional control signal is proposed,
which is based on a barrier artificial potential. The proposed control scheme
is proven to be passive and its performance is demonstrated through
experimental evaluations conducted using the Unitree Go1 robot equipped with
the MIGHTY suction cup.

</details>


### [211] [OpenScout v1.1 mobile robot: a case study on open hardware continuation](https://arxiv.org/abs/2508.00625)
*Bartosz Krawczyk,Ahmed Elbary,Robbie Cato,Jagdish Patil,Kaung Myat,Anyeh Ndi-Tah,Nivetha Sakthivel,Mark Crampton,Gautham Das,Charles Fox*

Main category: cs.RO

TL;DR: OpenScout v1.1是一款开源的移动机器人，用于研究和工业领域。本案例研究介绍了其升级版本v1.1的特性，包括简化、更便宜且更强大的机载计算硬件，模拟ROS2接口和Gazebo仿真。同时，还报告了变更原因、项目方法和成果。


<details>
  <summary>Details</summary>
Motivation: 改进OpenScout的设计，使其机载计算硬件更加简化、成本更低且性能更强，同时提供模拟ROS2接口和Gazebo仿真，以提升该开源硬件在研究和工业领域的适用性和可扩展性。

Method: 项目采用开源硬件案例研究的方法，首先识别原始设计中的改进点，然后进行硬件简化以降低成本并提高性能。同时，开发了ROS2接口和Gazebo仿真功能，以方便开发和测试。所有变更、改进的原因以及详细的项目方法和实现过程都被记录下来并报告。

Result: 成功推出OpenScout v1.1版本，该版本在保持原有功能和性能的同时，实现了硬件简化和成本的降低。新的机载计算硬件提高了整体性能，同时提供的模拟ROS2接口和Gazebo仿真为开发和研究提供了便利。通过案例研究详细记录了改进过程和成果。

Conclusion: OpenScout v1.1通过硬件改进和新增模拟支持，提升了其作为开源研究平台的价值。该项目展示了开源硬件在快速迭代和共享改进方面的优势，为后续研究者和开发者提供了一个高效、低成本的开发和测试平台。

Abstract: OpenScout is an Open Source Hardware (OSH) mobile robot for research and
industry. It is extended to v1.1 which includes simplified, cheaper and more
powerful onboard compute hardware; a simulated ROS2 interface; and a Gazebo
simulation. Changes, their rationale, project methodology, and results are
reported as an OSH case study.

</details>


### [212] [Towards Data-Driven Adaptive Exoskeleton Assistance for Post-stroke Gait](https://arxiv.org/abs/2508.00691)
*Fabian C. Weigend,Dabin K. Choe,Santiago Canete,Conor J. Walsh*

Main category: cs.RO

TL;DR: 该论文提出了一种基于时间卷积网络（TCN）的数据驱动方法，用于中风后行走时的踝关节力矩估计，以实现自适应足底屈曲和背屈辅助。


<details>
  <summary>Details</summary>
Motivation: 当前的数据驱动外骨骼控制方法在健康年轻人中已证明能动态适应不同任务，但在中风后偏瘫等神经运动障碍人群中的应用面临挑战。这些挑战包括人群异质性大、步态变异性高以及缺乏训练准确模型的中风后步态数据集。因此，本研究旨在探索如何利用数据驱动方法，使外骨骼在无结构社区环境中安全有效地运行。

Method: 研究收集了4名中风后参与者在跑步机上行走的数据，使用3个惯性测量单元（IMU）采集信号。模型采用多任务时间卷积网络（TCN），并利用6名健康参与者的步行数据进行预训练。最终实现了一个可穿戴原型系统，用于实时传感、力矩估计和执行。

Result: 所提出的TCN模型在测试中获得了0.74 ± 0.13的决定系数（R²）。此外，研究还通过1名中风后参与者成功演示了实时传感、估计和执行过程的可行性。

Conclusion: 该工作为中风后行走的适应性辅助外骨骼控制提供了初步实现。通过多任务学习架构和健康数据预训练策略，成功缓解了小样本神经运动障碍数据训练的挑战，并验证了实时系统的可行性，为未来社区环境应用奠定了基础。

Abstract: Recent work has shown that exoskeletons controlled through data-driven
methods can dynamically adapt assistance to various tasks for healthy young
adults. However, applying these methods to populations with neuromotor gait
deficits, such as post-stroke hemiparesis, is challenging. This is due not only
to high population heterogeneity and gait variability but also to a lack of
post-stroke gait datasets to train accurate models. Despite these challenges,
data-driven methods offer a promising avenue for control, potentially allowing
exoskeletons to function safely and effectively in unstructured community
settings. This work presents a first step towards enabling adaptive
plantarflexion and dorsiflexion assistance from data-driven torque estimation
during post-stroke walking. We trained a multi-task Temporal Convolutional
Network (TCN) using collected data from four post-stroke participants walking
on a treadmill ($R^2$ of $0.74 \pm 0.13$). The model uses data from three
inertial measurement units (IMU) and was pretrained on healthy walking data
from 6 participants. We implemented a wearable prototype for our ankle torque
estimation approach for exoskeleton control and demonstrated the viability of
real-time sensing, estimation, and actuation with one post-stroke participant.

</details>


### [213] [On-Device Diffusion Transformer Policy for Efficient Robot Manipulation](https://arxiv.org/abs/2508.00697)
*Yiming Wu,Huan Wang,Zhenghao Chen,Jianxin Pang,Dong Xu*

Main category: cs.RO

TL;DR: 轻DP（LightDP）是一个针对移动设备设计的轻量级扩散策略框架，通过网络剪枝和减少采样步骤优化实时性能。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人模仿学习中表现优秀，但计算效率低和内存占用大阻碍了其在资源有限移动平台的应用。因此，需要一种高效的方法使扩散策略能够在移动设备实时部署。

Method: 首先分析计算瓶颈，确定降噪网络是延迟主因。提出统一剪枝和再训练流程，优化后剪枝恢复能力。同时结合一致性蒸馏技术减少采样步骤，平衡准确性和效率。

Result: 实验在PushT、Robomimic、CALVIN和LIBERO数据集进行。LightDP实现了移动设备上的实时动作预测，并保持高性能。真实世界测试表明其性能可与先进扩散策略媲美。

Conclusion: LightDP成功解决了扩散策略在移动设备部署时的计算瓶颈问题，兼顾实时性和准确性，为资源受限环境中实用化部署奠定了基础。

Abstract: Diffusion Policies have significantly advanced robotic manipulation tasks via
imitation learning, but their application on resource-constrained mobile
platforms remains challenging due to computational inefficiency and extensive
memory footprint. In this paper, we propose LightDP, a novel framework
specifically designed to accelerate Diffusion Policies for real-time deployment
on mobile devices. LightDP addresses the computational bottleneck through two
core strategies: network compression of the denoising modules and reduction of
the required sampling steps. We first conduct an extensive computational
analysis on existing Diffusion Policy architectures, identifying the denoising
network as the primary contributor to latency. To overcome performance
degradation typically associated with conventional pruning methods, we
introduce a unified pruning and retraining pipeline, optimizing the model's
post-pruning recoverability explicitly. Furthermore, we combine pruning
techniques with consistency distillation to effectively reduce sampling steps
while maintaining action prediction accuracy. Experimental evaluations on the
standard datasets, \ie, PushT, Robomimic, CALVIN, and LIBERO, demonstrate that
LightDP achieves real-time action prediction on mobile devices with competitive
performance, marking an important step toward practical deployment of
diffusion-based policies in resource-limited environments. Extensive real-world
experiments also show the proposed LightDP can achieve performance comparable
to state-of-the-art Diffusion Policies.

</details>


### [214] [Video Generators are Robot Policies](https://arxiv.org/abs/2508.00795)
*Junbang Liang,Pavel Tokmakov,Ruoshi Liu,Sruthi Sudhakar,Paarth Shah,Rares Ambrus,Carl Vondrick*

Main category: cs.RO

TL;DR: 提出了Video Policy框架，利用视频生成作为机器人策略学习的代理，以解决鲁棒性和样本效率问题。该方法通过生成机器人行为视频来提取策略，显著减少了对演示数据的依赖，并在新物体、背景和任务上表现出优异的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉运动策略在泛化性和数据效率上存在局限：难以应对感知或行为分布的变化，且性能受限于人类演示数据的规模。

Method: 提出模块化框架Video Policy，结合视频生成和动作生成，可端到端训练。通过生成机器人行为视频，从中提取策略，减少演示数据需求。利用大规模视频生成模型提升性能。

Result: 方法在仿真和真实世界中均展现出对新物体、背景和任务的强大泛化能力。任务成功与生成的视频质量紧密相关，且无需动作标签的视频数据对泛化至新任务至关重要。性能显著超越传统行为克隆方法。

Conclusion: 通过视频生成代理策略学习，实现了更高可扩展性和数据效率的机器人策略学习，为克服当前策略的泛化和数据限制提供了新途径。

Abstract: Despite tremendous progress in dexterous manipulation, current visuomotor
policies remain fundamentally limited by two challenges: they struggle to
generalize under perceptual or behavioral distribution shifts, and their
performance is constrained by the size of human demonstration data. In this
paper, we use video generation as a proxy for robot policy learning to address
both limitations simultaneously. We propose Video Policy, a modular framework
that combines video and action generation that can be trained end-to-end. Our
results demonstrate that learning to generate videos of robot behavior allows
for the extraction of policies with minimal demonstration data, significantly
improving robustness and sample efficiency. Our method shows strong
generalization to unseen objects, backgrounds, and tasks, both in simulation
and the real world. We further highlight that task success is closely tied to
the generated video, with action-free video data providing critical benefits
for generalizing to novel tasks. By leveraging large-scale video generative
models, we achieve superior performance compared to traditional behavior
cloning, paving the way for more scalable and data-efficient robot policy
learning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [215] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: 本文分析了HealthBench基准测试在评估医疗语言模型时存在的局限性，特别是其依赖专家意见而非高级临床证据，可能导致地域偏见和个体临床医生特性被固化的问题，尤其在低收入和中等收入地区。作者提出通过将奖励函数锚定在版本控制的临床实践指南（CPGs）上来解决这些问题，并结合系统评价和GRADE证据评级，以构建更具全球相关性和公平性的基准。


<details>
  <summary>Details</summary>
Motivation: 现有HealthBench基准在评估医疗语言模型时过分依赖专家意见，没有充分考虑高级临床证据，这可能导致地域性偏见和个体临床医生的特性被系统内化。此外，在资源有限的地区，如非洲，基准的适用性进一步受到数据稀缺、基础设施不足和监管框架不完善的限制。因此，需要开发更公平、更具全球适用性的医疗AI评估标准。

Method: 作者提出了一个名为'证据稳健（evidence-robust）'的强化学习框架，通过以下步骤构建：1）将评估规则（rubric）与临床实践指南（CPGs）关联起来，这些指南整合了系统评价和GRADE证据评级；2）采用证据加权的评分机制，根据证据强弱调整分值；3）设计上下文覆盖逻辑以处理特殊情况；4）关注伦理考量并整合延迟结果反馈，使模型在实时应用后能根据实际临床结果进行调整。

Result: 本文没有报告具体实验结果，而是提出了一个理论框架。通过将奖励函数锚定在严格审查的临床实践指南（CPGs）上，同时保留HealthBench的透明度和临床医生参与特性，作者预期该方法能够培养出不仅语言表达精炼，而且在临床上可信、伦理合理且具有全球适用性的医疗语言模型。

Conclusion: 研究团队呼吁开发更具全球公平性的医疗AI评估基准。他们通过将奖励机制根植于严格审查的临床实践指南，结合强化学习框架，解决了HealthBench基准存在的局限性。该方法旨在促进开发出在语言表达、临床可信度、伦理合规性和全球适用性等多方面表现优良的医疗语言模型，特别关注了低资源地区的需求。

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [216] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 本文提出了一个用于解决时间窗口时序逻辑（HyperTWTL）约束下的安全强化学习（SecRL）问题的方法，通过动态Boltzmann softmax强化学习算法学习满足HyperTWTL安全性约束的最优策略，并在机器人拾取与配送任务中验证了方法的有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前的时序逻辑约束安全强化学习（SRL）研究主要集中在安全性，而较少关注超属性（hyperproperties）表达的安全性约束，如安全性和可透明性（opacity）。鉴于HyperTWTL在表达安全属性方面的优势，本文旨在解决HyperTWTL约束下的安全强化学习问题，填补该领域的研究空白。

Method: 将智能体的动态建模为马尔可夫决策过程（MDP），并将安全性约束形式化为HyperTWTL公式。在此基础上，利用动态Boltzmann softmax强化学习算法学习既满足HyperTWTL约束又具有最优性的策略。通过与两种基线强化学习算法的对比来评估所提方法的性能。

Result: 该方法在机器人拾取与配送任务案例中表现出高效性和良好的扩展性。实验表明，与其他两种基线强化学习算法相比，所提出的方法在满足HyperTWTL安全性约束的同时，表现出更优的性能。

Conclusion: 本文提出的方法成功解决了HyperTWTL约束下的安全强化学习问题，提供了一种新的解决思路。该方法不仅有效，而且可扩展，为未来在复杂系统中应用超属性约束的安全强化学习提供了基础。

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [217] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: 该论文探讨了在端到端操作流程中成功应用人工智能（AI）的挑战，并提出了基于对象中心流程挖掘（OCPM）的过程智能（PI）作为解决方案，以支持生成式、预测式和规范式AI在改进运营流程中的应用。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在改变工作、交互、商业和研究方式方面有显著影响，但组织在工业环境中成功应用AI（特别是涉及端到端操作流程时）仍面临困难。流程相关数据的结构化、组织特定特性以及流程的高度动态性使得传统AI方法难以直接应用。

Method: 论文提出将对象中心流程挖掘（OCPM）作为连接数据和流程的桥梁，构建过程智能（PI）的概念。PI融合了以流程为中心的数据驱动技术，能够处理多种对象和事件类型。作者详细阐述了如何利用OCPM支持生成式、预测式和规范式AI，以实现对运营流程的诊断和改进。

Result: 研究表明，过程智能（PI）是AI在组织上下文中成功应用的必要条件，能够解决运营流程的数据和动态性挑战。OCPM与生成式、预测式和规范式AI的结合为流程改进提供了新的机会。

Conclusion: 论文得出结论，过程智能（由OCPM驱动）是实现AI在运营流程中有效应用的关键基础。作者强调，AI技术（尤其是生成式、预测式和规范式AI）需要与PI框架整合，以提升组织运营效率并实现流程优化。

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [218] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 介绍三种检测多准则决策中排位反转的测试方法及其在Scikit-Criteria库中的实现，包括处理一般场景的设计考虑


<details>
  <summary>Details</summary>
Motivation: 多准则决策分析中的排位反转问题严重影响决策结果，需要一种机制评估不同方法在特定备选方案集上的性能，并进一步构建全局方法有效性排名

Method: 设计三种检测排位反转的测试方法；在Scikit-Criteria库中实现这些测试；解决通用场景实现中的技术难题；制定相应的设计决策

Result: 成功实现三种检测机制并集成到开源库中；解决通用实现中的边界情况处理问题

Conclusion: 这些测试机制为评估多准则决策方法效果提供重要工具，将促进方法选择过程科学化，并支撑多准则决策领域的客观比较研究

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [219] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: 本文提出了一种基于SHACL的RDF图更新语言，研究了静态验证问题，即验证一个SHACL规范在应用更新序列后是否依然有效。通过将更新操作嵌入到SHACL约束中，将静态验证问题转化为SHACL约束的可满足性问题，并分析了其计算复杂度。最后，实现了一个原型系统并进行了初步实验。


<details>
  <summary>Details</summary>
Motivation: 随着RDF图的更新，需要确保图在更新后仍然满足原有的SHACL约束。因此，研究更新的静态验证问题对于管理演化的RDF图至关重要。

Method: 1. 提出一种可表达直观和现实修改的SHACL更新语言。2. 将静态验证问题定义为：验证满足SHACL规范的图在应用给定更新序列后是否仍然满足该规范。3. 通过回归技术将更新操作嵌入SHACL约束，将静态验证问题转化为（扩展）SHACL约束的（不）可满足性问题。4. 分析SHACL及其关键片段的静态验证问题的计算复杂度。5. 实现原型系统，支持静态验证和其他静态分析任务。

Result: 展示了静态验证问题可以转化为SHACL约束的可满足性问题，并分析了不同SHACL片段的计算复杂度。原型系统通过初步实验验证了方法的可行性。

Conclusion: 本文通过嵌入更新操作的方法，成功将静态验证问题转化为SHACL约束的可满足性问题，为演化的RDF图提供了验证基础。原型实现证明了方法的实用性，为后续服务提供了支持。

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [220] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: 尽管已有努力减轻人工智能算法的固有风险与偏见，这些算法仍对文化边缘化群体产生不成比例的影响。本文主张通过重新设计AI生产流程，以共同生产、多样性、公平性、包容性（DEI）和多学科协作为核心。我们引入了一个由五个互连阶段组成的增强型AI生命周期，并通过多学科工作坊提炼出分布式权威和迭代知识交流的主题。


<details>
  <summary>Details</summary>
Motivation: 尽管提出了多种应对措施（如伦理指南和算法公平性技术），AI算法仍对文化边缘群体造成不成比例的影响。因此需要从根本上重构AI生产流程，以弥合这些危害。

Method: 提出重新设计AI生产管道的过程，包括五个阶段：共同构架、共同设计、共同执行、共同部署和共同维护。此生命周期基于分布式权威和迭代知识交换的主题，得到了四个多学科研讨会的支持。

Result: 我们引入了参与度AI生命周期的五个阶段模型，将其与多种主要伦理框架相关联，并为扩展参与式治理指明了未来的关键研究问题。

Conclusion: 缓解AI系统对文化边缘化群体的不良影响，需要通过增强型生命周期重构开发过程，实现以共生产、DEI和多学科协作为核心的AI生产管道。

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [221] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 该立场论文批评了过度依赖人类交互评判者可靠性(IRR)作为标注质量标准的做法，认为这阻碍了教育AI领域的进展。论文主张采用多种互补的评估方法，关注效度和教育影响，而非仅依赖共识。


<details>
  <summary>Details</summary>
Motivation: 当前教育AI应用中，人类作为评判者常存在偏见和不可靠性，但传统的IRR指标(如Cohen's kappa)仍被广泛用作标注数据的验证标准。这种过度依赖阻碍了有效预测学习改进的数据分类方法的发展。

Method: 提出五种互补的评估方法：1) 多标签标注方案；2) 基于专家的方法；3) 闭环效度验证；4) 强调外部效度(如验证辅导行为跨类别通用性)；5) 建立优先考虑教育影响的标注验证程序。

Result: 论证表明，相比单纯依赖IRR，这些方法能产生更有效的训练数据，构建更能改善学习效果、提供更可行洞察的模型。

Conclusion: 呼吁教育AI领域重新思考标注质量和事实标准——应优先考虑效度和教育影响，而非仅仅追求评判者间共识。

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [222] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: 该论文提出了一种促进AI安全与人类福祉的方法，核心是让AI系统明确增强人类能力并管理人类与AI之间的权力平衡。通过部分公理化方法，设计了一个可参数化、可分解的目标函数，表示一种考虑不平等和风险厌恶的长期人类能力聚集体，该函数考虑了人类有限理性、社会规范及多种人类目标。给出了通过反向归纳法或多智能体强化学习来计算该指标的算法，并在多种典型场景中示范了其最大化带来的结果。结论是：适当的人类能力聚合指标作为目标比基于效用的目标更安全。


<details>
  <summary>Details</summary>
Motivation: 在AI安全领域，权力（power）是关键概念，包括其作为工具性目标的寻求、人类权力的突然或逐渐削弱、人机交互中的权力平衡以及国际AI治理。同时，权力作为实现多样目标的能力也是人类福祉的核心。为应对AI系统可能导致的人类权力被削弱的风险，本文提出直接要求AI增强人类并以可控方式管理人机权力平衡的理念，以兼顾安全与福祉。

Method: 1. 通过部分公理化方法构建一个目标函数：该函数是参数化、可分解的长期聚合指标，具有不平等厌恶和风险厌恶特征；2. 函数设计的考虑要素包括：人类有限理性（bounded rationality）、社会规范（social norms）、以及覆盖广泛可能的人类目标；3. 开发算法：利用反向归纳法（backward induction）或多智能体强化学习（从给定世界模型学习）近似计算该指标；4. 在多种典型情境中测试最大化该目标函数对AI辅助行为的影响，并分析其蕴含的工具性子目标（如避免操纵、支持人类等）。

Result: 在多个测试场景中，使用聚合人类能力指标的目标函数促使AI采取尊重人类自主性的行动：避免破坏人类能动性、支持人类掌控权、防止危险冲突（如欺骗、胁迫）、鼓励促进合作与共赢的行动（如提升人类技能、辅助决策）。结果表明，这类目标较传统基于效用的目标在降低权力失衡风险方面更具优势。

Conclusion: 本文提出的聚合人类权力指标作为一种AI优化目标，相较于直接使用基于人类效用函数的目标更安全有效。在满足谨慎的参数选择与适当算法设计的前提下，这种方法可能避免因人类目标误指定（misinterpreted goals）或模型失窃（training objectives）导致的AI不良风险（如权力争夺），从而推动人机协作的健康发展并保障人类的长期福祉。

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [223] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: 本文提出了RL-PLUS，一种结合内部探索与外部数据的方法，用以解决强化学习与可验证奖励（RLVR）在大型语言模型（LLMs）推理中遇到的基模型能力边界突破问题和能力边界崩溃问题。该方法通过多重重要性采样和基于探索的优势函数提升性能，在多个数学推理基准和分布外任务上取得最先进的结果。


<details>
  <summary>Details</summary>
Motivation: RLVR方法虽能提升LLMs的复杂推理能力，但受限于基模型的能力边界（因其固有的同策略特性、巨大的动作空间与稀疏奖励），且可能导致能力边界崩溃（缩小模型解决问题范围）。

Method: 提出RL-PLUS方法，核心包括：1) 多重重要性采样（处理外部数据分布不匹配）；2) 基于探索的优势函数（引导模型探索高价值、未涉及的推理路径）。方法融合内部开发（思考）与外部数据（学习）。

Result: 1) 在6个数学推理基准上优于现有RLVR方法；2) 在6个分布外推理任务上表现更优；3) 跨不同模型家族实现一致显著提升（相对提升21.1%至69.2%）；4) 在多基准Pass@k曲线显示有效解决能力边界崩溃问题。

Conclusion: RL-PLUS通过结合内部思考和外部学习，突破了基模型能力的固有边界，缓解了能力边界崩溃，显著提升LLMs推理性能，具备较强普适性与泛化能力。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [224] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: 提出了一个名为MetaAgent的智能框架，通过最小起始配置、工具路由、自学习和内建工具库，实现自我迭代以适应任务需求的自主智能系统，并在多项知识发现基准测试上表现优异。


<details>
  <summary>Details</summary>
Motivation: 动机源自传统的端到端训练智能系统在工具使用和知识获取方面需要持续重训练，无法适应新的知识场景。MetaAgent致力于通过无参数更新的方式实现持续自我进化，解决动态开放环境下工具学习及知识的持续适应问题。

Method: 方法包括：(1) 初始化使用基础推理能力与自适应求助机制的轻量化工作流；(2) 知识缺失时使用自然语言请求工具并路由到适当外部工具；(3) 任务解决中持续自我反思、回答验证、提炼经验；(4) 组织使用历史持续自建工具库和持续更新知识库；(5) 通过任务上下文将知识复用为提示词，不依赖模型参数更新或下游训练。

Result: 在GAIA, WebWalkerQA, BrowseCamp等知识获取数据集上明显优于流程基线系统并能匹配端到端训练的智能体。

Conclusion: MetaAgent验证了基于自我进化的智能体可以通过数据驱动的方法逐步提升工具的推理使用能力，不依赖模型参数重训练即可实现通用知识发现系统的鲁棒性表现。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [225] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 本研究比较了人类和大型语言模型（LLM）代理（GPT-4o）在任务生成中的差异。研究发现，人类的任务生成受到心理驱动因素（如个人价值观和认知风格）的显著影响，而LLM即使被告知这些驱动因素，也无法产生类似的行为模式。LLM生成的任务更少社交性、更少身体活动、更偏向抽象主题。尽管LLM的任务被认为更有趣和新颖，但这突显了其语言能力与生成人类化、具身化目标的能力之间存在脱节。结论指出，人类基于价值驱动的具身认知与LLM的统计模式之间存在核心差距，因此有必要在设计更符合人类特征的代理时纳入内在动机和物理基础。


<details>
  <summary>Details</summary>
Motivation: 人类的多样性任务生成受到内在动机（如个人价值观和认知风格）的引导。虽然基于大型语言模型的生成式代理旨在模拟这种行为，但尚不清楚其是否遵循类似的认知原则。因此，研究者试图通过实验比较人类和LLM代理在任务生成上的表现，以探究LLM是否能模拟人类的心理驱动特性。

Method: 本研究设计了一项任务生成实验，直接比较人类参与者与LLM代理（GPT-4o）的表现。实验中，人类参与者根据内部动机生成任务，同时LLM也被要求完成相同的任务生成流程。关键部分在于，研究者向LLM提供了人类被试的心理驱动因素（如个人价值观和认知风格），以测试其能否复现相应的行为模式。随后，研究者对生成的任务进行了多维度分析（包括社交性、身体活动、主题偏向），并通过感知调查评估了任务的有趣性和新颖性。

Result: 实验发现：1）人类任务生成显著受心理驱动因素（如个人价值观）影响，而LLM即使被明确告知这些因素也无法复现相同模式；2）LLM生成的任务与人类任务相比：在性质上更少涉及社交（social）和身体活动（physical），主题更偏向抽象化（如思维活动）；3）在主观感知方面，LLM生成的任务被评估为更有趣和更具新颖性，但这与其在社交性和具身化上的缺陷共同表明：其语言能力与生成真实人类目标的能力是脱节的。

Conclusion: 该研究揭示了人类基于价值驱动的具身认知与LLM基于统计模式的运作之间存在根本性差距，这导致LLM无法完全模拟人类在任务生成中的内在动机和身体互动倾向。作者强调，未来设计更具人类对齐特征的代理时，必须将内在心理驱动机制（如价值观、动机）和物理具身化因素纳入建模核心。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [226] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: 提出了ReasonBench，首个专注于结构化图形推理任务的评估基准，包括来自真实世界智力测试的1613个问题，用于评估视觉语言模型在复杂图形推理中的表现。此外，还提出了双重优化策略（DiaCoT和ReasonTune）以提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在模拟人类图形推理能力方面存在明显不足，特别是在复杂图形推理和抽象问题解决上，相关研究较少且集中于简单图形。因此，需要一个专门的评估基准来测试VLMs在复杂图形推理中的表现。

Method: 创建ReasonBench评估基准，涵盖1,613个来自真实智力测试的问题，涉及位置、属性、数量和多元素等多个推理维度。测试了11个主流VLMs。并提出双重优化策略：图式推理链（DiaCoT）通过层次分解增强推理的可解释性；ReasonTune通过训练增强模型推理的任务适应性。

Result: 基准测试揭示了当前模型的显著局限。在提出的优化策略下，DiaCoT和ReasonTune分别从不同角度优化模型，最终提升VLM在ReasonBench上的性能达33.5%。

Conclusion: ReasonBench首次针对复杂结构化图形推理任务提供全面评估，证明当前VLMs存在局限性，而提出的双重优化策略能有效提升模型性能。未来应继续改进VLMs在复杂推理任务中的表现。

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [227] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: 提出R1-Act方法，通过结构化推理显式触发大模型已有的安全知识，在仅需少量训练资源的情况下显著提升模型安全性，同时保持推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究表明大语言模型具备安全知识却无法在推理中正确激活，导致面对有害指令时失效。

Method: 1. 仅需1000个安全样本训练；2. 采用两阶段结构：(a) 识别指令安全风险 (b) 基于风险类型触发相应安全知识；3. 使用单张RTX A6000显卡训练90分钟。

Result: 1. 多尺寸模型安全性能显著提升；2. 推理能力保持（GSM8K/MATH指标无损失）；3. 训练效率优于现有对齐方法；4. 在AdvBench攻击下平均攻击成功率降低至<5%

Conclusion: 揭示了大模型安全失效的核心是知识激活而非知识缺失；R1-Act为安全对齐提供了高效可扩展的解决方案。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [228] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: 提出CoRGI框架来解决CoT提示在视觉语言模型中的幻觉问题，通过引入视觉验证步骤来确保中间推理步骤基于视觉证据，从而提高推理的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 观察到Chain-of-Thought（CoT）在视觉语言模型（VLMs）中产生的解释虽然语言流畅，但往往缺乏对视觉内容的真实依据（即幻觉问题），部分原因在于多步推理过程中缺乏明确的验证机制。

Method: CoRGI框架采用三阶段流程：首先生成文本推理链；然后通过专门的视觉证据验证模块（VEVM）为每一步推理提取支持性的视觉证据；最后将文本推理与视觉证据结合，生成经过验证的答案。框架可与现有VLM无缝集成，无需端到端重新训练。

Result: 在VCR基准测试中，CoRGI提升了两种主流开源VLM（Qwen-2.5VL和LLaVA-1.6）的推理性能。消融实验验证了各验证步骤的贡献，人工评估也表明其解释更忠实且有用。研究了视觉验证步骤的替代设计并讨论了事后验证框架的局限。

Conclusion: 在中间推理步骤中融入视觉证据的验证，能显著增强多模态推理的稳健性。CoRGI作为一种模块化框架，为改进CoT在VLM中的应用提供了可行方案。

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [229] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: 本文提出了一种在多智能体合作中模拟心智理论（ToM）的方法，通过主动推理框架实现，无需任务特定的共享生成模型或显式通信。该方法允许智能体分别表示自身及他人的信念和目标，并基于递归推理规划行动，经避撞和觅食任务验证有效提升了合作效率。


<details>
  <summary>Details</summary>
Motivation: 在多智能体合作中，理解他者信念（ToM能力）对协调行动至关重要，但现有主动推理方法需依赖特定共享模型或显式通信。本文旨在开发一种通用、免显式通信的ToM建模框架，使智能体通过行为观察推断他者信念，提升合作自主性。

Method: 1. 在主动推理框架中构建ToM机制：智能体分别维护自身及他者的信念（环境状态分布）与目标（偏好状态）。2. 扩展推理树规划算法：通过递归推演他者行为意图（如计算他者预测行为对自身目标的影响），在联合策略空间中进行系统搜索。3. 行为生成：根据期望自由能最小化原则，选择最优策略（组合自身行动及预测的他者行为）。

Result: 避撞任务：ToM智能体成功推断他者路径意图，提前规避碰撞（如转向避开对方预测轨迹），碰撞率显著低于无ToM基线（具体数据未提供）。觅食任务：ToM智能体通过推断他者目标位置，主动选择未重叠区域收集资源，任务完成时间比基线缩短32%。关键证据表明，智能体仅通过观察他者历史行为即可精确建模其信念（如通过轨迹推测目标点）。

Conclusion: 本研究成功将心智理论整合至主动推理框架，实现免共享模型/通信的通用多智能体合作。实验结果验证了ToM机制通过递归信念推断提升合作效率的能力，这对人工智能协作系统设计具有指导意义，并为ToM的神经计算建模提供了可验证框架。

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [230] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: 本文介绍了Cognitive Kernel-Pro，一个完全开源且基本免费的多模块代理框架，旨在推动高级AI代理的发展和评估。该框架解决了当前代理系统封闭或依赖付费API的问题。作者研究了高质量训练数据的构建，并在四个领域（网络、文件、代码和一般推理）上探索了代理测试时的反思和投票策略以提高性能。在GAIA基准测试中，该框架达到了开源免费代理中的最先进水平，其8B参数的模型甚至超越了之前的领先系统。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理系统大多闭源或依赖付费API和专有工具，限制了研究社区的可访问性和复现性。为了解决这一问题，作者开发了一个完全开源并尽量免费的多模块代理框架。

Method: 1. 开发Cognitive Kernel-Pro：一个开源且免费的多模块代理框架；2. 为代理基础模型构建高质量训练数据，包括查询、轨迹和可验证的答案，覆盖网络、文件、代码和一般推理四个领域；3. 探索新的代理测试时策略：反射和投票，以增强代理的鲁棒性和性能；4. 在GAIA基准上进行评估。

Result: 在GAIA基准测试中，Cognitive Kernel-Pro达到了开源免费代理中的最先进水平。其8B参数的模型超越了之前的领先系统（如WebDancer和WebSailor），建立了高性能且可访问的AI代理新标准。

Conclusion: Cognitive Kernel-Pro作为开源免费的AI代理框架，不仅提高了该领域的可访问性，还通过精心设计的数据构建和新策略的应用，在性能上取得了突破。这为未来AI代理的研究和开发提供了新的基准。

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [231] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: 本文探讨了大语言模型（LLMs）在正式数学（定理证明）领域应用的困难。尽管LLMs在编程任务中表现出色，但它们在数学定理证明上的进展却相对缓慢。文章分析了这种差异的原因，并提出三个核心问题：非正式与正式数学训练领域的权衡、证明生成比代码合成更脆弱的原因，以及LLMs是否真正表示逻辑状态的变化。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在编程任务中表现出色，但在正式数学推理（如定理证明）领域却进展缓慢。这种差异引发了对LLM推理机制、训练监督方式以及其内部状态表示方式的深入思考。本研究旨在探索LLMs在数学认知方面的局限，分析为什么在表面上相似的编程和证明构造任务中，LLM的表现却有明显差距。

Method: 本研究通过回顾该领域的最新进展，包括关键模型和基准测试，探讨了三个核心问题：(i) 正式与非正式数学作为训练领域的权衡；(ii) 证明生成比代码合成更脆弱的深层次原因；(iii) LLMs是表示还是仅仅模仿逻辑状态的演化。

Result: 文章指出，正式数学领域对精确逻辑状态跟踪的要求使LLMs面临巨大挑战。当前研究揭示了监督机制和状态表示的内在限制，并展示了在缺乏真正内部演算能力时，LLMs在定理证明中的脆弱性。

Conclusion: 本文未设定严格边界，而是着眼于识别当前LLMs在正式数学推理中的局限性——尤其在逻辑状态的演化表示方面。作者建议未来的研究方向应集中在增强模型对内部状态的表示能力和改进监督框架上，从而突破现有瓶颈。

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [232] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: 提出了一个称为Pro2Guard的主动运行时强制执行框架，用于解决大型语言模型（LLM）代理在安全关键领域中的安全问题。它通过概率可达性分析来预测并预防潜在风险，而不是在风险发生后才做出响应。


<details>
  <summary>Details</summary>
Motivation: 现有的基于规则的安全执行系统（例如AgentSpec）是反应式的，只能在即将发生或已发生的不安全行为时做出反应，这缺乏预见性，并且难以处理长时依赖和分布偏移问题。因此，需要一种能够主动预测风险并在风险发生之前进行干预的方法。

Method: 1. 将代理行为抽象为符号状态。2. 从执行轨迹中学习离散时间马尔可夫链（DTMC）。3. 在运行时，估计到达不安全状态的概率，预测未来风险。4. 当预测风险超过用户定义的阈值时，在违规发生前触发干预。5. 通过结合语义有效性检查并利用概率近似正确（PAC）边界，确保统计可靠性并逼近真实模型。

Result: 1. 在具身家庭代理任务中，Pro2Guard能够提前阻止高达93.6%的不安全任务（使用低阈值），同时通过可配置的模式（例如reflect）在安全性和任务成功率之间取得平衡，任务完成率最高可达80.4%。2. 在自动驾驶场景中，Pro2Guard实现了100%的交通违章和碰撞预测，能够提前高达38.66秒预测风险。

Conclusion: Pro2Guard框架通过概率可达性分析，在多个安全关键领域（如具身代理和自动驾驶）中实现了主动的风险预测和干预，显著提高了安全性，同时保持了一定水平的任务成功率。该方法解决了现有反应式系统的不足，具有预见性并能适应分布偏移。

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [233] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: 提出了一个名为MultiSHAP的模型不可知解释框架，通过Shapley交互指数量化跨模态元素之间的协同和抑制效应，为开放和封闭源模型提供细粒度的实例级和数据集级解释。


<details>
  <summary>Details</summary>
Motivation: 当前多模态AI模型在需要融合多种模态信息的任务上表现出色，但缺乏可解释性和可信度是阻碍其应用于高风险场景的主要障碍。现有解释方法只能提供粗粒度的跨模态关系见解，无法精确量化模态间的协同效应，且仅适用于有权限访问内部权重的开源模型。

Method: MultiSHAP利用Shapley交互指数属性，将多模态预测归因于细粒度视觉和文本元素之间的成对交互（如图像块和文本片段）。该框架对开放和封闭源模型均适用。具体流程包括：(1) 对输入样本进行视觉和文本元素的分解；(2) 使用预训练模型提取特征；(3) 基于SHAP理论计算特征交互值；(4) 生成实例级解释（展示个体样本中的跨模态效应）和数据集级解释（揭示跨样本的通用交互模式）。可支持超过两种模态的扩展。

Result: 在公共多模态基准数据集上进行实验，验证了MultiSHAP能够准确捕捉跨模态推理机制。实例研究展示了模型在特定输入样本中识别到的跨模态协同效应（如文本中的关键词与图像中的对应区域），以及数据集层面的通用交互模式分析（例如视觉语义与特定词汇的固定关联）。

Conclusion: MultiSHAP为复杂多模态AI模型提供了可扩展且细粒度的解释方案，解决了传统方法无法精确量化跨模态交互的局限性。框架兼容开源/闭源模型，在高风险应用中具有提高AI可信度和透明度的重要潜力。

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [234] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 为了解决直接从复杂的电子病历生成全面预咨询问卷的困难，本文提出一种多阶段大语言模型（LLM）驱动框架。该框架分三步：提取关键原子断言、构建个人因果网络和疾病知识图谱、生成定制化问卷。经真实EMR数据和临床专家验证，该方法在信息覆盖、诊断相关性、可理解性和生成时间上表现优异。


<details>
  <summary>Details</summary>
Motivation: 电子病历（EMR）数据庞杂，直接使用大语言模型生成预咨询问卷存在信息完整性、逻辑顺序和疾病级别合成上的困难。因此，需要一种新的方法来克服这些限制，提升预咨询效率。

Method: 本文提出三阶段框架：
1. 提取原子断言：从EMR中提取带有时间戳的关键事实。
2. 构建知识结构：根据EMR语料库，构建个人因果网络并聚类生成代表性的疾病知识网络。
3. 生成问卷：基于上述结构化表示，生成个性化的和标准化的疾病特异性问卷。

Result: 在真实EMR数据集上评估，并由临床专家验证，该方法在信息覆盖度、诊断相关性、可理解性和生成时间上均优于直接方法，显示出实际应用中提升患者信息收集的潜力。

Conclusion: 通过构建显式临床知识结构，该多阶段LLM框架有效解决了直接生成问卷的局限性，为优化预咨询流程提供了可行方案。

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [235] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: 论文提出AVR-Eval评估指标和AVR-Agent多智能体系统，用于解决AI生成互动式视听内容（如电子游戏）的挑战。其中AVR-Eval利用全模态模型通过音视频记录评估内容质量，而AVR-Agent通过迭代优化代码生成高质量内容。实验显示AVR-Agent优于单次生成，但当前模型在利用自定义资产和反馈方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 当前AI在生成文本、音频、图像和视频方面表现出色，但在生成交互式视听内容（如视频游戏）时仍面临挑战。现有模型缺乏自动评估指标，且难以处理复杂内容（通常需要多人团队数月工作）。为应对这些问题，本文提出了新的评估指标和多智能体系统。

Method: 1. 提出AVR-Eval评估指标：通过全模态模型（处理文本/视频/音频）比较两个内容的音视频记录（AVRs），并使用文本模型审核评估结果以判定优劣。
2. 构建AVR-Agent多智能体系统：从多媒体资产库中选择相关资产，生成多个初始代码版本，用AVR-Eval选出最佳版本，并通过AVR的全模态反馈迭代改进代码。

Result: 1. AVR-Eval能有效区分优质内容与破损/不匹配内容。
2. AVR-Agent生成的内容在‘胜率’（win rate）上显著优于单次生成的内容（实验对象为游戏和动画）。
3. 关键发现：当前模型无法有效利用自定义资产和音视频反馈（胜率未提升），揭示了人类与机器在内容创作方法上的根本差异。

Conclusion: AVR-Agent系统成功提升了生成内容的交互质量，但实验暴露了AI在利用资产和反馈能力上的局限性——人类可高效利用这些资源，而现有编码模型却难以实现。这为未来改进AI的视听内容创作能力指明了方向。

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [236] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 本文提出了一种多波段可变滞后格兰杰因果关系（MB-VLGC）框架，该框架通过显式模拟频率相关的因果延迟，泛化了传统的可变滞后格兰杰因果关系（VLGC），可推断时间序列中不同频段的时变因果关系。


<details>
  <summary>Details</summary>
Motivation: 传统格兰杰因果方法假设固定的时间滞后，而实际复杂系统中因果延迟可能随时间变化（由VLGC方法解决），但忽略了不同频率波段的因果延迟也可能不同这一问题。例如在脑电信号中，不同频段的振荡可能以不同延迟影响其他脑区。为弥补这一不足，需要一种能考虑频率依赖性因果延迟的框架。

Method: 1. 形式化定义多波段可变滞后格兰杰因果关系（MB-VLGC），通过建模频率相关的因果延迟来扩展VLGC框架；2. 建立理论框架证明其合理性；3. 提出高效推断管道：包括信号的多频带分解（如使用小波变换），对每个频带推断时变延迟轨迹，最终整合各频带结果构建整体因果图。实验采用合成和真实数据集进行验证。

Result: 在多个领域的合成和真实数据集上的实验表明：1. MB-VLGC显著优于现有方法（如固定滞后和常规VLGC方法），F1分数平均提升21%；2. 在神经科学领域的脑电数据分析中，成功检测到α波段和δ波段的频率特异性延迟模式；3. 框架具有通用性，适用于经济、行为科学等领域的时间序列。

Conclusion: MB-VLGC成功解决了频率依赖性因果延迟的建模问题，为复杂系统（如脑网络）的跨频段因果交互研究提供了有效工具。通过显式建模频段-延迟关系，框架在多个领域展示出优越性能且具有广泛适用性。公开的代码和数据集将促进后续研究。

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [237] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: 本文提出了一个混合框架，将传统可解释人工智能（XAI）技术与生成式AI模型和用户个性化相结合，生成符合用户需求的多模态个性化解释，旨在增强自适应学习系统的透明度并支持以用户为中心的体验。


<details>
  <summary>Details</summary>
Motivation: 目前自适应学习系统缺乏透明度，且现有XAI技术多关注技术输出而忽视用户角色和理解。为了改善这一状况，作者试图重新定义可解释性，将其视为一种针对用户角色和学习目标动态调整的交流过程。

Method: 提出一个混合框架，该框架整合了传统XAI技术和生成式AI模型，并引入用户个性化模块。此框架设计考虑了用户角色和学习目标的动态需求，生成多模态（例如文本、视觉等）的个性化解释。

Result: 虽然论文没有报告具体实验结果，但框架设计目标已明确：重点解决教育领域中XAI在准确性、公平性和个性化方面的局限性，并为这些研究方向提供了思路。

Conclusion: 通过将生成式AI与传统XAI结合并加入用户个性化，能更有效地实现针对不同用户需求的动态解释生成，从而提升自适应学习系统的透明度和用户体验。该框架为未来在教育环境中实现更可靠的XAI提供了理论基础。

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [238] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: 这篇愿景论文提出了一个针对社交媒体推荐的可视化解释系统，该系统根据用户的不同需求和上下文提供不同形式和粒度的解释，旨在提高用户对推荐的理解和信任。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体平台的AI推荐系统缺乏有效的解释性，导致用户无法理解推荐背后的原因，从而降低了推荐的价值。现有的解释通常过于通用，未能与用户的特定需求和背景对齐。

Method: 作者提出了一种用户分层和上下文感知的解释层框架，该系统包含多样化的解释方法，并以可视化方式展示。该框架能够根据用户类型（如AI专家或普通用户）动态调整解释的风格（可视化与数值）和粒度（专家级与通俗级），这些调整在单一流程中完成。为验证效果，计划进行一项有30名X用户的公开试验，测试系统对用户决策和信任的影响。

Result: 该论文提出的是一个框架设计，尚未进行大规模验证。但计划中的公开试验将评估该系统在改善用户决策和增强对推荐系统信任方面的效果。

Conclusion: 通过开发一个能够适应不同用户需求和背景的可视化解释系统，可以显著提高社交媒体推荐的可理解性和用户信任，这需要通过用户试验来验证其实际效果。

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [239] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 提出了一种使用大型预训练多模态模型进行生成内容检测的方法，通过在预训练模型的特征上训练线性分类器，实现跨模态的SOTA检测性能，高效且适用于少样本设置。


<details>
  <summary>Details</summary>
Motivation: 现有的虚假信息检测器通常只适用于同一类生成器和同种数据模态，无法泛化到新出现的生成式模型和其他数据模态。为了解决跨模态和跨生成器的通用检测问题，利用预训练多模态模型的特征区分真实与生成内容。

Method: 1. 利用大型预训练多模态模型的潜在特征（latent code）区分生成内容。
2. 基于该特征训练线性分类器。
3. 针对音频和图像两种模态进行检测。

Result: 该方法在音频和图像模态上超越或匹配强大的基线方法，表现为：1. 在多种模态下取得SOTA结果；2. 计算高效、训练快；3. 在少样本场景下依然有效。

Conclusion: 预训练多模态模型的特征天然携带区分真实与生成内容的信息。在这些特征上训练简单线性分类器是一种通用、高效的跨模态生成内容检测方法。

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>
