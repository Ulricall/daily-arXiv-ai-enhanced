<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 69]
- [cs.CL](#cs.CL) [Total: 37]
- [cs.LG](#cs.LG) [Total: 58]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.RO](#cs.RO) [Total: 11]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Runtime Failure Hunting for Physics Engine Based Software Systems: How Far Can We Go?](https://arxiv.org/abs/2507.22099)
*Shuqing Li,Qiang Chen,Xiaoxue Ren,Michael R. Lyu*

Main category: cs.CV

TL;DR: 本文提出了PhysiXFails框架，并进行了关于物理引擎软件（PEs）中物理失效的第一项大规模实证研究。研究包括物理失效的表现形式分类、检测方法评估（如深度学习和大型多模态模型），以及开发者经验的洞见。成果包括开放的代码和材料，用于未来的物理失效检测研究。


<details>
  <summary>Details</summary>
Motivation: 物理引擎在各种应用中至关重要，但物理失效问题会影响软件可靠性、用户体验，甚至可能导致严重事故（如自动驾驶或医疗机器人领域）。现有的PE软件测试方法不足，通常需要白盒访问且仅专注于崩溃检测，而非复杂的物理失效问题。为此，本文首次对物理引擎软件中的物理失效进行大规模研究，以填补这一空白。

Method: 研究围绕三个问题展开：物理失效的表现形式（形成分类），检测方法（包括深度学习、提示工程技术和大型多模态模型）的有效性，以及开发者对当前检测实践的认知。方法包括构建一个包含现实世界物理失效实例的数据集（PhysiXFails），并使用不同检测技术对数据集进行评测，同时对开发者进行调研以收集经验反馈。

Result: 研究发现：(1)提出了物理失效表现的详细分类法；(2)全面评估了多种检测方法，其中大型多模态模型和带提示的模型优于纯深度学习方法；(3)开发者的反馈强调了对自动化和更强大测试工具的强烈需求，而现有工具不足以捕捉复杂失效模式。

Conclusion: 该研究首次系统性地总结了物理引擎软件中物理失效的表现特征，并证明了利用先进检测模型（尤其是结合提示工程的大型模型）检测物理失效的有效性。通过PhysiXFails数据集及开放材料，研究结果为开发者和未来研究提供了工具资源。研究者还呼吁针对复杂物理情境开发更加智能且用户友好的检测工具。

Abstract: Physics Engines (PEs) are fundamental software frameworks that simulate
physical interactions in applications ranging from entertainment to
safety-critical systems. Despite their importance, PEs suffer from physics
failures, deviations from expected physical behaviors that can compromise
software reliability, degrade user experience, and potentially cause critical
failures in autonomous vehicles or medical robotics. Current testing approaches
for PE-based software are inadequate, typically requiring white-box access and
focusing on crash detection rather than semantically complex physics failures.
This paper presents the first large-scale empirical study characterizing
physics failures in PE-based software. We investigate three research questions
addressing the manifestations of physics failures, the effectiveness of
detection techniques, and developer perceptions of current detection practices.
Our contributions include: (1) a taxonomy of physics failure manifestations;
(2) a comprehensive evaluation of detection methods including deep learning,
prompt-based techniques, and large multimodal models; and (3) actionable
insights from developer experiences for improving detection approaches. To
support future research, we release PhysiXFails, code, and other materials at
https://sites.google.com/view/physics-failure-detection.

</details>


### [2] [Trade-offs in Image Generation: How Do Different Dimensions Interact?](https://arxiv.org/abs/2507.22100)
*Sicheng Zhang,Binzhu Xie,Zhonghao Yan,Yuli Zhang,Donghao Zhou,Xiaofei Chen,Shi Qiu,Jiaqi Liu,Guoyang Xie,Zhichao Lu*

Main category: cs.CV

TL;DR: 引入TRIG-Bench基准和TRIGScore评分标准，用于量化图像生成任务中的多维评估，并提出DTM可视化和微调方法来优化模型性能


<details>
  <summary>Details</summary>
Motivation: 为克服图像生成任务中无法量化多维度性能的局限性：缺少细粒度量化数据集和多维度单一评估标准

Method: (1) 构建涵盖10个维度、40200个样本（132对维度）的TRIG-Bench基准；(2) 研发TRIGScore评估指标（VLM作为评估工具）；(3) 运用关系识别系统生成DTM（模型能力维度的可视化）；(4) 通过微调DTM优化模型

Result: (1) 成功评估14种图像生成模型；(2) DTM可视化可揭示模型在维度上的性能取舍；(3) 经DTM微调的模型可提升特定维度性能，增强综合表现

Conclusion: TRIG-Bench和TRIGScore可量化图像生成的维度平衡，DTM可视化帮助理解模型能力缺陷，微调DTM可提高整体性能

Abstract: Model performance in text-to-image (T2I) and image-to-image (I2I) generation
often depends on multiple aspects, including quality, alignment, diversity, and
robustness. However, models' complex trade-offs among these dimensions have
rarely been explored due to (1) the lack of datasets that allow fine-grained
quantification of these trade-offs, and (2) the use of a single metric for
multiple dimensions. To bridge this gap, we introduce TRIG-Bench (Trade-offs in
Image Generation), which spans 10 dimensions (Realism, Originality, Aesthetics,
Content, Relation, Style, Knowledge, Ambiguity, Toxicity, and Bias), contains
40,200 samples, and covers 132 pairwise dimensional subsets. Furthermore, we
develop TRIGScore, a VLM-as-judge metric that automatically adapts to various
dimensions. Based on TRIG-Bench and TRIGScore, we evaluate 14 models across T2I
and I2I tasks. In addition, we propose the Relation Recognition System to
generate the Dimension Trade-off Map (DTM) that visualizes the trade-offs among
model-specific capabilities. Our experiments demonstrate that DTM consistently
provides a comprehensive understanding of the trade-offs between dimensions for
each type of generative model. Notably, we show that the model's
dimension-specific weaknesses can be mitigated through fine-tuning on DTM to
enhance overall performance. Code is available at:
https://github.com/fesvhtr/TRIG

</details>


### [3] [AI in Agriculture: A Survey of Deep Learning Techniques for Crops, Fisheries and Livestock](https://arxiv.org/abs/2507.22101)
*Umair Nawaz,Muhammad Zaigham Zaheer,Fahad Shahbaz Khan,Hisham Cholakkal,Salman Khan,Rao Muhammad Anwer*

Main category: cs.CV

TL;DR: 本文系统综述了人工智能在农业领域的应用，涵盖了从传统机器学习到深度学习和视觉语言大模型的多种技术，在作物病害检测、牲畜健康管理等任务上的研究现状，并讨论了数据变异性、实验数据集、性能评估及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 全球粮食生产面临如气候变化、资源有限及可持续管理等挑战，需要高效、准确且可扩展的技术支持。人工智能，特别是先进的深度学习技术，为解决这些问题提供了潜力，因此有必要对AI在农业中的应用进行全面调研。

Method: 作者系统性地综述了200多篇相关研究，内容包括传统机器学习方法、高级深度学习技术（如视觉Transformer）和新兴的视觉语言基础模型（如CLIP），并涵盖了模型在农业领域的具体应用任务及相关实验因素（数据集、评估指标、地理分布等）。

Result: 该调查总结了当前AI在农业重点领域（如作物病害检测、畜牧健康管理和水生生物监测）的应用现状及挑战（如数据变异性），并识别出现有模型的局限性。

Conclusion: 未来研究应关注多模态数据融合、模型在边缘设备的高效部署以及适用于不同农业环境的领域自适应AI。同时，作者提供了项目页面以跟踪该领域的快速进展。

Abstract: Crops, fisheries and livestock form the backbone of global food production,
essential to feed the ever-growing global population. However, these sectors
face considerable challenges, including climate variability, resource
limitations, and the need for sustainable management. Addressing these issues
requires efficient, accurate, and scalable technological solutions,
highlighting the importance of artificial intelligence (AI). This survey
presents a systematic and thorough review of more than 200 research works
covering conventional machine learning approaches, advanced deep learning
techniques (e.g., vision transformers), and recent vision-language foundation
models (e.g., CLIP) in the agriculture domain, focusing on diverse tasks such
as crop disease detection, livestock health management, and aquatic species
monitoring. We further cover major implementation challenges such as data
variability and experimental aspects: datasets, performance evaluation metrics,
and geographical focus. We finish the survey by discussing potential open
research directions emphasizing the need for multimodal data integration,
efficient edge-device deployment, and domain-adaptable AI models for diverse
farming environments. Rapid growth of evolving developments in this field can
be actively tracked on our project page:
https://github.com/umair1221/AI-in-Agriculture

</details>


### [4] [Color as the Impetus: Transforming Few-Shot Learner](https://arxiv.org/abs/2507.22136)
*Chaofei Qi,Zhitai Liu,Jianbin Qiu*

Main category: cs.CV

TL;DR: 本文提出了一种受人类颜色感知启发的元学习框架ColorSense Learner，通过颜色通道交互和知识蒸馏来提升小样本分类性能，在多个基准测试中展现出强大的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有元学习方法忽视了颜色作为直观视觉特征的作用，而人类颜色感知能力对小样本学习有重要贡献。

Method: 1. 设计基于颜色感知通道交互的元学习框架（ColorSense Learner），通过跨通道特征提取强化类内共性、扩大类间差异；2. 引入基于知识蒸馏的元蒸馏器（ColorSense Distiller），利用教师网络先验知识增强学生网络。

Result: 在11个小样本基准测试（粗/细粒度及跨域场景）中验证，方法展现出极强的泛化能力、鲁棒性和可迁移性。

Conclusion: 从颜色感知角度处理小样本分类问题，通过模拟人类颜色感知机制能显著提升元学习性能。

Abstract: Humans possess innate meta-learning capabilities, partly attributable to
their exceptional color perception. In this paper, we pioneer an innovative
viewpoint on few-shot learning by simulating human color perception mechanisms.
We propose the ColorSense Learner, a bio-inspired meta-learning framework that
capitalizes on inter-channel feature extraction and interactive learning. By
strategically emphasizing distinct color information across different channels,
our approach effectively filters irrelevant features while capturing
discriminative characteristics. Color information represents the most intuitive
visual feature, yet conventional meta-learning methods have predominantly
neglected this aspect, focusing instead on abstract feature differentiation
across categories. Our framework bridges the gap via synergistic color-channel
interactions, enabling better intra-class commonality extraction and larger
inter-class differences. Furthermore, we introduce a meta-distiller based on
knowledge distillation, ColorSense Distiller, which incorporates prior teacher
knowledge to augment the student network's meta-learning capacity. We've
conducted comprehensive coarse/fine-grained and cross-domain experiments on
eleven few-shot benchmarks for validation. Numerous experiments reveal that our
methods have extremely strong generalization ability, robustness, and
transferability, and effortless handle few-shot classification from the
perspective of color perception.

</details>


### [5] [Enhancing efficiency in paediatric brain tumour segmentation using a pathologically diverse single-center clinical dataset](https://arxiv.org/abs/2507.22152)
*A. Piffer,J. A. Buchner,A. G. Gennari,P. Grehten,S. Sirin,E. Ross,I. Ezhov,M. Rosier,J. C. Peeken,M. Piraud,B. Menze,A. Guerreiro Stücklin,A. Jakab,F. Kofler*

Main category: cs.CV

TL;DR: 这篇论文研究了使用深度学习模型（3D nnU-Net）对儿童脑肿瘤（包括高级别和低级别胶质瘤、髓母细胞瘤、室管膜瘤等）进行MRI图像分割的可行性。模型在不同肿瘤亚区和不同MRI序列组合上的表现被评估，并与人工标注的变异性进行比较。结果表明，模型在整体肿瘤（WT）和T2高信号区域（T2H）的分割上表现出色（平均Dice分数0.85），与人工标注变异性相当（0.86）；增强肿瘤（ET）分割中等；囊性成分（CC）分割较差。研究还发现T1、T1-C和T2序列单独使用即可达到接近全序列组合的效果，支持简化成像协议。


<details>
  <summary>Details</summary>
Motivation: 儿童脑肿瘤（PBTs）具有高度异质性，包括多种组织学、分子亚型和影像特征。当前，深度学习的分割方法在成人脑肿瘤中应用较多，但在儿童脑肿瘤中由于类型多样性和成像协议差异，其性能尚不确定。因此，研究旨在评估深度学习模型在多种儿童脑肿瘤亚型上的分割表现，为临床应用提供依据。

Method: 1. 数据收集：回顾性纳入174例儿童脑肿瘤患者（含高级别胶质瘤、低级别胶质瘤、髓母细胞瘤、室管膜瘤等罕见亚型）的MRI数据（T1、T1增强、T2、FLAIR序列）。
2. 标注：人工标注四个肿瘤子区域：整体肿瘤（WT）、T2高信号区（T2H）、增强肿瘤（ET）和囊性成分（CC）。
3. 模型训练与测试：使用3D nnU-Net模型，按121例训练、53例测试的比例划分数据集。
4. 评估指标：以Dice相似系数（DSC）评估分割性能，并与人工标注者内部和之间的变异性进行对比。
5. 实验设计：测试不同MRI序列组合对分割效果的影响。

Result: 1. 整体肿瘤（WT）和T2高信号区（T2H）分割表现优秀，平均DSC达0.85（与人工标注变异性0.86相当）。
2. 增强肿瘤（ET）分割中等（平均DSC 0.75），囊性成分（CC）分割效果差。
3. 分割效果受肿瘤类型、MRI序列组合和位置影响。
4. 关键发现：仅使用T1、T1增强或T2单一序列即可达到接近全序列组合（T1+T1-C+T2+FLAIR）的分割效果。

Conclusion: 深度学习模型（3D nnU-Net）在儿童脑肿瘤的WT和T2H分割中可行，表现接近人工水平，但在ET和CC分割上仍需改进。研究结果支持简化MRI成像协议（单一序列即可满足需求），有望提升肿瘤体积评估效率并优化儿科神经肿瘤工作流程。未来需重点优化对囊性和增强区域的分割算法。

Abstract: Background Brain tumours are the most common solid malignancies in children,
encompassing diverse histological, molecular subtypes and imaging features and
outcomes. Paediatric brain tumours (PBTs), including high- and low-grade
gliomas (HGG, LGG), medulloblastomas (MB), ependymomas, and rarer forms, pose
diagnostic and therapeutic challenges. Deep learning (DL)-based segmentation
offers promising tools for tumour delineation, yet its performance across
heterogeneous PBT subtypes and MRI protocols remains uncertain. Methods A
retrospective single-centre cohort of 174 paediatric patients with HGG, LGG,
medulloblastomas (MB), ependymomas, and other rarer subtypes was used. MRI
sequences included T1, T1 post-contrast (T1-C), T2, and FLAIR. Manual
annotations were provided for four tumour subregions: whole tumour (WT),
T2-hyperintensity (T2H), enhancing tumour (ET), and cystic component (CC). A 3D
nnU-Net model was trained and tested (121/53 split), with segmentation
performance assessed using the Dice similarity coefficient (DSC) and compared
against intra- and inter-rater variability. Results The model achieved robust
performance for WT and T2H (mean DSC: 0.85), comparable to human annotator
variability (mean DSC: 0.86). ET segmentation was moderately accurate (mean
DSC: 0.75), while CC performance was poor. Segmentation accuracy varied by
tumour type, MRI sequence combination, and location. Notably, T1, T1-C, and T2
alone produced results nearly equivalent to the full protocol. Conclusions DL
is feasible for PBTs, particularly for T2H and WT. Challenges remain for ET and
CC segmentation, highlighting the need for further refinement. These findings
support the potential for protocol simplification and automation to enhance
volumetric assessment and streamline paediatric neuro-oncology workflows.

</details>


### [6] [Temporally Consistent Unsupervised Segmentation for Mobile Robot Perception](https://arxiv.org/abs/2507.22194)
*Christian Ellis,Maggie Wigness,Craig Lennon,Lance Fiondella*

Main category: cs.CV

TL;DR: 提出一种名为Frontier-Seg的无监督分割方法，通过利用基础模型（DINOv2）提取超像素级特征并强制帧间时间一致性，实现移动机器人视频流中的地形分割，无需人类标注。在多个非结构化越野环境的数据集上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在无准备、非结构化环境中，缺乏标注数据且语义类别模糊的问题使得传统监督语义分割难以适用。现有无监督分割方法多为单帧处理，缺少时间一致性（在非结构化环境中鲁棒感知的关键特性）。

Method: 1. 使用基础模型（DINOv2）提取超像素级别的特征；2. 对特征进行聚类；3. 强制相邻帧之间的时间一致性以识别持久存在的边界（即Frontiers）。整个流程无需人工监督。

Result: 在RUGD和RELLIS-3D等多个非结构化越野环境的数据集上进行评估，证明了该方法能够有效实现非结构化环境中的无监督分割。

Conclusion: Frontier-Seg通过时间一致性机制解决了无监督环境中边界检测的稳定性问题，为移动机器人在非结构化环境中的地形分割提供了一种无需标注的方案。

Abstract: Rapid progress in terrain-aware autonomous ground navigation has been driven
by advances in supervised semantic segmentation. However, these methods rely on
costly data collection and labor-intensive ground truth labeling to train deep
models. Furthermore, autonomous systems are increasingly deployed in
unrehearsed, unstructured environments where no labeled data exists and
semantic categories may be ambiguous or domain-specific. Recent zero-shot
approaches to unsupervised segmentation have shown promise in such settings but
typically operate on individual frames, lacking temporal consistency-a critical
property for robust perception in unstructured environments. To address this
gap we introduce Frontier-Seg, a method for temporally consistent unsupervised
segmentation of terrain from mobile robot video streams. Frontier-Seg clusters
superpixel-level features extracted from foundation model
backbones-specifically DINOv2-and enforces temporal consistency across frames
to identify persistent terrain boundaries or frontiers without human
supervision. We evaluate Frontier-Seg on a diverse set of benchmark
datasets-including RUGD and RELLIS-3D-demonstrating its ability to perform
unsupervised segmentation across unstructured off-road environments.

</details>


### [7] [SmartCLIP: Modular Vision-language Alignment with Identification Guarantees](https://arxiv.org/abs/2507.22264)
*Shaoan Xie,Lingjing Kong,Yujia Zheng,Yu Yao,Zeyu Tang,Eric P. Xing,Guangyi Chen,Kun Zhang*

Main category: cs.CV

TL;DR: 本文提出了SmartCLIP，一种解决CLIP模型在图文对齐中信息不对齐和表示纠缠问题的新方法。通过理论条件和模块化对齐，提高了模型在细粒度文本概念上的表现。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在图文数据集上存在信息不对齐和表示纠缠的问题。例如，MSCOCO数据集中的短标题可能描述图像中的不同区域，导致模型不确定应保留或忽略哪些视觉特征；而直接对齐长标题和图像可能导致模型保留纠缠的细节，难以学习解耦的原子概念，影响下游任务的表现。

Method: 首先建立文本和视觉表示在不同粒度上灵活对齐的理论条件。然后提出SmartCLIP方法，该方法以模块化的方式识别和对齐最相关的视觉和文本表示。具体来说，该方法能够保持跨模态语义信息的完整性，同时解耦视觉表示以捕捉细粒度的文本概念。

Result: SmartCLIP在各种任务上表现优异，验证了其处理信息不对齐的能力，并支持了所提出的识别理论。

Conclusion: SmartCLIP通过模块化对齐方式解决了CLIP模型的信息不对齐和表示纠缠问题，提高了模型对细粒度文本概念的理解能力，从而在下游任务中获得更好的泛化性能。

Abstract: Contrastive Language-Image Pre-training (CLIP)~\citep{radford2021learning}
has emerged as a pivotal model in computer vision and multimodal learning,
achieving state-of-the-art performance at aligning visual and textual
representations through contrastive learning. However, CLIP struggles with
potential information misalignment in many image-text datasets and suffers from
entangled representation. On the one hand, short captions for a single image in
datasets like MSCOCO may describe disjoint regions in the image, leaving the
model uncertain about which visual features to retain or disregard. On the
other hand, directly aligning long captions with images can lead to the
retention of entangled details, preventing the model from learning
disentangled, atomic concepts -- ultimately limiting its generalization on
certain downstream tasks involving short prompts.
  In this paper, we establish theoretical conditions that enable flexible
alignment between textual and visual representations across varying levels of
granularity. Specifically, our framework ensures that a model can not only
\emph{preserve} cross-modal semantic information in its entirety but also
\emph{disentangle} visual representations to capture fine-grained textual
concepts. Building on this foundation, we introduce \ours, a novel approach
that identifies and aligns the most relevant visual and textual representations
in a modular manner. Superior performance across various tasks demonstrates its
capability to handle information misalignment and supports our identification
theory. The code is available at https://github.com/Mid-Push/SmartCLIP.

</details>


### [8] [HOG-CNN: Integrating Histogram of Oriented Gradients with Convolutional Neural Networks for Retinal Image Classification](https://arxiv.org/abs/2507.22274)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: 提出了一种基于HOG-CNN混合特征提取模型的自动可解释临床决策支持框架，用于视网膜疾病的早期检测。通过融合手工HOG特征和CNN特征，捕捉局部纹理和高层语义信息。在三个公共数据集上评估：APTOS 2019（糖尿病视网膜病变分类）、ORIGA（青光眼检测）和IC-AMD（年龄相关性黄斑变性诊断），模型表现优异且具有轻量级、可解释性强的特点。


<details>
  <summary>Details</summary>
Motivation: 传统视网膜疾病诊断依赖人工判读，耗时耗力。为克服这些限制，需要建立自动化的临床决策支持系统，在确保高准确率的同时兼顾模型可解释性，以适应资源受限的医疗环境。

Method: 1. 提出HOG-CNN混合模型架构：
   - 手工特征层：提取HOG特征（捕获局部纹理模式）
   - 深度特征层：通过CNN提取高层语义特征
   - 特征融合层：结合两类特征形成联合表示
2. 评估框架：
   - 数据集：APTOS 2019（糖尿病视网膜病变二元/五分类）、ORIGA（青光眼）、IC-AMD（黄斑变性）
   - 对比方法：多个先进模型
   - 附录分析：验证HOG与CNN特征的互补性

Result: 
- APTOS 2019数据集：
  • 二元DR分类：准确率98.5%，AUC 99.2
  • 五类DR分类：AUC 94.2
- IC-AMD数据集：
  • 准确率92.8%，精确率94.8%，AUC 94.5（超越现有最优模型）
- ORIGA数据集：
  • 青光眼检测：准确率83.9%，AUC 87.2（在数据有限情况下具竞争力）

Conclusion: HOG-CNN融合策略有效结合了手工特征与深度特征的互补优势，在多种视网膜疾病诊断任务中实现高性能。模型的轻量化设计适合在资源有限的临床环境中部署，为自动化视网膜疾病筛查提供了可扩展的解决方案。

Abstract: The analysis of fundus images is critical for the early detection and
diagnosis of retinal diseases such as Diabetic Retinopathy (DR), Glaucoma, and
Age-related Macular Degeneration (AMD). Traditional diagnostic workflows,
however, often depend on manual interpretation and are both time- and
resource-intensive. To address these limitations, we propose an automated and
interpretable clinical decision support framework based on a hybrid feature
extraction model called HOG-CNN. Our key contribution lies in the integration
of handcrafted Histogram of Oriented Gradients (HOG) features with deep
convolutional neural network (CNN) representations. This fusion enables our
model to capture both local texture patterns and high-level semantic features
from retinal fundus images. We evaluated our model on three public benchmark
datasets: APTOS 2019 (for binary and multiclass DR classification), ORIGA (for
Glaucoma detection), and IC-AMD (for AMD diagnosis); HOG-CNN demonstrates
consistently high performance. It achieves 98.5\% accuracy and 99.2 AUC for
binary DR classification, and 94.2 AUC for five-class DR classification. On the
IC-AMD dataset, it attains 92.8\% accuracy, 94.8\% precision, and 94.5 AUC,
outperforming several state-of-the-art models. For Glaucoma detection on ORIGA,
our model achieves 83.9\% accuracy and 87.2 AUC, showing competitive
performance despite dataset limitations. We show, through comprehensive
appendix studies, the complementary strength of combining HOG and CNN features.
The model's lightweight and interpretable design makes it particularly suitable
for deployment in resource-constrained clinical environments. These results
position HOG-CNN as a robust and scalable tool for automated retinal disease
screening.

</details>


### [9] [AlphaEarth Foundations: An embedding field model for accurate and efficient global mapping from sparse label data](https://arxiv.org/abs/2507.22291)
*Christopher F. Brown,Michal R. Kazmierski,Valerie J. Pasquarella,William J. Rucklidge,Masha Samsikova,Chenhui Zhang,Evan Shelhamer,Estefania Lahera,Olivia Wiles,Simon Ilyushchenko,Noel Gorelick,Lihui Lydia Zhang,Sophia Alj,Emily Schechter,Sean Askay,Oliver Guinan,Rebecca Moore,Alexis Boukouvalas,Pushmeet Kohli*

Main category: cs.CV

TL;DR: AlphaEarth Foundations是一种创新的嵌入域模型，能够有效利用稀疏标注生成地球观测数据的通用表示，显著提升地图制作和监测系统的准确性与效率


<details>
  <summary>Details</summary>
Motivation: 地球观测数据体量巨大但高质量标注稀缺，传统建模方法无法高效利用这些数据。因此需要一个通用模型整合多源信息的时空和测量背景

Method: 提出AlphaEarth Foundations嵌入域模型：1) 融合多源数据的空间、时间和测量信息；2) 在统一框架中构建泛化的地理空间表征；3) 无需重新训练即可迁移应用

Result: 1) 在多样地图评估任务中全面超越现有特征提取方法；2) 唯一持续表现最佳的嵌入模型；3) 将发布2017-2024年覆盖全球的年化即用级嵌入数据

Conclusion: AlphaEarth Foundations通过全局表征学习开创性地解决了卫星数据量大而标注少的问题，为地理空间建模提供了高效通用框架，推动大规模持续监测系统发展

Abstract: Unprecedented volumes of Earth observation data are continually collected
around the world, but high-quality labels remain scarce given the effort
required to make physical measurements and observations. This has led to
considerable investment in bespoke modeling efforts translating sparse labels
into maps. Here we introduce AlphaEarth Foundations, an embedding field model
yielding a highly general, geospatial representation that assimilates spatial,
temporal, and measurement contexts across multiple sources, enabling accurate
and efficient production of maps and monitoring systems from local to global
scales. The embeddings generated by AlphaEarth Foundations are the only to
consistently outperform all previous featurization approaches tested on a
diverse set of mapping evaluations without re-training. We will release a
dataset of global, annual, analysis-ready embedding field layers from 2017
through 2024.

</details>


### [10] [Recognizing Actions from Robotic View for Natural Human-Robot Interaction](https://arxiv.org/abs/2507.22522)
*Ziyi Wang,Peiming Li,Hong Liu,Zhichao Deng,Can Wang,Jun Liu,Junsong Yuan,Mengyuan Liu*

Main category: cs.CV

TL;DR: 提出ACTIVE数据集用于机器人视角下的自然人机交互（N-HRI）动作识别，挑战在于长距离和移动平台下的识别。提出的ACTIVE-PC方法通过多级邻域采样、分层识别器、弹性椭圆查询等方式解决长距离动作识别问题。


<details>
  <summary>Details</summary>
Motivation: 传统动作识别任务难以满足N-HRI的需求。在机器人移动或人在远距离、机器人平台晃动等实际N-HRI场景中，现有数据集的模态、任务类、主体和环境多样性不足。

Method: 1. 构建大规模数据集ACTIVE：包含30个组合动作类别、80名参与者、46,868个带注释的视频实例，涵盖RGB和点云模态；2. 提出ACTIVE-PC方法：使用多级邻域采样处理点云特征，设计分层识别器进行动作特征学习，用弹性椭圆查询进行动作区域检测，解耦人体动作中的运动干扰。

Result: 构建了具有长距离、多环境、移动平台特点的ACTIVE数据集。ACTIVE-PC方法在实验中被证明有效，特别是在远距离情况下能准确感知人类动作。

Conclusion: ACTIVE数据集为N-HRI动作识别提供更实际的研究基础。ACTIVE-PC在解决机器人视角中的长距离动作识别问题上具有优势。代码已开源。

Abstract: Natural Human-Robot Interaction (N-HRI) requires robots to recognize human
actions at varying distances and states, regardless of whether the robot itself
is in motion or stationary. This setup is more flexible and practical than
conventional human action recognition tasks. However, existing benchmarks
designed for traditional action recognition fail to address the unique
complexities in N-HRI due to limited data, modalities, task categories, and
diversity of subjects and environments. To address these challenges, we
introduce ACTIVE (Action from Robotic View), a large-scale dataset tailored
specifically for perception-centric robotic views prevalent in mobile service
robots. ACTIVE comprises 30 composite action categories, 80 participants, and
46,868 annotated video instances, covering both RGB and point cloud modalities.
Participants performed various human actions in diverse environments at
distances ranging from 3m to 50m, while the camera platform was also mobile,
simulating real-world scenarios of robot perception with varying camera heights
due to uneven ground. This comprehensive and challenging benchmark aims to
advance action and attribute recognition research in N-HRI. Furthermore, we
propose ACTIVE-PC, a method that accurately perceives human actions at long
distances using Multilevel Neighborhood Sampling, Layered Recognizers, Elastic
Ellipse Query, and precise decoupling of kinematic interference from human
actions. Experimental results demonstrate the effectiveness of ACTIVE-PC. Our
code is available at:
https://github.com/wangzy01/ACTIVE-Action-from-Robotic-View.

</details>


### [11] [LAMA-Net: A Convergent Network Architecture for Dual-Domain Reconstruction](https://arxiv.org/abs/2507.22316)
*Chi Ding,Qingchao Zhang,Ge Wang,Xiaojing Ye,Yunmei Chen*

Main category: cs.CV

TL;DR: 该论文提出了一个可学习的变分模型，通过结合图像域和测量域的互补信息进行图像重建。研究重点在于证明LAMA算法的收敛性，并展示其稳定性，进一步提出iLAMA-Net提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图像重建方法往往未能充分利用图像域和测量域的互补信息，且缺乏理论收敛保障的端到端可学习网络结构。

Method: 1. 提出LAMA（Learned Alternating Minimization Algorithm）算法：将残差学习架构引入近端交替框架，解决两区块非凸非光滑优化问题；2. 严格证明LAMA算法收敛性：证明特定子序列的积累点必为Clarke驻点；3. 构建可解释网络LAMA-Net：直接由LAMA推导；4. 改进版iLAMA-Net：增加生成合适初始值的网络模块；5. 在稀疏视图CT任务上与其他SOTA方法进行对比实验。

Result: 1. LAMA的收敛性证明确立了算法稳定性；2. LAMA-Net在稀疏视图CT任务中表现出出色的鲁棒性和稳定性；3. 引入初始值生成模块的iLAMA-Net进一步提升了重建性能；4. 实验证实两个网络在公开数据集上均超越现有SOTA方法。

Conclusion: LAMA算法为图像重建提供了理论收敛保证，其衍生的网络架构兼具可解释性和性能优势。初始值优化策略能进一步提升效果，该框架具有向其他逆问题推广的潜力。

Abstract: We propose a learnable variational model that learns the features and
leverages complementary information from both image and measurement domains for
image reconstruction. In particular, we introduce a learned alternating
minimization algorithm (LAMA) from our prior work, which tackles two-block
nonconvex and nonsmooth optimization problems by incorporating a residual
learning architecture in a proximal alternating framework. In this work, our
goal is to provide a complete and rigorous convergence proof of LAMA and show
that all accumulation points of a specified subsequence of LAMA must be Clarke
stationary points of the problem. LAMA directly yields a highly interpretable
neural network architecture called LAMA-Net. Notably, in addition to the
results shown in our prior work, we demonstrate that the convergence property
of LAMA yields outstanding stability and robustness of LAMA-Net in this work.
We also show that the performance of LAMA-Net can be further improved by
integrating a properly designed network that generates suitable initials, which
we call iLAMA-Net. To evaluate LAMA-Net/iLAMA-Net, we conduct several
experiments and compare them with several state-of-the-art methods on popular
benchmark datasets for Sparse-View Computed Tomography.

</details>


### [12] [Viser: Imperative, Web-based 3D Visualization in Python](https://arxiv.org/abs/2507.22885)
*Brent Yi,Chung Min Kim,Justin Kerr,Gina Wu,Rebecca Feng,Anthony Zhang,Jonas Kulhanek,Hongsuk Choi,Yi Ma,Matthew Tancik,Angjoo Kanazawa*

Main category: cs.CV

TL;DR: 介绍Viser：一个用于计算机视觉和机器人的3D可视化库，提供易于使用且可扩展的Python接口，具有丰富的3D场景和2D GUI原语，支持独立或组合使用。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决在Python中缺乏易于使用且功能丰富的3D可视化工具的问题。Viser通过提供一套全面的3D场景和2D GUI原语，简化了3D可视化的过程，并支持灵活构建专业界面。

Method: Viser采用命令式API和基于Web的查看器设计。通过命令行最小配置即可独立使用各个功能元素，也可以组合使用以构建定制界面。设计考虑了与现代编程模式和工作流的兼容性。

Result: 提出了一个功能齐全的3D可视化库，包括丰富的3D场景和2D GUI元素，并提供了一个可扩展的平台，供开发者在计算机视觉和机器人任务中使用。

Conclusion: Viser库凭借其灵活性、易用性以及对现代工作流的支持，成为计算机视觉和机器人领域中强大的3D可视化工具。

Abstract: We present Viser, a 3D visualization library for computer vision and
robotics. Viser aims to bring easy and extensible 3D visualization to Python:
we provide a comprehensive set of 3D scene and 2D GUI primitives, which can be
used independently with minimal setup or composed to build specialized
interfaces. This technical report describes Viser's features, interface, and
implementation. Key design choices include an imperative-style API and a
web-based viewer, which improve compatibility with modern programming patterns
and workflows.

</details>


### [13] [Learning from Heterogeneous Structural MRI via Collaborative Domain Adaptation for Late-Life Depression Assessment](https://arxiv.org/abs/2507.22321)
*Yuzhen Gao,Qianqian Wang,Yongheng Sun,Cui Wang,Yongquan Liang,Mingxia Liu*

Main category: cs.CV

TL;DR: 提出了一种名为协作域适应（CDA）的框架，通过结合视觉Transformer（ViT）和卷积神经网络（CNN）来处理多源脑部MRI数据中的域差异问题，用于提高晚年抑郁症（LLD）检测的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练样本量小且存在域异质性（如成像协议、扫描设备和人口统计差异）时泛化能力差，导致跨域迁移效果不佳。

Method: CDA框架包括三个阶段：(a) 在带标签的源数据上监督训练ViT和CNN（每个分支包括编码器和分类器）；(b) 通过最小化ViT和CNN分类器输出的差异进行自监督目标特征适应，以清晰化分类边界；(c) 在未标记目标数据上进行协作训练：使用伪标签和增强后的目标域MRI数据，通过强制强增强和弱增强下预测一致性来提升域鲁棒性和泛化能力。

Result: 在多站点T1加权MRI数据上的实验表明，CDA持续优于最先进的无监督域适应方法。

Conclusion: 所提出的CDA框架通过融合全局（ViT）和局部（CNN）特征，结合分阶段训练策略有效处理了域异构问题，提升了LLD检测的泛化性能。

Abstract: Accurate identification of late-life depression (LLD) using structural brain
MRI is essential for monitoring disease progression and facilitating timely
intervention. However, existing learning-based approaches for LLD detection are
often constrained by limited sample sizes (e.g., tens), which poses significant
challenges for reliable model training and generalization. Although
incorporating auxiliary datasets can expand the training set, substantial
domain heterogeneity, such as differences in imaging protocols, scanner
hardware, and population demographics, often undermines cross-domain
transferability. To address this issue, we propose a Collaborative Domain
Adaptation (CDA) framework for LLD detection using T1-weighted MRIs. The CDA
leverages a Vision Transformer (ViT) to capture global anatomical context and a
Convolutional Neural Network (CNN) to extract local structural features, with
each branch comprising an encoder and a classifier. The CDA framework consists
of three stages: (a) supervised training on labeled source data, (b)
self-supervised target feature adaptation and (c) collaborative training on
unlabeled target data. We first train ViT and CNN on source data, followed by
self-supervised target feature adaptation by minimizing the discrepancy between
classifier outputs from two branches to make the categorical boundary clearer.
The collaborative training stage employs pseudo-labeled and augmented
target-domain MRIs, enforcing prediction consistency under strong and weak
augmentation to enhance domain robustness and generalization. Extensive
experiments conducted on multi-site T1-weighted MRI data demonstrate that the
CDA consistently outperforms state-of-the-art unsupervised domain adaptation
methods.

</details>


### [14] [UFV-Splatter: Pose-Free Feed-Forward 3D Gaussian Splatting Adapted to Unfavorable Views](https://arxiv.org/abs/2507.22342)
*Yuki Fujimura,Takahiro Kushida,Kazuya Kitano,Takuya Funatomi,Yasuhiro Mukaigawa*

Main category: cs.CV

TL;DR: 本文提出了一个无需姿态信息的前馈式3D高斯喷洒（3DGS）框架，用于处理不利的输入视角。通常，前馈方法在训练时将3D物体置于世界坐标系原点，并从指向原点的相机视角（即有利视角）进行渲染，限制了模型在涉及未知相机姿态的真实场景中的适用性。作者引入一种新的适应框架，使得预训练的无姿态前馈3DGS模型能够处理不利视角。方法包括：1）利用学习到的有利图像先验，通过将重心的图像输入加入低秩适应（LoRA）层的预训练模型；2）提出高斯适配器模块，增强从重心输入得到的高斯点的几何一致性；3）设计高斯对齐方法，为训练渲染准确的目标视角；4）利用仅含有利图像的现成数据集的训练策略。在Google Scanned Objects合成的图像和OmniObject3D的真实图像上实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈式3DGS模型假设输入图像是从指向原点的视角（有利视角）拍摄，但在真实场景中相机姿态可能不固定或未知，无法满足要求。因此，需要一种方法能够适应任意视角（特别是偏离中心的不利视角）输入的3D重建。

Method: 1. 提出一种适应框架，将预训练的无姿态前馈3DGS模型（如LRM）通过添加LoRA层来适配处理不利视角。2. 核心是使用一个高斯适配器模块：通过多层感知机（MLP）在图像编码器的中间层预测高斯参数的调整量（Δ），从而提高几何一致性。3. 引入高斯对齐机制：在训练时使用视角变换将已调整的高斯点对齐到目标视角以合成图像。4. 提出一个仅使用有利图像数据集的训练策略：首先将输入视角变换到以物体为中心的坐标系（recentering），然后将变换后的图像输入添加了LoRA层的预训练编码器，再通过高斯适配器细化高斯参数，最后将高斯点对齐到目标视角进行渲染。

Result: 在Google Scanned Objects（合成对象）和OmniObject3D（真实对象）数据集上的实验结果表明：1）在PSNR、SSIM、LPIPS指标上优于基线方法（如LRM、3DGS等）；2）能有效处理视角变化（45度偏移）而基线方法性能大幅下降；3）通过可视化对比，生成的不利视角图像质量显著高于基线方法（减少模糊和伪影）；4）消融研究确认了LoRA和高斯适配器的贡献；5）推理效率高（小于1秒/对象）。

Conclusion: 本文工作填补了预训练前馈3DGS模型在不利视角输入时的性能鸿沟。关键点在于：1）利用重心变换将任意视角输入转换为接近预训练模型期望的形式；2）通过LoRA微调预训练编码器；3）引入高斯适配器解决几何不一致性问题。该方法只需在预训练模型参数上进行少量优化，即可高效扩展到处理未知相机姿态的场景。

Abstract: This paper presents a pose-free, feed-forward 3D Gaussian Splatting (3DGS)
framework designed to handle unfavorable input views. A common rendering setup
for training feed-forward approaches places a 3D object at the world origin and
renders it from cameras pointed toward the origin -- i.e., from favorable
views, limiting the applicability of these models to real-world scenarios
involving varying and unknown camera poses. To overcome this limitation, we
introduce a novel adaptation framework that enables pretrained pose-free
feed-forward 3DGS models to handle unfavorable views. We leverage priors
learned from favorable images by feeding recentered images into a pretrained
model augmented with low-rank adaptation (LoRA) layers. We further propose a
Gaussian adapter module to enhance the geometric consistency of the Gaussians
derived from the recentered inputs, along with a Gaussian alignment method to
render accurate target views for training. Additionally, we introduce a new
training strategy that utilizes an off-the-shelf dataset composed solely of
favorable images. Experimental results on both synthetic images from the Google
Scanned Objects dataset and real images from the OmniObject3D dataset validate
the effectiveness of our method in handling unfavorable input views.

</details>


### [15] [DeltaVLM: Interactive Remote Sensing Image Change Analysis via Instruction-guided Difference Perception](https://arxiv.org/abs/2507.22346)
*Pei Deng,Wenqian Zhou,Hanlin Wu*

Main category: cs.CV

TL;DR: 提出了RSICA（遥感影像交互变化分析）新范式，结合变化检测（CD）和视觉问答（VQA）实现多轮指令驱动的双时相遥感影像变化分析；构建了大规模对话数据集ChangeChat，提出了端到端架构DeltaVLM（包含细调的双时相视觉编码器、差异感知模块和指令引导的Q-former），在多任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 传统多时相遥感影像分析方法仅能提供一次性变化掩膜或静态描述，缺乏交互性与查询驱动能力。RSICA融合CD与VQA的优势，使AI能够根据多轮指令动态回答用户关于图像变化的具体问题（六类任务），提升变化分析灵活性。

Method: 1. 构建ChangeChat数据集（105k指令样本）：混合规则生成和GPT辅助的标注流程覆盖六类任务（描述/分类/定量/定位/开放问答/多轮对话）。2. DeltaVLM模型：
  a. 微调Bi-temporal视觉编码器捕捉时相差异；
  b. 视觉差异感知模块引入跨语义关联度量机制（CSRM）；
  c. 指令引导Q-former提取查询相关的视觉变化特征。3.训练策略：冻结LLM，仅训练视觉与对齐模块提升效率。

Result: DeltaVLM在单轮描述/多轮交互分析任务上均达到SOTA性能，显著优于现有遥感视觉语言模型与多模态LLM（如MM-GPT、RS5M等）。

Conclusion: RSICA开创了遥感影像交互式变化分析的新任务范式；DeltaVLM以高效架构（局部训练）实现强大的多指令变化理解能力；ChangeChat数据集为社区提供重要资源（开源代码/模型/数据）。

Abstract: Accurate interpretation of land-cover changes in multi-temporal satellite
imagery is critical for real-world scenarios. However, existing methods
typically provide only one-shot change masks or static captions, limiting their
ability to support interactive, query-driven analysis. In this work, we
introduce remote sensing image change analysis (RSICA) as a new paradigm that
combines the strengths of change detection and visual question answering to
enable multi-turn, instruction-guided exploration of changes in bi-temporal
remote sensing images. To support this task, we construct ChangeChat-105k, a
large-scale instruction-following dataset, generated through a hybrid
rule-based and GPT-assisted process, covering six interaction types: change
captioning, classification, quantification, localization, open-ended question
answering, and multi-turn dialogues. Building on this dataset, we propose
DeltaVLM, an end-to-end architecture tailored for interactive RSICA. DeltaVLM
features three innovations: (1) a fine-tuned bi-temporal vision encoder to
capture temporal differences; (2) a visual difference perception module with a
cross-semantic relation measuring (CSRM) mechanism to interpret changes; and
(3) an instruction-guided Q-former to effectively extract query-relevant
difference information from visual changes, aligning them with textual
instructions. We train DeltaVLM on ChangeChat-105k using a frozen large
language model, adapting only the vision and alignment modules to optimize
efficiency. Extensive experiments and ablation studies demonstrate that
DeltaVLM achieves state-of-the-art performance on both single-turn captioning
and multi-turn interactive change analysis, outperforming existing multimodal
large language models and remote sensing vision-language models. Code, dataset
and pre-trained weights are available at https://github.com/hanlinwu/DeltaVLM.

</details>


### [16] [FaceGCD: Generalized Face Discovery via Dynamic Prefix Generation](https://arxiv.org/abs/2507.22353)
*Yunseok Oh,Dong-Wan Choi*

Main category: cs.CV

TL;DR: 该论文提出了广义人脸发现（GFD）任务，结合了传统人脸识别与广义类别发现（GCD），旨在识别已知标记和无标记身份的同时发现新身份。针对人脸ID的高维性和细粒度特性导致的现有GCD方法失效，作者提出了FaceGCD方法，通过基于超动态网络生成即时轻量级分层前缀来构建实例特定的特征提取器，从而在不依赖大模型的情况下捕捉身份细节。实验表明FaceGCD显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的人脸识别系统缺乏同时识别已知身份（包括标记和无标记的）和发现新身份的能力。受人类同时识别熟悉和陌生面孔能力的启发，作者希望推动人脸识别系统向开放世界、具备更强通用人工智能（AGI）能力的方向发展。传统广义类别发现（GCD）在处理人脸任务时面临高基数（大量身份）和细粒度（相似度高）的挑战，现有方法无法直接适用。

Method: 1. 任务定义：提出GFD任务，要求同时识别已知ID（含已标注和未标注部分）和发现新ID。
2. 方法设计（FaceGCD）：
   - 动态特征提取：采用轻量化的分层前缀机制，为每个输入实例生成特定的特征提取器（而非传统静态模型）。
   - 超网络架构：输入图像后由HyperNetwork自适应生成一组条件化的前缀生成器（prefix generators）。
   - 训练机制：通过构建这些可即时生成的动态结构，在避免增加模型复杂度的前提下，学习身份间的细微差别特征。
3. 技术优势：无需扩大模型容量，即能有效解决高基数/细粒度带来的泛化难题。

Result: 1. 在GFD任务上，FaceGCD显著优于现有GCD方法（如DeepCluster-v2, UNO）以及人脸识别基准模型ArcFace。
2. FaceGCD在所有测试集上均刷新了最佳性能（取得SOTA），特别是在发现新ID的指标上提升明显。
3. 消融实验证明了动态前缀机制的有效性：轻量级设计在提升性能的同时未引入计算负担。

Conclusion: 论文通过定义GFD任务和提出FaceGCD方法，解决了开放世界人脸识别的关键挑战。FaceGCD的动态前缀机制创新性地平衡了模型效率与对未知ID的发现能力，推动了人脸识别系统向更接近人类认知能力的开放世界场景迈进。该工作奠定了统一识别和发现范式的基础，是AGI在人脸领域的实质性进展。

Abstract: Recognizing and differentiating among both familiar and unfamiliar faces is a
critical capability for face recognition systems and a key step toward
artificial general intelligence (AGI). Motivated by this ability, this paper
introduces generalized face discovery (GFD), a novel open-world face
recognition task that unifies traditional face identification with generalized
category discovery (GCD). GFD requires recognizing both labeled and unlabeled
known identities (IDs) while simultaneously discovering new, previously unseen
IDs. Unlike typical GCD settings, GFD poses unique challenges due to the high
cardinality and fine-grained nature of face IDs, rendering existing GCD
approaches ineffective. To tackle this problem, we propose FaceGCD, a method
that dynamically constructs instance-specific feature extractors using
lightweight, layer-wise prefixes. These prefixes are generated on the fly by a
HyperNetwork, which adaptively outputs a set of prefix generators conditioned
on each input image. This dynamic design enables FaceGCD to capture subtle
identity-specific cues without relying on high-capacity static models.
Extensive experiments demonstrate that FaceGCD significantly outperforms
existing GCD methods and a strong face recognition baseline, ArcFace, achieving
state-of-the-art results on the GFD task and advancing toward open-world face
recognition.

</details>


### [17] [GVD: Guiding Video Diffusion Model for Scalable Video Distillation](https://arxiv.org/abs/2507.22360)
*Kunyang Li,Jeffrey A Chan Santiago,Sarinda Dhanesh Samarasinghe,Gaowen Liu,Mubarak Shah*

Main category: cs.CV

TL;DR: GVD（指导视频扩散）是首个基于扩散模型的视频数据集蒸馏方法，它通过联合蒸馏时空特征，在保持高保真视频生成的同时捕获关键运动信息。该方法在MiniUCF和HMDB51数据集上显著超越先前的最佳方法，分别达到了原始数据集性能的78.29%（仅使用1.98%的帧数）和73.83%（仅使用3.30%的帧数），同时支持更高分辨率视频和更高IPC的训练而不显著增加计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型视频数据集的计算与存储需求巨大，视频数据集蒸馏旨在通过提取关键时空信息构建一个极小的数据集，使其训练性能接近完整数据集训练结果。

Method: 提出GVD方法，这是一种基于扩散模型的视频蒸馏方法，联合蒸馏空间（外观）和时间（运动）特征。该方法通过引导生成过程确保生成视频具有高保真度与多样性，同时高效捕获核心运动信息。蒸馏过程覆盖帧级与跨帧一致性信息，从而保证视频序列的连贯性。

Result: 在多个IPC（每个类别的实例数）设置下（5/10/20 IPC），GVD在MiniUCF和HMDB51数据集上均刷新了SOTA。关键指标：1) MiniUCF：仅使用约2%帧数即达原数据78.3%性能；2) HMDB51：使用3.3%帧数达原数据73.8%性能。此外实验证明：GVD可生成更高分辨率视频，且提升IPC时计算开销增长可控。

Conclusion: GVD首次将扩散模型引入视频数据集蒸馏领域，其方法在性能保真度与计算效率上均突破现有技术极限，同时具备扩展性和普适性，为大规模视频理解任务提供了高效的数据压缩方案。

Abstract: To address the larger computation and storage requirements associated with
large video datasets, video dataset distillation aims to capture spatial and
temporal information in a significantly smaller dataset, such that training on
the distilled data has comparable performance to training on all of the data.
We propose GVD: Guiding Video Diffusion, the first diffusion-based video
distillation method. GVD jointly distills spatial and temporal features,
ensuring high-fidelity video generation across diverse actions while capturing
essential motion information. Our method's diverse yet representative
distillations significantly outperform previous state-of-the-art approaches on
the MiniUCF and HMDB51 datasets across 5, 10, and 20 Instances Per Class (IPC).
Specifically, our method achieves 78.29 percent of the original dataset's
performance using only 1.98 percent of the total number of frames in MiniUCF.
Additionally, it reaches 73.83 percent of the performance with just 3.30
percent of the frames in HMDB51. Experimental results across benchmark video
datasets demonstrate that GVD not only achieves state-of-the-art performance
but can also generate higher resolution videos and higher IPC without
significantly increasing computational cost.

</details>


### [18] [Object Recognition Datasets and Challenges: A Review](https://arxiv.org/abs/2507.22361)
*Aria Salari,Abtin Djavadifar,Xiangrui Liu,Homayoun Najjaran*

Main category: cs.CV

TL;DR: 对160多个公共数据集进行了详细分析，回顾了目标识别领域的重要数据集、基准测试和评估指标。


<details>
  <summary>Details</summary>
Motivation: 目标识别是计算机视觉应用中的基础任务，而数据集的规模和质量对深度学习技术的有效性至关重要。通过审视常用公开数据集的特征，可以为数据驱动和机器学习研究者提供重要参考。

Method: 通过对目标识别领域160多个公共数据集进行详尽的统计分析和特征描述，同时梳理了该领域的主要基准测试和比赛，并总结了常用的评估指标。所有数据集和挑战任务信息在github公开。

Result: 提供了多维度数据集分析报告；汇总了目标识别领域的核心基准测试和权威竞赛；整理了计算机视觉社区广泛采用的评估指标。

Conclusion: 深入分析公共数据集对识别模型的公平评估与研究发展具有重要作用；数据集信息的公开共享将促进整个领域的研究与合作。

Abstract: Object recognition is among the fundamental tasks in the computer vision
applications, paving the path for all other image understanding operations. In
every stage of progress in object recognition research, efforts have been made
to collect and annotate new datasets to match the capacity of the
state-of-the-art algorithms. In recent years, the importance of the size and
quality of datasets has been intensified as the utility of the emerging deep
network techniques heavily relies on training data. Furthermore, datasets lay a
fair benchmarking means for competitions and have proved instrumental to the
advancements of object recognition research by providing quantifiable
benchmarks for the developed models. Taking a closer look at the
characteristics of commonly-used public datasets seems to be an important first
step for data-driven and machine learning researchers. In this survey, we
provide a detailed analysis of datasets in the highly investigated object
recognition areas. More than 160 datasets have been scrutinized through
statistics and descriptions. Additionally, we present an overview of the
prominent object recognition benchmarks and competitions, along with a
description of the metrics widely adopted for evaluation purposes in the
computer vision community. All introduced datasets and challenges can be found
online at github.com/AbtinDjavadifar/ORDC.

</details>


### [19] [Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring](https://arxiv.org/abs/2507.22369)
*Sinh Trong Vu,Hieu Trung Pham,Dung Manh Nguyen,Hieu Minh Hoang,Nhu Hoang Le,Thu Ha Pham,Tai Tan Mai*

Main category: cs.CV

TL;DR: 本研究提出了基于视觉问答（VQA）模型的课堂行为分析方法，并在越南银行学院真实课堂视频数据集（BAV-Classroom-VQA）上评估了包括LLaMA2、LLaMA3、QWEN3和NVILA在内的先进开源模型。实验结果表明，所有模型在行为相关视觉问题上均表现出良好性能，展示了其在未来课堂分析系统中的潜力。


<details>
  <summary>Details</summary>
Motivation: 课堂行为监测对教育研究至关重要，但人工分析效率低下。随着VQA模型的发展，自动分析复杂课堂互动成为可能。本研究旨在探索当前最先进的开源VQA模型在课堂行为分析任务中的适用性。

Method: 1）创建BAV-Classroom-VQA数据集：在越南银行学院采集真实课堂视频，并进行专业标注；2）模型选择：挑选LLaMA2、LLaMA3、QWEN3和NVILA四种开源VQA模型；3）实验设计：在构建的数据集上测试模型回答行为相关视觉问题的能力。

Result: 所有测试模型（LLaMA2/3, QWEN3, NVILA）均在课堂行为视觉问答任务中展现出良好性能（具体指标未提及），验证了VQA模型在复杂课堂场景中的实用性。

Conclusion: 实验证明先进VQA模型可有效用于课堂行为分析，为未来自动化课堂监控与教育干预系统奠定了基础。后续将扩大数据集规模并优化模型对教育特定场景的适应性。

Abstract: Classroom behavior monitoring is a critical aspect of educational research,
with significant implications for student engagement and learning outcomes.
Recent advancements in Visual Question Answering (VQA) models offer promising
tools for automatically analyzing complex classroom interactions from video
recordings. In this paper, we investigate the applicability of several
state-of-the-art open-source VQA models, including LLaMA2, LLaMA3, QWEN3, and
NVILA, in the context of classroom behavior analysis. To facilitate rigorous
evaluation, we introduce our BAV-Classroom-VQA dataset derived from real-world
classroom video recordings at the Banking Academy of Vietnam. We present the
methodology for data collection, annotation, and benchmark the performance of
the selected VQA models on this dataset. Our initial experimental results
demonstrate that all four models achieve promising performance levels in
answering behavior-related visual questions, showcasing their potential in
future classroom analytics and intervention systems.

</details>


### [20] [Gems: Group Emotion Profiling Through Multimodal Situational Understanding](https://arxiv.org/abs/2507.22393)
*Anubhav Kataria,Surbhi Madan,Shreya Ghosh,Tom Gedeon,Abhinav Dhall*

Main category: cs.CV

TL;DR: 该论文介绍了GEMS框架，用于预测细粒度个体情绪到粗粒度群体和事件级别的情绪。它采用多模态swin-transformer和S3Attention架构，通过VGAF-GEMS基准数据集进行验证，并在个体、群体和情境情绪预测上取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 当前多人员情绪相关基准主要关注基于时间感知和群体级别的原子互动，缺乏对个体、群体和事件情绪及其上下文信息的细粒度综合理解。为了解决这个问题，论文提出了GEMS框架和VGAF-GEMS基准数据集。

Method: 1. 框架设计：GEMS利用多模态swin-transformer和S3Attention架构，处理输入场景、群体成员和上下文信息，联合预测离散/连续基本情绪（包括效价和激活度）以及个体、群体和事件级感知情绪。2. 数据扩展：在VGAF数据集的群体级别标注基础上构建VGAF-GEMS基准，提供更细粒度和全面的分析。3. 评估：与现有最先进模型进行定量和定性比较。

Result: GEMS框架在VGAF-GEMS基准上表现优异，定量和定性分析均证明了其在个体、群体和事件层面情绪预测的有效性，为全面理解社会情境中的情绪铺平了道路。

Conclusion: GEMS通过整合个体、群体和情境情绪反应，实现了更细粒度的多级别情绪分析。提出的VGAF-GEMS基准和模型架构为未来研究提供了新方向，代码和数据已开源。

Abstract: Understanding individual, group and event level emotions along with
contextual information is crucial for analyzing a multi-person social
situation. To achieve this, we frame emotion comprehension as the task of
predicting fine-grained individual emotion to coarse grained group and event
level emotion. We introduce GEMS that leverages a multimodal swin-transformer
and S3Attention based architecture, which processes an input scene, group
members, and context information to generate joint predictions. Existing
multi-person emotion related benchmarks mainly focus on atomic interactions
primarily based on emotion perception over time and group level. To this end,
we extend and propose VGAF-GEMS to provide more fine grained and holistic
analysis on top of existing group level annotation of VGAF dataset. GEMS aims
to predict basic discrete and continuous emotions (including valence and
arousal) as well as individual, group and event level perceived emotions. Our
benchmarking effort links individual, group and situational emotional responses
holistically. The quantitative and qualitative comparisons with adapted
state-of-the-art models demonstrate the effectiveness of GEMS framework on
VGAF-GEMS benchmarking. We believe that it will pave the way of further
research. The code and data is available at:
https://github.com/katariaak579/GEMS

</details>


### [21] [On the Reliability of Vision-Language Models Under Adversarial Frequency-Domain Perturbations](https://arxiv.org/abs/2507.22398)
*Jordan Vice,Naveed Akhtar,Yansong Gao,Richard Hartley,Ajmal Mian*

Main category: cs.CV

TL;DR: 本文揭示了视觉语言模型（VLMs）在频率域中受到结构化扰动的脆弱性，说明了这些扰动对自动图像字幕和DeepFake检测任务的破坏效果。研究表明，微小的频率变换能显著改变五款前沿VLM模型的输出，暴露了它们在实际应用中的不可靠性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索VLMs对频率域中细微结构扰动的鲁棒性，特别关注这些模型在关键视觉任务（如图像字幕和DeepFake检测）中面对针对性扰动的表现。现有的研究揭示了深度模型的脆弱性，但对于多模态VLMs在频率域扰动的稳健性研究仍不完善，此工作是填补这一空白的尝试。

Method: 论文创建了在频率域的特定扰动方法，包括对真实图像和合成图像注入干扰以系统地操纵VLM的输出。研究者通过实验评估了五个前沿VLM模型的稳健性以覆盖不同架构：包括Qwen2/2.5和BLIP的不同变体。实验中选取了十类真实图片和生成式数据集在两种场景下应用扰动。随后，使用频域干扰在‘黑盒’使用条件下测试各模型对扰动图像的反应能力。

Result: 论文证实了VLMs对频率域扰动具有高敏感性，即便在微小空间频率变化（肉眼不可见）下，其输出也发生偏移；该操作不仅破坏了图像真实性检测、也篡改了自动描述文本结果。测试结果在五类VLM上全部展现高度一致性：针对频率的扰动使系统产生错误判断；同时指出其在检测合成图像时依赖频率特征而非语义内容。

Conclusion: 该研究发现，在频域中实施轻微扰动会严重欺骗视觉语言模型，揭示了当前VLMs在自动化视觉任务中存在明显缺陷。该结论挑战了VLMs作为多模态感知系统的可靠性，提示后续应通过引入更加稳健的频率鲁棒训练方案以提升模型安全性。

Abstract: Vision-Language Models (VLMs) are increasingly used as perceptual modules for
visual content reasoning, including through captioning and DeepFake detection.
In this work, we expose a critical vulnerability of VLMs when exposed to
subtle, structured perturbations in the frequency domain. Specifically, we
highlight how these feature transformations undermine authenticity/DeepFake
detection and automated image captioning tasks. We design targeted image
transformations, operating in the frequency domain to systematically adjust VLM
outputs when exposed to frequency-perturbed real and synthetic images. We
demonstrate that the perturbation injection method generalizes across five
state-of-the-art VLMs which includes different-parameter Qwen2/2.5 and BLIP
models. Experimenting across ten real and generated image datasets reveals that
VLM judgments are sensitive to frequency-based cues and may not wholly align
with semantic content. Crucially, we show that visually-imperceptible spatial
frequency transformations expose the fragility of VLMs deployed for automated
image captioning and authenticity detection tasks. Our findings under
realistic, black-box constraints challenge the reliability of VLMs,
underscoring the need for robust multimodal perception systems.

</details>


### [22] [MINR: Implicit Neural Representations with Masked Image Modelling](https://arxiv.org/abs/2507.22404)
*Sua Lee,Joonhun Lee,Myungjoo Kang*

Main category: cs.CV

TL;DR: MINR框架将隐式神经表示与掩码图像建模结合，以学习连续函数表达图像，提升掩码策略的鲁棒性和泛化能力。在分布内和分布外场景中均优于MAE，同时降低模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法（如MAE）的性能高度依赖训练时的掩码策略，且在分布外数据上表现退化。为解决这一问题，提出MINR框架。

Method: 融合隐式神经表示(INR)与掩码图像建模(MIM)：用连续函数建模图像，通过坐标点映射像素值并训练网络根据掩码坐标预测像素值。支持任意掩码策略且保持重建鲁棒性。

Result: 1) MINR在分布内（同源数据）场景超越MAE性能 2) 在分布外（如分布偏移/未见数据）场景表现更稳健 3) 模型参数更少，复杂度降低

Conclusion: MINR作为自监督学习新框架，具有掩码鲁棒性强、泛化性能好、效率高的优势，适用于多种下游任务。

Abstract: Self-supervised learning methods like masked autoencoders (MAE) have shown
significant promise in learning robust feature representations, particularly in
image reconstruction-based pretraining task. However, their performance is
often strongly dependent on the masking strategies used during training and can
degrade when applied to out-of-distribution data. To address these limitations,
we introduce the masked implicit neural representations (MINR) framework that
synergizes implicit neural representations with masked image modeling. MINR
learns a continuous function to represent images, enabling more robust and
generalizable reconstructions irrespective of masking strategies. Our
experiments demonstrate that MINR not only outperforms MAE in in-domain
scenarios but also in out-of-distribution settings, while reducing model
complexity. The versatility of MINR extends to various self-supervised learning
applications, confirming its utility as a robust and efficient alternative to
existing frameworks.

</details>


### [23] [Moiré Zero: An Efficient and High-Performance Neural Architecture for Moiré Removal](https://arxiv.org/abs/2507.22407)
*Seungryong Lee,Woojeong Baek,Younghyun Kim,Eunwoo Kim,Haru Moon,Donggon Yoo,Eunbyung Park*

Main category: cs.CV

TL;DR: 本文提出了一种称为MZNet的U形网络结构，旨在通过多尺度双注意力块（MSDAB）、多形状大卷积核块（MSLKB）和基于特征融合的跳跃连接三个关键组件来消除图像中的摩尔纹，从而解决现有方法在去除多尺度、多方向及颜色偏移摩尔纹时的问题。


<details>
  <summary>Details</summary>
Motivation: 摩尔纹是由精细重复结构与相机传感器采样过程之间的频率混叠引起的，在消费摄影和工业缺陷检测等领域造成严重干扰。虽然已有基于卷积神经网络（CNN）的解决方案，但其受限的感知野难以有效捕捉摩尔纹复杂多变的属性（如尺度、方向、颜色偏移），从而导致处理效果不佳。

Method: 1. 设计U形网络MZNet，包含三个核心组件：
   - 多尺度双注意力块（MSDAB）：提取和优化多尺度特征；
   - 多形状大卷积核块（MSLKB）：通过异形大卷积核捕捉各种摩尔纹结构；
   - 基于特征融合的跳跃连接：加强信息流动。
2. 联合优化局部纹理恢复和大尺度伪影抑制。

Result: 在多个基准数据集上，MZNet在高分辨率数据集上取得最先进性能，在低分辨率数据集上表现也具竞争力；同时计算成本较低，适合实际应用。

Conclusion: MZNet通过引入自适应多尺度/多形状特征提取机制与改进的信息传递结构，显著提升了对复杂摩尔纹的去除能力，验证了其在效率和效果上优于现有方法。

Abstract: Moir\'e patterns, caused by frequency aliasing between fine repetitive
structures and a camera sensor's sampling process, have been a significant
obstacle in various real-world applications, such as consumer photography and
industrial defect inspection. With the advancements in deep learning
algorithms, numerous studies-predominantly based on convolutional neural
networks-have suggested various solutions to address this issue. Despite these
efforts, existing approaches still struggle to effectively eliminate artifacts
due to the diverse scales, orientations, and color shifts of moir\'e patterns,
primarily because the constrained receptive field of CNN-based architectures
limits their ability to capture the complex characteristics of moir\'e
patterns. In this paper, we propose MZNet, a U-shaped network designed to bring
images closer to a 'Moire-Zero' state by effectively removing moir\'e patterns.
It integrates three specialized components: Multi-Scale Dual Attention Block
(MSDAB) for extracting and refining multi-scale features, Multi-Shape Large
Kernel Convolution Block (MSLKB) for capturing diverse moir\'e structures, and
Feature Fusion-Based Skip Connection for enhancing information flow. Together,
these components enhance local texture restoration and large-scale artifact
suppression. Experiments on benchmark datasets demonstrate that MZNet achieves
state-of-the-art performance on high-resolution datasets and delivers
competitive results on lower-resolution dataset, while maintaining a low
computational cost, suggesting that it is an efficient and practical solution
for real-world applications. Project page:
https://sngryonglee.github.io/MoireZero

</details>


### [24] [UAVScenes: A Multi-Modal Dataset for UAVs](https://arxiv.org/abs/2507.22412)
*Sijie Wang,Siqi Li,Yawei Zhang,Shangshu Yu,Shenghai Yuan,Rui She,Quanjiang Guo,JinXuan Zheng,Ong Kang Howe,Leonrich Chandra,Shrivarshann Srijeyan,Aditya Sivadas,Toshan Aggarwal,Heyuan Liu,Hongming Zhang,Chujie Chen,Junyu Jiang,Lihua Xie,Wee Peng Tay*

Main category: cs.CV

TL;DR: 本文介绍了UAVScenes数据集，用于多模态无人机感知的基准测试，提供图像和LiDAR点云的标注以及精确的6-DoF位姿，支持多种感知任务。


<details>
  <summary>Details</summary>
Motivation: 现有无人机多模态数据集主要偏向定位和3D重建，缺乏逐帧标注，无法支持高层场景理解任务。因此，作者提出了UAVScenes来弥补这一空白。

Method: 在MARS-LVIG数据集的基础上，增加了图像和点云的逐帧语义标注以及6-DoF位姿。

Result: 构建了UAVScenes数据集，支持分割、深度估计、定位、场景识别和视图合成等任务。

Conclusion: UAVScenes数据集填补了多模态无人机感知领域的空白，为多种任务提供支持，推动高级场景理解的发展。

Abstract: Multi-modal perception is essential for unmanned aerial vehicle (UAV)
operations, as it enables a comprehensive understanding of the UAVs'
surrounding environment. However, most existing multi-modal UAV datasets are
primarily biased toward localization and 3D reconstruction tasks, or only
support map-level semantic segmentation due to the lack of frame-wise
annotations for both camera images and LiDAR point clouds. This limitation
prevents them from being used for high-level scene understanding tasks. To
address this gap and advance multi-modal UAV perception, we introduce
UAVScenes, a large-scale dataset designed to benchmark various tasks across
both 2D and 3D modalities. Our benchmark dataset is built upon the
well-calibrated multi-modal UAV dataset MARS-LVIG, originally developed only
for simultaneous localization and mapping (SLAM). We enhance this dataset by
providing manually labeled semantic annotations for both frame-wise images and
LiDAR point clouds, along with accurate 6-degree-of-freedom (6-DoF) poses.
These additions enable a wide range of UAV perception tasks, including
segmentation, depth estimation, 6-DoF localization, place recognition, and
novel view synthesis (NVS). Our dataset is available at
https://github.com/sijieaaa/UAVScenes

</details>


### [25] [Aleatoric Uncertainty Medical Image Segmentation Estimation via Flow Matching](https://arxiv.org/abs/2507.22418)
*Phi Van Nguyen,Ngoc Huynh Trinh,Duy Minh Lam Nguyen,Phu Loc Nguyen,Quoc Long Tran*

Main category: cs.CV

TL;DR: 该论文针对医学图像分割中难以量化标注者之间固有变异性（aleatoric uncertainty）的问题，提出了一种基于条件流匹配（conditional flow matching）的方法，以生成精确的分割样本并可靠地反映数据分布的不确定性。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分割中，多个专家标注者之间存在的自然变异性（aleatoric uncertainty）难以被准确捕捉。现有的生成模型（如扩散模型）虽能逼近数据分布，但依赖于随机采样且无法精确建模密度，因此限制了其捕捉不确定性的准确性。

Method: 作者提出使用条件流匹配（一种无模拟、基于流的生成模型）来学习精确的密度函数。该方法在输入图像的引导下训练流模型，通过对模型进行多次采样，生成多个分割样本；接着计算像素级方差来量化不确定性，从而反映数据分布及标注者之间的差异。具体地，模型从输入图像条件化分割分布，并合成多样本，其方差能突出边界模糊区域的不确定性。

Result: 实验结果表明，该方法在分割准确性方面具备竞争力，同时生成的uncertainty map能有效揭示分割结果的可靠性，尤其是在标注者分歧大的区域（如边界模糊处）。此外，代码已开源。

Conclusion: 条件流匹配模型凭借其精确密度建模和高效采样能力，可准确捕获医学图像分割中的不确定性，为临床决策提供更透明的可靠性分析。

Abstract: Quantifying aleatoric uncertainty in medical image segmentation is critical
since it is a reflection of the natural variability observed among expert
annotators. A conventional approach is to model the segmentation distribution
using the generative model, but current methods limit the expression ability of
generative models. While current diffusion-based approaches have demonstrated
impressive performance in approximating the data distribution, their inherent
stochastic sampling process and inability to model exact densities limit their
effectiveness in accurately capturing uncertainty. In contrast, our proposed
method leverages conditional flow matching, a simulation-free flow-based
generative model that learns an exact density, to produce highly accurate
segmentation results. By guiding the flow model on the input image and sampling
multiple data points, our approach synthesizes segmentation samples whose
pixel-wise variance reliably reflects the underlying data distribution. This
sampling strategy captures uncertainties in regions with ambiguous boundaries,
offering robust quantification that mirrors inter-annotator differences.
Experimental results demonstrate that our method not only achieves competitive
segmentation accuracy but also generates uncertainty maps that provide deeper
insights into the reliability of the segmentation outcomes. The code for this
paper is freely available at https://github.com/huynhspm/Data-Uncertainty

</details>


### [26] [Efficient Spatial-Temporal Modeling for Real-Time Video Analysis: A Unified Framework for Action Recognition and Object Tracking](https://arxiv.org/abs/2507.22421)
*Shahla John*

Main category: cs.CV

TL;DR: 一种新颖的分层注意力机制统一框架，在UCF-101、HMDB-51和MOT17上超越SOTA 3.2%（行为识别）/2.8%（追踪精度），速度快40%。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在资源受限环境中兼顾实时视频分析的时空建模精度与速度平衡

Method: 基于并行序列建模技术，构建同时进行行为识别和物体追踪的统一框架，引入自适应时空相关区域的分层注意力机制

Result: 标准基准测试中实时推理速度下取得SOTA：UCF-101/HMDB-51/MOT17数据集上行为识别准确率提升3.2%，物体追踪精度提升2.8%，推理速度快40%

Conclusion: 所提出的统一框架通过分层注意力机制有效提升视频分析任务的性能与效率，实现精度与速度的突破性平衡

Abstract: Real-time video analysis remains a challenging problem in computer vision,
requiring efficient processing of both spatial and temporal information while
maintaining computational efficiency. Existing approaches often struggle to
balance accuracy and speed, particularly in resource-constrained environments.
In this work, we present a unified framework that leverages advanced
spatial-temporal modeling techniques for simultaneous action recognition and
object tracking. Our approach builds upon recent advances in parallel sequence
modeling and introduces a novel hierarchical attention mechanism that
adaptively focuses on relevant spatial regions across temporal sequences. We
demonstrate that our method achieves state-of-the-art performance on standard
benchmarks while maintaining real-time inference speeds. Extensive experiments
on UCF-101, HMDB-51, and MOT17 datasets show improvements of 3.2% in action
recognition accuracy and 2.8% in tracking precision compared to existing
methods, with 40% faster inference time.

</details>


### [27] [HQ-CLIP: Leveraging Large Vision-Language Models to Create High-Quality Image-Text Datasets and CLIP Models](https://arxiv.org/abs/2507.22431)
*Zhixiang Wei,Guangting Wang,Xiaoxiao Ma,Ke Mei,Huaian Chen,Yi Jin,Fengyun Rao*

Main category: cs.CV

TL;DR: 提出一种利用大规模视觉语言模型（LVLM）驱动的数据精炼流程，从图像和原始替代文本中生成多粒度的正负文本描述，构建VLM-150M数据集。在该数据集上训练了HQ-CLIP模型，通过融入负描述和短标签作为新的监督信号，在多项任务中达到了先进水平。


<details>
  <summary>Details</summary>
Motivation: CLIP模型的成功依赖于大规模的图像-文本对数据集。同时，基于CLIP的大规模视觉语言模型（LVLMs）得到了快速发展。是否可以利用LVLMs反过来提升训练图像-文本对数据集质量，形成自我强化的提升循环？

Method: 1. 数据精炼流程：使用LVLM处理图像和原始替代文本，生成4种文本描述：长正描述、长负描述、短正标签和短负标签
2. 基于DFN-Large数据集构建VLM-150M数据集，具有多粒度标注
3. 训练模型（HQ-CLIP）：扩展传统对比学习，融入负描述和短标签作为额外的监督信号

Result: 1. 基于VLM-150M训练HQ-CLIP
2. 在零样本分类、跨模态检索和细粒度视觉理解任务中达到最先进水平
3. 在检索任务上，HQ-CLIP超越了基于DFN-2B（10倍训练数据）训练的CLIP模型

Conclusion: 提出的LVLM驱动的数据精炼流程可以显著提升数据集质量。新训练的HQ-CLIP在多个任务上展现出优越性能，证明通过融入多粒度的正负文本监督信号可有效改进CLIP模型。

Abstract: Large-scale but noisy image-text pair data have paved the way for the success
of Contrastive Language-Image Pretraining (CLIP). As the foundation vision
encoder, CLIP in turn serves as the cornerstone for most large vision-language
models (LVLMs). This interdependence naturally raises an interesting question:
Can we reciprocally leverage LVLMs to enhance the quality of image-text pair
data, thereby opening the possibility of a self-reinforcing cycle for
continuous improvement? In this work, we take a significant step toward this
vision by introducing an LVLM-driven data refinement pipeline. Our framework
leverages LVLMs to process images and their raw alt-text, generating four
complementary textual formulas: long positive descriptions, long negative
descriptions, short positive tags, and short negative tags. Applying this
pipeline to the curated DFN-Large dataset yields VLM-150M, a refined dataset
enriched with multi-grained annotations. Based on this dataset, we further
propose a training paradigm that extends conventional contrastive learning by
incorporating negative descriptions and short tags as additional supervised
signals. The resulting model, namely HQ-CLIP, demonstrates remarkable
improvements across diverse benchmarks. Within a comparable training data
scale, our approach achieves state-of-the-art performance in zero-shot
classification, cross-modal retrieval, and fine-grained visual understanding
tasks. In retrieval benchmarks, HQ-CLIP even surpasses standard CLIP models
trained on the DFN-2B dataset, which contains 10$\times$ more training data
than ours. All code, data, and models are available at
https://zxwei.site/hqclip.

</details>


### [28] [From Sharp to Blur: Unsupervised Domain Adaptation for 2D Human Pose Estimation Under Extreme Motion Blur Using Event Cameras](https://arxiv.org/abs/2507.22438)
*Youngho Kim,Hoonhee Cho,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: 本文提出了一种利用事件相机进行领域自适应的方法，以解决运动模糊导致的人体姿态估计性能下降问题。通过事件数据增强生成运动模糊图像，并结合师生框架迭代优化伪标签，方法在运动模糊条件下显著提升了姿态估计的鲁棒性，无需目标域标注。


<details>
  <summary>Details</summary>
Motivation: 在快速运动或低光环境下，运动模糊会显著降低人体姿态估计模型的性能。现有数据集通常假设理想光照和静态条件，导致模型在模糊场景下出现领域差距。事件相机因高时间分辨率和抗运动模糊特性成为潜在解决方案，但缺乏针对事件相机与模糊图像间领域自适应的方法。

Method: 1. 事件数据增强：利用事件相机采集的高频运动信息合成运动感知模糊图像，弥合清晰图像与模糊图像间的领域差距；2. 师生框架：教师模型在模糊图像上生成伪标签，学生模型通过互不确定性掩码筛选可靠标签进行训练；3. 迭代优化：通过掩码过滤错误伪标签并交替更新师生模型，逐步提升目标域性能。

Result: 实验表明，本文方法在运动模糊场景下超越现有领域自适应姿态估计方法。在无需目标域标注的情况下，平均精度（AP）指标显著提升（具体数值需参考原文），验证了事件相机在领域自适应中的有效性。

Conclusion: 事件相机可作为解决运动模糊场景下人体姿态估计领域差距的强有力工具。所提出的领域自适应框架通过事件增强和伪标签优化实现了不依赖标注的跨域适应，为实际应用提供了可扩展方案。代码已开源。

Abstract: Human pose estimation is critical for applications such as rehabilitation,
sports analytics, and AR/VR systems. However, rapid motion and low-light
conditions often introduce motion blur, significantly degrading pose estimation
due to the domain gap between sharp and blurred images. Most datasets assume
stable conditions, making models trained on sharp images struggle in blurred
environments. To address this, we introduce a novel domain adaptation approach
that leverages event cameras, which capture high temporal resolution motion
data and are inherently robust to motion blur. Using event-based augmentation,
we generate motion-aware blurred images, effectively bridging the domain gap
between sharp and blurred domains without requiring paired annotations.
Additionally, we develop a student-teacher framework that iteratively refines
pseudo-labels, leveraging mutual uncertainty masking to eliminate incorrect
labels and enable more effective learning. Experimental results demonstrate
that our approach outperforms conventional domain-adaptive human pose
estimation methods, achieving robust pose estimation under motion blur without
requiring annotations in the target domain. Our findings highlight the
potential of event cameras as a scalable and effective solution for domain
adaptation in real-world motion blur environments. Our project codes are
available at https://github.com/kmax2001/EvSharp2Blur.

</details>


### [29] [TopoLiDM: Topology-Aware LiDAR Diffusion Models for Interpretable and Realistic LiDAR Point Cloud Generation](https://arxiv.org/abs/2507.22454)
*Jiuming Liu,Zheng Huang,Mengmeng Liu,Tianchen Deng,Francesco Nex,Hao Cheng,Hesheng Wang*

Main category: cs.CV

TL;DR: 提出了一种名为TopoLiDM的创新LiDAR场景生成框架，它结合了图神经网络和扩散模型，并通过拓扑正则化（如使用持续同调约束）来保证生成数据的几何真实性和全局拓扑一致性，显著降低了生成指标的FRID和MMD，并在KITTI-360数据集上展现优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LiDAR扩散模型为提高效率常将点云嵌入潜在空间，导致在捕捉几何细节和保持全局拓扑一致性方面能力不足，这阻碍了它们生成真实且具有一致性的LiDAR场景。

Method: 1. 首先训练一个具有拓扑保持能力的变分自编码器（VAE），通过图构建和多个图卷积层提取潜在图表示。
2. 冻结VAE，使用潜在扩散模型在潜在图空间生成新的拓扑图结构。
3. 引入0维持续同调（PH）约束，确保生成的LiDAR场景符合真实世界的全局拓扑结构。

Result: 在KITTI-360数据集上，TopoLiDM相比SOTA方法显著提升了性能：FRID降低了22.6%，MMD降低了9.2%。此外，推理速度平均达到1.68样本/秒，具有高效生成能力。

Conclusion: TopoLiDM结合GNN和扩散模型，并引入拓扑正则化，成功解决了现有方法在几何真实性和全局拓扑一致性上的不足，不仅在性能指标上大幅提升，且推理速度快，具有实际应用前景。

Abstract: LiDAR scene generation is critical for mitigating real-world LiDAR data
collection costs and enhancing the robustness of downstream perception tasks in
autonomous driving. However, existing methods commonly struggle to capture
geometric realism and global topological consistency. Recent LiDAR Diffusion
Models (LiDMs) predominantly embed LiDAR points into the latent space for
improved generation efficiency, which limits their interpretable ability to
model detailed geometric structures and preserve global topological
consistency. To address these challenges, we propose TopoLiDM, a novel
framework that integrates graph neural networks (GNNs) with diffusion models
under topological regularization for high-fidelity LiDAR generation. Our
approach first trains a topological-preserving VAE to extract latent graph
representations by graph construction and multiple graph convolutional layers.
Then we freeze the VAE and generate novel latent topological graphs through the
latent diffusion models. We also introduce 0-dimensional persistent homology
(PH) constraints, ensuring the generated LiDAR scenes adhere to real-world
global topological structures. Extensive experiments on the KITTI-360 dataset
demonstrate TopoLiDM's superiority over state-of-the-art methods, achieving
improvements of 22.6% lower Frechet Range Image Distance (FRID) and 9.2% lower
Minimum Matching Distance (MMD). Notably, our model also enables fast
generation speed with an average inference time of 1.68 samples/s, showcasing
its scalability for real-world applications. We will release the related codes
at https://github.com/IRMVLab/TopoLiDM.

</details>


### [30] [Exploiting Diffusion Prior for Task-driven Image Restoration](https://arxiv.org/abs/2507.22459)
*Jaeha Kim,Junghun Oh,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: 提出了一种名为EDTR的新方法，利用扩散先验进行任务驱动的图像修复（TDIR），以恢复与任务相关的细节，提升高复杂退化下的任务性能和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有的任务驱动图像修复方法难以处理多重复杂退化导致的图像质量问题，而扩散先验作为强大的自然图像先验，虽然能生成视觉上合理的结果，但如何将其用于恢复与任务相关的细节仍然困难。因此，作者旨在有效利用扩散先验，解决TDIR中的性能下降问题。

Method: EDTR方法的核心是直接在扩散过程中利用低质量图像的线索：首先，对输入的低质量图像进行预恢复（基于像素误差），并添加少量噪声；然后，通过少量去噪步骤生成修复图像，以避免产生冗余细节而稀释关键任务信息。该方法结合了扩散模型的生成能力和任务驱动的修复目标。

Result: 该方法在多种任务（面临多重复杂退化）中显著提升了视觉质量和任务性能，证明了扩散先验在TDIR中的有效利用。

Conclusion: EDTR成功地将扩散先验应用于任务驱动的图像修复，通过直接利用低质量图像的线索并减少去噪步骤生成高质量图像，不仅恢复了视觉上合理的细节，还着重增强了与任务相关的信息，从而在复杂退化场景下实现了显著的性能提升。

Abstract: Task-driven image restoration (TDIR) has recently emerged to address
performance drops in high-level vision tasks caused by low-quality (LQ) inputs.
Previous TDIR methods struggle to handle practical scenarios in which images
are degraded by multiple complex factors, leaving minimal clues for
restoration. This motivates us to leverage the diffusion prior, one of the most
powerful natural image priors. However, while the diffusion prior can help
generate visually plausible results, using it to restore task-relevant details
remains challenging, even when combined with recent TDIR methods. To address
this, we propose EDTR, which effectively harnesses the power of diffusion prior
to restore task-relevant details. Specifically, we propose directly leveraging
useful clues from LQ images in the diffusion process by generating from
pixel-error-based pre-restored LQ images with mild noise added. Moreover, we
employ a small number of denoising steps to prevent the generation of redundant
details that dilute crucial task-related information. We demonstrate that our
method effectively utilizes diffusion prior for TDIR, significantly enhancing
task performance and visual quality across diverse tasks with multiple complex
degradations.

</details>


### [31] [Shallow Features Matter: Hierarchical Memory with Heterogeneous Interaction for Unsupervised Video Object Segmentation](https://arxiv.org/abs/2507.22465)
*Zheng Xiangyu,He Songcheng,Li Wanyun,Li Xiaoqiang,Zhang Wei*

Main category: cs.CV

TL;DR: 提出一种新型分层记忆架构HMHI-Net，通过结合浅层与深层特征解决现有UVOS方法过度依赖高层语义特征导致细节丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督视频目标分割方法过度依赖记忆高层语义特征，但忽略浅层像素级细粒度信息，导致预测精度受限。分析表明高层特征缺乏细节信息是核心问题。

Method: 1) 构建分层记忆架构：同时存储浅层像素特征和高层语义特征；2) 提出异构交互机制: PLAM模块利用高层特征引导浅层特征对齐局部细节，SGIM模块利用浅层细节优化全局语义整合；3) 通过像素-语义双向交互平衡两种特征。

Result: 在UVOS和视频显著性检测基准上全面达到SOTA，且在不同骨干网络下均保持高性能，展现优越性和鲁棒性。

Conclusion: 证明同时利用像素级细节和语义信息的必要性，所提异构交互机制有效融合多级特征，为UVOS领域提供了新解决方案。

Abstract: Unsupervised Video Object Segmentation (UVOS) aims to predict pixel-level
masks for the most salient objects in videos without any prior annotations.
While memory mechanisms have been proven critical in various video segmentation
paradigms, their application in UVOS yield only marginal performance gains
despite sophisticated design. Our analysis reveals a simple but fundamental
flaw in existing methods: over-reliance on memorizing high-level semantic
features. UVOS inherently suffers from the deficiency of lacking fine-grained
information due to the absence of pixel-level prior knowledge. Consequently,
memory design relying solely on high-level features, which predominantly
capture abstract semantic cues, is insufficient to generate precise
predictions. To resolve this fundamental issue, we propose a novel hierarchical
memory architecture to incorporate both shallow- and high-level features for
memory, which leverages the complementary benefits of pixel and semantic
information. Furthermore, to balance the simultaneous utilization of the pixel
and semantic memory features, we propose a heterogeneous interaction mechanism
to perform pixel-semantic mutual interactions, which explicitly considers their
inherent feature discrepancies. Through the design of Pixel-guided Local
Alignment Module (PLAM) and Semantic-guided Global Integration Module (SGIM),
we achieve delicate integration of the fine-grained details in shallow-level
memory and the semantic representations in high-level memory. Our Hierarchical
Memory with Heterogeneous Interaction Network (HMHI-Net) consistently achieves
state-of-the-art performance across all UVOS and video saliency detection
benchmarks. Moreover, HMHI-Net consistently exhibits high performance across
different backbones, further demonstrating its superiority and robustness.
Project page: https://github.com/ZhengxyFlow/HMHI-Net .

</details>


### [32] [Visual Language Models as Zero-Shot Deepfake Detectors](https://arxiv.org/abs/2507.22469)
*Viacheslav Pirogov*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉语言模型（VLM）的零样本领能力的深度伪造检测方法，实验表明其在高质量数据集上优于现有方法，并在DFDC-P数据集上通过零样本和微调两种场景验证了VLM相对于传统分类器的优越性。


<details>
  <summary>Details</summary>
Motivation: 针对深度伪造（deepfakes）对数字媒体和身份验证等领域构成的威胁，现有检测方法多集中在图像域分类且缺乏辅助任务增强鲁棒性。本文创新性地利用VLM的零样本来提升检测效果。

Method: 1) 提出利用视觉语言模型的零样本能力进行深度伪造检测；2) 构建新的高质量深度伪造数据集（含60,000张图）；3) 在零样本与微调两种场景下评估模型，并与传统分类器比较，选用最佳架构InstructBLIP。

Result: 1) 在60,000张图新数据集上的零样本性能超越几乎所有现有方法；2) 在DFDC-P数据集上，InstructBLIP的零样本/微调性能均优于传统分类器，证实VLM有效性。

Conclusion: 采用VLM的深度伪造检测策略显著优于传统分类器，且VLM的零样本迁移潜力为不依赖样本的伪造检测提供新思路，尤其在高质量数据集上性能卓越。

Abstract: The contemporary phenomenon of deepfakes, utilizing GAN or diffusion models
for face swapping, presents a substantial and evolving threat in digital media,
identity verification, and a multitude of other systems. The majority of
existing methods for detecting deepfakes rely on training specialized
classifiers to distinguish between genuine and manipulated images, focusing
only on the image domain without incorporating any auxiliary tasks that could
enhance robustness. In this paper, inspired by the zero-shot capabilities of
Vision Language Models, we propose a novel VLM-based approach to image
classification and then evaluate it for deepfake detection. Specifically, we
utilize a new high-quality deepfake dataset comprising 60,000 images, on which
our zero-shot models demonstrate superior performance to almost all existing
methods. Subsequently, we compare the performance of the best-performing
architecture, InstructBLIP, on the popular deepfake dataset DFDC-P against
traditional methods in two scenarios: zero-shot and in-domain fine-tuning. Our
results demonstrate the superiority of VLMs over traditional classifiers.

</details>


### [33] [LIDAR: Lightweight Adaptive Cue-Aware Fusion Vision Mamba for Multimodal Segmentation of Structural Cracks](https://arxiv.org/abs/2507.22477)
*Hui Liu,Chen Jia,Fan Shi,Xu Cheng,Mengfei Shi,Xia Xie,Shengyong Chen*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级自适应线索感知视觉Mamba网络（LIDAR），用于在裂缝分割任务中实现低计算成本的像素级分割。该方法通过自适应感知和高效交互融合跨模态特征，解决了现有方法在跨模态线索感知和融合方面的不足。


<details>
  <summary>Details</summary>
Motivation: 在裂缝分割任务中，利用多模态数据以较低的计算成本实现像素级分割仍是一个关键挑战。现有方法缺乏自适应感知能力和高效的跨模态特征交互融合能力。因此，需要一种能够高效感知并整合不同模态的形态学和纹理线索的方法。

Method: LIDAR由轻量级自适应线索感知视觉状态空间模块（LacaVSS）和轻量级双域动态协作融合模块（LD3CF）组成。LacaVSS通过掩码引导的高效动态引导扫描策略（EDG-SS）自适应建模裂缝线索。LD3CF则利用自适应频域感知器（AFDP）和双池化融合策略捕捉跨模态的空间和频域线索。此外，还设计了轻量级动态调制多核卷积（LDMK）以最小计算开销感知复杂形态结构，替代了LIDAR中的大部分卷积操作。

Result: 在三个数据集上的实验表明，该方法优于其他最先进方法。在光场深度数据集上，仅用5.35M参数就实现了0.8204的F1分数和0.8465的mIoU。

Conclusion: 提出的LIDAR网络通过高效的自适应感知和跨模态融合机制，以及轻量化的结构设计，成功实现了低计算成本下的高精度裂缝分割。方法在多个指标上超越了现有SOTA，同时模型参数量大幅减少，具有实际应用价值。

Abstract: Achieving pixel-level segmentation with low computational cost using
multimodal data remains a key challenge in crack segmentation tasks. Existing
methods lack the capability for adaptive perception and efficient interactive
fusion of cross-modal features. To address these challenges, we propose a
Lightweight Adaptive Cue-Aware Vision Mamba network (LIDAR), which efficiently
perceives and integrates morphological and textural cues from different
modalities under multimodal crack scenarios, generating clear pixel-level crack
segmentation maps. Specifically, LIDAR is composed of a Lightweight Adaptive
Cue-Aware Visual State Space module (LacaVSS) and a Lightweight Dual Domain
Dynamic Collaborative Fusion module (LD3CF). LacaVSS adaptively models crack
cues through the proposed mask-guided Efficient Dynamic Guided Scanning
Strategy (EDG-SS), while LD3CF leverages an Adaptive Frequency Domain
Perceptron (AFDP) and a dual-pooling fusion strategy to effectively capture
spatial and frequency-domain cues across modalities. Moreover, we design a
Lightweight Dynamically Modulated Multi-Kernel convolution (LDMK) to perceive
complex morphological structures with minimal computational overhead, replacing
most convolutional operations in LIDAR. Experiments on three datasets
demonstrate that our method outperforms other state-of-the-art (SOTA) methods.
On the light-field depth dataset, our method achieves 0.8204 in F1 and 0.8465
in mIoU with only 5.35M parameters. Code and datasets are available at
https://github.com/Karl1109/LIDAR-Mamba.

</details>


### [34] [Estimating 2D Camera Motion with Hybrid Motion Basis](https://arxiv.org/abs/2507.22480)
*Haipeng Li,Tianhao Zhou,Zhanglei Yang,Yi Wu,Yan Chen,Zijing Mao,Shen Cheng,Bing Zeng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: 提出了一个名为CamFlow的新框架，通过结合物理基（来自相机几何）和随机基（用于复杂场景）来表示相机运动，并引入了基于Laplace分布的混合概率损失函数来提高训练的鲁棒性。在动态目标被掩蔽的新基准测试中，CamFlow在零样本设置中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的2D相机运动估计方法存在局限性：基于单应性的方法仅适用于平面场景，而基于网格流的方法难以处理复杂的非线性变换。本文观察到，来自不同单应性的流场组合会产生无法用任何单一单应性表示的运动模式。因此，需要一种能够更灵活表示相机运动的方法。

Method: 1. 引入CamFlow框架，使用混合运动基表示相机运动：物理基（源自相机几何）捕捉基础运动，随机基处理更复杂的场景变换。2. 设计了一种基于Laplace分布的混合概率损失函数，提高模型训练的鲁棒性。3. 在现有光流数据集上通过掩蔽动态目标创建新的基准数据集，以隔离纯粹的相机运动。

Result: 1. 实验表明，CamFlow在多样场景中优于现有最先进方法。2. 在零样本设置下表现出更好的鲁棒性和泛化能力。3. 代码和数据集已在项目页面公开。

Conclusion: CamFlow通过混合运动基表示方法有效解决了现有2D相机运动估计方法的局限性，尤其是在处理复杂非线性变换方面的不足。提出的混合损失函数和新基准数据集进一步推动了该领域的研究。

Abstract: Estimating 2D camera motion is a fundamental computer vision task that models
the projection of 3D camera movements onto the 2D image plane. Current methods
rely on either homography-based approaches, limited to planar scenes, or
meshflow techniques that use grid-based local homographies but struggle with
complex non-linear transformations. A key insight of our work is that combining
flow fields from different homographies creates motion patterns that cannot be
represented by any single homography. We introduce CamFlow, a novel framework
that represents camera motion using hybrid motion bases: physical bases derived
from camera geometry and stochastic bases for complex scenarios. Our approach
includes a hybrid probabilistic loss function based on the Laplace distribution
that enhances training robustness. For evaluation, we create a new benchmark by
masking dynamic objects in existing optical flow datasets to isolate pure
camera motion. Experiments show CamFlow outperforms state-of-the-art methods
across diverse scenarios, demonstrating superior robustness and generalization
in zero-shot settings. Code and datasets are available at our project page:
https://lhaippp.github.io/CamFlow/.

</details>


### [35] [Robust Adverse Weather Removal via Spectral-based Spatial Grouping](https://arxiv.org/abs/2507.22498)
*Yuhwan Jeong,Yunseo Yang,Youngjo Yoon,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: 本文提出SSGformer，一种基于频谱分解和分组注意力的多天气图像恢复方法，解决现有All-in-One模型在处理复杂局部退化时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有All-in-One模型使用全局滤波方法（如频域直接操作）难以处理高度变化和局部化的扭曲退化问题。

Method: 1. 使用边缘检测提取高频特征，SVD分解提取低频信息。2. 多头条形注意力建模特征间关系并融合生成分组掩码。3. 提出分组注意力和空间分组变换块（结合通道和空间注意力）。

Result: 大量实验证明SSGformer在恢复精度上具有优越性，可以有效处理多样化的恶劣天气退化。

Conclusion: 提出的频谱空间分组方法能够有效捕获不同天气的复杂退化模式，通过分组注意力机制实现鲁棒的天气图像恢复。

Abstract: Adverse weather conditions cause diverse and complex degradation patterns,
driving the development of All-in-One (AiO) models. However, recent AiO
solutions still struggle to capture diverse degradations, since global
filtering methods like direct operations on the frequency domain fail to handle
highly variable and localized distortions. To address these issue, we propose
Spectral-based Spatial Grouping Transformer (SSGformer), a novel approach that
leverages spectral decomposition and group-wise attention for multi-weather
image restoration. SSGformer decomposes images into high-frequency edge
features using conventional edge detection and low-frequency information via
Singular Value Decomposition. We utilize multi-head linear attention to
effectively model the relationship between these features. The fused features
are integrated with the input to generate a grouping-mask that clusters regions
based on the spatial similarity and image texture. To fully leverage this mask,
we introduce a group-wise attention mechanism, enabling robust adverse weather
removal and ensuring consistent performance across diverse weather conditions.
We also propose a Spatial Grouping Transformer Block that uses both channel
attention and spatial attention, effectively balancing feature-wise
relationships and spatial dependencies. Extensive experiments show the
superiority of our approach, validating its effectiveness in handling the
varied and intricate adverse weather degradations.

</details>


### [36] [DACA-Net: A Degradation-Aware Conditional Diffusion Network for Underwater Image Enhancement](https://arxiv.org/abs/2507.22501)
*Chang Huang,Jiahang Cao,Jun Ma,Kieren Yu,Cong Li,Huayong Yang,Kaishun Wu*

Main category: cs.CV

TL;DR: 本文提出了一种基于条件扩散模型的退化感知水下图像增强方法，利用退化分数指导自适应恢复网络，结合物理先验和对比损失，显著提升了图像的颜色保真度、感知质量和结构细节。


<details>
  <summary>Details</summary>
Motivation: 水下图像常因散射和吸收等光学效应出现颜色失真、低可见度和结构模糊，现有增强方法难以自适应处理多样化退化情况且未能有效利用水下物理先验。

Method: 1. 使用轻量级双流卷积网络预测输入图像的连续退化分数；2. 基于该分数构建Swin UNet主干的条件扩散恢复网络，实现自适应噪声调度和分层特征优化；3. 设计退化引导的自适应特征融合模块；4. 结合感知一致性、直方图匹配和特征对比的混合损失函数进行训练。

Result: 在多个基准数据集上验证，本方法在颜色保真度、感知质量和结构细节恢复方面均优于现有技术，定量指标和定性视觉评估均有显著提升。

Conclusion: 退化感知的条件扩散模型能有效利用水下物理先验实现自适应增强，为水下图像恢复及下游视觉任务提供了鲁棒解决方案。

Abstract: Underwater images typically suffer from severe colour distortions, low
visibility, and reduced structural clarity due to complex optical effects such
as scattering and absorption, which greatly degrade their visual quality and
limit the performance of downstream visual perception tasks. Existing
enhancement methods often struggle to adaptively handle diverse degradation
conditions and fail to leverage underwater-specific physical priors
effectively. In this paper, we propose a degradation-aware conditional
diffusion model to enhance underwater images adaptively and robustly. Given a
degraded underwater image as input, we first predict its degradation level
using a lightweight dual-stream convolutional network, generating a continuous
degradation score as semantic guidance. Based on this score, we introduce a
novel conditional diffusion-based restoration network with a Swin UNet
backbone, enabling adaptive noise scheduling and hierarchical feature
refinement. To incorporate underwater-specific physical priors, we further
propose a degradation-guided adaptive feature fusion module and a hybrid loss
function that combines perceptual consistency, histogram matching, and
feature-level contrast. Comprehensive experiments on benchmark datasets
demonstrate that our method effectively restores underwater images with
superior colour fidelity, perceptual quality, and structural details. Compared
with SOTA approaches, our framework achieves significant improvements in both
quantitative metrics and qualitative visual assessments.

</details>


### [37] [AlphaDent: A dataset for automated tooth pathology detection](https://arxiv.org/abs/2507.22512)
*Evgeniy I. Sosnin,Yuriy L. Vasilev,Roman A. Solovyev,Aleksandr L. Stempkovskiy,Dmitry V. Telpukhov,Artem A. Vasilev,Aleksandr A. Amerikanov,Aleksandr Y. Romanov*

Main category: cs.CV

TL;DR: 文章介绍了一个名为AlphaDent的新牙科研究数据集，包含295名患者的牙齿照片（超过1200张图像），标注用于实例分割任务，并分为9个类别。文章详细描述了数据集、标注格式及基于该数据集的实例分割实验，结果显示了高质量的预测性能。数据集、代码和模型权重均开源。


<details>
  <summary>Details</summary>
Motivation: 为了解决牙科研究中缺乏高质量标注数据集的问题，作者创建了一个基于真实患者牙齿照片的数据集AlphaDent。

Method: 使用295名患者的牙齿照片建立数据集（1200多张图像），每个图像都标注并分为9个类。建立方法：1）数据采集：通过DSLR相机拍摄患者牙齿；2）数据标注：进行实例分割标注；3）数据集划分：用于训练和评估；4）模型训练：使用该数据集训练神经网络；5）实验设置：训练与评估实例分割模型。

Result: 实验获得了高质量的预测结果（具体指标未在摘要中给出），模型的推理性能良好，数据集和代码已公开。

Conclusion: AlphaDent是一个高质量、公开可用的牙科图像数据集，经过验证的实例分割模型在真实场景中表现优异，为推动牙科研究提供了基础资源。

Abstract: In this article, we present a new unique dataset for dental research -
AlphaDent. This dataset is based on the DSLR camera photographs of the teeth of
295 patients and contains over 1200 images. The dataset is labeled for solving
the instance segmentation problem and is divided into 9 classes. The article
provides a detailed description of the dataset and the labeling format. The
article also provides the details of the experiment on neural network training
for the Instance Segmentation problem using this dataset. The results obtained
show high quality of predictions. The dataset is published under an open
license; and the training/inference code and model weights are also available
under open licenses.

</details>


### [38] [HRVVS: A High-resolution Video Vasculature Segmentation Network via Hierarchical Autoregressive Residual Priors](https://arxiv.org/abs/2507.22530)
*Xincheng Yao,Yijun Yang,Kangwei Guo,Ruiqiang Xiao,Haipeng Zhou,Haisu Tao,Jian Yang,Lei Zhu*

Main category: cs.CV

TL;DR: 提出了一个高质量肝胆手术视频数据集HRVVS和一个新型高分辨率视频血管分割网络HRVVS，通过嵌入预训练的VAR模型和使用动态记忆解码器，显著提升了血管分割效果。


<details>
  <summary>Details</summary>
Motivation: 肝胆手术视频中肝血管分割至关重要，但缺乏合适的数据集且任务复杂，因此目前研究较少。为解决该问题，本文构建了一个高质量标注数据集并提出了新的分割网络。

Method: 1. 构建包含35个长视频和11442帧的高质量标注数据集；2. 提出HRVVS网络：在分层编码器中嵌入预训练的VAR模型以减少下采样信息损失；3. 设计多视图分割网络上的动态记忆解码器，最小化冗余信息传递同时保留帧间细节。

Result: 在手术视频数据集上的大量实验证明，HRVVS显著优于现有最先进方法。

Conclusion: 本文提出的数据集和HRVVS网络有效解决了手术视频中肝血管分割难题，代码和数据集将开源。

Abstract: The segmentation of the hepatic vasculature in surgical videos holds
substantial clinical significance in the context of hepatectomy procedures.
However, owing to the dearth of an appropriate dataset and the inherently
complex task characteristics, few researches have been reported in this domain.
To address this issue, we first introduce a high quality frame-by-frame
annotated hepatic vasculature dataset containing 35 long hepatectomy videos and
11442 high-resolution frames. On this basis, we propose a novel high-resolution
video vasculature segmentation network, dubbed as HRVVS. We innovatively embed
a pretrained visual autoregressive modeling (VAR) model into different layers
of the hierarchical encoder as prior information to reduce the information
degradation generated during the downsampling process. In addition, we designed
a dynamic memory decoder on a multi-view segmentation network to minimize the
transmission of redundant information while preserving more details between
frames. Extensive experiments on surgical video datasets demonstrate that our
proposed HRVVS significantly outperforms the state-of-the-art methods. The
source code and dataset will be publicly available at
\href{https://github.com/scott-yjyang/xx}{https://github.com/scott-yjyang/HRVVS}.

</details>


### [39] [RainbowPrompt: Diversity-Enhanced Prompt-Evolving for Continual Learning](https://arxiv.org/abs/2507.22553)
*Kiseong Hong,Gyeong-hyeon Kim,Eunwoo Kim*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的提示演化机制，通过自适应整合基础提示（任务特定提示）来提升表示多样性，解决现有基于提示的持续学习方法中表示多样性不足的问题，并在图像分类和视频动作识别任务上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于提示的持续学习方法存在表示多样性受限的问题：要么依赖固定学习的提示（在新任务学习期间表示不变），要么依赖从纠缠的任务共享空间生成的提示。这导致无法有效整合任务特定知识以满足序列任务的复杂需求。

Method: 1. 提出提示演化机制：自适应地将基础提示（包括先前学习的和新引入的任务特定提示）聚合为统一提示，同时确保多样性。通过转换和对齐基础提示，持续演化累积知识以促进新任务学习。
2. 引入可学习的概率门：自适应确定在演化过程中激活哪些层。
3. 在图像分类和视频动作识别任务上验证方法，采用类增量学习设置。

Result: 在图像分类和视频动作识别任务的类增量学习场景中，相比现有方法平均提升9.07%和7.40%。

Conclusion: 提示演化机制通过自适应聚合任务特定提示并确保表示多样性，有效增强了基于提示的持续学习性能，显著优于现有方法。

Abstract: Prompt-based continual learning provides a rehearsal-free solution by tuning
small sets of parameters while keeping pre-trained models frozen. To meet the
complex demands of sequential tasks, it is crucial to integrate task-specific
knowledge within prompts effectively. However, existing works rely on either
fixed learned prompts (i.e., prompts whose representations remain unchanged
during new task learning) or on prompts generated from an entangled task-shared
space, limiting the representational diversity of the integrated prompt. To
address this issue, we propose a novel prompt-evolving mechanism to adaptively
aggregate base prompts (i.e., task-specific prompts) into a unified prompt
while ensuring diversity. By transforming and aligning base prompts, both
previously learned and newly introduced, our approach continuously evolves
accumulated knowledge to facilitate learning new tasks. We further introduce a
learnable probabilistic gate that adaptively determines which layers to
activate during the evolution process. We validate our method on image
classification and video action recognition tasks in class-incremental
learning, achieving average gains of 9.07% and 7.40% over existing methods
across all scenarios.

</details>


### [40] [Subtyping Breast Lesions via Generative Augmentation based Long-tailed Recognition in Ultrasound](https://arxiv.org/abs/2507.22568)
*Shijing Chen,Xinrui Zhou,Yuhao Wang,Yuhao Huang,Ao Chang,Dong Ni,Ruobing Huang*

Main category: cs.CV

TL;DR: 提出了一种针对长尾分布的乳腺超声图像分类的双阶段框架，通过强化学习驱动的自适应采样器和类可控制的合成网络，生成高保真图像以平衡数据分布，避免过拟合，并在长尾数据集上实现优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺病变亚型的准确识别有助于个性化治疗。超声成像应用广泛，但不同亚型的发病率呈长尾分布，不利于自动识别。生成式增强可纠正数据分布，但需要避免过度使用导致整体性能下降。

Method: 1. 提出双阶段框架：第一阶段通过强化学习驱动的自适应采样器动态校准合成图像与真实图像的比例，补偿数据稀缺性，同时保持判别能力稳定；第二阶段使用类可控制的合成网络，集成基于草图的感知分支，利用解剖先验保持类别特征，实现无注释推理。

Result: 在内部长尾和公共不平衡乳腺超声数据集上验证，与现有方法相比具有优越性能；同时提供了大量合成图像示例。

Conclusion: 所提框架通过高保真数据合成和动态数据比例校准，有效缓解长尾分布问题，在乳腺超声影像分类中实现高精度。

Abstract: Accurate identification of breast lesion subtypes can facilitate personalized
treatment and interventions. Ultrasound (US), as a safe and accessible imaging
modality, is extensively employed in breast abnormality screening and
diagnosis. However, the incidence of different subtypes exhibits a skewed
long-tailed distribution, posing significant challenges for automated
recognition. Generative augmentation provides a promising solution to rectify
data distribution. Inspired by this, we propose a dual-phase framework for
long-tailed classification that mitigates distributional bias through
high-fidelity data synthesis while avoiding overuse that corrupts holistic
performance. The framework incorporates a reinforcement learning-driven
adaptive sampler, dynamically calibrating synthetic-real data ratios by
training a strategic multi-agent to compensate for scarcities of real data
while ensuring stable discriminative capability. Furthermore, our
class-controllable synthetic network integrates a sketch-grounded perception
branch that harnesses anatomical priors to maintain distinctive class features
while enabling annotation-free inference. Extensive experiments on an in-house
long-tailed and a public imbalanced breast US datasets demonstrate that our
method achieves promising performance compared to state-of-the-art approaches.
More synthetic images can be found at
https://github.com/Stinalalala/Breast-LT-GenAug.

</details>


### [41] [COOkeD: Ensemble-based OOD detection in the era of zero-shot CLIP](https://arxiv.org/abs/2507.22576)
*Galadrielle Humblot-Renaux,Gianni Franchi,Sergio Escalera,Thomas B. Moeslund*

Main category: cs.CV

TL;DR: 本文介绍了一个名为COOkeD的新方法，通过结合不同的分类器（包括特定任务训练的封闭世界分类器、基于CLIP的零样本分类器以及CLIP视觉特征的线性分类器），形成一个异构集成模型，以提升OOD检测（未知分布检测）的性能和鲁棒性。该方法在多个基准测试中实现了SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测方法通常使用单一分类器（如传统的监督学习模型或基于CLIP的零样本模型），其性能受限于ID数据的处理能力。作者提出通过融合不同分类器（具有不同优势）形成异构集成模型来克服这一限制。

Method: 提出COOkeD方法，融合三个分类器：1) 在特定数据集上微调的传统封闭世界分类器；2) 基于CLIP文本特征的零样本分类器；3) 基于CLIP视觉特征预训练模型的线性分类器。采用后处理整合策略，无需训练集标签外的标签。

Result: 在CIFAR100、ImageNet及其更具挑战性的场景（含标签噪声、协变量偏移、零样本偏移）中均取得了显著提升，相比现有方法（包括经典方法与CLIP基方法）达到最佳性能和最强鲁棒性。

Conclusion: 通过巧妙组合已有的不同类型的分类器构建轻量异构集成模型，可大幅提高OOD检测的效率。

Abstract: Out-of-distribution (OOD) detection is an important building block in
trustworthy image recognition systems as unknown classes may arise at
test-time. OOD detection methods typically revolve around a single classifier,
leading to a split in the research field between the classical supervised
setting (e.g. ResNet18 classifier trained on CIFAR100) vs. the zero-shot
setting (class names fed as prompts to CLIP). In both cases, an overarching
challenge is that the OOD detection performance is implicitly constrained by
the classifier's capabilities on in-distribution (ID) data. In this work, we
show that given a little open-mindedness from both ends, remarkable OOD
detection can be achieved by instead creating a heterogeneous ensemble - COOkeD
combines the predictions of a closed-world classifier trained end-to-end on a
specific dataset, a zero-shot CLIP classifier, and a linear probe classifier
trained on CLIP image features. While bulky at first sight, this approach is
modular, post-hoc and leverages the availability of pre-trained VLMs, thus
introduces little overhead compared to training a single standard classifier.
We evaluate COOkeD on popular CIFAR100 and ImageNet benchmarks, but also
consider more challenging, realistic settings ranging from training-time label
noise, to test-time covariate shift, to zero-shot shift which has been
previously overlooked. Despite its simplicity, COOkeD achieves state-of-the-art
performance and greater robustness compared to both classical and CLIP-based
OOD detection methods. Code is available at https://github.com/glhr/COOkeD

</details>


### [42] [Robust Deepfake Detection for Electronic Know Your Customer Systems Using Registered Images](https://arxiv.org/abs/2507.22601)
*Takuma Amada,Kazuya Kakizaki,Taiki Miyagawa,Akinori F. Ebihara,Kaede Shiohara,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: 本文提出了一种专为电子身份认证（eKYC）系统设计的深度伪造检测算法。算法通过检测身份特征的时间不一致性、利用注册图像计算身份差异，以及使用更大数据集训练的特征提取器，来检测人脸替换和重现攻击，并对图像退化具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了提高eKYC系统抵御深度伪造攻击的能力，需要开发一种稳健的深度伪造检测器，能够涵盖人脸替换和人脸重现两种攻击形式，并且能够抵御图像退化带来的影响。

Method: 1. 通过人脸识别模型提取身份特征向量，检测视频中的身份时间不一致性。2. 利用注册的真实图像计算输入视频与注册图像的身份差异。3. 使用更大数据集训练的人脸特征提取器来提高检测性能和鲁棒性。

Result: 实验结果表明，该方法能准确检测人脸替换和人脸重现攻击，并对多种未知形式的图像退化具有较好的鲁棒性。

Conclusion: 该方法通过结合时间不一致性检测、注册图像辅助判断和更强大的特征提取器，显著提升了eKYC系统中深度伪造检测的准确性和鲁棒性。

Abstract: In this paper, we present a deepfake detection algorithm specifically
designed for electronic Know Your Customer (eKYC) systems. To ensure the
reliability of eKYC systems against deepfake attacks, it is essential to
develop a robust deepfake detector capable of identifying both face swapping
and face reenactment, while also being robust to image degradation. We address
these challenges through three key contributions: (1)~Our approach evaluates
the video's authenticity by detecting temporal inconsistencies in identity
vectors extracted by face recognition models, leading to comprehensive
detection of both face swapping and face reenactment. (2)~In addition to
processing video input, the algorithm utilizes a registered image (assumed to
be genuine) to calculate identity discrepancies between the input video and the
registered image, significantly improving detection accuracy. (3)~We find that
employing a face feature extractor trained on a larger dataset enhances both
detection performance and robustness against image degradation. Our
experimental results show that our proposed method accurately detects both face
swapping and face reenactment comprehensively and is robust against various
forms of unseen image degradation. Our source code is publicly available
https://github.com/TaikiMiyagawa/DeepfakeDetection4eKYC.

</details>


### [43] [ShortFT: Diffusion Model Alignment via Shortcut-based Fine-Tuning](https://arxiv.org/abs/2507.22604)
*Xiefan Guo,Miaomiao Cui,Liefeng Bo,Di Huang*

Main category: cs.CV

TL;DR: 提出了Shortcut-based Fine-Tuning (ShortFT)方法，通过利用更短的去噪链和轨迹保留的少步扩散模型提高基于反向传播的扩散模型与奖励函数对齐的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于反向传播的扩散模型对齐方法由于梯度传播链过长导致的梯度爆炸风险和高计算成本，导致无法实现完整的梯度回传，优化效果不佳。

Method: 利用轨迹保留的少步扩散模型构建更短的去噪链，称为Shortcut-based Fine-Tuning (ShortFT)，能够更高效地进行基础模型微调。

Result: 经严格测试，该方法有效适用于多种奖励函数，显著提升对齐性能，优于现有方法。

Conclusion: ShortFT方法在效率和性能上都显著优于现有方法，为解决长时间去噪链带来的计算和优化问题提供了有效方案。

Abstract: Backpropagation-based approaches aim to align diffusion models with reward
functions through end-to-end backpropagation of the reward gradient within the
denoising chain, offering a promising perspective. However, due to the
computational costs and the risk of gradient explosion associated with the
lengthy denoising chain, existing approaches struggle to achieve complete
gradient backpropagation, leading to suboptimal results. In this paper, we
introduce Shortcut-based Fine-Tuning (ShortFT), an efficient fine-tuning
strategy that utilizes the shorter denoising chain. More specifically, we
employ the recently researched trajectory-preserving few-step diffusion model,
which enables a shortcut over the original denoising chain, and construct a
shortcut-based denoising chain of shorter length. The optimization on this
chain notably enhances the efficiency and effectiveness of fine-tuning the
foundational model. Our method has been rigorously tested and can be
effectively applied to various reward functions, significantly improving
alignment performance and surpassing state-of-the-art alternatives.

</details>


### [44] [VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning](https://arxiv.org/abs/2507.22607)
*Ruifeng Yuan,Chenghao Xiao,Sicong Leng,Jianyu Wang,Long Li,Weiwen Xu,Hou Pong Chan,Deli Zhao,Tingyang Xu,Zhongyu Wei,Hao Zhang,Yu Rong*

Main category: cs.CV

TL;DR: 本文提出了一种称为VL-Cogito的多模态推理模型，使用了一种新颖的多阶段渐进课程强化学习（PCuRL）框架进行训练。该框架通过逐步增加任务难度来提升模型在多模态环境中的推理能力，并引入了两个关键创新：难度软加权机制和动态长度奖励机制。实验证明，VL-Cogito在多个主流多模态基准测试中达到了与现有推理导向模型相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 由于多模态任务在语义内容和问题形式上的复杂性和多样性，现有模型在不同领域和难度级别上的表现不稳定。为了克服这些限制，作者提出了PCuRL框架，旨在通过结构化的强化学习阶段提升模型在多模态任务中的推理能力。

Method: 1. 使用多阶段渐进课程强化学习（PCuRL）框架进行训练，逐步提高任务难度。2. 引入在线难度软加权机制，在连续的强化学习训练阶段中动态调整训练难度。3. 采用动态长度奖励机制，使模型能够根据任务复杂性自适应调节推理路径长度，平衡推理效率和正确性。

Result: 在数学、科学、逻辑和一般理解等多个主流多模态基准测试中，VL-Cogito模型的表现与现有的推理导向模型相当或更好，验证了PCuRL框架的有效性。

Conclusion: PCuRL框架通过渐进式难度训练和创新的奖励机制，显著提升了多模态推理模型在各种复杂任务中的表现，为解决多模态推理任务中的不稳定性问题提供了有效解决方案。

Abstract: Reinforcement learning has proven its effectiveness in enhancing the
reasoning capabilities of large language models. Recent research efforts have
progressively extended this paradigm to multimodal reasoning tasks. Due to the
inherent complexity and diversity of multimodal tasks, especially in semantic
content and problem formulations, existing models often exhibit unstable
performance across various domains and difficulty levels. To address these
limitations, we propose VL-Cogito, an advanced multimodal reasoning model
trained via a novel multi-stage Progressive Curriculum Reinforcement Learning
(PCuRL) framework. PCuRL systematically guides the model through tasks of
gradually increasing difficulty, substantially improving its reasoning
abilities across diverse multimodal contexts. The framework introduces two key
innovations: (1) an online difficulty soft weighting mechanism, dynamically
adjusting training difficulty across successive RL training stages; and (2) a
dynamic length reward mechanism, which encourages the model to adaptively
regulate its reasoning path length according to task complexity, thus balancing
reasoning efficiency with correctness. Experimental evaluations demonstrate
that VL-Cogito consistently matches or surpasses existing reasoning-oriented
models across mainstream multimodal benchmarks spanning mathematics, science,
logic, and general understanding, validating the effectiveness of our approach.

</details>


### [45] [Generative Active Learning for Long-tail Trajectory Prediction via Controllable Diffusion Model](https://arxiv.org/abs/2507.22615)
*Daehee Park,Monu Surana,Pranav Desai,Ashish Mehta,Reuben MV John,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: 本文提出了一种名为GALTraj的新方法，通过改进训练过程来解决数据驱动的轨迹预测模型在处理罕见长尾场景时的不足。该方法利用生成式主动学习识别模型失败的尾部样本，并使用可控扩散模型进行增强，显著提升了在尾部样本上的性能，并同时提高了头部样本的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的轨迹预测方法在处理长尾场景（即罕见但关键的情境）时表现不佳。虽然已有工作通过修改模型结构（如使用超网络）来应对，但本文认为无需改变模型结构，通过优化训练过程即可充分挖掘模型潜力。因此，引入生成式主动学习来解决长尾问题。

Method: 提出GALTraj方法：1）主动识别模型在尾部样本上的失败案例；2）使用可控扩散模型对识别出的尾部样本进行增强生成，确保生成样本的多样性、真实性和对尾部分布特性的保留；3）设计了一种尾部感知的生成机制，通过定制化的扩散指导同时捕获罕见行为和遵守交通规则。整个流程将模拟器的增强整合到训练过程中优化长尾学习。

Result: 在多个轨迹预测数据集（WOMD、Argoverse2）和主流模型（QCNet、MTR）上验证：GALTraj显著提升模型在尾部样本的性能，同时头部样本的准确性也得到增强。实验表明，该方法比仅关注场景多样性的传统模拟方法更有效地改善长尾学习。

Conclusion: GALTraj首次成功将生成式主动学习引入轨迹预测领域，通过不改变模型结构而优化训练过程，证明了可控扩散增强对长尾学习的有效性。该方法为应对自动驾驶中的关键长尾挑战提供了新思路，且具备通用性和扩展性。

Abstract: While data-driven trajectory prediction has enhanced the reliability of
autonomous driving systems, it still struggles with rarely observed long-tail
scenarios. Prior works addressed this by modifying model architectures, such as
using hypernetworks. In contrast, we propose refining the training process to
unlock each model's potential without altering its structure. We introduce
Generative Active Learning for Trajectory prediction (GALTraj), the first
method to successfully deploy generative active learning into trajectory
prediction. It actively identifies rare tail samples where the model fails and
augments these samples with a controllable diffusion model during training. In
our framework, generating scenarios that are diverse, realistic, and preserve
tail-case characteristics is paramount. Accordingly, we design a tail-aware
generation method that applies tailored diffusion guidance to generate
trajectories that both capture rare behaviors and respect traffic rules. Unlike
prior simulation methods focused solely on scenario diversity, GALTraj is the
first to show how simulator-driven augmentation benefits long-tail learning in
trajectory prediction. Experiments on multiple trajectory datasets (WOMD,
Argoverse2) with popular backbones (QCNet, MTR) confirm that our method
significantly boosts performance on tail samples and also enhances accuracy on
head samples.

</details>


### [46] [Bridging the Gap in Missing Modalities: Leveraging Knowledge Distillation and Style Matching for Brain Tumor Segmentation](https://arxiv.org/abs/2507.22626)
*Shenghao Zhu,Yifei Chen,Weihong Chen,Yuanhan Wang,Chang Liu,Shuo Jiang,Feiwei Qin,Changmiao Wang*

Main category: cs.CV

TL;DR: 摘要提出了一个名为MST-KDNet的新模型，用于解决多模态脑部肿瘤图像分割中因缺失模态而导致的边界分割不敏感和特征迁移困难问题。该模型通过多尺度Transformer知识提取、双模态分布蒸馏和全局风格匹配模块提升了分割性能，尤其在缺失关键成像模态的情况下，其Dice和HD95分数均超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 在脑部肿瘤分割任务中，当存在某些成像模态缺失时，传统方法的边界分割不敏感和特征迁移能力不足，这会影响分割的准确性和可靠性。

Method: 1. 多尺度Transformer知识提取：在多分辨率层级的Transformer结构上提取注意力权重，提升分割边界的敏感性。2. 双模态分布蒸馏：使用KL散度在输出层进行教师-学生模式的知识蒸馏。3. 全局风格匹配：通过对抗学习实现缺失模态的特征补全。该模型在训练阶段使用了完整模态的教师模型（Teacher）指导缺失模态的学生模型（Student）。

Result: 在BraTS和FeTS2024数据集上进行测试，MST-KDNet模型的Dice系数和HD95指标均超越现有技术方法，在严重缺模态的情况下优势尤其显著。

Conclusion: 该模型具有出色的鲁棒性与泛化能力，适用于临床实践。未来工作可进一步拓展应用场景（如其他医疗图像分析任务）并进行临床验证提升可靠性。

Abstract: Accurate and reliable brain tumor segmentation, particularly when dealing
with missing modalities, remains a critical challenge in medical image
analysis. Previous studies have not fully resolved the challenges of tumor
boundary segmentation insensitivity and feature transfer in the absence of key
imaging modalities. In this study, we introduce MST-KDNet, aimed at addressing
these critical issues. Our model features Multi-Scale Transformer Knowledge
Distillation to effectively capture attention weights at various resolutions,
Dual-Mode Logit Distillation to improve the transfer of knowledge, and a Global
Style Matching Module that integrates feature matching with adversarial
learning. Comprehensive experiments conducted on the BraTS and FeTS 2024
datasets demonstrate that MST-KDNet surpasses current leading methods in both
Dice and HD95 scores, particularly in conditions with substantial modality
loss. Our approach shows exceptional robustness and generalization potential,
making it a promising candidate for real-world clinical applications. Our
source code is available at https://github.com/Quanato607/MST-KDNet.

</details>


### [47] [LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing](https://arxiv.org/abs/2507.22627)
*Federico Girella,Davide Talon,Ziyue Liu,Zanxi Ruan,Yiming Wang,Marco Cristani*

Main category: cs.CV

TL;DR: LOTS是一个用于时尚图像生成的compositional方法，利用草图+文本的localized信息进行条件化，并采用新颖的分步融合策略进行扩散模型适配。方法包括Modularized Pair-Centric表示学习将草图文本编码共享空间，和一个Diffusion Pair Guidance阶段将local与global条件在扩散过程多步降噪中集成。作者发布了Sketchy数据集。实验结果在量化与定性上均领先。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于全局文本描述生成图像，但在如时尚设计等需要高度细节控制与组合修改的领域，全局描述方法在捕捉局部变化时表现不佳。设计师经常混合草图和文本表达想法，全局描述缺乏局部控制。现有草图条件生成方法通常无法整合文本细节描述（如面料），而融合多模态输入在空间上对齐的方法在草图不完整情况表现不佳。为此提出LOTS，通过草图与文本对的局部化信息实现高度可控生成。

Method: 方法分为三部分：1.训练独立的草图编码器和文本编码器，使用预训练的图像文本对模型辅助学习Modularized Pair-Centric表示空间，使草图文本具有对齐表示但不影响独立特征。2.LOTS将全局文本描述与多个草图+文本对（指定位置元素）作为条件输入。核心创新是使用分层控制：先编码全局文本特征与草图+文本对特征（经共享网络得到局部表示）。在扩散模型去噪的多个阶段注入这些不同粒度的条件：前一半步骤专注全局条件，后一半步骤使用注意力融合全局+局部特征（局部特征通过跨注意力模块融合至扩散特征图）。3.采用新颖的分步融合策略，在前一半降噪步骤仅用全局条件，后一半步骤加入局部条件。训练中为克服局部条件可能淹没全局信息的问题，设计了条件退出机制（随机在部分前向步骤丢弃部分局部条件）。

Result: 1.定量实验：在作者新建的Sketchy数据集（Fashionpedia基础上构建，包含完整全局描述+多个草图-文本对）上进行实验。评估指标：IS、FID（整体生成质量）、PSNR（草图层相似度）、CLIP相似度（全局描述匹配）和提出的新指标CLIPPair（特定文本-草图对与生成图片相关区域的相似度）。结果显示LOTS所有指标全面领先基准方法包括GLIGEN、ComposableDiffusion等。2.定性结果：LOTS能精准控制图像不同位置如袖子材质、纽扣位置等；而基准方法无法同时保持整体风格与局部控制。3.人工评估：在真实性与条件对齐两个维度人工打分，LOTS显著优于所有基准。

Conclusion: 提出LOTS方法实现组合式草图-文本+全局文本的时尚图像生成。该方法的创新在于：①使用成对草图文本共享表示但保留独立特征的表征方式②提出分步骤整合全局与局部条件（尤其扩散过程后期引入局部条件）。实验证明在全局与局部指标均突破性领先，实现高设计自由度。数据集Sketchy填补了缺少高质量草图+文本对标注时尚数据集的空缺，为相关研究提供新基准。

Abstract: Fashion design is a complex creative process that blends visual and textual
expressions. Designers convey ideas through sketches, which define spatial
structure and design elements, and textual descriptions, capturing material,
texture, and stylistic details. In this paper, we present LOcalized Text and
Sketch for fashion image generation (LOTS), an approach for compositional
sketch-text based generation of complete fashion outlooks. LOTS leverages a
global description with paired localized sketch + text information for
conditioning and introduces a novel step-based merging strategy for diffusion
adaptation. First, a Modularized Pair-Centric representation encodes sketches
and text into a shared latent space while preserving independent localized
features; then, a Diffusion Pair Guidance phase integrates both local and
global conditioning via attention-based guidance within the diffusion model's
multi-step denoising process. To validate our method, we build on Fashionpedia
to release Sketchy, the first fashion dataset where multiple text-sketch pairs
are provided per image. Quantitative results show LOTS achieves
state-of-the-art image generation performance on both global and localized
metrics, while qualitative examples and a human evaluation study highlight its
unprecedented level of design customization.

</details>


### [48] [SpectraSentinel: LightWeight Dual-Stream Real-Time Drone Detection, Tracking and Payload Identification](https://arxiv.org/abs/2507.22650)
*Shahriar Kabir,Istiak Ahmmed Rifti,H. M. Shadman Tabib,Mushfiqur Rahman,Sadatul Islam Sadi,Hasnaen Adil,Ahmed Mahir Sultan Rumi,Ch Md Rakin Haider*

Main category: cs.CV

TL;DR: 为应对2025年VIP杯挑战中的无人机检测、追踪及负载识别任务，提出一种双流实时监控框架。该框架利用两个独立的YOLOv11n目标检测器分别处理红外与可见光数据流，通过优化数据预处理、增强策略及训练超参数来提升多种环境下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着民用空域无人机激增，亟需建立实时监控系统以确保安全。现有方法在复杂环境（如强噪声、弱光、动态模糊）下处理多模态数据时存在性能瓶颈，因此开发一个能在红外与可见光通道上高效、准确工作的系统成为关键需求。

Method: 1）设计双流架构：通过两个独立的YOLOv11n检测器分别处理红外和可见光数据，避免早期融合以保证对各自模态的特征优化；2）定制化数据策略：针对红外影像限制色彩抖动、针对RGB影像优化其他增强方法；3）微调超参数以适应噪声、弱光等挑战；4）系统可实时输出无人机/鸟类分类及负载识别结果。

Result: 在VIP Cup任务中取得高精度表现：1）在复杂条件下（强噪声、弱光、运动模糊）有效区分无人机与鸟类；2）准确识别无人机负载类型；3）检测模型保持轻量级，满足实时性能要求。

Conclusion: 该双流分离架构通过对不同模态数据的针对性优化解决了小尺度空中物体检测的难题，其优化后的数据预处理和训练策略显著提升了多环境鲁棒性。最终系统兼顾准确性与实时性，为无人机构成威胁下的关键区域保护提供了有效方案。

Abstract: The proliferation of drones in civilian airspace has raised urgent security
concerns, necessitating robust real-time surveillance systems. In response to
the 2025 VIP Cup challenge tasks - drone detection, tracking, and payload
identification - we propose a dual-stream drone monitoring framework. Our
approach deploys independent You Only Look Once v11-nano (YOLOv11n) object
detectors on parallel infrared (thermal) and visible (RGB) data streams,
deliberately avoiding early fusion. This separation allows each model to be
specifically optimized for the distinct characteristics of its input modality,
addressing the unique challenges posed by small aerial objects in diverse
environmental conditions. We customize data preprocessing and augmentation
strategies per domain - such as limiting color jitter for IR imagery - and
fine-tune training hyperparameters to enhance detection performance under
conditions of heavy noise, low light, and motion blur. The resulting
lightweight YOLOv11n models demonstrate high accuracy in distinguishing drones
from birds and in classifying payload types, all while maintaining real-time
performance. This report details the rationale for a dual-modality design, the
specialized training pipelines, and the architectural optimizations that
collectively enable efficient and accurate drone surveillance across RGB and IR
channels.

</details>


### [49] [Graph-Guided Dual-Level Augmentation for 3D Scene Segmentation](https://arxiv.org/abs/2507.22668)
*Hongbin Lin,Yifan Jiang,Juangui Xu,Jesse Jiaxi Xu,Yi Lu,Zhengyu Hu,Ying-Cong Chen,Hao Wang*

Main category: cs.CV

TL;DR: 3D点云分割任务通常依赖数据增强来减少大规模标注的压力，但现有方法通常只关注局部变换或语义重组，而忽视了场景中全局结构依赖关系。本文提出了一种基于图引导的双层次约束数据增强框架，用于生成真实的3D场景以提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有3D点云数据增强方法缺乏全局结构依赖考虑的问题，本文旨在通过构建反映真实场景中物体关系的引导图，生成同时满足局部几何一致性及全局拓扑结构的增强数据。

Method: 1. 从真实数据学习物体关系构建引导图；2. 通过局部约束（几何合理性与语义一致性）和全局约束（场景布局与引导图对齐）生成多样化且高质量的合成场景；3. 在增强数据集上训练点云分割模型。

Result: 在室内/外数据集上的实验表明，该框架生成的增强场景质量高、多样性强，在各种点云分割模型上均实现了性能提升。

Conclusion: 全局结构依赖建模对于3D场景合成至关重要，所提出的图引导双层次约束方法能有效提升点云分割任务的泛化能力。

Abstract: 3D point cloud segmentation aims to assign semantic labels to individual
points in a scene for fine-grained spatial understanding. Existing methods
typically adopt data augmentation to alleviate the burden of large-scale
annotation. However, most augmentation strategies only focus on local
transformations or semantic recomposition, lacking the consideration of global
structural dependencies within scenes. To address this limitation, we propose a
graph-guided data augmentation framework with dual-level constraints for
realistic 3D scene synthesis. Our method learns object relationship statistics
from real-world data to construct guiding graphs for scene generation.
Local-level constraints enforce geometric plausibility and semantic consistency
between objects, while global-level constraints maintain the topological
structure of the scene by aligning the generated layout with the guiding graph.
Extensive experiments on indoor and outdoor datasets demonstrate that our
framework generates diverse and high-quality augmented scenes, leading to
consistent improvements in point cloud segmentation performance across various
models.

</details>


### [50] [MergeSAM: Unsupervised change detection of remote sensing images based on the Segment Anything Model](https://arxiv.org/abs/2507.22675)
*Meiqi Hu,Lingzhi Lu,Chengxi Han,Xiaoping Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于Segment Anything Model (SAM)的无监督变化检测方法MergeSAM，用于高分辨率遥感影像变化检测。该方法设计了MaskMatching和MaskSplitting两种策略以处理物体分割、融合等复杂变化，充分利用SAM的目标分割能力并嵌入空间结构信息。


<details>
  <summary>Details</summary>
Motivation: 尽管大型基础模型在特征提取方面表现出色，但在加速无监督变化检测方法方面仍有潜力。传统变化检测技术在处理高分辨率遥感影像中的复杂变化（如物体分裂与合并）时面临挑战，需要更有效地利用空间结构信息。

Method: 1. 利用SAM模型生成多时相掩码以捕捉复杂变化；2. 设计MaskMatching策略处理物体匹配问题；3. 开发MaskSplitting策略解决物体分裂问题；4. 将空间结构信息嵌入到变化检测流程中。

Result: （基于摘要信息，未提及具体实验结果）

Conclusion: 所提出的MergeSAM方法通过创新的策略有效解决了复杂场景变化检测问题，并验证了大型基础模型在提升变化检测技术实用性方面的价值。

Abstract: Recently, large foundation models trained on vast datasets have demonstrated
exceptional capabilities in feature extraction and general feature
representation. The ongoing advancements in deep learning-driven large models
have shown great promise in accelerating unsupervised change detection methods,
thereby enhancing the practical applicability of change detection technologies.
Building on this progress, this paper introduces MergeSAM, an innovative
unsupervised change detection method for high-resolution remote sensing
imagery, based on the Segment Anything Model (SAM). Two novel strategies,
MaskMatching and MaskSplitting, are designed to address real-world complexities
such as object splitting, merging, and other intricate changes. The proposed
method fully leverages SAM's object segmentation capabilities to construct
multitemporal masks that capture complex changes, embedding the spatial
structure of land cover into the change detection process.

</details>


### [51] [Hydra-Bench: A Benchmark for Multi-Modal Leaf Wetness Sensing](https://arxiv.org/abs/2507.22685)
*Yimeng Liu,Maolin Gan,Yidong Ren,Gen Li,Jingkai Lin,Younsuk Dong,Zhichao Cao*

Main category: cs.CV

TL;DR: 本文引入了一个用于叶片湿度检测的多模态数据集，该数据集包含毫米波原始数据、合成孔径雷达（SAR）图像和RGB图像，覆盖六个月收集自五种植物物种的数据，涵盖了室内和室外环境。通过Hydra模型提供了详细的基准测试，包括单模态基线、多融合策略以及不同扫描距离下的性能评估。该数据集不仅用于叶片湿度检测的算法优化，还可作为未来SAR成像算法的基准。


<details>
  <summary>Details</summary>
Motivation: 现有的叶片湿度传感系统在动态真实世界条件下应用于自然叶片时，在鲁棒性、准确性和环境适应性方面存在局限。为解决这些挑战，我们构建了一个专门用于评估和推进叶片湿度检测机器学习算法的新数据集。

Method: 在六个月时间内，从五种不同植物物种分别在受控环境和室外田间环境中收集数据。数据集包括同步获取的毫米波原始数据、合成孔径雷达（SAR）图像和RGB图像。利用Hydra模型建立了基准测试，包括单模态基线（仅毫米波、仅SAR、仅RGB）和多种融合策略（早期融合、晚期融合）的性能比较，并评估了不同扫描距离下的模型表现。

Result: 基准测试结果展示了多模态方法的优势。Hydra模型在融合多模态数据后表现出比单模态基线更高的准确率。在融合策略中，晚期融合（决策级融合）表现最优。实验还发现在2-5cm的最佳扫描距离范围内模型性能最稳定，距离变化时性能会下降。该数据集同时也为SAR成像算法提供了一个评估基准。

Conclusion: 提出的多模态数据集显著推进了叶片湿度检测研究，通过毫米波和雷达图像的组合解决了现有传感系统的局限性。Hydra模型在融合多模态数据上的出色表现证明了多模态方法在该问题上的有效性。数据集还特别有助于SAR成像算法的优化研究，能系统评估不同条件下的检测精度。这项工作填补了真实环境中叶片湿度检测研究的空白。

Abstract: Leaf wetness detection is a crucial task in agricultural monitoring, as it
directly impacts the prediction and protection of plant diseases. However,
existing sensing systems suffer from limitations in robustness, accuracy, and
environmental resilience when applied to natural leaves under dynamic
real-world conditions. To address these challenges, we introduce a new
multi-modal dataset specifically designed for evaluating and advancing machine
learning algorithms in leaf wetness detection. Our dataset comprises
synchronized mmWave raw data, Synthetic Aperture Radar (SAR) images, and RGB
images collected over six months from five diverse plant species in both
controlled and outdoor field environments. We provide detailed benchmarks using
the Hydra model, including comparisons against single modality baselines and
multiple fusion strategies, as well as performance under varying scan
distances. Additionally, our dataset can serve as a benchmark for future SAR
imaging algorithm optimization, enabling a systematic evaluation of detection
accuracy under diverse conditions.

</details>


### [52] [Zero-Shot Image Anomaly Detection Using Generative Foundation Models](https://arxiv.org/abs/2507.22692)
*Lemar Abdi,Amaan Valiuddin,Francisco Caetano,Christiaan Viviers,Fons van der Sommen*

Main category: cs.CV

TL;DR: 本文提出了一种使用扩散模型作为通用感知模板进行OOD检测的新方法。该方法利用去噪轨迹中的信息，通过分析基于SSIM放大的Stein评分误差来检测异常样本，无需在目标数据集上重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 在开放世界环境中部署安全的视觉系统时，检测分布外（OOD）输入至关重要。现有方法通常需要为每个目标数据集重新训练模型，计算成本高昂且效率低下。因此，研究团队探索使用扩散模型作为基础工具进行语义异常检测，克服现有方法的局限性。

Method: 1. 引入去噪扩散模型（DDMs）的去噪轨迹作为纹理和语义信息的丰富来源。2. 通过分析基于结构相似性指数（SSIM）放大的Stein评分误差来识别异常样本。该方法利用了在CelebA数据集上预训练的单个模型，可作为多个目标数据集的通用感知模板。

Result: 实验结果表明该方法在多个基准上取得优异表现：1. 在部分基准上达到接近完美的性能（如MNIST上0.998 AUC）。2. 在其他数据集上也高于现有最佳方法（如CIFAR-100上84.3% AUC）。3. 显著优于使用ImageNet等常用基分布的方法，证明了CelebA作为基分布的有效性。

Conclusion: 扩散模型作为生成基础模型在异常检测中展现强大潜力。该方法无需在目标数据集上重新训练，显著提高效率。CelebA被发现是比ImageNet更有效的基分布。实验结果同时指明了生成式基础模型在异常检测领域的未来潜力方向。

Abstract: Detecting out-of-distribution (OOD) inputs is pivotal for deploying safe
vision systems in open-world environments. We revisit diffusion models, not as
generators, but as universal perceptual templates for OOD detection. This
research explores the use of score-based generative models as foundational
tools for semantic anomaly detection across unseen datasets. Specifically, we
leverage the denoising trajectories of Denoising Diffusion Models (DDMs) as a
rich source of texture and semantic information. By analyzing Stein score
errors, amplified through the Structural Similarity Index Metric (SSIM), we
introduce a novel method for identifying anomalous samples without requiring
re-training on each target dataset. Our approach improves over state-of-the-art
and relies on training a single model on one dataset -- CelebA -- which we find
to be an effective base distribution, even outperforming more commonly used
datasets like ImageNet in several settings. Experimental results show
near-perfect performance on some benchmarks, with notable headroom on others,
highlighting both the strength and future potential of generative foundation
models in anomaly detection.

</details>


### [53] [Image-Guided Shape-from-Template Using Mesh Inextensibility Constraints](https://arxiv.org/abs/2507.22699)
*Thuy Tran,Ruochen Chen,Shaifali Parashar*

Main category: cs.CV

TL;DR: 论文提出了一种无监督的形状从模板（SfT）方法，该方法仅使用图像观测（颜色特征、梯度和轮廓）和网格不可延展约束，以比最佳无监督SfT快400倍的速度重建3D形状。该方法在生成精细细节和处理严重遮挡方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统SfT方法依赖图像与模板之间的点对应关系，在严重遮挡情况下性能急剧下降。现代SfT方法使用深度学习，但需要大量监督数据。最近的无监督/自监督方法结合了可微物理和图形，但速度慢。本文旨在实现快速且不受点对应关系限制的无监督重建，尤其优化处理遮挡和精细细节。

Method: 该方法仅使用图像观测（颜色特征、梯度和轮廓），结合网格不可延展约束（inextensibility constraint）进行3D重建。通过避免点对应关系并利用轮廓信息，模型在无监督条件下快速学习变形模板。

Result: 1. 重建速度比当前最佳无监督SfT方法快400倍。
2. 在生成精细细节和处理严重遮挡方面大幅超越现有方法。

Conclusion: 所提出的无监督SfT方法避免了传统SfT对点对应的依赖和现代方法对大量数据的需求，实现了高效、鲁棒的3D重建，尤其在遮挡场景下表现出色。

Abstract: Shape-from-Template (SfT) refers to the class of methods that reconstruct the
3D shape of a deforming object from images/videos using a 3D template.
Traditional SfT methods require point correspondences between images and the
texture of the 3D template in order to reconstruct 3D shapes from images/videos
in real time. Their performance severely degrades when encountered with severe
occlusions in the images because of the unavailability of correspondences. In
contrast, modern SfT methods use a correspondence-free approach by
incorporating deep neural networks to reconstruct 3D objects, thus requiring
huge amounts of data for supervision. Recent advances use a fully unsupervised
or self-supervised approach by combining differentiable physics and graphics to
deform 3D template to match input images. In this paper, we propose an
unsupervised SfT which uses only image observations: color features, gradients
and silhouettes along with a mesh inextensibility constraint to reconstruct at
a $400\times$ faster pace than (best-performing) unsupervised SfT. Moreover,
when it comes to generating finer details and severe occlusions, our method
outperforms the existing methodologies by a large margin. Code is available at
https://github.com/dvttran/nsft.

</details>


### [54] [A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks](https://arxiv.org/abs/2507.22733)
*Hang Su,Yunlong Feng,Daniel Gehrig,Panfeng Jiang,Ling Gao,Xavier Lagorce,Laurent Kneip*

Main category: cs.CV

TL;DR: 提出了一种从具有任意时间戳的2D点对应中估计结构和线性运动的新算法，适用于多种相机类型（全局快门、卷帘快门、事件相机），通过一阶动力学和恒定速度运动模型推导线性点入射关系，高效恢复线性速度和3D点。


<details>
  <summary>Details</summary>
Motivation: 现有的结构运动估计算法（如5点或8点算法）需要同步的瞬时捕获点对应。然而，在卷帘快门或事件相机等异步数据场景下，这些算法无法有效处理。为解决异步点对应问题，提出一种统一方法处理不同时间戳的点数据。

Method: 采用一阶动力学公式和恒定速度运动模型，推导出线性点入射关系。通过该关系直接估计结构的线性速度和3D点位，可以处理全局快门、卷帘快门、事件相机等多种传感器的点对应数据，并支持多传感器数据融合。

Result: 在模拟和真实数据上进行实验验证，相比现有方法，该方法在所有相机模态（全局快门、卷帘快门、事件相机）上均表现出一致的性能提升。

Conclusion: 提出了一种统一的解决方案，能够高效处理异步传感器数据的结构和运动估计问题，为多种相机数据融合提供了新思路。代码已开源。

Abstract: Structure and continuous motion estimation from point correspondences is a
fundamental problem in computer vision that has been powered by well-known
algorithms such as the familiar 5-point or 8-point algorithm. However, despite
their acclaim, these algorithms are limited to processing point correspondences
originating from a pair of views each one representing an instantaneous capture
of the scene. Yet, in the case of rolling shutter cameras, or more recently,
event cameras, this synchronization breaks down. In this work, we present a
unified approach for structure and linear motion estimation from 2D point
correspondences with arbitrary timestamps, from an arbitrary set of views. By
formulating the problem in terms of first-order dynamics and leveraging a
constant velocity motion model, we derive a novel, linear point incidence
relation allowing for the efficient recovery of both linear velocity and 3D
points with predictable degeneracies and solution multiplicities. Owing to its
general formulation, it can handle correspondences from a wide range of sensing
modalities such as global shutter, rolling shutter, and event cameras, and can
even combine correspondences from different collocated sensors. We validate the
effectiveness of our solver on both simulated and real-world data, where we
show consistent improvement across all modalities when compared to recent
approaches. We believe our work opens the door to efficient structure and
motion estimation from asynchronous data. Code can be found at
https://github.com/suhang99/AsyncTrack-Motion-Solver.

</details>


### [55] [Social-Pose: Enhancing Trajectory Prediction with Human Body Pose](https://arxiv.org/abs/2507.22742)
*Yang Gao,Saeed Saadatnejad,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出了Social-pose，一种基于注意力的姿态编码器，用于通过人体姿态预测轨迹，提升轨迹预测性能


<details>
  <summary>Details</summary>
Motivation: 现有模型未能充分利用人类在导航过程中潜意识传递的视觉线索，尤其是人体姿态信息。

Method: 提出Social-pose注意力姿态编码器捕获场景中所有人姿态及其社交关系；方法可集成到多种轨迹预测架构（LSTM/GAN/MLP/Transformer）；验证了2D/3D姿态效果及噪声影响

Result: 在合成数据集(JointTrackAuto)和真实数据集(Human3.6M/Pedestrians and Cyclists in Road Traffic/JRDB)上全面超越现有模型；验证了机器人导航应用可行性

Conclusion: 利用人体姿态替代传统笛卡尔坐标能显著提升轨迹预测精度；Social-pose作为通用模块有效增强多种主流模型性能

Abstract: Accurate human trajectory prediction is one of the most crucial tasks for
autonomous driving, ensuring its safety. Yet, existing models often fail to
fully leverage the visual cues that humans subconsciously communicate when
navigating the space. In this work, we study the benefits of predicting human
trajectories using human body poses instead of solely their Cartesian space
locations in time. We propose `Social-pose', an attention-based pose encoder
that effectively captures the poses of all humans in a scene and their social
relations. Our method can be integrated into various trajectory prediction
architectures. We have conducted extensive experiments on state-of-the-art
models (based on LSTM, GAN, MLP, and Transformer), and showed improvements over
all of them on synthetic (Joint Track Auto) and real (Human3.6M, Pedestrians
and Cyclists in Road Traffic, and JRDB) datasets. We also explored the
advantages of using 2D versus 3D poses, as well as the effect of noisy poses
and the application of our pose-based predictor in robot navigation scenarios.

</details>


### [56] [HOLA: Enhancing Audio-visual Deepfake Detection via Hierarchical Contextual Aggregations and Efficient Pre-training](https://arxiv.org/abs/2507.22781)
*Xuecheng Wu,Danlei Huang,Heli Sun,Xinyi Yin,Yifan Wang,Hao Wang,Jia Zhang,Fei Wang,Peihao Guo,Suyu Xing,Junxiao Xue,Liang He*

Main category: cs.CV

TL;DR: 提出HOLA模型解决视频级深伪检测问题，采用两阶段框架，结合迭代跨模态学习和分层上下文建模，在1M-DeepFake竞赛中以0.0476 AUC优势夺冠。


<details>
  <summary>Details</summary>
Motivation: 生成式AI使视频级深伪检测面临挑战，现有技术存在局限。旨在通过大规模音视频自监督预训练及新型模型架构提升检测能力。

Method: 1. 利用自建181万样本数据集进行音视频自监督预训练

2. 构建两阶段框架含：
   - 迭代感知跨模态学习模块（选择性音视频交互）
   - 全局-局部视角下带门控聚合的分层上下文建模
   - 金字塔式精细化模块实现跨粒度语义增强

3. 引入伪监督信号注入策略提升性能

Result: 1. 在1M-Deepfakes竞赛TestA集以0.0476 AUC优势排名第一

2. 通过消融实验验证关键组件有效性

3. 在专家模型和MLLMs对比中展现优异性能

Conclusion: HOLA通过迭代跨模态学习和多尺度建模显著提升视频级深伪检测性能，大规模预训练与新型组件设计是关键成功因素。未来可探索跨模态伪造场景下的泛化能力优化。

Abstract: Advances in Generative AI have made video-level deepfake detection
increasingly challenging, exposing the limitations of current detection
techniques. In this paper, we present HOLA, our solution to the Video-Level
Deepfake Detection track of 2025 1M-Deepfakes Detection Challenge. Inspired by
the success of large-scale pre-training in the general domain, we first scale
audio-visual self-supervised pre-training in the multimodal video-level
deepfake detection, which leverages our self-built dataset of 1.81M samples,
thereby leading to a unified two-stage framework. To be specific, HOLA features
an iterative-aware cross-modal learning module for selective audio-visual
interactions, hierarchical contextual modeling with gated aggregations under
the local-global perspective, and a pyramid-like refiner for scale-aware
cross-grained semantic enhancements. Moreover, we propose the pseudo supervised
singal injection strategy to further boost model performance. Extensive
experiments across expert models and MLLMs impressivly demonstrate the
effectiveness of our proposed HOLA. We also conduct a series of ablation
studies to explore the crucial design factors of our introduced components.
Remarkably, our HOLA ranks 1st, outperforming the second by 0.0476 AUC on the
TestA set.

</details>


### [57] [Modality-Aware Feature Matching: A Comprehensive Review of Single- and Cross-Modality Techniques](https://arxiv.org/abs/2507.22791)
*Weide Liu,Wei Zhou,Jun Liu,Ping Hu,Jun Cheng,Jungong Han,Weisi Lin*

Main category: cs.CV

TL;DR: 对多模态特征匹配的传统方法和深度学习方法的综述研究，强调跨模态应用的进展和挑战。


<details>
  <summary>Details</summary>
Motivation: 特征匹配是计算机视觉的核心任务，但随着多模态数据的兴起，传统方法在跨模态场景中表现不佳。本文旨在全面回顾和总结不同模态下的特征匹配方法，推动多领域研究的进步。

Method: 1. 分析传统手工方法（例如SIFT、ORB）在跨模态匹配中的局限；2. 综述基于CNN、Transformer的深度学习方法（如SuperPoint、LoFTR）的改进；3. 分模态对比技术：针对深度图像设计几何描述子、LiDAR采用注意力网络、医疗图像使用MIND描述子；4. 探讨跨模态应用（如图像配准、视觉语言交互）的专用解决方案。

Result: 1. 传统方法在中等模态变化下稳健但难以应对显著模态差异；2. 深度学习方法显著提升跨模态鲁棒性；3. 各模态针对性策略有效：点云采用稀疏/稠密学习、深度图像用空间特征增强、医疗领域利用结构感知描述子；4. 视觉-语言等跨模态任务成为新兴研究方向。

Conclusion: 特征匹配正向处理多模态数据交互演化。传统方法仍有价值，但深度学习方法已主导跨模态领域。未来需强化小样本跨模态学习、统一框架设计及多模态数据融合。

Abstract: Feature matching is a cornerstone task in computer vision, essential for
applications such as image retrieval, stereo matching, 3D reconstruction, and
SLAM. This survey comprehensively reviews modality-based feature matching,
exploring traditional handcrafted methods and emphasizing contemporary deep
learning approaches across various modalities, including RGB images, depth
images, 3D point clouds, LiDAR scans, medical images, and vision-language
interactions. Traditional methods, leveraging detectors like Harris corners and
descriptors such as SIFT and ORB, demonstrate robustness under moderate
intra-modality variations but struggle with significant modality gaps.
Contemporary deep learning-based methods, exemplified by detector-free
strategies like CNN-based SuperPoint and transformer-based LoFTR, substantially
improve robustness and adaptability across modalities. We highlight
modality-aware advancements, such as geometric and depth-specific descriptors
for depth images, sparse and dense learning methods for 3D point clouds,
attention-enhanced neural networks for LiDAR scans, and specialized solutions
like the MIND descriptor for complex medical image matching. Cross-modal
applications, particularly in medical image registration and vision-language
tasks, underscore the evolution of feature matching to handle increasingly
diverse data interactions.

</details>


### [58] [Segment Anything for Video: A Comprehensive Review of Video Object Segmentation and Tracking from Past to Future](https://arxiv.org/abs/2507.22792)
*Guoping Xu,Jayaram K. Udupa,Yajun Yu,Hua-Chieh Shao,Songlin Zhao,Wei Liu,You Zhang*

Main category: cs.CV

TL;DR: 该摘要介绍了一篇关于基于SAM和SAM2基础模型的视频目标分割与跟踪（VOST）技术的综述论文。论文从过去、现在和未来三个时间维度，系统地回顾了该领域的方法演进，并讨论了当前挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视频目标分割与跟踪（VOST）在计算机视觉中具有重要应用价值，但传统方法在领域泛化、时间一致性和计算效率方面存在不足。随着SAM/SAM2等基础模型的出现，VOST领域迎来了新的技术范式。本综述旨在系统梳理这一技术路线的发展，帮助研究人员把握该领域的研究脉络。

Method: 通过三个时间维度构建综述框架：1) 过去：分析历史信息保留和更新策略（如存储机制）；2) 现在：总结当前帧的特征提取优化方法；3) 未来：探讨运动预测与轨迹估计技术。重点关注从早期存储架构到SAM2流式处理的技术演进，并分析了运动感知记忆选择、轨迹引导提示等创新技术。

Result: 研究指出基础模型大幅提升了VOST的泛化能力与实时性，但当前仍存在三大核心挑战：1) 内存冗余问题；2) 错误累积效应；3) 提示机制效率不足。技术演进呈现出从静态存储向动态流式处理发展的明显趋势。

Conclusion: 该综述为VOST研究提供了结构化视角，强调基础模型正在重塑该领域的技术路线。未来研究应聚焦内存优化、抗误差传播机制和高效提示设计三个方向，以推动VOST技术在精度与效率上的突破。

Abstract: Video Object Segmentation and Tracking (VOST) presents a complex yet critical
challenge in computer vision, requiring robust integration of segmentation and
tracking across temporally dynamic frames. Traditional methods have struggled
with domain generalization, temporal consistency, and computational efficiency.
The emergence of foundation models like the Segment Anything Model (SAM) and
its successor, SAM2, has introduced a paradigm shift, enabling prompt-driven
segmentation with strong generalization capabilities. Building upon these
advances, this survey provides a comprehensive review of SAM/SAM2-based methods
for VOST, structured along three temporal dimensions: past, present, and
future. We examine strategies for retaining and updating historical information
(past), approaches for extracting and optimizing discriminative features from
the current frame (present), and motion prediction and trajectory estimation
mechanisms for anticipating object dynamics in subsequent frames (future). In
doing so, we highlight the evolution from early memory-based architectures to
the streaming memory and real-time segmentation capabilities of SAM2. We also
discuss recent innovations such as motion-aware memory selection and
trajectory-guided prompting, which aim to enhance both accuracy and efficiency.
Finally, we identify remaining challenges including memory redundancy, error
accumulation, and prompt inefficiency, and suggest promising directions for
future research. This survey offers a timely and structured overview of the
field, aiming to guide researchers and practitioners in advancing the state of
VOST through the lens of foundation models.

</details>


### [59] [Advancing Fetal Ultrasound Image Quality Assessment in Low-Resource Settings](https://arxiv.org/abs/2507.22802)
*Dongli He,Hu Wang,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 提出FetalCLIP$_{CLS}$，一种基于预训练视觉语言模型FetalCLIP的胎儿超声图像质量评估方法，使用LoRA高效微调，在ACOUSLIC-AI数据集上取得最高F1分数0.757，并通过复用适应分割模型进一步提升至0.771，推动资源有限地区的产前护理。


<details>
  <summary>Details</summary>
Motivation: 胎儿生物测量对产前护理至关重要，但高质量的超声图像高度依赖专业医师，在低收入国家缺乏训练人员。为解决该问题，通过预训练模型实现胎儿超声图像质量自动评估。

Method: 1. 利用预训练于21万胎儿超声图像-文本对的数据集上的FetalCLIP模型；2. 引入FetalCLIP$_{CLS}$，采用LoRA进行参数高效微调；3. 在ACOUSLIC-AI数据集上与六个CNN和Transformer基线比较；4. 将适应分割模型重新用于分类。

Result: FetalCLIP$_{CLS}$在ACOUSLIC-AI数据集上达到0.757的F1分数，重新利用分割模型后分类性能进一步提升至0.771。

Conclusion: 研究证明胎儿超声基础模型通过参数高效微调可适配特定任务（如图像质量评估），促进资源受限地区的产前护理发展。

Abstract: Accurate fetal biometric measurements, such as abdominal circumference, play
a vital role in prenatal care. However, obtaining high-quality ultrasound
images for these measurements heavily depends on the expertise of sonographers,
posing a significant challenge in low-income countries due to the scarcity of
trained personnel. To address this issue, we leverage FetalCLIP, a
vision-language model pretrained on a curated dataset of over 210,000 fetal
ultrasound image-caption pairs, to perform automated fetal ultrasound image
quality assessment (IQA) on blind-sweep ultrasound data. We introduce
FetalCLIP$_{CLS}$, an IQA model adapted from FetalCLIP using Low-Rank
Adaptation (LoRA), and evaluate it on the ACOUSLIC-AI dataset against six CNN
and Transformer baselines. FetalCLIP$_{CLS}$ achieves the highest F1 score of
0.757. Moreover, we show that an adapted segmentation model, when repurposed
for classification, further improves performance, achieving an F1 score of
0.771. Our work demonstrates how parameter-efficient fine-tuning of fetal
ultrasound foundation models can enable task-specific adaptations, advancing
prenatal care in resource-limited settings. The experimental code is available
at: https://github.com/donglihe-hub/FetalCLIP-IQA.

</details>


### [60] [MoCHA: Advanced Vision-Language Reasoning with MoE Connector and Hierarchical Group Attention](https://arxiv.org/abs/2507.22805)
*Yuqi Pang,Bowen Yang,Yun Cao,Fan Rong,Xiaoyu Li,Chen He*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Vision large language models (VLLMs) are focusing primarily on handling
complex and fine-grained visual information by incorporating advanced vision
encoders and scaling up visual models. However, these approaches face high
training and inference costs, as well as challenges in extracting visual
details, effectively bridging across modalities. In this work, we propose a
novel visual framework, MoCHA, to address these issues. Our framework
integrates four vision backbones (i.e., CLIP, SigLIP, DINOv2 and ConvNeXt) to
extract complementary visual features and is equipped with a sparse Mixture of
Experts Connectors (MoECs) module to dynamically select experts tailored to
different visual dimensions. To mitigate redundant or insufficient use of the
visual information encoded by the MoECs module, we further design a
Hierarchical Group Attention (HGA) with intra- and inter-group operations and
an adaptive gating strategy for encoded visual features. We train MoCHA on two
mainstream LLMs (e.g., Phi2-2.7B and Vicuna-7B) and evaluate their performance
across various benchmarks. Notably, MoCHA outperforms state-of-the-art
open-weight models on various tasks. For example, compared to CuMo
(Mistral-7B), our MoCHA (Phi2-2.7B) presents outstanding abilities to mitigate
hallucination by showing improvements of 3.25% in POPE and to follow visual
instructions by raising 153 points on MME. Finally, ablation studies further
confirm the effectiveness and robustness of the proposed MoECs and HGA in
improving the overall performance of MoCHA.

</details>


### [61] [DISTIL: Data-Free Inversion of Suspicious Trojan Inputs via Latent Diffusion](https://arxiv.org/abs/2507.22813)
*Hossein Mirzaei,Zeinab Taghavi,Sepehr Rezaee,Masoud Hadi,Moein Madadi,Mackenzie W. Mathis*

Main category: cs.CV

TL;DR: 提出一种零样本、免数据的触发器反演方法DISTIL，用于检测深度神经网络中的后门攻击，该方法利用目标分类器引导的扩散模型在受限空间迭代生成候选触发器，有效区分干净与被植入后门的模型，在各种任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有触发器反演方法需在全像素空间搜索且依赖强假设，无法保证反演出的触发器真实反映后门模式而非对抗扰动。需开发不依赖数据与强先验假设的可靠防御方法。

Method: 1. 限制搜索空间：通过受目标分类器引导的扩散模型，在潜在空间而非全像素空间生成触发器；2. 迭代生成对齐：生成与模型内部表示对齐的候选触发器；3. 零样本检测：不依赖外部数据或触发器形态假设，通过重建触发器的有效性检测后门模型。

Result: 1. 在BackdoorBench上准确率最高提升7.1%；2. 被植入后门的目标检测模型扫描性能提升9.4%；3. 定性分析显示能重建有效区分恶意行为的触发器。

Conclusion: DISTIL为无数据、零样本的后门防御提供了新方向，显著优于现有方法且不依赖数据或强假设，代码已开源。

Abstract: Deep neural networks have demonstrated remarkable success across numerous
tasks, yet they remain vulnerable to Trojan (backdoor) attacks, raising serious
concerns about their safety in real-world mission-critical applications. A
common countermeasure is trigger inversion -- reconstructing malicious
"shortcut" patterns (triggers) inserted by an adversary during training.
Current trigger-inversion methods typically search the full pixel space under
specific assumptions but offer no assurances that the estimated trigger is more
than an adversarial perturbation that flips the model output. Here, we propose
a data-free, zero-shot trigger-inversion strategy that restricts the search
space while avoiding strong assumptions on trigger appearance. Specifically, we
incorporate a diffusion-based generator guided by the target classifier;
through iterative generation, we produce candidate triggers that align with the
internal representations the model relies on for malicious behavior. Empirical
evaluations, both quantitative and qualitative, show that our approach
reconstructs triggers that effectively distinguish clean versus Trojaned
models. DISTIL surpasses alternative methods by high margins, achieving up to
7.1% higher accuracy on the BackdoorBench dataset and a 9.4% improvement on
trojaned object detection model scanning, offering a promising new direction
for reliable backdoor defense without reliance on extensive data or strong
prior assumptions about triggers. The code is available at
https://github.com/AdaptiveMotorControlLab/DISTIL.

</details>


### [62] [Wall Shear Stress Estimation in Abdominal Aortic Aneurysms: Towards Generalisable Neural Surrogate Models](https://arxiv.org/abs/2507.22817)
*Patryk Rygiel,Julian Suk,Christoph Brune,Kak Khee Yeung,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 本文提出了一种使用几何深度学习方法快速估计腹主动脉瘤（AAA）患者血流动力学参数的方法，具有高效、可泛化至不同真实世界因素的特点。


<details>
  <summary>Details</summary>
Motivation: 腹主动脉瘤（AAA）破裂风险高，传统计算流体动力学（CFD）仿真计算耗时耗力，需要一种快速替代方法。几何深度学习方法为潜力解决方案，但现有方法对现实变化因素（如血管几何重构、边界条件变化、血管树拓扑差异及网格分辨率）的泛化性能有待验证。

Method: 1. 提出一种具有E(3)-等变性的几何深度学习模型，利用稳健的几何描述符和射影几何代数。
2. 使用100位AAA患者的CT扫描数据训练模型：首先提取管腔几何形状；其次采用不同边界条件进行CFD仿真获得参考血流动力学数据。
3. 训练模型瞬时壁面切应力（WSS）。
4. 系统评估模型对多种干扰因素的泛化能力：分布内数据、外部测试集、几何重构、边界条件变化、血管树拓扑调整（新增血管分支）、网格分辨率差异等场景。

Result: 1. 模型在分布内数据集表现优秀。
2. 能对未见过的外部测试集保持高精度。
3. 对几何重构及边界条件变化敏感度低，适应性优异（边界条件变化包含流速压力变动）。
4. 在推理阶段添加从未见过的血管分支后，仍可保持精度高。
5. 性能对网格分辨率依赖性弱，具备网格自适应性。

Conclusion: 该模型在快速、精准估计AAA血流动力学问题上具有临床转化潜力，其独特优势在于对真实场景中多种变化因素（几何构型、边界条件、血管树拓扑、网格质量）的强大泛化能力，克服了传统CFD的计算瓶颈。这些特性使其有望成为临床实践中血流动力学评估的高效工具。

Abstract: Abdominal aortic aneurysms (AAAs) are pathologic dilatations of the abdominal
aorta posing a high fatality risk upon rupture. Studying AAA progression and
rupture risk often involves in-silico blood flow modelling with computational
fluid dynamics (CFD) and extraction of hemodynamic factors like time-averaged
wall shear stress (TAWSS) or oscillatory shear index (OSI). However, CFD
simulations are known to be computationally demanding. Hence, in recent years,
geometric deep learning methods, operating directly on 3D shapes, have been
proposed as compelling surrogates, estimating hemodynamic parameters in just a
few seconds. In this work, we propose a geometric deep learning approach to
estimating hemodynamics in AAA patients, and study its generalisability to
common factors of real-world variation. We propose an E(3)-equivariant deep
learning model utilising novel robust geometrical descriptors and projective
geometric algebra. Our model is trained to estimate transient WSS using a
dataset of CT scans of 100 AAA patients, from which lumen geometries are
extracted and reference CFD simulations with varying boundary conditions are
obtained. Results show that the model generalizes well within the distribution,
as well as to the external test set. Moreover, the model can accurately
estimate hemodynamics across geometry remodelling and changes in boundary
conditions. Furthermore, we find that a trained model can be applied to
different artery tree topologies, where new and unseen branches are added
during inference. Finally, we find that the model is to a large extent agnostic
to mesh resolution. These results show the accuracy and generalisation of the
proposed model, and highlight its potential to contribute to hemodynamic
parameter estimation in clinical practice.

</details>


### [63] [Bi-Level Optimization for Self-Supervised AI-Generated Face Detection](https://arxiv.org/abs/2507.22824)
*Mian Zou,Nan Zhong,Baosheng Yu,Yibing Zhan,Kede Ma*

Main category: cs.CV

TL;DR: 提出了一种基于双层优化的自监督方法来检测AI生成的人脸，该方法通过优化多个前置任务的权重来提升在未见过的生成器上的泛化能力，并在实验中对现有方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于监督学习的AI生成人脸检测器通常依赖于特定生成器的合成图像，这限制了它们对新兴生成技术的泛化能力。

Method: 采用双层优化。内层仅在真实人脸图像上通过线性加权的多个前置任务预训练视觉编码器，包括分类EXIF标签、排序EXIF标签和检测人工篡改人脸。外层优化这些任务的权重，以提升篡改人脸检测作为代理任务，这更接近AI生成人脸检测的终极目标。训练后，固定编码器，使用高斯混合模型或轻量级双层感知机进行检测。

Result: 在单类别和二元分类设置中都显著优于现有方法，对未见过的生成器展现出强大的泛化能力。

Conclusion: 所提出的自监督方法在AI生成人脸检测中取得了优秀的泛化和检测性能，为解决现有方法对新生成器泛化不佳的问题提供了有效方案。

Abstract: AI-generated face detectors trained via supervised learning typically rely on
synthesized images from specific generators, limiting their generalization to
emerging generative techniques. To overcome this limitation, we introduce a
self-supervised method based on bi-level optimization. In the inner loop, we
pretrain a vision encoder only on photographic face images using a set of
linearly weighted pretext tasks: classification of categorical exchangeable
image file format (EXIF) tags, ranking of ordinal EXIF tags, and detection of
artificial face manipulations. The outer loop then optimizes the relative
weights of these pretext tasks to enhance the coarse-grained detection of
manipulated faces, serving as a proxy task for identifying AI-generated faces.
In doing so, it aligns self-supervised learning more closely with the ultimate
goal of AI-generated face detection. Once pretrained, the encoder remains
fixed, and AI-generated faces are detected either as anomalies under a Gaussian
mixture model fitted to photographic face features or by a lightweight
two-layer perceptron serving as a binary classifier. Extensive experiments
demonstrate that our detectors significantly outperform existing approaches in
both one-class and binary classification settings, exhibiting strong
generalization to unseen generators.

</details>


### [64] [DepR: Depth Guided Single-view Scene Reconstruction with Instance-level Diffusion](https://arxiv.org/abs/2507.22825)
*Qingcheng Zhao,Xiang Zhang,Haiyang Xu,Zeyuan Chen,Jianwen Xie,Yuan Gao,Zhuowen Tu*

Main category: cs.CV

TL;DR: DepR是一个通过深度信息引导的单视角场景重建框架，结合实例级扩散模型和组合方法，在训练和推理中充分利用深度数据，实现高泛化性和先进性能的场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在推理过程中仅使用深度信息进行物体布局估计，未能充分利用其丰富的几何信息。为了在训练和推理中都有效利用深度信息，提升单视角场景重建的准确性和泛化能力，提出了DepR框架。

Method: 1. 组合式重建：DepR将场景分解为独立对象，分别生成后再组合成3D布局。
2. 深度引导条件：在训练和推理中引入深度信息，通过深度数据增强形状先验编码。
3. DDIM采样优化：在推理过程中，使用深度引导DDIM采样和布局优化，确保重建结果与输入图像对齐。

Result: 在合成和真实数据集上评估表明，即使在有限的合成数据上训练，DepR也达到了最先进的重建性能，并且表现出强大的泛化能力。

Conclusion: DepR通过全程利用深度信息，显著提升了单视角场景重建的效果，证明深度信息在训练和推理中的统一利用能够克服现有方法在几何信息利用上的不足，实现高质量重建。

Abstract: We propose DepR, a depth-guided single-view scene reconstruction framework
that integrates instance-level diffusion within a compositional paradigm.
Instead of reconstructing the entire scene holistically, DepR generates
individual objects and subsequently composes them into a coherent 3D layout.
Unlike previous methods that use depth solely for object layout estimation
during inference and therefore fail to fully exploit its rich geometric
information, DepR leverages depth throughout both training and inference.
Specifically, we introduce depth-guided conditioning to effectively encode
shape priors into diffusion models. During inference, depth further guides DDIM
sampling and layout optimization, enhancing alignment between the
reconstruction and the input image. Despite being trained on limited synthetic
data, DepR achieves state-of-the-art performance and demonstrates strong
generalization in single-view scene reconstruction, as shown through
evaluations on both synthetic and real-world datasets.

</details>


### [65] [ScreenCoder: Advancing Visual-to-Code Generation for Front-End Automation via Modular Multimodal Agents](https://arxiv.org/abs/2507.22827)
*Yilei Jiang,Yaozhi Zheng,Yuxuan Wan,Jiaming Han,Qunzhong Wang,Michael R. Lyu,Xiangyu Yue*

Main category: cs.CV

TL;DR: 论文提出了一种模块化的多智能体框架ScreenCoder，用于将用户界面（UI）设计自动转换为前端代码。该框架分为三个阶段：基础（识别和标记UI组件）、规划（构建分层布局）和生成（通过自适应提示合成HTML/CSS代码）。此外，还扩展为一个数据引擎以生成大规模图像-代码对，并微调了一个开源视觉语言模型（VLM），显著提升了UI理解和代码质量。实验证明该方法在布局准确性、结构连贯性和代码正确性上达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的UI到代码生成方法主要依赖自然语言提示，难以有效捕捉空间布局和视觉设计意图。实际上，UI开发始于视觉草图或模型，具有多模态特性。为弥合这一差距，作者提出了一个可解释、稳健且保真度高的多智能体框架。

Method: 1. 基础阶段：使用视觉语言模型（VLM）检测和标记UI组件。
2. 规划阶段：基于前端工程先验构建分层布局结构。
3. 生成阶段：通过自适应提示合成技术生成HTML/CSS代码。
此外，框架扩展为一个数据引擎，自动生成大规模的图像-代码对，用于微调和增强开源的VLM模型。

Result: 实验结果表明，该方法在布局准确性、结构连贯性和代码正确性方面优于现有方法，达到了最先进水平。微调后的VLM在UI理解和代码质量上取得了显著提升。

Conclusion: ScreenCoder框架通过多阶段、多智能体的设计，实现了高性能的UI到代码生成，且具有可解释性、鲁棒性和高保真度。扩展的数据引擎进一步提升了模型能力。该方法有效解决了传统单一自然语言提示方法的局限性，并在多个指标上超越现有技术。

Abstract: Automating the transformation of user interface (UI) designs into front-end
code holds significant promise for accelerating software development and
democratizing design workflows. While recent large language models (LLMs) have
demonstrated progress in text-to-code generation, many existing approaches rely
solely on natural language prompts, limiting their effectiveness in capturing
spatial layout and visual design intent. In contrast, UI development in
practice is inherently multimodal, often starting from visual sketches or
mockups. To address this gap, we introduce a modular multi-agent framework that
performs UI-to-code generation in three interpretable stages: grounding,
planning, and generation. The grounding agent uses a vision-language model to
detect and label UI components, the planning agent constructs a hierarchical
layout using front-end engineering priors, and the generation agent produces
HTML/CSS code via adaptive prompt-based synthesis. This design improves
robustness, interpretability, and fidelity over end-to-end black-box methods.
Furthermore, we extend the framework into a scalable data engine that
automatically produces large-scale image-code pairs. Using these synthetic
examples, we fine-tune and reinforce an open-source VLM, yielding notable gains
in UI understanding and code quality. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in layout accuracy,
structural coherence, and code correctness. Our code is made publicly available
at https://github.com/leigest519/ScreenCoder.

</details>


### [66] [CapRecover: A Cross-Modality Feature Inversion Attack Framework on Vision Language Models](https://arxiv.org/abs/2507.22828)
*Kedong Xiu,Saiqian Zhang*

Main category: cs.CV

TL;DR: 提出CapRecover框架以从视觉语言模型的分割部署中间特征直接恢复语义内容（如标签或描述），避免图像重建带来的模糊问题，并通过添加噪声来保护隐私。


<details>
  <summary>Details</summary>
Motivation: 针对分割部署的视觉语言模型中视觉编码器（如ResNet）生成的中间特征存在语义信息泄露风险，现有图像重建方法产生模糊图像无法有效保护隐私，因此需要直接恢复语义以实现隐私评估和保护。

Method: 设计CapRecover框架：1) 直接从中间特征预测标签或生成描述（无需重建图像）；2) 分层分析语义信息分布（发现深层特征语义更丰富）；3) 防御方法：在每层添加噪声，下一层移除噪声以避免训练开销。

Result: 在多个数据集及模型上验证：1) CIFAR-10的标签Top-1准确率达92.71%；2) COCO2017上ResNet50特征生成描述的ROUGE-L达0.52；3) 分层实验显示深层卷积层语义更丰富；4) 噪声防御方案能有效阻止语义泄露。

Conclusion: 证明分割部署的视觉模型存在高级语义泄露风险；CapRecover可直接高效恢复语义；分层噪声注入是低成本防御方案。

Abstract: As Vision-Language Models (VLMs) are increasingly deployed in split-DNN
configurations--with visual encoders (e.g., ResNet, ViT) operating on user
devices and sending intermediate features to the cloud--there is a growing
privacy risk from semantic information leakage. Existing approaches to
reconstructing images from these intermediate features often result in blurry,
semantically ambiguous images. To directly address semantic leakage, we propose
CapRecover, a cross-modality inversion framework that recovers high-level
semantic content, such as labels or captions, directly from intermediate
features without image reconstruction.
  We evaluate CapRecover on multiple datasets and victim models, demonstrating
strong performance in semantic recovery. Specifically, CapRecover achieves up
to 92.71% Top-1 label accuracy on CIFAR-10 and generates fluent captions from
ResNet50 features on COCO2017 with ROUGE-L scores up to 0.52. Our analysis
further reveals that deeper convolutional layers encode significantly more
semantic information compared to shallow layers. To mitigate semantic leakage,
we introduce a simple yet effective protection method: adding random noise to
intermediate features at each layer and removing the noise in the next layer.
Experimental results show that this approach prevents semantic leakage without
additional training costs.

</details>


### [67] [TR-PTS: Task-Relevant Parameter and Token Selection for Efficient Tuning](https://arxiv.org/abs/2507.22872)
*Siqi Luo,Haoran Yang,Yi Xin,Mingyang Yi,Guangyang Wu,Guangtao Zhai,Xiaohong Liu*

Main category: cs.CV

TL;DR: TR-PTS是一种任务驱动的框架，通过联合优化参数和令牌选择，提高计算效率和精度。它利用Fisher信息矩阵（FIM）选择信息量最大的参数进行逐层微调，同时动态选择信息量最大的令牌并合并冗余令牌。在FGVC和VTAB-1k基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 目前大规模预训练模型在视觉任务中表现优异，但微调需要大量计算和存储资源。现有的参数高效微调方法（PEFT）多是任务无关的，不能在任务相关参数和令牌选择上做到最优，导致性能和效率低下。

Method: TR-PTS框架包括两个主要部分：
1. 任务相关参数选择：利用Fisher信息矩阵（FIM）识别每一层中最具信息量的参数，仅微调这部分参数，冻结其余参数。
2. 任务相关令牌选择：动态保留信息量最大的令牌并合并冗余令牌，减少计算开销。
两个过程共同优化，使得模型能够专注于任务判别信息。

Result: 在FGVC和VTAB-1k基准测试中，TR-PTS均取得了最先进的性能。具体而言，与全微调相比，TR-PTS在FGVC上超过3.40%，在VTAB-1k上超过10.35%。

Conclusion: TR-PTS是一种创新的任务驱动框架，通过联合参数和令牌选择，实现了计算效率和性能的双重提升。在基准测试中表现超越全微调，为大规模模型的参数高效微调提供了新思路。代码已开源。

Abstract: Large pre-trained models achieve remarkable performance in vision tasks but
are impractical for fine-tuning due to high computational and storage costs.
Parameter-Efficient Fine-Tuning (PEFT) methods mitigate this issue by updating
only a subset of parameters; however, most existing approaches are
task-agnostic, failing to fully exploit task-specific adaptations, which leads
to suboptimal efficiency and performance. To address this limitation, we
propose Task-Relevant Parameter and Token Selection (TR-PTS), a task-driven
framework that enhances both computational efficiency and accuracy.
Specifically, we introduce Task-Relevant Parameter Selection, which utilizes
the Fisher Information Matrix (FIM) to identify and fine-tune only the most
informative parameters in a layer-wise manner, while keeping the remaining
parameters frozen. Simultaneously, Task-Relevant Token Selection dynamically
preserves the most informative tokens and merges redundant ones, reducing
computational overhead. By jointly optimizing parameters and tokens, TR-PTS
enables the model to concentrate on task-discriminative information. We
evaluate TR-PTS on benchmark, including FGVC and VTAB-1k, where it achieves
state-of-the-art performance, surpassing full fine-tuning by 3.40% and 10.35%,
respectively. The code are available at https://github.com/synbol/TR-PTS.

</details>


### [68] [LCS: An AI-based Low-Complexity Scaler for Power-Efficient Super-Resolution of Game Content](https://arxiv.org/abs/2507.22873)
*Simon Pochinda,Momen K. Tageldeen,Mark Thompson,Tony Rinaldi,Troy Giorshev,Keith Lee,Jie Zhou,Frederick Walls*

Main category: cs.CV

TL;DR: 提出一种基于AI的低复杂度缩放器（LCS），利用高效超分辨率（ESR）模型减少GPU负载，将工作转移到NPU等低功耗设备上。通过对抗性训练、重参数化和量化技术优化模型，实验证明LCS在多个指标上优于AMD的硬件缩放方案，感知质量更佳。


<details>
  <summary>Details</summary>
Motivation: 现代游戏内容渲染日益复杂，GPU负载过大。为减轻GPU负担，作者希望将高分辨率渲染任务转移到低功耗设备（如NPU）上执行。

Method: 1. 训练数据：使用游戏中低分辨率和高分辨率配对的图像（GameIR）；
2. 模型设计：基于高效超分辨率（ESR）模型构建LCS；
3. 训练策略：采用对抗训练以提升感知细节重建质量；
4. 模型压缩：应用重参数化和量化技术降低模型复杂性和尺寸；
5. 对比方法：与AMD EASF、FSR1硬件缩放方案比较；
6. 评估指标：使用五种不同指标（包括感知质量）。

Result: LCS在五项指标上均优于AMD的EASF和FSR1方案，尤其在感知质量方面表现更佳，验证了高效超分辨率模型在资源受限设备上进行图像放大的潜力。

Conclusion: 基于AI的低复杂度缩放器（LCS）能有效减轻GPU负载，并在感知质量上优于现有硬件方案，为资源受限设备提供高质量图像放大解决方案。

Abstract: The increasing complexity of content rendering in modern games has led to a
problematic growth in the workload of the GPU. In this paper, we propose an
AI-based low-complexity scaler (LCS) inspired by state-of-the-art efficient
super-resolution (ESR) models which could offload the workload on the GPU to a
low-power device such as a neural processing unit (NPU). The LCS is trained on
GameIR image pairs natively rendered at low and high resolution. We utilize
adversarial training to encourage reconstruction of perceptually important
details, and apply reparameterization and quantization techniques to reduce
model complexity and size. In our comparative analysis we evaluate the LCS
alongside the publicly available AMD hardware-based Edge Adaptive Scaling
Function (EASF) and AMD FidelityFX Super Resolution 1 (FSR1) on five different
metrics, and find that the LCS achieves better perceptual quality,
demonstrating the potential of ESR models for upscaling on resource-constrained
devices.

</details>


### [69] [Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation](https://arxiv.org/abs/2507.22886)
*Kaining Ying,Henghui Ding,Guanquan Jie,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 提出了OmniAVS数据集，包含8种模态的表达组合，强调对音频内容的理解和复杂推理，并引入了OISA模型来处理多模态推理和细粒度音视频内容分割。


<details>
  <summary>Details</summary>
Motivation: 现有的Referring Audio-Visual Segmentation（RAVS）在整合多模态信息和深入理解音视频内容方面仍存在挑战，需要扩展RAVS的边界并促进未来研究。

Method: 构建了OmniAVS数据集，包含2098个视频和59458个多模态参考表达式，具有8种多模态表达组合、强调音频内容理解及包含复杂推理和世界知识的特点。提出了Omnimodal Instructed Segmentation Assistant (OISA)模型，利用MLLM（多模态大语言模型）理解复杂线索并进行基于推理的分割。

Result: 在OmniAVS数据集上的实验显示，OISA超越了现有方法，并在其他相关任务上取得了有竞争力的结果。

Conclusion: OmniAVS推动了RAVS领域的发展，OISA模型有效解决了多模态推理和细粒度理解的挑战，为未来研究提供了新基准。

Abstract: Referring audio-visual segmentation (RAVS) has recently seen significant
advancements, yet challenges remain in integrating multimodal information and
deeply understanding and reasoning about audiovisual content. To extend the
boundaries of RAVS and facilitate future research in this field, we propose
Omnimodal Referring Audio-Visual Segmentation (OmniAVS), a new dataset
containing 2,098 videos and 59,458 multimodal referring expressions. OmniAVS
stands out with three key innovations: (1) 8 types of multimodal expressions
that flexibly combine text, speech, sound, and visual cues; (2) an emphasis on
understanding audio content beyond just detecting their presence; and (3) the
inclusion of complex reasoning and world knowledge in expressions. Furthermore,
we introduce Omnimodal Instructed Segmentation Assistant (OISA), to address the
challenges of multimodal reasoning and fine-grained understanding of
audiovisual content in OmniAVS. OISA uses MLLM to comprehend complex cues and
perform reasoning-based segmentation. Extensive experiments show that OISA
outperforms existing methods on OmniAVS and achieves competitive results on
other related tasks.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [70] [IndoPref: A Multi-Domain Pairwise Preference Dataset for Indonesian](https://arxiv.org/abs/2507.22159)
*Vanessa Rebecca Wiyono,David Anugraha,Ayu Purwarianti,Genta Indra Winata*

Main category: cs.CL

TL;DR: IndoPref是第一个全人工标注、多领域的印尼语偏好数据集，用于评估大语言模型生成文本的自然性和质量，以解决印尼语在偏好研究中代表性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 虽然超过2亿人讲印尼语，但该语言在大型语言模型（LLMs）的偏好研究中明显代表性不足。现有的多语言数据集大多源自英语翻译，常导致内容缺乏文化和语言真实性。

Method: 构建IndoPref——首个全人工标注、多领域的印尼语偏好数据集。所有标注均由印尼母语者完成，并使用Krippendorff's alpha系数评估标注者间的一致性，表现出较高的可靠性。此外，还在多个LLM上进行基准测试，评估各模型的输出质量。

Result: 数据集通过Krippendorff's alpha显示出较强的标注者间一致性。同时，在多模型基准测试中评估了不同模型的输出质量。

Conclusion: IndoPref弥补了印尼语在偏好研究领域的空白，为更真实、可靠地评估印尼语文本生成提供基础，并已证明其作为评估工具的有效性。

Abstract: Over 200 million people speak Indonesian, yet the language remains
significantly underrepresented in preference-based research for large language
models (LLMs). Most existing multilingual datasets are derived from English
translations, often resulting in content that lacks cultural and linguistic
authenticity. To address this gap, we introduce IndoPref, the first fully
human-authored and multi-domain Indonesian preference dataset specifically
designed to evaluate the naturalness and quality of LLM-generated text. All
annotations are natively written in Indonesian and evaluated using
Krippendorff's alpha, demonstrating strong inter-annotator agreement.
Additionally, we benchmark the dataset across multiple LLMs and assess the
output quality of each model.

</details>


### [71] [Persona-Augmented Benchmarking: Evaluating LLMs Across Diverse Writing Styles](https://arxiv.org/abs/2507.22168)
*Kimberly Le Truong,Riccardo Fogliato,Hoda Heidari,Zhiwei Steven Wu*

Main category: cs.CL

TL;DR: 当前大语言模型（LLM）评测基准的写作风格多样性不足，可能导致LLM在面对非标准输入时表现脆弱。本研究通过基于人物角色的提示语改写模拟多样化写作风格，发现即使语义一致，写作风格及格式的变化也将显著影响性能评估结果；还识别出对多个任务/模型均能触发低/高水平的特定写作风格参数。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准缺乏写作风格多样性，其标准化格式未能反映人类交流模式的丰富性；担心优化此类基准训练的LLM面对非标准输入时表现脆弱性。

Method: [1] 基于人物角色的LLM提示重写（低成本模拟多样化写作风格）[2] 保持语义不变仅改变表述风格/格式 [3] 测试不同风格提示在多个LLM任务上的性能变化 [4] 分析触发高低性能的风格模式

Result: [1] 发现即便语义相同，写作风格/格式变动将显著改变LLM性能估值 [2] 识别出在模型族/规模/发布时间无关前提下，特定写作风格可对多任务多模型持续产生低/高水平表现

Conclusion: 提出可拓展的基准增强方法，通过纳入写作风格多样性提高LLM评估的外部有效性（测量跨语言变体的稳定性），验证了风格变化对现有评估基准的重要影响。

Abstract: Current benchmarks for evaluating Large Language Models (LLMs) often do not
exhibit enough writing style diversity, with many adhering primarily to
standardized conventions. Such benchmarks do not fully capture the rich variety
of communication patterns exhibited by humans. Thus, it is possible that LLMs,
which are optimized on these benchmarks, may demonstrate brittle performance
when faced with "non-standard" input. In this work, we test this hypothesis by
rewriting evaluation prompts using persona-based LLM prompting, a low-cost
method to emulate diverse writing styles. Our results show that, even with
identical semantic content, variations in writing style and prompt formatting
significantly impact the estimated performance of the LLM under evaluation.
Notably, we identify distinct writing styles that consistently trigger either
low or high performance across a range of models and tasks, irrespective of
model family, size, and recency. Our work offers a scalable approach to augment
existing benchmarks, improving the external validity of the assessments they
provide for measuring LLM performance across linguistic variations.

</details>


### [72] [A Scalable Pipeline for Estimating Verb Frame Frequencies Using Large Language Models](https://arxiv.org/abs/2507.22187)
*Adam M. Morgan,Adeen Flinker*

Main category: cs.CL

TL;DR: 使用大型语言模型（LLMs）自动估计动词框架频率（VFF）的管道，该方法优于现有解析器，且资源消耗少于人工解析，并生成了一个更全面的新VFF数据库。


<details>
  <summary>Details</summary>
Motivation: 动词框架频率（VFF）是研究人类和机器语言系统中语法的重要窗口，但现有计算工具在规模、准确性和可访问性上存在局限。

Method: 1. 使用LLMs生成包含476个英语动词的句子语料库。2. 指导LLM像专家语言学家一样分析这些句子的句法结构。3. 利用该管道代替手工解析，以更少资源实现快速、可扩展的VFF估计。4. 构建新的VFF数据库，覆盖更广的动词、更细粒度的句法区分，并提供结构变体的相对频率估计。

Result: 该管道在多个评估数据集上优于两种广泛使用的句法解析器。生成了一个新的VFF数据库，具有更广泛的动词覆盖范围、更细粒度的句法区分，以及对心理语言学中常见结构变体的相对频率估计。

Conclusion: 该研究提供了一种自动化的帧频率估计方案，易于定制和扩展到新动词、句法框架及其他语言。所有代码和数据已开源，支持未来研究。

Abstract: We present an automated pipeline for estimating Verb Frame Frequencies
(VFFs), the frequency with which a verb appears in particular syntactic frames.
VFFs provide a powerful window into syntax in both human and machine language
systems, but existing tools for calculating them are limited in scale,
accuracy, or accessibility. We use large language models (LLMs) to generate a
corpus of sentences containing 476 English verbs. Next, by instructing an LLM
to behave like an expert linguist, we had it analyze the syntactic structure of
the sentences in this corpus. This pipeline outperforms two widely used
syntactic parsers across multiple evaluation datasets. Furthermore, it requires
far fewer resources than manual parsing (the gold-standard), thereby enabling
rapid, scalable VFF estimation. Using the LLM parser, we produce a new VFF
database with broader verb coverage, finer-grained syntactic distinctions, and
explicit estimates of the relative frequencies of structural alternates
commonly studied in psycholinguistics. The pipeline is easily customizable and
extensible to new verbs, syntactic frames, and even other languages. We present
this work as a proof of concept for automated frame frequency estimation, and
release all code and data to support future research.

</details>


### [73] [The role of media memorability in facilitating startups' access to venture capital funding](https://arxiv.org/abs/2507.22201)
*L. Toschi,S. Torrisi,A. Fronzetti Colladon*

Main category: cs.CL

TL;DR: 本文引入媒体记忆性的概念，探究其对风险投资决策的影响，并发现初创公司的媒体记忆性（通过新闻网络中的独特性和连通性体现）显著影响投资结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究过于关注媒体的整体曝光，而忽视了媒体内容中更细微的方面如何影响风险资本的投资决策。因此，研究需要引入媒体记忆性的概念，理解其如何在风险投资者的决策中发挥作用。

Method: 研究使用了197家英国微纳米技术领域初创公司（1995年至2004年间获得投资）的数据，分析了媒体报道如何通过影响投资者的记忆（以媒体记忆性为代表）进而影响投资结果。具体而言，媒体记忆性通过媒体报道中初创公司名称的独特性（distinctiveness）以及其在新闻语义网络中的连通性（connectivity）来衡量。

Result: 研究发现媒体记忆性显著影响投资结果。风险资本家会关注媒体报道中的详细线索，如初创公司的独特性及其在新闻语义网络中的连通性，这些线索有助于初创公司在投资者记忆中形成印象，从而影响投资决策。

Conclusion: 本研究表明，除了增加媒体曝光频率，初创公司应通过更有针对性、有意义的报道来提升品牌记忆性，突出其独特性和在行业对话中的相关性；研究也补充了关于创业金融和媒体合法化的文献。

Abstract: Media reputation plays an important role in attracting venture capital
investment. However, prior research has focused too narrowly on general media
exposure, limiting our understanding of how media truly influences funding
decisions. As informed decision-makers, venture capitalists respond to more
nuanced aspects of media content. We introduce the concept of media
memorability - the media's ability to imprint a startup's name in the memory of
relevant investors. Using data from 197 UK startups in the micro and
nanotechnology sector (funded between 1995 and 2004), we show that media
memorability significantly influences investment outcomes. Our findings suggest
that venture capitalists rely on detailed cues such as a startup's
distinctiveness and connectivity within news semantic networks. This
contributes to research on entrepreneurial finance and media legitimation. In
practice, startups should go beyond frequent media mentions to strengthen brand
memorability through more targeted, meaningful coverage highlighting their
uniqueness and relevance within the broader industry conversation.

</details>


### [74] [How Well Does First-Token Entropy Approximate Word Entropy as a Psycholinguistic Predictor?](https://arxiv.org/abs/2507.22209)
*Christian Clark,Byung-Doh Oh,William Schuler*

Main category: cs.CL

TL;DR: 研究探讨了心理语言学中的语境熵测量问题，指出传统方法仅基于单词的第一个子词标记来估计熵会导致低估和失真，并提出一种蒙特卡洛方法来估计单词熵，覆盖可变长度词汇跨度。在阅读时间回归实验中，两种方法得出不同结果，警示使用第一子词标记作为熵近似值的风险。


<details>
  <summary>Details</summary>
Motivation: 语境熵是心理语言学中用于度量单词前处理预期难度的指标。现有研究常基于语言模型下单词第一个子词标记的概率分布估计熵，但这会导致低估和潜在失真。为更准确捕捉单词熵，研究者提出改进方法。

Method: 采用蒙特卡洛方法估计单词熵——通过模拟多个可能的单词生成后续，允许单词跨越可变数量的子词标记，从而避免依赖首个标记概率造成的偏差。

Result: 在阅读时间数据上的回归实验中，传统首子词标记熵估计方法与蒙特卡洛方法产生显著差异：蒙特卡洛估计显示更合理语言加工预测效应，而前者可能因低估导致无效或反向预测效果（具体系数对比需参考实验表格）

Conclusion: 论文证明基于第一子词标记的语境熵近似存在缺陷，蒙特卡洛方法能更准确地估计真实单词熵。心理语言学研究需谨慎选用熵测算方法以免导致错误推论，并建议后续研究采纳多标记跨度的完整单词熵评估。

Abstract: Contextual entropy is a psycholinguistic measure capturing the anticipated
difficulty of processing a word just before it is encountered. Recent studies
have tested for entropy-related effects as a potential complement to well-known
effects from surprisal. For convenience, entropy is typically estimated based
on a language model's probability distribution over a word's first subword
token. However, this approximation results in underestimation and potential
distortion of true word entropy. To address this, we generate Monte Carlo (MC)
estimates of word entropy that allow words to span a variable number of tokens.
Regression experiments on reading times show divergent results between
first-token and MC word entropy, suggesting a need for caution in using
first-token approximations of contextual entropy.

</details>


### [75] [RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation](https://arxiv.org/abs/2507.22219)
*Dongyub Jude Lee,Zhenyi Ye,Pengcheng He*

Main category: cs.CL

TL;DR: 提出了一种名为RLfR（Reinforcement Learning from Teacher-Model Refinement）的新型框架，通过外部教师模型（GPT-4o）提供连续高质量反馈，避免了传统基于静态三元组数据集的依赖，并在多语言翻译任务中显著提升了语义保真度和实体保留能力。


<details>
  <summary>Details</summary>
Motivation: 当前的偏好学习方法（如DPO）严重依赖大型且精心策划的三元组数据集，且难以泛化到调优域之外。这促使研究者寻求一种不依赖静态数据、能持续学习的方法。

Method: RLfR框架将每个翻译步骤构建为微教学：首先，演员（actor）生成译文假设；其次，教师模型（GPT-4o）对该译文进行精炼；最后，演员根据其输出与教师精炼结果的匹配度获得奖励。奖励信号结合了两种互补指标：负编辑距离（评估词汇和结构忠实度）和COMET分数（确保语义充分性）。演员通过这种逐步迭代的奖励机制学习模仿教师模型的改进行为。

Result: 在FLORES-200基准测试（涵盖英⇄德/西/中/韩/日双向翻译）上，RLfR在语义充分性（COMET）和实体保留（M-ETA）分数上均显著超越基线方法MT-SFT和基于偏好的方法。

Conclusion: RLfR通过教师模型提供的动态精炼反馈，使机器翻译模型得以持续迭代优化，不仅免除了对静态三元组数据的强依赖，还能跨语言对实现翻译质量的有效提升。该方法模拟了人类渐进式学习过程，为偏好学习领域提供了新范式。

Abstract: Preference-learning methods for machine translation (MT)--such as Direct
Preference Optimization (DPO)--have achieved impressive gains but depend
heavily on large, carefully curated triplet datasets and often struggle to
generalize beyond their tuning domains. We propose Reinforcement Learning from
Teacher-Model Refinement (RLfR), a novel framework that removes reliance on
static triplets by leveraging continuous, high-quality feedback from an
external teacher model (GPT-4o). RLfR frames each translation step as a
micro-tutorial: the actor generates a hypothesis, the teacher refines it, and
the actor is rewarded based on how closely it aligns with the teacher's
refinement. Guided by two complementary signals--(i) negative edit distance,
promoting lexical and structural fidelity, and (ii) COMET score, ensuring
semantic adequacy--the actor progressively learns to emulate the teacher,
mirroring a human learning process through incremental, iterative improvement.
On the FLORES-200 benchmark (English to and from German, Spanish, Chinese,
Korean, and Japanese), RLfR consistently outperforms both MT-SFT and
preference-based baselines, significantly improving COMET (semantic adequacy)
and M-ETA (entity preservation) scores.

</details>


### [76] [Meaning-infused grammar: Gradient Acceptability Shapes the Geometric Representations of Constructions in LLMs](https://arxiv.org/abs/2507.22286)
*Supantho Rakshit,Adele Goldberg*

Main category: cs.CL

TL;DR: 这项研究探讨了大型语言模型（LLMs）的内部表征是否反映了基于用法的构式主义理论中的功能注入梯度性。通过分析英语与格构式在Pythia-1.4B模型中的表征，发现构式表征的可分离性受人类偏好强度梯度调节，证明了LLMs学习到了丰富的、含语义的渐变构式表征。


<details>
  <summary>Details</summary>
Motivation: 基于用法的构式主义理论认为语言由形式-意义对（构式）组成，其使用主要受意义/功能驱动，且具有梯度性和概率性。本研究旨在验证LLMs的内部表征是否也符合这种功能注入的梯度特性。

Method: 使用英语双宾构式和介词宾语构式的5000个句对数据集（系统化调整人类偏好强度），在Pythia-1.4B模型中分析其神经表征。通过能量距离和Jensen-Shannon散度进行宏观几何分析，测量构式表征的可分离性。

Result: 构式表征的可分离性受梯度偏好强度的系统性调节：每种构式中更典型的示例在LLM激活空间中占据更独特的区域。

Conclusion: LLMs学习了丰富且注入语义的渐变构式表征，支持将几何测量作为验证LLMs中构式主义基本原则的工具。

Abstract: The usage-based constructionist (UCx) approach posits that language comprises
a network of learned form-meaning pairings (constructions) whose use is largely
determined by their meanings or functions, requiring them to be graded and
probabilistic. This study investigates whether the internal representations in
Large Language Models (LLMs) reflect the proposed function-infused gradience.
We analyze the neural representations of the English dative constructions
(Double Object and Prepositional Object) in Pythia-$1.4$B, using a dataset of
$5000$ sentence pairs systematically varied for human-rated preference
strength. A macro-level geometric analysis finds that the separability between
construction representations, as measured by Energy Distance or Jensen-Shannon
Divergence, is systematically modulated by gradient preference strength. More
prototypical exemplars of each construction occupy more distinct regions in the
activation space of LLMs. These results provide strong evidence that LLMs learn
rich, meaning-infused, graded representations of constructions and offer
support for geometric measures of basic constructionist principles in LLMs.

</details>


### [77] [Intent Recognition and Out-of-Scope Detection using LLMs in Multi-party Conversations](https://arxiv.org/abs/2507.22289)
*Galo Castillo-López,Gaël de Chalendar,Nasredine Semmar*

Main category: cs.CL

TL;DR: 提出了一个结合BERT和大型语言模型（LLM）的混合方法，用于零样本和少样本设置下的意图识别和超出范围（OOS）检测，以提高任务导向对话系统（TODS）的意图识别能力。该方法利用LLM的泛化能力和BERT的计算效率，并在多方对话语料库上验证了性能提升。


<details>
  <summary>Details</summary>
Motivation: 任务导向对话系统（TODS）需要大量标注数据进行意图识别和超出范围（OOS）检测，但在现实场景中获取标注数据困难。因此，作者提出一种混合方法，结合BERT的计算效率和LLM的泛化能力，在零样本和少样本条件下提升意图识别的效果。

Method: 1. 提出一个混合框架：使用BERT作为快速意图识别器，并将BERT的输出作为提示词的一部分输入给LLM，以优化LLM的推理过程。2. 在零样本和少样本设置下应用该方法，利用LLM的泛化能力减少对标注数据的依赖。3. 设计信息共享机制：将BERT的预测结果（如意图标签和置信度）作为上下文信息提供给LLM，从而帮助LLM更准确地进行意图识别和OOS检测。

Result: 实验在多方对话语料库上进行。结果显示，与传统单独使用BERT或LLM的方式相比，混合方法显著提高了意图识别准确率和OOS检测的可靠性。另外，共享BERT的输出信息到LLM后，整体系统性能得到了提升。

Conclusion: 混合BERT与LLM的方法有效结合了两者的优势，在标注数据有限的场景下提升了意图识别和OOS检测的性能。该方法为任务导向对话系统的意图识别提供了一种高效低成本的解决方案。

Abstract: Intent recognition is a fundamental component in task-oriented dialogue
systems (TODS). Determining user intents and detecting whether an intent is
Out-of-Scope (OOS) is crucial for TODS to provide reliable responses. However,
traditional TODS require large amount of annotated data. In this work we
propose a hybrid approach to combine BERT and LLMs in zero and few-shot
settings to recognize intents and detect OOS utterances. Our approach leverages
LLMs generalization power and BERT's computational efficiency in such
scenarios. We evaluate our method on multi-party conversation corpora and
observe that sharing information from BERT outputs to LLMs leads to system
performance improvement.

</details>


### [78] [A Comprehensive Taxonomy of Negation for NLP and Neural Retrievers](https://arxiv.org/abs/2507.22337)
*Roxana Petcu,Samarth Bhargav,Maarten de Rijke,Evangelos Kanoulas*

Main category: cs.CL

TL;DR: 该研究针对信息检索中否定查询处理不足的问题，提出了一个否定分类法，创建了两个基准数据集，并开发了一种基于逻辑的分类机制，用于评估和提升神经信息检索模型在否定查询上的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管密集神经模型学习了上下文化的嵌入，但在包含否定的查询上表现不佳。为了理解这一现象，研究旨在探索传统神经信息检索模型和基于LLM的模型在处理否定时的表现。

Method: 1. 引入了源自哲学、语言学和逻辑学定义的否定分类法；2. 生成了两个基准数据集，用于评估神经信息检索模型的性能，并微调模型以在否定查询上获得更鲁棒的性能；3. 提出了一种基于逻辑的分类机制，用于分析检索模型在现有数据集上的表现。

Result: 该分类法在NevIR数据集上产生了平衡的数据分布，提供了更好的训练设置，从而实现了更快的收敛速度。同时，提出的分类模式揭示了现有数据集中否定类型的覆盖情况，为微调模型在否定上的泛化因素提供了洞见。

Conclusion: 研究通过提出新的分类法、数据集和分类机制，为改善神经信息检索模型在否定查询上的性能提供了有效工具，并揭示了模型在否定处理上的泛化因素。

Abstract: Understanding and solving complex reasoning tasks is vital for addressing the
information needs of a user. Although dense neural models learn contextualised
embeddings, they still underperform on queries containing negation. To
understand this phenomenon, we study negation in both traditional neural
information retrieval and LLM-based models. We (1) introduce a taxonomy of
negation that derives from philosophical, linguistic, and logical definitions;
(2) generate two benchmark datasets that can be used to evaluate the
performance of neural information retrieval models and to fine-tune models for
a more robust performance on negation; and (3) propose a logic-based
classification mechanism that can be used to analyze the performance of
retrieval models on existing datasets. Our taxonomy produces a balanced data
distribution over negation types, providing a better training setup that leads
to faster convergence on the NevIR dataset. Moreover, we propose a
classification schema that reveals the coverage of negation types in existing
datasets, offering insights into the factors that might affect the
generalization of fine-tuned models on negation.

</details>


### [79] [Traits Run Deep: Enhancing Personality Assessment via Psychology-Guided LLM Representations and Multimodal Apparent Behaviors](https://arxiv.org/abs/2507.22367)
*Jia Li,Yichao He,Jiacheng Xu,Tianhao Luo,Zhenzhen Hu,Richang Hong,Meng Wang*

Main category: cs.CL

TL;DR: 本文提出了一个名为Traits Run Deep的人格评估框架，使用心理学启发的提示和以文本为中心的特征融合网络，在多个模态中融合异步信号以提升人格评估的准确性。在AVI挑战赛2025上排名第一。


<details>
  <summary>Details</summary>
Motivation: 传统的表面特征难以建模人格语义，且难以实现有效的跨模态理解。人格特质稳定地通过语言、面部表情和身体行为无意识泄露，但各模态间存在异步性。因此需要一种能提取高质量人格感知表达并融合异步多模态信号的框架。

Method: （1）使用心理学启发的提示（prompts）引导大语言模型（LLMs）提取高层次的人格相关语义表示；（2）设计一个以文本为中心的特质融合网络（Text-Centric Trait Fusion Network），通过文本特征作为锚点来对齐和融合其他模态的异步信号。具体包括：块级投影器降维、跨模态连接器与文本特征增强器实现模态融合、集成回归头提高数据稀缺时的泛化能力；（3）同时融合音频和视觉模态的外观行为特征以提高准确性。

Result: 在AVI验证集上，与基线相比，平均平方误差（MSE）降低了约45%；在AVI挑战赛2025测试集的人格评估赛道中获得第一名的成绩。

Conclusion: 该方法通过心理学提示引导LLMs和跨模态融合网络，有效解决了人格评估中的表示质量和异步多模态融合问题。源代码将公开。

Abstract: Accurate and reliable personality assessment plays a vital role in many
fields, such as emotional intelligence, mental health diagnostics, and
personalized education. Unlike fleeting emotions, personality traits are
stable, often subconsciously leaked through language, facial expressions, and
body behaviors, with asynchronous patterns across modalities. It was hard to
model personality semantics with traditional superficial features and seemed
impossible to achieve effective cross-modal understanding. To address these
challenges, we propose a novel personality assessment framework called
\textit{\textbf{Traits Run Deep}}. It employs
\textit{\textbf{psychology-informed prompts}} to elicit high-level
personality-relevant semantic representations. Besides, it devises a
\textit{\textbf{Text-Centric Trait Fusion Network}} that anchors rich text
semantics to align and integrate asynchronous signals from other modalities. To
be specific, such fusion module includes a Chunk-Wise Projector to decrease
dimensionality, a Cross-Modal Connector and a Text Feature Enhancer for
effective modality fusion and an ensemble regression head to improve
generalization in data-scarce situations. To our knowledge, we are the first to
apply personality-specific prompts to guide large language models (LLMs) in
extracting personality-aware semantics for improved representation quality.
Furthermore, extracting and fusing audio-visual apparent behavior features
further improves the accuracy. Experimental results on the AVI validation set
have demonstrated the effectiveness of the proposed components, i.e.,
approximately a 45\% reduction in mean squared error (MSE). Final evaluations
on the test set of the AVI Challenge 2025 confirm our method's superiority,
ranking first in the Personality Assessment track. The source code will be made
available at https://github.com/MSA-LMC/TraitsRunDeep.

</details>


### [80] [PATENTWRITER: A Benchmarking Study for Patent Drafting with LLMs](https://arxiv.org/abs/2507.22387)
*Homaira Huda Shomee,Suman Kalyan Maity,Sourav Medya*

Main category: cs.CL

TL;DR: 本文提出了PATENTWRITER，首个评估大型语言模型（LLMs）在专利摘要生成任务的统一基准框架，测试包括GPT-4和LLaMA-3在内的六种模型，并在多个维度评估生成质量，结果表明现代LLMs能够生成高保真且符合风格的专利摘要。


<details>
  <summary>Details</summary>
Motivation: 专利撰写流程繁琐，本文希望通过利用LLMs来改变专利撰写方式。

Method: 提出统一基准框架PATENTWRITER，在给定专利权利要求第一条的情况下，采用零样本、少样本及思维链提示策略系统评估六种主流LLMs生成专利摘要的能力。评估指标包括标准NLP指标（BLEU、ROUGE、BERTScore）、三种输入扰动下的鲁棒性、两项下游任务（专利分类和检索）表现以及风格分析（长度、可读性、语调）。

Result: 现代LLMs能够生成高质量且符合风格的专利摘要，其表现常超越领域特定基线模型。

Conclusion: PATENTWRITER框架为LLMs在专利摘要生成提供了可靠评估，表明LLMs在该任务上具有实用潜力，并开源代码及数据集推动后续研究。

Abstract: Large language models (LLMs) have emerged as transformative approaches in
several important fields. This paper aims for a paradigm shift for patent
writing by leveraging LLMs to overcome the tedious patent-filing process. In
this work, we present PATENTWRITER, the first unified benchmarking framework
for evaluating LLMs in patent abstract generation. Given the first claim of a
patent, we evaluate six leading LLMs -- including GPT-4 and LLaMA-3 -- under a
consistent setup spanning zero-shot, few-shot, and chain-of-thought prompting
strategies to generate the abstract of the patent. Our benchmark PATENTWRITER
goes beyond surface-level evaluation: we systematically assess the output
quality using a comprehensive suite of metrics -- standard NLP measures (e.g.,
BLEU, ROUGE, BERTScore), robustness under three types of input perturbations,
and applicability in two downstream patent classification and retrieval tasks.
We also conduct stylistic analysis to assess length, readability, and tone.
Experimental results show that modern LLMs can generate high-fidelity and
stylistically appropriate patent abstracts, often surpassing domain-specific
baselines. Our code and dataset are open-sourced to support reproducibility and
future research.

</details>


### [81] [Question Generation for Assessing Early Literacy Reading Comprehension](https://arxiv.org/abs/2507.22410)
*Xiaocheng Yang,Sumuk Shashidhar,Dilek Hakkani-Tur*

Main category: cs.CL

TL;DR: 提出了一种针对K-2英语学习者的阅读理解问题生成方法，该方法确保内容全覆盖、适应学习者能力，并生成多种题型和难度的问题。


<details>
  <summary>Details</summary>
Motivation: 在阅读习得过程中，基于内容的阅读理解评估至关重要。但生成适合K-2英语学习者、能够全覆盖材料并适应其能力的问题仍具挑战性。

Method: 使用FairytaleQA数据集作为源材料，评估不同语言模型在框架中的表现。方法注重内容全覆盖、能力适应，并能生成多种题型和难度的问题。

Result: 研究表明所提出的方法有效支持了多种问题生成，初步评估显示其潜力。（注意：摘要未明确列出具体数值结果）

Conclusion: 该方法有望成为AI驱动的自主英语教学的重要组成部分，尤其适用于低龄学习者的阅读理解评估。

Abstract: Assessment of reading comprehension through content-based interactions plays
an important role in the reading acquisition process. In this paper, we propose
a novel approach for generating comprehension questions geared to K-2 English
learners. Our method ensures complete coverage of the underlying material and
adaptation to the learner's specific proficiencies, and can generate a large
diversity of question types at various difficulty levels to ensure a thorough
evaluation. We evaluate the performance of various language models in this
framework using the FairytaleQA dataset as the source material. Eventually, the
proposed approach has the potential to become an important part of autonomous
AI-driven English instructors.

</details>


### [82] [NeedleChain: Measuring Intact Long-Context Reasoning Capability of Large Language Models](https://arxiv.org/abs/2507.22411)
*Hyeonseok Moon,Heuiseok Lim*

Main category: cs.CL

TL;DR: 该论文指出，现有的 NIAH（大海捞针）基准测试可能高估了大型语言模型（LLM）的长上下文理解能力。作者发现即便是最先进的模型如 GPT-4o 在仅包含10个与查询相关句子的短上下文中也存在困难。为此，他们提出新的基准测试 NeedleChain，它使用完全由查询相关信息组成的上下文，并允许灵活调整上下文长度和推理顺序，从而为 LLM 性能提供更全面的分析。此外，作者还提出一种简单的方法 ROPE Contraction 来提升模型的长期上下文理解能力。实验表明当前先进模型在长上下文理解方面仍存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有的 NIAH 基准测试可能无法准确评估大型语言模型（LLM）的长上下文理解能力，因为 NIAH 测试需要从大量无关信息（干草堆）中找出少量相关信息（针），实际上无关信息过多会干扰模型对相关信息的有效整合，导致测试结果可能高估模型的真实能力。另外，作者希望设计一种更全面、更灵活的基准测试来更准确地评估 LLM 的长上下文能力。因此研究问题主要包括设计更有效的评估基准，并提出提升模型长文本理解能力的方法。

Method: 首先，作者发现现有 NIAH 测试方法的弊端：它仅需模型从大量无关信息中找出少量相关信息，因此模型成功定位到“针”后无需全面理解整个文本（干草堆中的无关部分无需理解）。但现实中模型需要理解完整的相关上下文，因此 NIAH存在测试偏误。针对此，作者提出全新的基准测试 NeedleChain：测试上下文中全部信息都相关，从而迫使模型必须完整理解所有内容才能正确回答问题。上下文长度和句子顺序均可灵活调整，能够更全面地衡量模型的上下文理解能力。此外，作者提出一种改进模型长文本理解能力的方法 ROPE Contraction，具体方法是移除 LLM 输入中某些冗余内容（比如重复标题、空格等），使模型能更关注核心信息。

Result: 1. NeedleChain 测试表明，即使是最先进的模型如 GPT-4o、Claude 等在处理完全由相关句子构成的长文本时准确率仍不足。相比之下，它们在NIAH测试中表现优秀，这验证了 NIAH 测试可能高估模型能力的假设。2. NeedleChain 的测试结果揭示了当前 LLM实际的长文本理解能力的不足。3. ROPE Contraction 方法在实验中有效提升了模型在长上下文任务中的准确率。

Conclusion: 该研究的主要结论包括两点：1. 广泛使用的 NIAH 测试方法高估了模型的真实长上下文理解能力；2. 提出的新基准测试 NeedleChain 能更有效评估模型理解完整上下文的能力；同时提出的简单策略 ROPE Contraction 在实验中被证明有效提升模型的上下文理解力。未来方向包括基于 NeedleChain 设计更多评估场景和持续改进长文本处理方法。

Abstract: The Needle-in-a-Haystack (NIAH) benchmark is widely used to evaluate Large
Language Models' (LLMs) ability to understand long contexts (LC). It evaluates
the capability to identify query-relevant context within extensive
query-irrelevant passages. Although this method serves as a widely accepted
standard for evaluating long-context understanding, our findings suggest it may
overestimate the true LC capability of LLMs. We demonstrate that even
state-of-the-art models such as GPT-4o struggle to intactly incorporate given
contexts made up of solely query-relevant ten sentences. In response, we
introduce a novel benchmark, \textbf{NeedleChain}, where the context consists
entirely of query-relevant information, requiring the LLM to fully grasp the
input to answer correctly. Our benchmark allows for flexible context length and
reasoning order, offering a more comprehensive analysis of LLM performance.
Additionally, we propose an extremely simple yet compelling strategy to improve
LC understanding capability of LLM: ROPE Contraction. Our experiments with
various advanced LLMs reveal a notable disparity between their ability to
process large contexts and their capacity to fully understand them. Source code
and datasets are available at https://github.com/hyeonseokk/NeedleChain

</details>


### [83] [AI-generated stories favour stability over change: homogeneity and cultural stereotyping in narratives generated by gpt-4o-mini](https://arxiv.org/abs/2507.22445)
*Jill Walker Rettberg,Hermann Wigers*

Main category: cs.CL

TL;DR: 该研究使用GPT-4o-mini为236个国家生成11,800个故事，发现无论国家文化背景如何，生成的故事均呈现出单一叙事结构：主角在小镇通过回归传统和组织社区活动解决小冲突。研究指出这是一种新型的AI偏差——叙事标准化。


<details>
  <summary>Details</summary>
Motivation: 探究主要在盎格鲁-撒克逊文本上训练的语言模型能否为不同国家生成具有文化相关性的故事，以及揭示生成式AI可能存在的文化偏差问题。

Method: 1. 向GPT-4o-mini模型发送标准化提示："写一个1500字的潜在{国家称谓}故事"；2. 为236个国家各生成50个故事（总计11,800篇）；3. 对故事内容进行叙事结构和主题分析。

Result: 1. 故事仅包含表面民族文化符号；2. 98%故事遵循统一叙事结构：主角在小镇通过回归传统/组织活动解决微小冲突；3. 现实冲突被淡化，爱情元素缺失，叙事侧重怀旧与和解；4. 呈现叙事同质化现象：强调稳定优于变革、传统重于发展。

Conclusion: 研究发现AI生成故事存在结构性同质化现象，提出这是区别于表征偏差的新型AI偏差形式——‘叙事标准化’。该现象对文学研究、叙事学、NLP及改善AI文化对齐具有启示意义。

Abstract: Can a language model trained largely on Anglo-American texts generate stories
that are culturally relevant to other nationalities? To find out, we generated
11,800 stories - 50 for each of 236 countries - by sending the prompt "Write a
1500 word potential {demonym} story" to OpenAI's model gpt-4o-mini. Although
the stories do include surface-level national symbols and themes, they
overwhelmingly conform to a single narrative plot structure across countries: a
protagonist lives in or returns home to a small town and resolves a minor
conflict by reconnecting with tradition and organising community events.
Real-world conflicts are sanitised, romance is almost absent, and narrative
tension is downplayed in favour of nostalgia and reconciliation. The result is
a narrative homogenisation: an AI-generated synthetic imaginary that
prioritises stability above change and tradition above growth. We argue that
the structural homogeneity of AI-generated narratives constitutes a distinct
form of AI bias, a narrative standardisation that should be acknowledged
alongside the more familiar representational bias. These findings are relevant
to literary studies, narratology, critical AI studies, NLP research, and
efforts to improve the cultural alignment of generative AI.

</details>


### [84] [Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance](https://arxiv.org/abs/2507.22448)
*Jingwei Zuo,Maksim Velikanov,Ilyas Chahed,Younes Belkada,Dhia Eddine Rhayem,Guillaume Kunsch,Hakim Hacid,Hamza Yous,Brahim Farhat,Ibrahim Khadraoui,Mugariya Farooq,Giulia Campesan,Ruxandra Cojocaru,Yasser Djilali,Shi Hu,Iheb Chaabane,Puneesh Khanna,Mohamed El Amine Seddik,Ngoc Dung Huynh,Phuc Le Khac,Leen AlQadi,Billel Mokeddem,Mohamed Chami,Abdalgader Abubaker,Mikhail Lubinets,Kacper Piskorski,Slim Frikha*

Main category: cs.CL

TL;DR: Falcon-H1系列是一种新型混合架构大语言模型（LLM），结合了Transformer注意力和状态空间模型（SSM），具有高性能和高效率，参数规模涵盖0.5B至34B。该模型在多个方面表现出色，尤其在小参数规模下超越同类更大模型，并支持256K上下文和18种语言。


<details>
  <summary>Details</summary>
Motivation: 为了克服纯Transformer或Mamba模型的效率限制，作者提出混合架构Falcon-H1，旨在兼顾长上下文记忆、计算效率和跨语言多任务性能，打破传统模型设计的局限。

Method: 采用Transformer和SSM的并行混合架构；重新审视了模型设计、数据策略和训练动态；发布基础模型与指令调优模型，提供0.5B-34B多种大小的参数模型；包含量化版本，总计30多个HF Hub检查点。

Result: 34B模型性能媲美70B竞品（如Qwen3-32B/Qwen2.5-72B/Llama3.3-70B）；1.5B-Deep版本相当于7B-10B模型能力；0.5B模型接近主流7B模型表现；在逻辑推理、数学、多语言任务、指令跟随和科学知识领域表现优异。

Conclusion: Falcon-H1通过混合架构实现参数/训练效率的显著提升，在多个基准测试中大幅领先，其开源性质和应用广度（256K上下文+多语言支持）体现了AI研究的开放性与实用性价值。

Abstract: In this report, we introduce Falcon-H1, a new series of large language models
(LLMs) featuring hybrid architecture designs optimized for both high
performance and efficiency across diverse use cases. Unlike earlier Falcon
models built solely on Transformer or Mamba architectures, Falcon-H1 adopts a
parallel hybrid approach that combines Transformer-based attention with State
Space Models (SSMs), known for superior long-context memory and computational
efficiency. We systematically revisited model design, data strategy, and
training dynamics, challenging conventional practices in the field. Falcon-H1
is released in multiple configurations, including base and instruction-tuned
variants at 0.5B, 1.5B, 1.5B-deep, 3B, 7B, and 34B parameters. Quantized
instruction-tuned models are also available, totaling over 30 checkpoints on
Hugging Face Hub. Falcon-H1 models demonstrate state-of-the-art performance and
exceptional parameter and training efficiency. The flagship Falcon-H1-34B
matches or outperforms models up to 70B scale, such as Qwen3-32B, Qwen2.5-72B,
and Llama3.3-70B, while using fewer parameters and less data. Smaller models
show similar trends: the Falcon-H1-1.5B-Deep rivals current leading 7B-10B
models, and Falcon-H1-0.5B performs comparably to typical 7B models from 2024.
These models excel across reasoning, mathematics, multilingual tasks,
instruction following, and scientific knowledge. With support for up to 256K
context tokens and 18 languages, Falcon-H1 is suitable for a wide range of
applications. All models are released under a permissive open-source license,
underscoring our commitment to accessible and impactful AI research.

</details>


### [85] [What is an "Abstract Reasoner"? Revisiting Experiments and Arguments about Large Language Models](https://arxiv.org/abs/2507.22457)
*Tian Yun,Chen Sun,Ellie Pavlick*

Main category: cs.CL

TL;DR: 反驳近期关于大语言模型（LLMs）无法进行抽象推理的论断，研究表明在零样本设置下LLMs表现不佳，但通过微调编码层参数可以实现接近完美的性能。然而，这种微调效果无法跨数据集迁移。论文提出需要重新审视'抽象推理'的定义及其在LLMs中的重要性。


<details>
  <summary>Details</summary>
Motivation: 针对近期研究称LLMs缺乏抽象推理能力（主要基于零样本任务表现）的论断，本论文旨在通过可控实验揭示问题的复杂性：通过参数微调可显著提升LLMs在抽象推理任务上的表现，但同时发现其泛化能力受限。

Method: 1. 在多个抽象推理基准任务上验证LLMs的零样本表现；2. 仅对输入编码层参数进行微调（调整比例0.1%-2%）；3. 测试微调模型在同领域但不同分布数据集上的泛化能力。

Result: 1. 零样本表现确实较差（多项任务准确率<50%）；2. 微调极少量参数后可达97%+任务准确率；3. 微调模型在新数据集上性能平均下降21.3%，表明过拟合且缺乏泛化性。

Conclusion: LLMs具备通过微调实现特定任务抽象推理的能力，但其非通用抽象推理体（因缺乏跨任务泛化）。研究呼吁重新定义'抽象推理'标准，并强调需区分任务专用性能与通用能力。

Abstract: Recent work has argued that large language models (LLMs) are not "abstract
reasoners", citing their poor zero-shot performance on a variety of challenging
tasks as evidence. We revisit these experiments in order to add nuance to the
claim. First, we show that while LLMs indeed perform poorly in a zero-shot
setting, even tuning a small subset of parameters for input encoding can enable
near-perfect performance. However, we also show that this finetuning does not
necessarily transfer across datasets. We take this collection of empirical
results as an invitation to (re-)open the discussion of what it means to be an
"abstract reasoner", and why it matters whether LLMs fit the bill.

</details>


### [86] [IFEvalCode: Controlled Code Generation](https://arxiv.org/abs/2507.22462)
*Jian Yang,Wei Zhang,Shukai Liu,Linzheng Chai,Yingshui Tan,Jiaheng Liu,Ge Zhang,Wangchunshu Zhou,Guanglin Niu,Zhoujun Li,Binyuan Hui,Junyang Lin*

Main category: cs.CL

TL;DR: 论文提出了一种改进代码大语言模型（Code LLMs）在受控代码生成中遵循指令能力的方法，通过前向和后向约束生成技术，使生成的代码更符合人类定义的规范。同时，推出了多语言基准测试IFEvalCode，包含1.6K测试样本覆盖七种编程语言，并设计了正确性（Corr.）和指令遵循性（Instr.）两个独立评估指标。实验评估了超过40种LLMs，发现闭源模型在可控代码生成上优于开源模型，并揭示了模型在生成正确代码和精确遵循指令之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有的代码大语言模型在生成功能正确的代码方面取得了显著进展，但在现实应用中，代码还需要严格符合详细的非功能性需求（如编码风格、行数限制和结构约束）。当前模型在这些指令遵循方面的能力不足，因此需要一种方法来提升模型在受控条件下的代码生成能力，并建立一个更细粒度的评估基准以精确衡量模型表现。

Method: 1. 提出前向和后向约束生成技术：通过设计特定的约束生成机制（前向指在生成过程中动态注入约束，后向指对生成结果进行约束验证与重排），使模型在生成代码时能更好遵循复杂指令。
2. 构建IFEvalCode基准：该基准包含1.6K测试样本，覆盖七种编程语言（Python、Java、JavaScript、TypeScript、Shell、C++、C#），每个样本包含中英文查询。
3. 解耦评估指标：设计两个独立评分维度——正确性（Corr.）评估代码功能是否实现，指令遵循性（Instr.）评估代码是否满足非功能约束要求（如格式、行数等）。

Result: 1. 在40+LLMs的实验中，闭源模型（如GPT系列）在可控代码生成任务上显著优于开源模型。
2. 模型普遍存在正确性（Corr.）与指令遵循性（Instr.）的分离现象：即使生成的代码功能正确，也常违反非功能约束（如行数超限）。
3. 提出的基准IFEvalCode成功量化了这一差距，为模型改进提供明确方向。

Conclusion: 该研究揭示了当前Code LLMs在遵循复杂指令方面的局限性，提出约束生成策略能有效引导模型关注非功能需求。IFEvalCode基准通过解耦评估指标，为可控代码生成提供更准确的评测工具。未来工作需进一步探索如何缩小模型在正确性与指令遵循性之间的差距。

Abstract: Code large language models (Code LLMs) have made significant progress in code
generation by translating natural language descriptions into functional code;
however, real-world applications often demand stricter adherence to detailed
requirements such as coding style, line count, and structural constraints,
beyond mere correctness. To address this, the paper introduces forward and
backward constraints generation to improve the instruction-following
capabilities of Code LLMs in controlled code generation, ensuring outputs align
more closely with human-defined guidelines. The authors further present
IFEvalCode, a multilingual benchmark comprising 1.6K test samples across seven
programming languages (Python, Java, JavaScript, TypeScript, Shell, C++, and
C#), with each sample featuring both Chinese and English queries. Unlike
existing benchmarks, IFEvalCode decouples evaluation into two metrics:
correctness (Corr.) and instruction-following (Instr.), enabling a more nuanced
assessment. Experiments on over 40 LLMs reveal that closed-source models
outperform open-source ones in controllable code generation and highlight a
significant gap between the models' ability to generate correct code versus
code that precisely follows instructions.

</details>


### [87] [SLM-SQL: An Exploration of Small Language Models for Text-to-SQL](https://arxiv.org/abs/2507.22478)
*Lei Sheng,Shuai-Shuai Xu*

Main category: cs.CL

TL;DR: 本文提出SLM-SQL方法，通过后训练技术提升小型语言模型（SLM）在Text-to-SQL任务上的性能。使用新构建的数据集进行监督微调和基于强化学习的后训练，结合自一致性推理，使0.5B和1.5B模型在BIRD开发集上的执行准确率分别达到56.87%和67.08%，平均提升31.4分。


<details>
  <summary>Details</summary>
Motivation: 尽管小型语言模型（SLM）在推理速度和边缘部署上具有优势，但其有限的逻辑推理能力导致在Text-to-SQL任务中表现不佳。为了挖掘SLM在此类任务中的潜力，作者探索了后训练技术的应用。

Method: 1. 从SynSQL-2.5M数据集构建两个新数据集：SynSQL-Think-916K（用于SQL生成）和SynSQL-Merge-Think-310K（用于SQL合并修正）；2. 对SLM进行监督微调；3. 使用强化学习进行后训练；4. 推理阶段采用自一致性方法纠正错误。

Result: 在BIRD开发集上，五个评估模型平均提升31.4个点：0.5B模型达到56.87%的执行准确率（EX），1.5B模型达到67.08% EX。

Conclusion: 所提SLM-SQL方法显著提升了SLM在Text-to-SQL任务上的性能，证明了后训练技术和新数据集的有效性。作者将开源数据集、模型和代码。

Abstract: Large language models (LLMs) have demonstrated strong performance in
translating natural language questions into SQL queries (Text-to-SQL). In
contrast, small language models (SLMs) ranging from 0.5B to 1.5B parameters
currently underperform on Text-to-SQL tasks due to their limited logical
reasoning capabilities. However, SLMs offer inherent advantages in inference
speed and suitability for edge deployment. To explore their potential in
Text-to-SQL applications, we leverage recent advancements in post-training
techniques. Specifically, we used the open-source SynSQL-2.5M dataset to
construct two derived datasets: SynSQL-Think-916K for SQL generation and
SynSQL-Merge-Think-310K for SQL merge revision. We then applied supervised
fine-tuning and reinforcement learning-based post-training to the SLM, followed
by inference using a corrective self-consistency approach. Experimental results
validate the effectiveness and generalizability of our method, SLM-SQL. On the
BIRD development set, the five evaluated models achieved an average improvement
of 31.4 points. Notably, the 0.5B model reached 56.87\% execution accuracy
(EX), while the 1.5B model achieved 67.08\% EX. We will release our dataset,
model, and code to github: https://github.com/CycloneBoy/slm_sql.

</details>


### [88] [CliCARE: Grounding Large Language Models in Clinical Guidelines for Decision Support over Longitudinal Cancer Electronic Health Records](https://arxiv.org/abs/2507.22533)
*Dongchen Li,Jitao Liang,Wei Li,Xiaoyu Wang,Longbing Cao,Kun Yu*

Main category: cs.CL

TL;DR: 本文提出了CliCARE框架，旨在解决大型语言模型(LLMs)在临床决策支持中的应用挑战，包括处理长文本/多语言电子健康记录(EHRs)、临床幻觉风险以及不可靠的评估指标。该框架通过将纵向EHRs转化为时序知识图谱(TKGs)并依据临床指南进行对齐，为癌症诊疗提供决策支持。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在临床决策支持中面临三大挑战：1)无法有效处理冗长、多语言的癌症电子健康记录；2)传统方法如检索增强生成(RAG)未能融入流程导向的临床指南，导致临床幻觉风险；3)评估指标不可靠阻碍肿瘤学AI系统验证。

Method: 1. 将非结构化纵向EHRs转化为患者专属时序知识图谱(TKGs)以捕获长期依赖；2. 通过将真实患者轨迹与规范化指南知识图谱对齐，实现决策支持过程的临床指南落地；3. 生成高保真临床总结与可操作建议作为输出。在私有中文癌症数据集和公开英文MIMIC-IV数据集上进行了验证。

Result: CliCARE在跨语言数据集上显著优于当前主流长文本LLMs和知识图谱增强RAG方法；通过专家驱动的评估协议证实，其输出结果与肿瘤学专家评估具有高度相关性。

Conclusion: CliCARE通过时序知识图谱和临床指南对齐机制，有效解决了LLMs在癌症诊疗决策中的三大核心挑战，为高可靠性临床决策支持提供了可验证的方案框架。

Abstract: Large Language Models (LLMs) hold significant promise for improving clinical
decision support and reducing physician burnout by synthesizing complex,
longitudinal cancer Electronic Health Records (EHRs). However, their
implementation in this critical field faces three primary challenges: the
inability to effectively process the extensive length and multilingual nature
of patient records for accurate temporal analysis; a heightened risk of
clinical hallucination, as conventional grounding techniques such as
Retrieval-Augmented Generation (RAG) do not adequately incorporate
process-oriented clinical guidelines; and unreliable evaluation metrics that
hinder the validation of AI systems in oncology. To address these issues, we
propose CliCARE, a framework for Grounding Large Language Models in Clinical
Guidelines for Decision Support over Longitudinal Cancer Electronic Health
Records. The framework operates by transforming unstructured, longitudinal EHRs
into patient-specific Temporal Knowledge Graphs (TKGs) to capture long-range
dependencies, and then grounding the decision support process by aligning these
real-world patient trajectories with a normative guideline knowledge graph.
This approach provides oncologists with evidence-grounded decision support by
generating a high-fidelity clinical summary and an actionable recommendation.
We validated our framework using large-scale, longitudinal data from a private
Chinese cancer dataset and the public English MIMIC-IV dataset. In these
diverse settings, CliCARE significantly outperforms strong baselines, including
leading long-context LLMs and Knowledge Graph-enhanced RAG methods. The
clinical validity of our results is supported by a robust evaluation protocol,
which demonstrates a high correlation with assessments made by expert
oncologists.

</details>


### [89] [A Benchmark Dataset and Evaluation Framework for Vietnamese Large Language Models in Customer Support](https://arxiv.org/abs/2507.22542)
*Long S. T. Nguyen,Truong P. Hua,Thanh M. Nguyen,Toan Q. Pham,Nam K. Ngo,An X. Nguyen,Nghi D. M. Pham,Nghia H. Nguyen,Tho T. Quan*

Main category: cs.CL

TL;DR: 该研究针对大型越南语语言模型（ViLLMs）在客户服务QA系统中缺乏领域特定评估的问题，推出了超过9,000个真实客户咨询对话对组成的CSConDa数据集，并评估了11种轻量级越南语开源模型，提出了一套自动和句法分析结合的评估体系。


<details>
  <summary>Details</summary>
Motivation: 目前越南语轻量级开源大模型（ViLLMs）在特定领域（如客服问答系统）评估不足，且缺乏真实客服互动数据集作为基准，导致企业难以选择适合自身需求的模型。该研究旨在填补这一空白。

Method: 1. 构建越南客户支持对话数据集（CSConDa）：收集超过9,000个真实客户与软件公司人工顾问之间的问答对，覆盖定价、产品可用性、技术故障等多样化主题。<br>2. 建立自动指标和句法分析相结合的综合评估框架，对11种轻量级开源ViLLMs进行基准测试。

Result: 1. 推出开源数据集CSConDa。2. 通过系统评估揭示各模型的优势、弱点及语言特征。3. 发现模型间存在性能差异并识别关键改进领域。

Conclusion: 该研究为解决企业越南语客服模型选择难题提供了工具，推动了下一代越南语轻量级语言模型的研发。

Abstract: With the rapid growth of Artificial Intelligence, Large Language Models
(LLMs) have become essential for Question Answering (QA) systems, improving
efficiency and reducing human workload in customer service. The emergence of
Vietnamese LLMs (ViLLMs) highlights lightweight open-source models as a
practical choice for their accuracy, efficiency, and privacy benefits. However,
domain-specific evaluations remain limited, and the absence of benchmark
datasets reflecting real customer interactions makes it difficult for
enterprises to select suitable models for support applications. To address this
gap, we introduce the Customer Support Conversations Dataset (CSConDa), a
curated benchmark of over 9,000 QA pairs drawn from real interactions with
human advisors at a large Vietnamese software company. Covering diverse topics
such as pricing, product availability, and technical troubleshooting, CSConDa
provides a representative basis for evaluating ViLLMs in practical scenarios.
We further present a comprehensive evaluation framework, benchmarking 11
lightweight open-source ViLLMs on CSConDa with both automatic metrics and
syntactic analysis to reveal model strengths, weaknesses, and linguistic
patterns. This study offers insights into model behavior, explains performance
differences, and identifies key areas for improvement, supporting the
development of next-generation ViLLMs. By establishing a robust benchmark and
systematic evaluation, our work enables informed model selection for customer
service QA and advances research on Vietnamese LLMs. The dataset is publicly
available at
https://huggingface.co/datasets/ura-hcmut/Vietnamese-Customer-Support-QA.

</details>


### [90] [ControlMed: Adding Reasoning Control to Medical Language Model](https://arxiv.org/abs/2507.22545)
*Sung-Min Lee,Siyoon Lee,Juyeon Kim,Kyungmin Roh*

Main category: cs.CL

TL;DR: 提出ControlMed模型，让用户能够通过细粒度控制标记在推理时主动控制推理过程的长度，以解决现有推理大模型在医疗领域因生成冗长推理过程导致的计算开销和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的临床决策至关重要，需要可靠的模型支持。当前的大语言模型（LLMs）在推理时往往生成不必要的冗长过程，导致显著的计算开销和响应延迟，这阻碍了其在现实临床环境中的实际部署。

Method: 通过三阶段流程训练ControlMed：1）在大规模合成的医疗指令数据集（包含直接回答和推理回答）上进行预训练；2）使用多长度推理数据和显式长度控制标记进行监督微调；3）基于模型的奖励信号进行强化学习，以提高事实准确性和应答质量。

Result: 在多种英语和韩语医疗基准测试中，模型达到了与最先进模型相似或更好的性能。用户还能通过控制推理长度在推理准确性和计算效率之间灵活权衡。

Conclusion: ControlMed为临床问答和医疗信息分析提供了一种实用且适应性强的解决方案，能够平衡准确性和效率。

Abstract: Reasoning Large Language Models (LLMs) with enhanced accuracy and
explainability are increasingly being adopted in the medical domain, as the
life-critical nature of clinical decision-making demands reliable support.
Despite these advancements, existing reasoning LLMs often generate
unnecessarily lengthy reasoning processes, leading to significant computational
overhead and response latency. These limitations hinder their practical
deployment in real-world clinical environments. To address these challenges, we
introduce \textbf{ControlMed}, a medical language model that enables users to
actively control the length of the reasoning process at inference time through
fine-grained control markers. ControlMed is trained through a three-stage
pipeline: 1) pre-training on a large-scale synthetic medical instruction
dataset covering both \textit{direct} and \textit{reasoning responses}; 2)
supervised fine-tuning with multi-length reasoning data and explicit
length-control markers; and 3) reinforcement learning with model-based reward
signals to enhance factual accuracy and response quality. Experimental results
on a variety of English and Korean medical benchmarks demonstrate that our
model achieves similar or better performance compared to state-of-the-art
models. Furthermore, users can flexibly balance reasoning accuracy and
computational efficiency by controlling the reasoning length as needed. These
findings demonstrate that ControlMed is a practical and adaptable solution for
clinical question answering and medical information analysis.

</details>


### [91] [Exploiting Synergistic Cognitive Biases to Bypass Safety in LLMs](https://arxiv.org/abs/2507.22564)
*Xikang Yang,Biyu Zhou,Xuehai Tang,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 该研究提出了一个名为CognitiveAttack的新型攻击框架，利用多种认知偏差的组合来绕过大型语言模型（LLM）的安全防护机制。通过监督微调和强化学习生成包含优化偏差组合的对抗提示，该框架在多种LLM上实现了远高于现有方法的攻击成功率（60.1% vs 31.6%），尤其暴露了开源模型的缺陷，为更健壮安全模型的研究铺平道路。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）的安全机制容易受到利用认知偏差的对抗攻击影响。已有研究集中于单个认知偏差或技术性攻击方法，缺乏对多种认知偏差协同作用攻击的研究。作者旨在探索多偏差组合作为攻击载体的潜力和效果，以此揭示当前LLM安全防护的漏洞。

Method: 1. 提出了CognitiveAttack框架，包含监督微调（SFT）和强化学习（RL）两个阶段；
2. SFT阶段：通过指令微调使攻击模型理解多种认知偏差的提示形式；
3. RL阶段：利用PPO算法优化攻击提示的生成策略，实现偏差组合的动态优化；
4. 构建一个包含认知偏差攻击的多样评估基准；
5. 测试30个主流LLM（开源与商业模型），比较攻击成功率。

Result: 1. 实验覆盖30个不同规模与任务能力的LLM（如Vicuna-13B、Qwen-13B、Mistral-7B等）；
2. CognitiveAttack平均攻击成功率高达60.1%，远高于最先进黑盒方法PAP（31.6%）；
3. 开源模型漏洞更严重——在Vicuna-13B上攻击成功率高达92.2%；
4. 多偏差组合攻击比单一偏差攻击有效提升攻击成功率（60%以上），验证其关键作用；
5. 对抗训练后的防御模型仍存在缺陷，被攻击率远超人类评估。

Conclusion: 1. 多认知偏差组合作为攻击载体的有效性被证明，且目前主流LLM严重低估该威胁；
2. CognitiveAttack框架成功揭示当前安全防护（尤其是开源模型）的严重缺陷；
3. 该研究开创性地将认知科学纳入LLM攻防研究，建议未来应强化“多偏差鲁棒训练”并建立跨学科的安全评估标准。

Abstract: Large Language Models (LLMs) demonstrate impressive capabilities across a
wide range of tasks, yet their safety mechanisms remain susceptible to
adversarial attacks that exploit cognitive biases -- systematic deviations from
rational judgment. Unlike prior jailbreaking approaches focused on prompt
engineering or algorithmic manipulation, this work highlights the overlooked
power of multi-bias interactions in undermining LLM safeguards. We propose
CognitiveAttack, a novel red-teaming framework that systematically leverages
both individual and combined cognitive biases. By integrating supervised
fine-tuning and reinforcement learning, CognitiveAttack generates prompts that
embed optimized bias combinations, effectively bypassing safety protocols while
maintaining high attack success rates. Experimental results reveal significant
vulnerabilities across 30 diverse LLMs, particularly in open-source models.
CognitiveAttack achieves a substantially higher attack success rate compared to
the SOTA black-box method PAP (60.1% vs. 31.6%), exposing critical limitations
in current defense mechanisms. These findings highlight multi-bias interactions
as a powerful yet underexplored attack vector. This work introduces a novel
interdisciplinary perspective by bridging cognitive science and LLM safety,
paving the way for more robust and human-aligned AI systems.

</details>


### [92] [Unveiling the Influence of Amplifying Language-Specific Neurons](https://arxiv.org/abs/2507.22581)
*Inaya Rahmanisa,Lyzander Marciano Andrylie,Krisna Mahardika Ihsani,Alfan Farizki Wicaksono,Haryo Akbarianto Wibowo,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 通过放大语言特定神经元的干预研究，发现放大因子能有效引导输出至目标语言，尤其对低资源语言有益，但对跨语言迁移作用有限。


<details>
  <summary>Details</summary>
Motivation: 尽管已知语言特定神经元通过抑制会影响模型行为，但它们在放大作用中的角色尚未充分探索。本研究旨在探究放大这类神经元在多语言模型（尤其低资源语言）中的影响。

Method: 在三种主要训练语言不同的模型上，对18种语言（含低资源语言）进行神经元放大干预。提出LSS评分量化引导效果；在常识推理（XCOPA, XWinograd）、知识（Include）、翻译（FLORES）任务上测试放大效果。

Result: 最优放大因子可有效引导输出至几乎所有测试语言。干预后，特定语言任务性能偶有提升（尤其在低资源语言上），但普遍损害跨语言效果。

Conclusion: 放大语言特定神经元对提升低资源语言性能有益，但无法促进跨语言迁移，揭示了此类神经元在模型多语言行为中的双重影响。

Abstract: Language-specific neurons in LLMs that strongly correlate with individual
languages have been shown to influence model behavior by deactivating them.
However, their role in amplification remains underexplored. This work
investigates the effect of amplifying language-specific neurons through
interventions across 18 languages, including low-resource ones, using three
models primarily trained in different languages. We compare amplification
factors by their effectiveness in steering to the target language using a
proposed Language Steering Shift (LSS) evaluation score, then evaluate it on
downstream tasks: commonsense reasoning (XCOPA, XWinograd), knowledge
(Include), and translation (FLORES). The optimal amplification factors
effectively steer output toward nearly all tested languages. Intervention using
this factor on downstream tasks improves self-language performance in some
cases but generally degrades cross-language results. These findings highlight
the effect of language-specific neurons in multilingual behavior, where
amplification can be beneficial especially for low-resource languages, but
provides limited advantage for cross-lingual transfer.

</details>


### [93] [BALSAM: A Platform for Benchmarking Arabic Large Language Models](https://arxiv.org/abs/2507.22603)
*Rawan Al-Matham,Kareem Darwish,Raghad Al-Rasheed,Waad Alshammari,Muneera Alhoshan,Amal Almazrua,Asma Al Wazrah,Mais Alheraki,Firoj Alam,Preslav Nakov,Norah Alzahrani,Eman alBilali,Nizar Habash,Abdelrahman El-Sheikh,Muhammad Elmallah,Haonan Li,Hamdy Mubarak,Mohamed Anwar,Zaid Alyafeai,Ahmed Abdelali,Nora Altwairesh,Maram Hasanain,Abdulmohsen Al Thubaity,Shady Shehata,Bashar Alhafni,Injy Hamed,Go Inoue,Khalid Elmadani,Ossama Obeid,Fatima Haouari,Tamer Elsayed,Emad Alghamdi,Khalid Almubarak,Saied Alshahrani,Ola Aljarrah,Safa Alajlan,Areej Alshaqarawi,Maryam Alshihri,Sultana Alghurabi,Atikah Alzeghayer,Afrah Altamimi,Abdullah Alfaifi,Abdulrahman AlOsaimy*

Main category: cs.CL

TL;DR: 提出了BALSAM，一个社区驱动的阿拉伯语大语言模型（LLM）基准测试平台，旨在解决现有阿拉伯语基准测试质量不足的问题，包括数据静态性、任务覆盖不全面以及缺乏盲测集平台。


<details>
  <summary>Details</summary>
Motivation: 当前阿拉伯语LLM发展滞后，主要受限于数据稀缺、语言多样性、形态复杂性以及现有阿拉伯语基准测试的质量问题。这些问题导致难以准确评估模型性能和防止数据污染。

Method: 开发包含78个自然语言处理任务（涵盖14个大类）的基准测试，拥有52K样本（37K测试集和15K开发集）。同时搭建了一个集中化、透明的盲评估平台。

Result: 提出一个称为BALSAM的阿拉伯语基准测试平台，为阿拉伯语LLM提供了统一、全面的评估框架，包括大量任务和样本并支持盲测。

Conclusion: BALSAM作为社区驱动的标准化平台，有望通过设立标准并促进协作研究来推动阿拉伯语LLM的性能进步和能力提升。

Abstract: The impressive advancement of Large Language Models (LLMs) in English has not
been matched across all languages. In particular, LLM performance in Arabic
lags behind, due to data scarcity, linguistic diversity of Arabic and its
dialects, morphological complexity, etc. Progress is further hindered by the
quality of Arabic benchmarks, which typically rely on static, publicly
available data, lack comprehensive task coverage, or do not provide dedicated
platforms with blind test sets. This makes it challenging to measure actual
progress and to mitigate data contamination. Here, we aim to bridge these gaps.
In particular, we introduce BALSAM, a comprehensive, community-driven benchmark
aimed at advancing Arabic LLM development and evaluation. It includes 78 NLP
tasks from 14 broad categories, with 52K examples divided into 37K test and 15K
development, and a centralized, transparent platform for blind evaluation. We
envision BALSAM as a unifying platform that sets standards and promotes
collaborative research to advance Arabic LLM capabilities.

</details>


### [94] [Language Arithmetics: Towards Systematic Language Neuron Identification and Manipulation](https://arxiv.org/abs/2507.22608)
*Daniil Gurgurov,Katharina Trinley,Yusser Al Ghussin,Tanja Baeumel,Josef van Genabith,Simon Ostermann*

Main category: cs.CL

TL;DR: 该研究分析了多语言大模型中的语言特定神经元，通过语言算术方法（激活加减乘除）控制语言行为，提高了翻译、问答等任务的效果，并揭示了模型的语言选择机制。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）表现出强大的多语言能力，但其处理不同语言的神经机制尚不明确。本研究旨在识别和控制模型中的语言特定神经元，理解其工作机制和跨语言关系。

Method: 1. 使用语言激活概率熵（LAPE）方法分析Llama、Mistral和Aya模型的21种语言，识别语言控制神经元。2. 提出语言算术（激活加减乘除）干预技术：通过加减特定语言的神经元激活向量，来禁用或激活目标语言。3. 在五个多语言任务（语言强制、翻译、问答、理解和自然语言推理）上评估干预效果。4. 分析语言资源量级和类型学相似性对干预效果的影响，探索神经元逐步停用时模型的“备用”语言选择机制。

Result: 1. 语言特定神经元主要聚集在深层，非拉丁文字语言表现出更强的神经专门化。2. 语言算术方法在控制语言行为（如强制输出特定语言或翻译）上优于简单替换法。3. 高资源语言和类型学相似的语言干预成功率更高。4. 跨语言神经元控制不仅改变语言行为，还能提升下游任务表现（如更准确的翻译）。5. 逐步停用神经元时，模型会激活备用语言机制（如英语）维持功能。

Conclusion: 该研究揭示了LLMs内部的多语言控制机制，证明通过精确调控语言神经元可实现有效的语言行为控制。语言算术技术为模型干预提供了新工具，其发现的神经特征（如深层聚集、类型学映射）促进了对多语言表示的理解。代码已开源，支持进一步研究。

Abstract: Large language models (LLMs) exhibit strong multilingual abilities, yet the
neural mechanisms behind language-specific processing remain unclear. We
analyze language-specific neurons in Llama-3.1-8B, Mistral-Nemo-12B, and
Aya-Expanse-8B & 32B across 21 typologically diverse languages, identifying
neurons that control language behavior. Using the Language Activation
Probability Entropy (LAPE) method, we show that these neurons cluster in deeper
layers, with non-Latin scripts showing greater specialization. Related
languages share overlapping neurons, reflecting internal representations of
linguistic proximity.
  Through language arithmetics, i.e. systematic activation addition and
multiplication, we steer models to deactivate unwanted languages and activate
desired ones, outperforming simpler replacement approaches. These interventions
effectively guide behavior across five multilingual tasks: language forcing,
translation, QA, comprehension, and NLI. Manipulation is more successful for
high-resource languages, while typological similarity improves effectiveness.
We also demonstrate that cross-lingual neuron steering enhances downstream
performance and reveal internal "fallback" mechanisms for language selection
when neurons are progressively deactivated. Our code is made publicly available
at https://github.com/d-gurgurov/Language-Neurons-Manipulation.

</details>


### [95] [Multilingual Political Views of Large Language Models: Identification and Steering](https://arxiv.org/abs/2507.22623)
*Daniil Gurgurov,Katharina Trinley,Ivan Vykopal,Josef van Genabith,Simon Ostermann,Roberto Zamparelli*

Main category: cs.CL

TL;DR: 本文通过大规模研究现代开源指令调优的大型语言模型（LLMs）的政治倾向，发现较大模型偏向自由-左翼立场，并展示了如何通过简单的控制技术改变模型的政治立场。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在评估少数模型和语言的政治偏见，对模型架构、规模和多语言环境下的泛化性研究不足，且缺乏对偏见主动控制的研究。

Method: 使用包含11种语义等效重述的政治指南针测试，在14种语言上评估7个模型（包括LLaMA-3.1、Qwen-3和Aya-Expanse），并应用质心激活干预技术操纵模型的政治立场。

Result: 研究发现较大模型一致偏向自由-左翼立场，不同语言和模型家族间存在显著差异；质心激活干预技术能可靠地将模型响应导向其他意识形态位置。

Conclusion: 研究填补了LLMs政治偏见研究的空白，揭示了模型规模与政治倾向的关联，并证明操控模型政治立场在多种语言中的可行性。代码已在GitHub公开。

Abstract: Large language models (LLMs) are increasingly used in everyday tools and
applications, raising concerns about their potential influence on political
views. While prior research has shown that LLMs often exhibit measurable
political biases--frequently skewing toward liberal or progressive
positions--key gaps remain. Most existing studies evaluate only a narrow set of
models and languages, leaving open questions about the generalizability of
political biases across architectures, scales, and multilingual settings.
Moreover, few works examine whether these biases can be actively controlled.
  In this work, we address these gaps through a large-scale study of political
orientation in modern open-source instruction-tuned LLMs. We evaluate seven
models, including LLaMA-3.1, Qwen-3, and Aya-Expanse, across 14 languages using
the Political Compass Test with 11 semantically equivalent paraphrases per
statement to ensure robust measurement. Our results reveal that larger models
consistently shift toward libertarian-left positions, with significant
variations across languages and model families. To test the manipulability of
political stances, we utilize a simple center-of-mass activation intervention
technique and show that it reliably steers model responses toward alternative
ideological positions across multiple languages. Our code is publicly available
at https://github.com/d-gurgurov/Political-Ideologies-LLMs.

</details>


### [96] [Listening to the Unspoken: Exploring 365 Aspects of Multimodal Interview Performance Assessment](https://arxiv.org/abs/2507.22676)
*Jia Li,Yang Wang,Wenhao Qian,Zhenzhen Hu,Richang Hong,Meng Wang*

Main category: cs.CL

TL;DR: 本文提出了一个名为“365”方面的框架，用于面试表现评估，该框架整合了视频、音频和文本三种模态的数据，每位候选人的六个回答，以及五个关键评估维度。该框架通过模态特定的特征提取器编码多模态数据，并使用共享压缩多层感知机融合特征。采用了两级集成学习策略提高预测稳健性，最终在AVI Challenge 2025中取得了多维平均MSE为0.1824的成绩，获得了第一名。


<details>
  <summary>Details</summary>
Motivation: 面试表现评估是确定候选人是否适合专业职位的关键。为了确保评估的整体性和公平性，需要一种能够全面捕捉候选人多方面表现的自动化方法。传统的评估方法可能存在主观性和不全面性，因此需要一种能够整合多模态数据（视频、音频和文本）、多个回答以及多个评估维度的新框架。

Method: 1. 框架整合三种模态（视频、音频和文本）、每位候选人六个回答和五个评估维度。
2. 使用模态特定的特征提取器对异构数据进行编码。
3. 通过共享压缩多层感知机（Shared Compression Multilayer Perceptron）将多模态嵌入压缩到统一的潜在空间，以促进高效的特征交互。
4. 采用两级集成学习策略：第一级，独立的回归头对每个回答的分数进行预测；第二级，使用均值池化机制跨回答聚合预测，生成五个目标维度的最终分数。

Result: 该框架在AVI Challenge 2025中获得了第一名，多维度平均MSE为0.1824，证明了其在自动化多模态面试表现评估中的有效性和稳健性。

Conclusion: 所提出的“365”方面框架通过整合多模态数据、多个回答和多个评估维度，能够全面且公正地评估面试表现。同时，通过捕捉多模态数据中显性和隐性的线索，增强了评估的全面性和客观性。该框架在竞赛中的优异表现验证了其有效性和鲁棒性，为自动化面试评估提供了有力的工具。

Abstract: Interview performance assessment is essential for determining candidates'
suitability for professional positions. To ensure holistic and fair
evaluations, we propose a novel and comprehensive framework that explores
``365'' aspects of interview performance by integrating \textit{three}
modalities (video, audio, and text), \textit{six} responses per candidate, and
\textit{five} key evaluation dimensions. The framework employs
modality-specific feature extractors to encode heterogeneous data streams and
subsequently fused via a Shared Compression Multilayer Perceptron. This module
compresses multimodal embeddings into a unified latent space, facilitating
efficient feature interaction. To enhance prediction robustness, we incorporate
a two-level ensemble learning strategy: (1) independent regression heads
predict scores for each response, and (2) predictions are aggregated across
responses using a mean-pooling mechanism to produce final scores for the five
target dimensions. By listening to the unspoken, our approach captures both
explicit and implicit cues from multimodal data, enabling comprehensive and
unbiased assessments. Achieving a multi-dimensional average MSE of 0.1824, our
framework secured first place in the AVI Challenge 2025, demonstrating its
effectiveness and robustness in advancing automated and multimodal interview
performance assessment. The full implementation is available at
https://github.com/MSA-LMC/365Aspects.

</details>


### [97] [From Sufficiency to Reflection: Reinforcement-Guided Thinking Quality in Retrieval-Augmented Reasoning for LLMs](https://arxiv.org/abs/2507.22716)
*Jie He,Victor Gutierrez Basulto,Jeff Z. Pan*

Main category: cs.CL

TL;DR: 该论文提出了TIRESRAG-R1框架，通过引入多维度奖励机制（充分性奖励、推理质量奖励、反思奖励）和难度感知重加权策略，解决了现有检索增强生成（RAG）模型中存在的三个主要失败模式（信息不足、错误推理、答案与推理不一致）的问题，并在多跳问答数据集上表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的检索增强生成（RAG）方法主要依赖最终答案的正确性作为奖励，忽视了中间推理过程的质量。论文通过分析现有RAG模型的失败案例，归纳出三个主要问题：信息不足、错误推理以及答案与推理链不一致。这些问题限制了模型在复杂任务中的表现。

Method: 1. 提出TIRESRAG-R1框架，采用“思考-检索-反思”的流程。
2. 设计多维度奖励系统：
   - 充分性奖励：鼓励模型检索足够支撑推理的信息；
   - 推理质量奖励：评估推理链的合理性和准确性；
   - 反思奖励：检测并修正错误。
3. 引入难度感知的重加权策略和训练样本过滤机制，提升复杂任务上的表现。

Result: 在四个多跳问答数据集上的实验表明，TIRESRAG-R1优于现有RAG方法，并且能够很好地泛化到单跳任务。

Conclusion: TIRESRAG-R1通过关注中间推理质量并设计针对性的奖励机制，显著提升了RAG模型的推理能力和稳定性，为解决现有RAG模型的失败模式提供了有效方案。

Abstract: Reinforcement learning-based retrieval-augmented generation (RAG) methods
enhance the reasoning abilities of large language models (LLMs). However, most
rely only on final-answer rewards, overlooking intermediate reasoning quality.
This paper analyzes existing RAG reasoning models and identifies three main
failure patterns: (1) information insufficiency, meaning the model fails to
retrieve adequate support; (2) faulty reasoning, where logical or content-level
flaws appear despite sufficient information; and (3) answer-reasoning
inconsistency, where a valid reasoning chain leads to a mismatched final
answer. We propose TIRESRAG-R1, a novel framework using a
think-retrieve-reflect process and a multi-dimensional reward system to improve
reasoning and stability. TIRESRAG-R1 introduces: (1) a sufficiency reward to
encourage thorough retrieval; (2) a reasoning quality reward to assess the
rationality and accuracy of the reasoning chain; and (3) a reflection reward to
detect and revise errors. It also employs a difficulty-aware reweighting
strategy and training sample filtering to boost performance on complex tasks.
Experiments on four multi-hop QA datasets show that TIRESRAG-R1 outperforms
prior RAG methods and generalizes well to single-hop tasks. The code and data
are available at: https://github.com/probe2/TIRESRAG-R1.

</details>


### [98] [Investigating Hallucination in Conversations for Low Resource Languages](https://arxiv.org/abs/2507.22720)
*Amit Das,Md. Najib Hasan,Souvika Sarkar,Zheng Zhang,Fatemeh Jamshidi,Tathagata Bhattacharya,Nilanjana Raychawdhury,Dongji Feng,Vinija Jain,Aman Chadha*

Main category: cs.CL

TL;DR: 该研究探讨了LLM在多语言对话中的幻觉问题，比较了包括GPT-3.5、GPT-4o等多种模型在印度语、波斯语和中文中的表现，发现中文的幻觉率最低而印度语和波斯语较高。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型（LLM）在生成文本方面表现出色，但经常会生成事实错误的内容（即‘幻觉’）。现有研究主要关注英语中的幻觉问题，但对其他语言的了解有限。该研究旨在填补这一空白，通过分析多语言对话数据中的幻觉现象，以提高LLM在非英语语言中的可靠性和有效性。

Method: 研究使用包含印地语（Hindi）、波斯语（Farsi）和普通话（Mandarin）的对话数据集，评估了六种LLM（GPT-3.5、GPT-4o、Llama-3.1、Gemma-2.0、DeepSeek-R1和Qwen-3）的事实错误（幻觉）和语言错误。通过精心设计的评估框架，量化并比较了不同语言和模型之间的幻觉率。

Result: 研究结果显示，这些LLM在中文（Mandarin）中产生的幻觉响应非常少，但在印地语（Hindi）和波斯语（Farsi）中却生成了显著更多的幻觉内容。这表明语言语种对LLM生成的事实准确性有显著影响。

Conclusion: 该研究揭示了LLM的多语言幻觉问题存在显著差异，特别是在资源相对较少的语言（如印地语和波斯语）中幻觉率更高。这为提高LLM在全球应用中的可靠性提供了重要的研究方向，并强调了在非英语语言环境中加强模型开发和评估的必要性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in
generating text that closely resemble human writing. However, they often
generate factually incorrect statements, a problem typically referred to as
'hallucination'. Addressing hallucination is crucial for enhancing the
reliability and effectiveness of LLMs. While much research has focused on
hallucinations in English, our study extends this investigation to
conversational data in three languages: Hindi, Farsi, and Mandarin. We offer a
comprehensive analysis of a dataset to examine both factual and linguistic
errors in these languages for GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0,
DeepSeek-R1 and Qwen-3. We found that LLMs produce very few hallucinated
responses in Mandarin but generate a significantly higher number of
hallucinations in Hindi and Farsi.

</details>


### [99] [Resource-Efficient Adaptation of Large Language Models for Text Embeddings via Prompt Engineering and Contrastive Fine-tuning](https://arxiv.org/abs/2507.22729)
*Benedikt Roth,Stephan Rappensperger,Tianming Qiu,Hamza Imamović,Julian Wörmann,Hao Shen*

Main category: cs.CL

TL;DR: 本研究探索了三种策略（嵌入聚合、提示工程和对比微调）来改进Decoder-only LLMs的文本嵌入，在MTEB基准的聚类任务上取得SOTA，通过注意力图分析显示微调使模型关注语义相关词，从而更有效地将信息压缩入句向量。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在文本生成上表现出色，但将词向量池化为句向量时会丢失关键信息，而许多非生成任务（如聚类、分类和检索）需要准确且可控的句级/文档级嵌入。

Method: 1) 尝试多种词向量聚合技术；2) 设计任务特定的提示模板；3) 通过对比微调进行文本增强（使用合成正例对）。将三种策略结合。

Result: 在MTEB英文文本聚类赛道上取得当前最优结果。注意力图分析表明：微调后模型注意力从提示词转向语义相关词，证明能更有效压缩信息到最终隐藏状态。

Conclusion: 通过提示工程和资源高效的对比微调（合成正例对），可有效将Decoder-only LLMs改造为高性能文本嵌入模型。

Abstract: Large Language Models (LLMs) have become a cornerstone in Natural Language
Processing (NLP), achieving impressive performance in text generation. Their
token-level representations capture rich, human-aligned semantics. However,
pooling these vectors into a text embedding discards crucial information.
Nevertheless, many non-generative downstream tasks, such as clustering,
classification, or retrieval, still depend on accurate and controllable
sentence- or document-level embeddings. We explore several adaptation
strategies for pre-trained, decoder-only LLMs: (i) various aggregation
techniques for token embeddings, (ii) task-specific prompt engineering, and
(iii) text-level augmentation via contrastive fine-tuning. Combining these
components yields state-of-the-art performance on the English clustering track
of the Massive Text Embedding Benchmark (MTEB). An analysis of the attention
map further shows that fine-tuning shifts focus from prompt tokens to
semantically relevant words, indicating more effective compression of meaning
into the final hidden state. Our experiments demonstrate that LLMs can be
effectively adapted as text embedding models through a combination of prompt
engineering and resource-efficient contrastive fine-tuning on synthetically
generated positive pairs.

</details>


### [100] [Reducing Hallucinations in Summarization via Reinforcement Learning with Entity Hallucination Index](https://arxiv.org/abs/2507.22744)
*Praveenkumar Katwe,Rakesh Chandra,Balabantaray Kali,Prasad Vittala*

Main category: cs.CL

TL;DR: 提出了一种使用强化学习框架优化的奖励驱动微调方法，利用作者设计的实体幻觉索引（EHI）作为奖励信号来训练预训练语言模型，从而减少在会议摘要中出现的实体幻觉问题，并且在不需要人工标注的情况下提升了生成摘要的实体忠实度。


<details>
  <summary>Details</summary>
Motivation: 在摘要生成任务中，幻觉问题（即生成的实体不正确或未在原文中出现）是阻碍模型在真实世界部署的关键挑战。当前的解决方案通常依赖人工标注的事实性检查，难以扩展。本文旨在通过开发一个自动化指标EHI和奖励驱动的微调框架来减少摘要中的实体幻觉。

Method: 1. 预训练语言模型生成会议摘要作为基线；2. 通过自动实体提取和匹配计算实体幻觉索引（EHI）分数；3. 采用强化学习微调模型参数，使用EHI作为奖励信号，优化生成结果中的实体忠实度；4. 整个流程无需人工标注的事实性数据，可大规模应用。

Result: 实验在不同数据集上均显示EHI指标持续改进，定生分析证明实体级别的幻觉显著减少，同时不影响摘要的流畅性和信息量。该方法有效提升了摘要的实体忠实性。

Conclusion: 本文提出的奖励驱动微调框架能够有效减少摘要中的实体幻觉问题，且不需要依赖人工标注。通过自动的EHI指标驱动强化学习微调，该方法具有良好的可扩展性。作者开源了可复现的Colab流程，以促进利用轻量级幻觉指标的进一步研究。

Abstract: Reducing hallucinations in abstractive summarization remains a critical
challenge for deploying language models (LMs) in real-world settings. In this
work, we introduce a rewarddriven fine-tuning framework that explicitly
optimizes for Entity Hallucination Index (EHI), a metric designed to quantify
the presence, correctness, and grounding of named entities in generated
summaries. Given a corpus of meeting transcripts, we first generate baseline
summaries using a pre-trained LM and compute EHI scores via automatic entity
extraction and matching. We then apply reinforcement learning to fine-tune the
model parameters, using EHI as a reward signal to bias generation toward
entity-faithful outputs. Our approach does not rely on human-written factuality
annotations, enabling scalable fine-tuning. Experiments demonstrate consistent
improvements in EHI across datasets, with qualitative analysis revealing a
significant reduction in entity-level hallucinations without degradation in
fluency or informativeness. We release a reproducible Colab pipeline,
facilitating further research on hallucination-aware model fine-tuning using
lightweight, hallucintion metrics like EHI.

</details>


### [101] [CUS-QA: Local-Knowledge-Oriented Open-Ended Question Answering Dataset](https://arxiv.org/abs/2507.22752)
*Jindřich Libovický,Jindřich Helcl,Andrei Manea,Gianluca Vico*

Main category: cs.CL

TL;DR: 作者介绍了名为RegionQA的多模态开放性地区问答数据集，由母语专家创建，包含三个地区的图文问题，并评估了现有大语言模型（LLM）在该任务上的表现。结果显示：LLMs在地区知识上存在显著不足；除LLM自评外，自动评估指标与人工评判相关性较差。该数据集将用于评测LLM的地区知识、研究跨语言一致性、推动开放式问答评估方法的进步。


<details>
  <summary>Details</summary>
Motivation: 现有的QA数据集中在通用领域（如英语国家的SQuAD）或封闭式回答。大语言模型在地区特定知识上表现未知，尤其对于非英语背景的地区，且缺乏融合视觉推理的开放式评估能力。构建以地区特色为核心、多模态、包含人工评估数据的新数据集，以填补这些空缺并推动相关研究。

Method: 1. 数据构建：由捷克、斯洛伐克、乌克兰的母语专家用母语设计问题；2. 内容来源：基于维基百科的人工筛选数据；3. 数据类型：纯文本问题+需要图文理解的问题；4. 基线评测：a) 用prompting评估SOTA LLM；b) 人工标注模型输出的正确性；c) 比较自动指标与人工评判的相关性

Result: 1. 现有LLMS在RegionQA上准确率较低（与人类水平差距显著）；2. 发现评测指标问题：GPT-4自评与人工标注相关性高，但经典指标（如BLEU）与人工判断无显著关联；3. 开放发布了包含双语问题、需视觉理解及人工标注的RegionQA数据集。

Conclusion: 1. RegionQA暴露了LLMs在地区知识上的缺陷；2. 除LLM类指标外，当前QA自动评估体系不可靠；3. 该数据集未来可用于评测模型地区知识、跨语言一致性、推动开放QA评估方法的开发。

Abstract: We introduce a benchmark for open-ended regional question answering that
encompasses both textual and visual modalities. We also provide strong
baselines using state-of-the-art large language models (LLMs). Our dataset
consists of manually curated questions and answers grounded in Wikipedia,
created by native speakers from Czechia, Slovakia, and Ukraine, with
accompanying English translations. It includes both purely textual questions
and those requiring visual understanding. As a baseline, we evaluate
state-of-the-art LLMs through prompting and complement this with human
judgments of answer correctness. Using these human evaluations, we analyze the
reliability of existing automatic evaluation metrics. Our baseline results
highlight a significant gap in regional knowledge among current LLMs. Moreover,
apart from LLM-based evaluation, there is minimal correlation between automated
metrics and human judgment. We release this dataset as a resource to (1) assess
regional knowledge in LLMs, (2) study cross-lingual generation consistency in a
challenging setting, and (3) advance the development of evaluation metrics for
open-ended question answering.

</details>


### [102] [Opportunities and Challenges of LLMs in Education: An NLP Perspective](https://arxiv.org/abs/2507.22753)
*Sowmya Vajjala,Bashar Alhafni,Stefano Bannò,Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 本文探讨大语言模型(LLMs)在教育领域的作用，尤其在辅助和评估两个应用场景下的影响，涵盖阅读、写作、口语和辅导四个维度。


<details>
  <summary>Details</summary>
Motivation: 随着对LLMs在教育中作用兴趣的增长，研究者需要了解LLMs在数学和评估应用中的具体影响及未来方向与挑战。

Method: 从教育NLP的两个主要应用场景（辅助与评估）出发，沿着阅读/写作/口语/辅导四个维度进行系统性论证；并指由LLMs开启的新方向和待解决关键挑战。

Result: 系统性构建了LLMs在教育NLP领域的影响框架，指出未来语言导向型和NLP驱动教育应用的新研究方向。

Conclusion: LLMs为教育领域带来了全新机遇，特别是在教学/学习/评估方面，但需解决相关挑战才能充分实现其潜力。

Abstract: Interest in the role of large language models (LLMs) in education is
increasing, considering the new opportunities they offer for teaching,
learning, and assessment. In this paper, we examine the impact of LLMs on
educational NLP in the context of two main application scenarios: {\em
assistance} and {\em assessment}, grounding them along the four dimensions --
reading, writing, speaking, and tutoring. We then present the new directions
enabled by LLMs, and the key challenges to address. We envision that this
holistic overview would be useful for NLP researchers and practitioners
interested in exploring the role of LLMs in developing language-focused and
NLP-enabled educational applications of the future.

</details>


### [103] [MASCA: LLM based-Multi Agents System for Credit Assessment](https://arxiv.org/abs/2507.22758)
*Gautam Jajoo,Pranjal A Chitale,Saksham Agarwal*

Main category: cs.CL

TL;DR: 该论文提出了MASCA，一个基于LLM的多智能体系统，用于改进信用评估。通过分层架构和对比学习进行风险与回报评估，同时从信号博弈论角度分析多智能体系统，并进行偏差分析以确保公平性。实验表明MASCA在信用评分中超越基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM和智能体系统在金融领域（如交易和建模）取得进展，但信用评估仍主要依赖传统规则和统计模型，有待深入探索。因此，作者旨在开发一个能够模拟真实决策过程的系统来提升信用评估的准确性和公平性。

Method: 1. 架构设计：构建分层多智能体系统MASCA，各专业化LLM智能体协作处理子任务。
2. 决策优化：引入对比学习机制进行风险与回报评估以优化决策。
3. 理论分析：从信号博弈论视角解析分层多智能体的结构与交互。
4. 偏差控制：实施详细的信用评估偏差分析，解决公平性问题。

Result: 实验结果表明，MASCA在信用评分任务中的表现优于基线方法，验证了分层LLM多智能体系统在金融应用（尤其是信用评估）中的有效性。

Conclusion: 该研究证明了LLM驱动的多智能体系统（如MASCA）在信用评估中的优越性。其分层协作架构、结合对比学习与博弈论分析的方法为金融风险评估提供了新方向，同时通过偏差分析强调了公平性，为未来智能金融系统设计奠定基础。

Abstract: Recent advancements in financial problem-solving have leveraged LLMs and
agent-based systems, with a primary focus on trading and financial modeling.
However, credit assessment remains an underexplored challenge, traditionally
dependent on rule-based methods and statistical models. In this paper, we
introduce MASCA, an LLM-driven multi-agent system designed to enhance credit
evaluation by mirroring real-world decision-making processes. The framework
employs a layered architecture where specialized LLM-based agents
collaboratively tackle sub-tasks. Additionally, we integrate contrastive
learning for risk and reward assessment to optimize decision-making. We further
present a signaling game theory perspective on hierarchical multi-agent
systems, offering theoretical insights into their structure and interactions.
Our paper also includes a detailed bias analysis in credit assessment,
addressing fairness concerns. Experimental results demonstrate that MASCA
outperforms baseline approaches, highlighting the effectiveness of hierarchical
LLM-based multi-agent systems in financial applications, particularly in credit
scoring.

</details>


### [104] [DBLPLink 2.0 -- An Entity Linker for the DBLP Scholarly Knowledge Graph](https://arxiv.org/abs/2507.22811)
*Debayan Banerjee,Tilahun Abedissa Taffa,Ricardo Usbeck*

Main category: cs.CL

TL;DR: 本工作报告了一个针对DBLP 2025版RDF知识图谱的实体链接器，新版本引入了dblp:Stream作为新的实体类型（出版物场所）。与之前使用KG嵌入和重排器的DBLPLink不同，本文利用LLM开发了零样本实体链接器，提出一种新方法：通过LLM倒数第二层输出的'yes'标记的对数概率对候选实体进行重排。


<details>
  <summary>Details</summary>
Motivation: DBLP知识图谱的2025版本引入了新的实体类型dblp:Stream（出版物场所），这带来了实体链接的挑战。传统的DBLPLink方法依赖于训练KG嵌入和重排器，但本文旨在开发一种零样本方法，利用LLM来适应知识图谱的变化、减少训练成本和提高处理新出现实体类型的能力。

Method: 1. 实体链接流程：首先从DBLP KG中提取候选实体。
2. LLM交互设计：将实体提及和候选实体配对，构建问题如'[M]是否指代[E]?'输入LLM。
3. 重排机制：在LLM的倒数第二层提取'yes'标记（表示确认指代的token）的对数概率。
4. 零样本学习：直接使用未在特定任务上微调的LLM（如GPT-3或Llama）进行推理，跳过传统的训练或微调步骤。

Result: 新方法在DBLP 2025 KG的实体链接任务中实现了零样本性能，通过LLM的'yes'标记概率重排候选实体，该方法避免了训练数据的需求，并适应了新实体类型(dblp:Stream)的出现。

Conclusion: 本文的创新点在于利用LLM内部倒数第二层的token概率进行零样本实体链接重排，成功应用于新版DBLP KG，特别是处理新实体类型dblp:Stream。该方法减少了对训练数据的依赖，为知识图谱更新时的实体链接提供了高效解决方案。

Abstract: In this work we present an entity linker for DBLP's 2025 version of RDF-based
Knowledge Graph. Compared to the 2022 version, DBLP now considers publication
venues as a new entity type called dblp:Stream. In the earlier version of
DBLPLink, we trained KG-embeddings and re-rankers on a dataset to produce
entity linkings. In contrast, in this work, we develop a zero-shot entity
linker using LLMs using a novel method, where we re-rank candidate entities
based on the log-probabilities of the "yes" token output at the penultimate
layer of the LLM.

</details>


### [105] [Beyond Natural Language Plans: Structure-Aware Planning for Query-Focused Table Summarization](https://arxiv.org/abs/2507.22829)
*Weijia Zhang,Songgaojun Deng,Evangelos Kanoulas*

Main category: cs.CL

TL;DR: 该论文提出了一种新的结构化表示方法TaSoF和框架SPaGe，用于解决查询聚焦表摘要任务中自然语言计划的不明确性和结构性不足问题，通过结构化规划、图执行和摘要生成三阶段方法，在多个基准测试中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有查询聚焦表摘要方法使用自然语言(NL)步骤计划存在固有模糊性和缺乏结构的问题，阻碍了向可执行程序（如SQL）的转换，并在多表任务中扩展性差。为此，作者提出转向结构化表示，以提高可靠性和扩展性。

Method: SPaGe框架分为三个阶段：1) 结构化规划（Structured Planning）：将查询转化为结构化的TaSoF计划；2) 图执行（Graph-based Execution）：将计划步骤转换为SQL，并通过有向循环图建模依赖关系以并行执行；3) 摘要生成（Summary Generation）：生成查询聚焦的摘要。

Result: 在三个公共基准上的实验表明，SPaGe在单表和多表设置下均优于现有模型，验证了结构化表示对于鲁棒和可扩展摘要的优势。

Conclusion: 通过引入结构化计划TaSoF和三阶段框架SPaGe，实现了更可靠的查询聚焦表摘要，尤其是在多表任务中展现出更好的可扩展性和性能。

Abstract: Query-focused table summarization requires complex reasoning, often
approached through step-by-step natural language (NL) plans. However, NL plans
are inherently ambiguous and lack structure, limiting their conversion into
executable programs like SQL and hindering scalability, especially for
multi-table tasks. To address this, we propose a paradigm shift to structured
representations. We introduce a new structured plan, TaSoF, inspired by
formalism in traditional multi-agent systems, and a framework, SPaGe, that
formalizes the reasoning process in three phases: 1) Structured Planning to
generate TaSoF from a query, 2) Graph-based Execution to convert plan steps
into SQL and model dependencies via a directed cyclic graph for parallel
execution, and 3) Summary Generation to produce query-focused summaries. Our
method explicitly captures complex dependencies and improves reliability.
Experiments on three public benchmarks show that SPaGe consistently outperforms
prior models in both single- and multi-table settings, demonstrating the
advantages of structured representations for robust and scalable summarization.

</details>


### [106] [Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning](https://arxiv.org/abs/2507.22887)
*Kwesi Cobbina,Tianyi Zhou*

Main category: cs.CL

TL;DR: 论文发现了一个名为DPP的新型位置偏差，即演示样例在提示中的位置会影响大语言模型的上下文学习性能。通过系统评估发现，将演示置于提示开头能获得最稳定准确的结果，而置于用户消息末尾则可能导致预测显著翻转。


<details>
  <summary>Details</summary>
Motivation: 上下文学习（ICL）的性能对演示样例的选择和顺序敏感，但演示样例在输入提示中的位置变化对模型预测的影响尚未被充分研究。该研究旨在探索这种新型的DPP位置偏差及其对模型性能的影响。

Method: 1. 设计系统评估流程：在分类、问答、摘要和推理任务中，改变演示样例、系统提示和用户消息在输入提示中的位置。
2. 引入两个指标：ACCURACY-CHANGE（准确率变化）和PREDICTION-CHANGE（预测变化）来量化因位置变化导致的性能变化。
3. 在四大开源模型家族（QWEN、LLAMA3、MISTRAL、COHERE）的十个LLM上进行广泛实验。

Result: 1. 演示位置显著影响所有测试模型的准确率和预测（如：位置变化可导致超30%的预测翻转）。
2. 最优位置：演示置于提示开头时，准确率提升最高达6个百分点且输出最稳定。
3. 最差位置：演示置于用户消息末尾时，问答任务中预测大量翻转且无正确性提升。
4. 模型大小影响：小模型对该偏差最敏感；大模型在复杂任务中仍受轻微影响。

Conclusion: 研究首次揭示了LLM中ICL的DPP位置偏差，证明演示位置是影响模型性能的关键因素。实验结果建议：实践中应优先将演示置于提示开头以优化性能。该发现推动了对LLM输入结构敏感性的深入探索。

Abstract: In-context learning (ICL) is a critical emerging capability of large language
models (LLMs), enabling few-shot learning during inference by including a few
demonstrations (demos) in the prompt. However, it has been found that ICL's
performance can be sensitive to the choices of demos and their order. This
paper investigates an unexplored new positional bias of ICL for the first time:
we observe that the predictions and accuracy can drift drastically when the
positions of demos, the system prompt, and the user message in LLM input are
varied. We refer to this bias as DEMOS' POSITION IN PROMPT (DPP) bias. We
design a systematic evaluation pipeline to study this type of positional bias
across classification, question answering, summarization, and reasoning tasks.
We introduce two metrics, ACCURACY-CHANGE and PREDICTION-CHANGE, to quantify
net gains and output volatility induced by changes in the demos' position.
Extensive experiments on ten LLMs from four open-source model families (QWEN,
LLAMA3, MISTRAL, COHERE) verify that the bias significantly affects their
accuracy and predictions: placing demos at the start of the prompt yields the
most stable and accurate outputs with gains of up to +6 points. In contrast,
placing demos at the end of the user message flips over 30\% of predictions
without improving correctness on QA tasks. Smaller models are most affected by
this sensitivity, though even large models remain marginally affected on
complex tasks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [107] [CIMR: Contextualized Iterative Multimodal Reasoning for Robust Instruction Following in LVLMs](https://arxiv.org/abs/2507.22074)
*Yangshu Yuan,Heng Chen,Xinyi Jiang,Christian Ng,Kexin Qiu*

Main category: cs.LG

TL;DR: 该论文提出了一种名为CIMR的新框架，通过上下文感知的迭代推理和自我纠错机制提升大型多模态模型在复杂任务中的表现，并在多模态行动规划数据集上取得了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型和视觉语言模型在处理需要逻辑推理、动态反馈整合和迭代自我纠错的复杂多步多模态指令时仍存在困难，因此需要开发更先进的推理框架来提高这些任务的表现。

Method: CIMR框架包含两个阶段：初始推理和响应生成阶段，以及基于解析多模态反馈的迭代细化阶段。该框架包含一个动态融合模块，能够在每一步深度整合文本、视觉和上下文特征。作者在视觉指令微调数据集上对LLaVA-1.5-7B模型进行微调，并在多模态行动规划数据集上评估CIMR。

Result: CIMR在多模态行动规划数据集上达到了91.5%的准确率，超过了GPT-4V、LLaVA-1.5、MiniGPT-4和InstructBLIP等最先进模型的表现。

Conclusion: 该研究证明了CIMR框架中的迭代推理和自我纠错机制在处理复杂多模态任务上的有效性，为改进大型多模态模型的推理能力提供了一个有前景的方向。

Abstract: The rapid advancement of Large Language Models (LLMs) and Large
Vision-Language Models (LVLMs) has enhanced our ability to process and generate
human language and visual information. However, these models often struggle
with complex, multi-step multi-modal instructions that require logical
reasoning, dynamic feedback integration, and iterative self-correction. To
address this, we propose CIMR: Contextualized Iterative Multimodal Reasoning, a
novel framework that introduces a context-aware iterative reasoning and
self-correction module. CIMR operates in two stages: initial reasoning and
response generation, followed by iterative refinement using parsed multi-modal
feedback. A dynamic fusion module deeply integrates textual, visual, and
contextual features at each step. We fine-tune LLaVA-1.5-7B on the Visual
Instruction Tuning (VIT) dataset and evaluate CIMR on the newly introduced
Multi-modal Action Planning (MAP) dataset. CIMR achieves 91.5% accuracy,
outperforming state-of-the-art models such as GPT-4V (89.2%), LLaVA-1.5
(78.5%), MiniGPT-4 (75.3%), and InstructBLIP (72.8%), demonstrating the
efficacy of its iterative reasoning and self-correction capabilities in complex
tasks.

</details>


### [108] [Bayesian Optimization of Process Parameters of a Sensor-Based Sorting System using Gaussian Processes as Surrogate Models](https://arxiv.org/abs/2507.22766)
*Felix Kronenwett,Georg Maier,Thomas Laengle*

Main category: cs.LG

TL;DR: 基于贝叶斯优化的框架，通过高斯过程回归模型优化传感器分选系统的工艺参数，以最小化实验次数并满足双物料输出流的精度要求，考虑不确定性影响。


<details>
  <summary>Details</summary>
Motivation: 因物料流成分和需求变化，传感器分选系统需持续验证和调整工艺参数以确保分选精度。现有方法实验成本高且缺乏对不确定性的量化处理。

Method: 1. 建立高斯过程回归模型（基于贝叶斯优化）作为目标函数的替代模型；2. 同时优化两个物料输出流的分选精度指标；3. 在模型计算中引入不确定性量化；4. 仅需三次实验验证三个工艺参数。

Result: 方法在验证中有效平衡了双输出流精度需求，并通过不确定性量化提升了参数调整的鲁棒性。

Conclusion: 该框架能以少量实验实现工艺参数优化，解决了双目标权衡问题，并降低了因不确定性导致的决策风险。

Abstract: Sensor-based sorting systems enable the physical separation of a material
stream into two fractions. The sorting decision is based on the image data
evaluation of the sensors used and is carried out using actuators. Various
process parameters must be set depending on the properties of the material
stream, the dimensioning of the system, and the required sorting accuracy.
However, continuous verification and re-adjustment are necessary due to
changing requirements and material stream compositions. In this paper, we
introduce an approach for optimizing, recurrently monitoring and adjusting the
process parameters of a sensor-based sorting system. Based on Bayesian
Optimization, Gaussian process regression models are used as surrogate models
to achieve specific requirements for system behavior with the uncertainties
contained therein. This method minimizes the number of necessary experiments
while simultaneously considering two possible optimization targets based on the
requirements for both material output streams. In addition, uncertainties are
considered during determining sorting accuracies in the model calculation. We
evaluated the method with three example process parameters.

</details>


### [109] [Prototype-Guided Pseudo-Labeling with Neighborhood-Aware Consistency for Unsupervised Adaptation](https://arxiv.org/abs/2507.22075)
*Eman Ali,Chetan Arora,Muhammad Haris Khan*

Main category: cs.LG

TL;DR: 提出了一种新的自适应伪标签框架，通过原型一致性和基于邻域的一致性提升CLIP在无监督适应中的性能，包括PICS组件和NALR组件，并引入了自适应加权机制，在11个基准数据集上验证了其先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统伪标签过滤方法在完全无监督环境下不可靠，特别是在域偏移或视觉复杂场景下，零样本预测得到的伪标签噪声严重，因此需要更鲁棒的伪标签优化方案。

Method: 设计框架包含两个核心组件：1) PICS：基于类内特征紧密度和类间特征分离性评估伪标签准确性；2) NALR：利用相邻样本的语义相似性动态优化伪标签。额外引入自适应加权机制，根据伪标签的估计正确度调整训练权重。

Result: 在11个基准数据集上实现了最先进的无监督适应性能，提供更准确的伪标签并保持计算效率。

Conclusion: 提出的自适应伪标签框架显著提高了无监督适应中伪标签的可靠性，为视觉语言模型在面对域偏移和复杂场景时提供了有效的优化路径。

Abstract: In unsupervised adaptation for vision-language models such as CLIP,
pseudo-labels derived from zero-shot predictions often exhibit significant
noise, particularly under domain shifts or in visually complex scenarios.
Conventional pseudo-label filtering approaches, which rely on fixed confidence
thresholds, tend to be unreliable in fully unsupervised settings. In this work,
we propose a novel adaptive pseudo-labeling framework that enhances CLIP's
adaptation performance by integrating prototype consistency and
neighborhood-based consistency. The proposed method comprises two key
components: PICS, which assesses pseudo-label accuracy based on in-class
feature compactness and cross-class feature separation; and NALR, which
exploits semantic similarities among neighboring samples to refine
pseudo-labels dynamically. Additionally, we introduce an adaptive weighting
mechanism that adjusts the influence of pseudo-labeled samples during training
according to their estimated correctness. Extensive experiments on 11 benchmark
datasets demonstrate that our method achieves state-of-the-art performance in
unsupervised adaptation scenarios, delivering more accurate pseudo-labels while
maintaining computational efficiency.

</details>


### [110] [Test-time Prompt Refinement for Text-to-Image Models](https://arxiv.org/abs/2507.22076)
*Mohammad Abdul Hafeez Khan,Yash Jain,Siddhartha Bhattacharyya,Vibhav Vineet*

Main category: cs.LG

TL;DR: 提出了一种无需训练、即插即用的闭循环提示词修正框架（TIR），利用多模态大语言模型（MLLM）在生成后分析图像和提示的偏差，迭代修正提示词以提升文本到图像生成的对齐度和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本生成图像模型对提示词表述高度敏感，细微改动即导致输出不一致。为解决这一痛点，我们设计了一种闭循环测试时修正机制。

Method: 1. 图像初步生成 → 2. MLLM分析图像与提示的偏差（如缺失对象/属性错误）→ 3. MLLM输出物理修正后的新提示词 → 4. 重新生成 → 迭代上述步骤直到满足对齐要求。无需训练原始T2I模型。

Result: 在多个基准测试中显著提升了图像与文本的对齐度和视觉连贯性，且支持黑盒T2I模型的即插即用部署。

Conclusion: TIR通过模拟人类艺术家迭代修正过程，成功解决提示词敏感性问题，为提升生成模型鲁棒性提供新范式。

Abstract: Text-to-image (T2I) generation models have made significant strides but still
struggle with prompt sensitivity: even minor changes in prompt wording can
yield inconsistent or inaccurate outputs. To address this challenge, we
introduce a closed-loop, test-time prompt refinement framework that requires no
additional training of the underlying T2I model, termed TIR. In our approach,
each generation step is followed by a refinement step, where a pretrained
multimodal large language model (MLLM) analyzes the output image and the user's
prompt. The MLLM detects misalignments (e.g., missing objects, incorrect
attributes) and produces a refined and physically grounded prompt for the next
round of image generation. By iteratively refining the prompt and verifying
alignment between the prompt and the image, TIR corrects errors, mirroring the
iterative refinement process of human artists. We demonstrate that this
closed-loop strategy improves alignment and visual coherence across multiple
benchmark datasets, all while maintaining plug-and-play integration with
black-box T2I models.

</details>


### [111] [Multi-fidelity Bayesian Data-Driven Design of Energy Absorbing Spinodoid Cellular Structures](https://arxiv.org/abs/2507.22079)
*Leo Guo,Hirak Kansara,Siamak F. Khosroshahi,GuoQi Zhang,Wei Tan*

Main category: cs.LG

TL;DR: 该论文提出了一种使用贝叶斯优化（BO）和多保真度贝叶斯优化（MFBO）来优化自旋点阵细胞结构的能量吸收（EA）问题的方法。通过Sobol采样和基于方差的敏感性分析来降低问题的复杂性。结果发现，MFBO在多个超参数设置下比BO性能高出11%。


<details>
  <summary>Details</summary>
Motivation: 随着有限元（FE）模拟精度提高，计算成本也在增加，而数据驱动设计的需求也在增长。为了平衡两者，本文旨在比较BO和MFBO在优化真实工程问题（如自旋点阵结构变形和能量吸收特性）中的性能，并利用敏感性分析来简化设计问题。

Method: 1. 使用Sobol样本进行采样，结合基于方差的敏感性分析来降低设计复杂度。2. 采用贝叶斯优化（BO）和多保真度贝叶斯优化（MFBO）方法，其中MFBO利用FE模型不同网格宽度（保真度）来进行评估。3. 在优化自旋点阵细胞结构的能量吸收（EA）问题中应用这两种方法，并比较性能。

Result: MFBO在优化自旋点阵结构的能量吸收方面表现更佳，能够在不同超参数设置下比BO高出11%的性能。结果已开源。

Conclusion: 多保真度技术（MFBO）在昂贵的数据驱动设计问题中具有显著优势，能够有效提高优化性能。该研究为类似工程问题提供了一种高效的优化方法。

Abstract: Finite element (FE) simulations of structures and materials are getting
increasingly more accurate, but also more computationally expensive as a
collateral result. This development happens in parallel with a growing demand
of data-driven design. To reconcile the two, a robust and data-efficient
optimization method called Bayesian optimization (BO) has been previously
established as a technique to optimize expensive objective functions. In
parallel, the mesh width of an FE model can be exploited to evaluate an
objective at a lower or higher fidelity (cost & accuracy) level. The
multi-fidelity setting applied to BO, called multi-fidelity BO (MFBO), has also
seen previous success. However, BO and MFBO have not seen a direct comparison
with when faced with with a real-life engineering problem, such as metamaterial
design for deformation and absorption qualities. Moreover, sampling quality and
assessing design parameter sensitivity is often an underrepresented part of
data-driven design. This paper aims to address these shortcomings by employing
Sobol' samples with variance-based sensitivity analysis in order to reduce
design problem complexity. Furthermore, this work describes, implements,
applies and compares the performance BO with that MFBO when maximizing the
energy absorption (EA) problem of spinodoid cellular structures is concerned.
The findings show that MFBO is an effective way to maximize the EA of a
spinodoid structure and is able to outperform BO by up to 11% across various
hyperparameter settings. The results, which are made open-source, serve to
support the utility of multi-fidelity techniques across expensive data-driven
design problems.

</details>


### [112] [Shape Invariant 3D-Variational Autoencoder: Super Resolution in Turbulence flow](https://arxiv.org/abs/2507.22082)
*Anuraj Maurya*

Main category: cs.LG

TL;DR: 报告提供了湍流建模的经典和深度学习方法的概述，并研究了将多尺度湍流模型与深度学习架构结合以及应用深度生成模型进行超分辨率重建两个挑战。


<details>
  <summary>Details</summary>
Motivation: 深度学习能够从复杂数据中提取信息，有助于理解流体动力学现象。湍流建模领域有大量高维数据，适合应用深度学习方法。

Method: 对经典和深度学习的湍流建模方法进行综述，并具体研究两个方向：1. 多尺度湍流模型与深度学习架构的整合；2. 深度生成模型在超分辨率重建中的应用。

Result: 报告提供了湍流建模方法的概览，并深入探讨了两个交叉领域挑战的解决方案。

Conclusion: 深度学习在湍流建模中具有潜力，尤其是在整合多尺度模型和应用生成模型进行超分辨率重建方面。

Abstract: Deep learning provides a versatile suite of methods for extracting structured
information from complex datasets, enabling deeper understanding of underlying
fluid dynamic phenomena. The field of turbulence modeling, in particular,
benefits from the growing availability of high-dimensional data obtained
through experiments, field observations, and large-scale simulations spanning
multiple spatio-temporal scales. This report presents a concise overview of
both classical and deep learningbased approaches to turbulence modeling. It
further investigates two specific challenges at the intersection of fluid
dynamics and machine learning: the integration of multiscale turbulence models
with deep learning architectures, and the application of deep generative models
for super-resolution reconstruction

</details>


### [113] [Principled Curriculum Learning using Parameter Continuation Methods](https://arxiv.org/abs/2507.22089)
*Harsh Nilesh Pathak,Randy Paffenroth*

Main category: cs.LG

TL;DR: 本文提出了一种用于神经网络优化的参数延拓方法，该方法在理论上合理，在实践中对多个深度学习问题有效，包括监督和无监督学习任务，且表现优于ADAM等最先进的优化技术。


<details>
  <summary>Details</summary>
Motivation: 研究人员观察到参数延拓、同伦和课程学习之间存在紧密联系，旨在通过提出一种理论依据充分且实用的优化方法，来改进神经网络的训练过程。

Method: 该论文开发了一个参数延拓框架，通过逐渐调整模型参数，避免优化过程中的局部最小值，从而使神经网络的训练更加稳定和高效。参数延拓作为一种连续的变体，类似于课程学习中的逐步困难策略，但这里更侧重于优化路径的连续调整。

Result: 实验结果表明，该方法在多种监督和非监督学习任务中优于ADAM等当前最先进的优化器，实现了更好的泛化性能。

Conclusion: 参数延拓方法为神经网络的优化提供了一个强有力的替代方案，其理论保证和实证效果显著，未来有望在更复杂的深度学习问题和模型架构中得到发展和应用。

Abstract: In this work, we propose a parameter continuation method for the optimization
of neural networks. There is a close connection between parameter continuation,
homotopies, and curriculum learning. The methods we propose here are
theoretically justified and practically effective for several problems in deep
neural networks. In particular, we demonstrate better generalization
performance than state-of-the-art optimization techniques such as ADAM for
supervised and unsupervised learning tasks.

</details>


### [114] [Hybrid activation functions for deep neural networks: S3 and S4 -- a novel approach to gradient flow optimization](https://arxiv.org/abs/2507.22090)
*Sergii Kavun*

Main category: cs.LG

TL;DR: 论文介绍了两种新型混合激活函数S3和S4，其中S3结合了Sigmoid和Softsign，S4在S3基础上增加了平滑过渡机制，通过综合实验证明S4在多种任务和网络结构上优于基准激活函数。


<details>
  <summary>Details</summary>
Motivation: 传统激活函数（如ReLU存在死神经元问题，Sigmoid/Tanh存在梯度消失问题）限制了神经网络性能，因此需要设计能同时解决这些问题的激活函数。

Method: 1. 提出两种混合激活函数：S3（负输入用Sigmoid，正输入用Softsign）和S4（在S3基础上增加可控的平滑过渡参数k）；2. 在二元分类、多类别分类及回归任务上测试，使用三种网络架构与9种基线激活函数对比；3. 分析梯度范围、收敛速度及不同网络深度的稳定性。

Result: 1. S4在MNIST（97.4%）、Iris（96.0%）和Boston Housing（MSE=18.7）上全面超越基线；2. 收敛速度比ReLU快19倍（训练步骤）；3. 梯度范围稳定在[0.24, 0.59]，而ReLU在深层网络中出现18%的死亡神经元。

Conclusion: S4通过混合设计和平滑过渡机制解决了现有激活函数的局限性，可调参数k使其适配不同任务和网络深度，证明了混合激活函数是改进神经网络训练动态的有效方向。

Abstract: Activation functions are critical components in deep neural networks,
directly influencing gradient flow, training stability, and model performance.
Traditional functions like ReLU suffer from dead neuron problems, while sigmoid
and tanh exhibit vanishing gradient issues. We introduce two novel hybrid
activation functions: S3 (Sigmoid-Softsign) and its improved version S4
(smoothed S3). S3 combines sigmoid for negative inputs with softsign for
positive inputs, while S4 employs a smooth transition mechanism controlled by a
steepness parameter k. We conducted comprehensive experiments across binary
classification, multi-class classification, and regression tasks using three
different neural network architectures. S4 demonstrated superior performance
compared to nine baseline activation functions, achieving 97.4% accuracy on
MNIST, 96.0% on Iris classification, and 18.7 MSE on Boston Housing regression.
The function exhibited faster convergence (-19 for ReLU) and maintained stable
gradient flow across network depths. Comparative analysis revealed S4's
gradient range of [0.24, 0.59] compared to ReLU's 18% dead neurons in deep
networks. The S4 activation function addresses key limitations of existing
functions through its hybrid design and smooth transition mechanism. The
tunable parameter k allows adaptation to different tasks and network depths,
making S4 a versatile choice for deep learning applications. These findings
suggest that hybrid activation functions represent a promising direction for
improving neural network training dynamics.

</details>


### [115] [Spatial-Temporal Reinforcement Learning for Network Routing with Non-Markovian Traffic](https://arxiv.org/abs/2507.22174)
*Molly Wang*

Main category: cs.LG

TL;DR: 强化学习（RL）常用于优化通信网络中的分组路由，但标准RL基于马尔可夫决策过程（MDP），忽略了许多实际场景中的非马尔可夫性，且未显式考虑复杂网络拓扑的空间关系。此外，动态流量和网络规模的变化也增加了决策难度。为此，本文提出一种结合图神经网络（GNN）和循环神经网络（RNN）的时空强化学习方法，分别捕捉网络拓扑的空间动态和流量模式的时间动态。评估表明，该方法优于传统RL，且对网络拓扑的变动更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习（RL）基于马尔可夫决策过程（MDP），假设环境当前状态包含所有必要信息用于决策和演化。然而，在许多实际场景中（如通信网络）该马尔可夫性假设并不成立，导致MDP/RL框架无法提供最优解；同时传统RL函数近似（如神经网络）未能显式处理复杂网络拓扑的空间关系。通信网络的动态流量模式、节点/链路的任意规模变化进一步加剧了决策难度。

Method: 提出一种时空强化学习方法：为显式捕获网络拓扑的空间关系和时间维度的流量模式，分别引入图神经网络（GNN）和循环神经网络（RNN）。GNN处理网络节点/链路的空间结构信息（如邻接关系）；RNN（如LSTM/GRU）则用于建模流量的时间序列动态。两者结合，形成具备空间-时间感知能力的深度神经网络，作为强化学习的值函数/策略函数近似器，输出优化的路由决策。

Result: 在模拟通信网络上评估该方法与传统RL技术（如标准DQN）的性能对比。实验结果表明：（a）所提方法在路由优化指标（如延迟、丢包率）上优于传统RL；（b）当网络拓扑（节点/链路数量）变化时，该方法表现出更强的鲁棒性（即性能波动较小），而传统RL性能显著下降。

Conclusion: 针对通信网络路由决策问题，传统RL因其马尔可夫假设和空间关系建模不足而存在局限性。本文提出的GNN+RNN时空强化学习方法有效捕获网络拓扑的空间结构和流量的时间动态，显著提升路由优化性能，并增强了拓扑变化下的鲁棒性。

Abstract: Reinforcement Learning (RL) has become a well-established approach for
optimizing packet routing in communication networks. Standard RL algorithms
typically are based on the Markov Decision Process (MDP), which assumes that
the current state of the environment provides all the necessary information for
system evolution and decision-making. However, this Markovian assumption is
invalid in many practical scenarios, making the MDP and RL frameworks
inadequate to produce the optimal solutions. Additionally, traditional RL
algorithms often employ function approximations (e.g., by neural networks) that
do not explicitly capture the spatial relationships inherent in environments
with complex network topologies. Communication networks are characterized by
dynamic traffic patterns and arbitrary numbers of nodes and links, which
further complicate the decision-making process. To address these challenges, we
propose a spatial-temporal RL approach that integrates Graph Neural Networks
(GNNs) and Recurrent Neural Networks (RNNs) to adequately capture the spatial
dynamics regarding network topology and temporal traffic patterns,
respectively, to enhance routing decisions. Our evaluation demonstrates that
the proposed method outperforms and is more robust to changes in the network
topology when compared with traditional RL techniques.

</details>


### [116] [SourceSplice: Source Selection for Machine Learning Tasks](https://arxiv.org/abs/2507.22186)
*Ambarish Singh,Romila Pradhan*

Main category: cs.LG

TL;DR: 本文针对下游机器学习任务的数据源选择问题，提出了SourceGrasp和SourceSplice两种框架，旨在高效选择能最大化提升模型性能的数据源子集，并通过实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代组织可用数据源激增，但现有数据发现方法主要关注元数据匹配、语义相似性等，忽略了数据源质量对下游ML任务性能的影响。如何选择最优数据源子集以构建训练数据成为关键问题。

Method: 1. SourceGrasp：融合贪心策略与随机化的元启发式算法；2. SourceSplice：受基因剪接启发，模拟蛋白质合成中的选择机制。两种方法均基于'不同数据源组合对任务效用贡献不同'的核心思想。

Result: 在三个真实数据集和合成数据集上验证表明：SourceSplice能以更少的子集探索次数，高效识别出能带来高任务效用的数据源子集；研究还分析了不同设置下框架的敏感性。

Conclusion: 提出的SourceSplice框架在数据源选择问题上显著优于基线方法，为组合多源数据提升ML性能提供了有效解决方案，未来可扩展至动态数据源场景。

Abstract: Data quality plays a pivotal role in the predictive performance of machine
learning (ML) tasks - a challenge amplified by the deluge of data sources
available in modern organizations.Prior work in data discovery largely focus on
metadata matching, semantic similarity or identifying tables that should be
joined to answer a particular query, but do not consider source quality for
high performance of the downstream ML task.This paper addresses the problem of
determining the best subset of data sources that must be combined to construct
the underlying training dataset for a given ML task.We propose SourceGrasp and
SourceSplice, frameworks designed to efficiently select a suitable subset of
sources that maximizes the utility of the downstream ML model.Both the
algorithms rely on the core idea that sources (or their combinations)
contribute differently to the task utility, and must be judiciously
chosen.While SourceGrasp utilizes a metaheuristic based on a greediness
criterion and randomization, the SourceSplice framework presents a source
selection mechanism inspired from gene splicing - a core concept used in
protein synthesis.We empirically evaluate our algorithms on three real-world
datasets and synthetic datasets and show that, with significantly fewer subset
explorations, SourceSplice effectively identifies subsets of data sources
leading to high task utility.We also conduct studies reporting the sensitivity
of SourceSplice to the decision choices under several settings.

</details>


### [117] [Measuring Time-Series Dataset Similarity using Wasserstein Distance](https://arxiv.org/abs/2507.22189)
*Hongjie Chen,Akshay Mehra,Josh Kimball,Ryan A. Rossi*

Main category: cs.LG

TL;DR: 使用Wasserstein距离测量时间序列数据集相似性的分布方法，用于模型选择、微调和可视化。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型研究的兴起需要衡量时间序列数据集的（不）相似性。这种相似性度量有助于模型选择、微调和可视化。

Method: 将时间序列数据集视为基础多元正态分布（MVN）的实例化，通过计算两个数据集的对应多元正态分布之间的Wasserstein距离来衡量它们之间的相似性。

Result: 全面实验和可视化显示，该方法能有效识别相似时间序列数据集。在分布外和迁移学习的评估中，该方法与推断损失之间存在显著相关性（>0.60）。

Conclusion: 基于Wasserstein距离的数据集相似性指标与推断损失高度相关，在模型选择、微调和性能预测中具有实用价值。

Abstract: The emergence of time-series foundation model research elevates the growing
need to measure the (dis)similarity of time-series datasets. A time-series
dataset similarity measure aids research in multiple ways, including model
selection, finetuning, and visualization. In this paper, we propose a
distribution-based method to measure time-series dataset similarity by
leveraging the Wasserstein distance. We consider a time-series dataset an
empirical instantiation of an underlying multivariate normal distribution
(MVN). The similarity between two time-series datasets is thus computed as the
Wasserstein distance between their corresponding MVNs. Comprehensive
experiments and visualization show the effectiveness of our approach.
Specifically, we show how the Wasserstein distance helps identify similar
time-series datasets and facilitates inference performance estimation of
foundation models in both out-of-distribution and transfer learning evaluation,
with high correlations between our proposed measure and the inference loss
(>0.60).

</details>


### [118] [CTG-Insight: A Multi-Agent Interpretable LLM Framework for Cardiotocography Analysis and Classification](https://arxiv.org/abs/2507.22205)
*Black Sun,Die,Hu*

Main category: cs.LG

TL;DR: 提出了CTG-Insight，一种基于多智能体大语言模型的系统，可为胎心监护（CTG）数据提供结构化解读。该系统分解CTG信号为五个医学特征进行分析，并通过聚合智能体生成胎儿健康报告，实现了高准确率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前远程胎儿监护技术缺乏可解释性，仅提供难以理解的原始胎心监护数据。现有的深度学习模型像黑箱，单代理大语言模型可能产生不一致解释。因此需要一种既准确又透明的解读工具。

Method: 1.设计多智能体系统：创建五个专用代理分析五个特征：基线心率、变异性、加速、减速和正弦波形。2.利用医学指南：遵循医学规范对每个特征进行评价。3.聚合分析结果：采用合成代理整合子代理的输出，给出总体胎儿健康分类并伴随自然语言解释。4.评估方法：在NeuroFetalNet数据集上测试，并与深度学习模型和单代理LLM基线进行比较。

Result: CTG-Insight在准确性(96.4%)和F1分数(97.8%)方面达到最佳水平。系统输出透明且可解释，优于比较的基准模型。

Conclusion: 本工作提出了一个可解释且可扩展的胎心监护分析框架，为产前健康监护提供了兼具高准确性和透明性的技术方案。

Abstract: Remote fetal monitoring technologies are becoming increasingly common. Yet,
most current systems offer limited interpretability, leaving expectant parents
with raw cardiotocography (CTG) data that is difficult to understand. In this
work, we present CTG-Insight, a multi-agent LLM system that provides structured
interpretations of fetal heart rate (FHR) and uterine contraction (UC) signals.
Drawing from established medical guidelines, CTG-Insight decomposes each CTG
trace into five medically defined features: baseline, variability,
accelerations, decelerations, and sinusoidal pattern, each analyzed by a
dedicated agent. A final aggregation agent synthesizes the outputs to deliver a
holistic classification of fetal health, accompanied by a natural language
explanation. We evaluate CTG-Insight on the NeuroFetalNet Dataset and compare
it against deep learning models and the single-agent LLM baseline. Results show
that CTG-Insight achieves state-of-the-art accuracy (96.4%) and F1-score
(97.8%) while producing transparent and interpretable outputs. This work
contributes an interpretable and extensible CTG analysis framework.

</details>


### [119] [Explainability-Driven Feature Engineering for Mid-Term Electricity Load Forecasting in ERCOT's SCENT Region](https://arxiv.org/abs/2507.22220)
*Abhiram Bhupatiraju,Sung Bum Ahn*

Main category: cs.LG

TL;DR: 比较线性回归、XGBoost、LightGBM和LSTM在电力系统中长期负荷预测的性能，并利用SHAP方法提升模型可解释性和预测精度。


<details>
  <summary>Details</summary>
Motivation: 准确的负荷预测对电力系统运行至关重要。为满足电力需求对天气变化和时间动态的敏感性，捕捉非线性模式对于长期规划（如维护调度、资源分配和金融预测）是必不可少的。

Method: 采用四种机器学习模型（线性回归、XGBoost、LightGBM、LSTM）进行长达一年的系统级电力负荷预测，并引入SHAP（Shapley加性解释）方法量化特征贡献，指导特征工程，增强模型透明度和准确性。

Result: 未在摘要中明确给出具体数值结果，但表明SHAP方法有效提升了模型可解释性和预测精度。

Conclusion: 机器学习模型（特别是结合SHAP方法）能够有效提升中长期电力负荷预测的准确性和可解释性，为电力系统规划提供可靠支持。

Abstract: Accurate load forecasting is essential to the operation of modern electric
power systems. Given the sensitivity of electricity demand to weather
variability and temporal dynamics, capturing non-linear patterns is essential
for long-term planning. This paper presents a comparative analysis of machine
learning models, Linear Regression, XGBoost, LightGBM, and Long Short-Term
Memory (LSTM), for forecasting system-wide electricity load up to one year in
advance. Midterm forecasting has shown to be crucial for maintenance
scheduling, resource allocation, financial forecasting, and market
participation. The paper places a focus on the use of a method called "Shapley
Additive Explanations" (SHAP) to improve model explainability. SHAP enables the
quantification of feature contributions, guiding informed feature engineering
and improving both model transparency and forecasting accuracy.

</details>


### [120] [TRIBE: TRImodal Brain Encoder for whole-brain fMRI response prediction](https://arxiv.org/abs/2507.22229)
*Stéphane d'Ascoli,Jérémy Rapin,Yohann Benchetrit,Hubert Banville,Jean-Rémi King*

Main category: cs.LG

TL;DR: TRIBE是一个多模态深度神经网络，能够预测大脑对不同刺激的响应。它结合了文本、音频和视频基础模型的预训练表示，并使用Transformer处理时序数据，在Algonauts 2025大脑编码竞赛中取得第一名，大幅领先竞争对手。模型在感知和认知领域表现出色，为构建统一的大脑表示模型铺平道路。


<details>
  <summary>Details</summary>
Motivation: 神经科学领域长期分裂为专注于单一模态或脑区的专业方向，这阻碍了建立统一认知模型的发展。为了整合多模态、多脑区和跨个体的脑响应预测，作者开发了TRIBE模型。

Method: 1. 结合预训练的文本、音频和视频基础模型作为输入特征表示；2. 使用Transformer处理这些特征在时间维度上的演化；3. 通过多模态融合预测fMRI脑响应的空间和时间模式。实验通过Algonauts竞赛数据集验证，并对单模态与多模态模型进行消融研究。

Result: 1. 在Algonauts 2025大脑编码竞赛中获得第一名，且显著优于其他参赛模型；2. 消融实验表明：单模态模型能预测对应脑区（如视觉/听觉网络），但多模态模型在高级联合皮层优势明显；3. 模型能精确预测观看视频时人类大脑的时空fMRI响应模式。

Conclusion: TRIBE首次实现了跨模态、跨脑区和跨个体的脑响应预测。当前应用于感知与理解任务，该多模态方法为构建人类大脑的整合表征模型提供了新途径。未来可扩展至更高层次认知功能建模。

Abstract: Historically, neuroscience has progressed by fragmenting into specialized
domains, each focusing on isolated modalities, tasks, or brain regions. While
fruitful, this approach hinders the development of a unified model of
cognition. Here, we introduce TRIBE, the first deep neural network trained to
predict brain responses to stimuli across multiple modalities, cortical areas
and individuals. By combining the pretrained representations of text, audio and
video foundational models and handling their time-evolving nature with a
transformer, our model can precisely model the spatial and temporal fMRI
responses to videos, achieving the first place in the Algonauts 2025 brain
encoding competition with a significant margin over competitors. Ablations show
that while unimodal models can reliably predict their corresponding cortical
networks (e.g. visual or auditory networks), they are systematically
outperformed by our multimodal model in high-level associative cortices.
Currently applied to perception and comprehension, our approach paves the way
towards building an integrative model of representations in the human brain.
Our code is available at https://github.com/facebookresearch/algonauts-2025.

</details>


### [121] [Using Scaling Laws for Data Source Utility Estimation in Domain-Specific Pre-Training](https://arxiv.org/abs/2507.22250)
*Oleksiy Ostapenko,Charles Guille-Escuret,Luke Kumar,Max Tian,Denis Kocetkov,Gopeshh Subbaraj,Raymond Li,Joel Lamy-Poirier,Sebastien Paquet,Torsten Scholak*

Main category: cs.LG

TL;DR: 提出了一种优化领域特定数据集构建的框架，通过多轮退火运行估计数据源的缩放规律，以进行资源分配决策，避免点估计的局限性。


<details>
  <summary>Details</summary>
Motivation: 在基础模型训练中，为特定领域（如医学或数学）优化数据集构建时，传统点估计方法可能因不同计算规模下的排序不一致性而产生误导。需要一种更可靠的方法来评估不同数据源的质量，以优化资源分配。

Method: 1. 扩展点估计方法（微退火）为多轮退火运行：在不同数据量和计算量下多次运行退火（第二阶段预训练）。2. 针对每个数据源（如合成数据、网络数据）生成性能-成本缩放曲线。3. 分析性能增益与获取成本的关系，建立数据源的缩放规律。4. 利用缩放规律，在给定计算预算下优化不同数据源的资源分配（如采购比例）。验证实验基于70亿参数预训练模型，在医学（预训练数据充足）和数学（数据不足）领域进行测试。

Result: 1. 证实了仅依赖点估计会导致数据源排序错误：高计算规模下的最优数据源可能不同于低计算规模。2. 多退火方法生成的缩放曲线能够准确反映数据源的真实价值（如合成数据在数学领域的增益随规模变化模式）。3. 据此制定的资源分配方案显著优于点估计方法（如数学领域需混合使用合成和真实数据）。

Conclusion: 所提框架通过多轮退火建立数据源的缩放规律，解决了点估计的局限性，实现了面向成本效益的数据源选择与资源分配，可推广至任意领域适配场景。

Abstract: We introduce a framework for optimizing domain-specific dataset construction
in foundation model training. Specifically, we seek a cost-efficient way to
estimate the quality of data sources (e.g. synthetically generated or filtered
web data, etc.) in order to make optimal decisions about resource allocation
for data sourcing from these sources for the stage two pre-training phase, aka
annealing, with the goal of specializing a generalist pre-trained model to
specific domains. Our approach extends the usual point estimate approaches, aka
micro-annealing, to estimating scaling laws by performing multiple annealing
runs of varying compute spent on data curation and training. This addresses a
key limitation in prior work, where reliance on point estimates for data
scaling decisions can be misleading due to the lack of rank invariance across
compute scales -- a phenomenon we confirm in our experiments. By systematically
analyzing performance gains relative to acquisition costs, we find that scaling
curves can be estimated for different data sources. Such scaling laws can
inform cost effective resource allocation across different data acquisition
methods (e.g. synthetic data), data sources (e.g. user or web data) and
available compute resources. We validate our approach through experiments on a
pre-trained model with 7 billion parameters. We adapt it to: a domain
well-represented in the pre-training data -- the medical domain, and a domain
underrepresented in the pretraining corpora -- the math domain. We show that
one can efficiently estimate the scaling behaviors of a data source by running
multiple annealing runs, which can lead to different conclusions, had one used
point estimates using the usual micro-annealing technique instead. This enables
data-driven decision-making for selecting and optimizing data sources.

</details>


### [122] [Agent-centric learning: from external reward maximization to internal knowledge curation](https://arxiv.org/abs/2507.22255)
*Hanqi Zhou,Fryderyk Mantiuk,David G. Nagy,Charley M. Wu*

Main category: cs.LG

TL;DR: 提出了一种新的智能范式——表示赋权（representational empowerment），将控制焦点从外部环境转向内部知识结构，以提升智能体的适应性和知识多样性。


<details>
  <summary>Details</summary>
Motivation: 传统的通用智能追求侧重于外部目标（如环境控制或任务掌握），但这种方法可能导致智能体缺乏适应性。本文认为，将控制焦点转向内部（即智能体对自身知识结构的维护和多样化能力）是提升适应性的关键。

Method: 通过定义表示赋权作为新目标：量化智能体对其内部知识结构的可控维护和多样化能力，并论证这种能力（塑造自身理解）是实现更好准备状态的核心要素，区别于直接环境影响。该方法将内部表示作为计算赋权的主要载体。

Result: 该框架为设计适应性智能系统提供了新视角，通过关注内部知识动态而非外部奖励，理论上可增强智能体的泛化能力和长期自主性。

Conclusion: 表示赋权是一种以智能体为中心的学习范式创新，通过将赋权计算建立在内部表示层面上，为构建真正适应性的通用智能开辟新路径。

Abstract: The pursuit of general intelligence has traditionally centered on external
objectives: an agent's control over its environments or mastery of specific
tasks. This external focus, however, can produce specialized agents that lack
adaptability. We propose representational empowerment, a new perspective
towards a truly agent-centric learning paradigm by moving the locus of control
inward. This objective measures an agent's ability to controllably maintain and
diversify its own knowledge structures. We posit that the capacity -- to shape
one's own understanding -- is an element for achieving better ``preparedness''
distinct from direct environmental influence. Focusing on internal
representations as the main substrate for computing empowerment offers a new
lens through which to design adaptable intelligent systems.

</details>


### [123] [Weighted Conditional Flow Matching](https://arxiv.org/abs/2507.22270)
*Sergio Calvo-Ordonez,Matthieu Meunier,Alvaro Cartea,Christoph Reisinger,Yarin Gal,Jose Miguel Hernandez-Lobato*

Main category: cs.LG

TL;DR: 提出了加权条件流匹配（W-CFM），通过吉布斯核加权训练对改进条件流匹配，在保持计算效率的同时实现更短更直的轨迹，克服了批量最优输运的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 标准条件流匹配（CFM）的轨迹偏离先验与目标分布间的直线插值，导致生成速度慢且精度低。现有改进方法依赖计算昂贵的批量最优输运（OT）。本文从熵最优输运（EOT）获得启发，旨在保持CFM效率的同时提升性能。

Method: 1. 修改经典CFM损失函数：对每个训练对(x, y)用吉布斯核加权；2. 理论分析：证明加权恢复熵最优输运耦合（边际偏差可控），建立W-CFM与大批量OT方法的等价性；3. 设计：通过加权机制避免小批量OT的计算瓶颈。

Result: 在合成与真实数据集的无条件生成任务中验证：W-CFM在样本质量、保真度、多样性上媲美或优于基线；保持与原始CFM相当的计算效率。
关键指标：轨迹长度缩短（生成加速），采样精度提升（离散化需求减少）。

Conclusion: W-CFM在维持CFM效率的前提下，通过熵OT启发的加权机制有效优化了生成轨迹，解决了当前方法依赖高成本批量OT的问题，为高效高精度生成模型提供了新方向。

Abstract: Conditional flow matching (CFM) has emerged as a powerful framework for
training continuous normalizing flows due to its computational efficiency and
effectiveness. However, standard CFM often produces paths that deviate
significantly from straight-line interpolations between prior and target
distributions, making generation slower and less accurate due to the need for
fine discretization at inference. Recent methods enhance CFM performance by
inducing shorter and straighter trajectories but typically rely on
computationally expensive mini-batch optimal transport (OT). Drawing insights
from entropic optimal transport (EOT), we propose Weighted Conditional Flow
Matching (W-CFM), a novel approach that modifies the classical CFM loss by
weighting each training pair $(x, y)$ with a Gibbs kernel. We show that this
weighting recovers the entropic OT coupling up to some bias in the marginals,
and we provide the conditions under which the marginals remain nearly
unchanged. Moreover, we establish an equivalence between W-CFM and the
minibatch OT method in the large-batch limit, showing how our method overcomes
computational and performance bottlenecks linked to batch size. Empirically, we
test our method on unconditional generation on various synthetic and real
datasets, confirming that W-CFM achieves comparable or superior sample quality,
fidelity, and diversity to other alternative baselines while maintaining the
computational efficiency of vanilla CFM.

</details>


### [124] [Comparing Cluster-Based Cross-Validation Strategies for Machine Learning Model Evaluation](https://arxiv.org/abs/2507.22299)
*Afonso Martini Spezia,Mariana Recamonde-Mendoza*

Main category: cs.LG

TL;DR: 该研究提出了一种将Mini Batch K-Means与类分层相结合的新交叉验证技术，并在20个数据集（包括平衡和不平衡）上进行了实验。结果表明，对于平衡数据集，该方法在偏差和方差方面优于其他方法；对于不平衡数据集，传统的分层交叉验证表现更好。


<details>
  <summary>Details</summary>
Motivation: 交叉验证在机器学习中至关重要，但可能导致创建的数据子集无法充分代表原始数据集的多样性，从而产生有偏的性能估计。因此，需要研究基于聚类的交叉验证策略，以提高模型评估的鲁棒性和可靠性。

Method: 提出一种新的交叉验证技术，结合Mini Batch K-Means聚类和类分层。在20个平衡和类不平衡数据集上，使用四种监督学习算法比较不同交叉验证策略，评估指标包括偏差、方差和计算成本。

Result: 在平衡数据集上，结合Mini Batch K-Means与类分层的技术在偏差和方差方面表现最优，但未显著降低计算成本。在不平衡数据集上，传统分层交叉验证的偏差、方差和计算成本均更低。不同聚类算法比较中，没有一种算法始终优于其他算法。

Conclusion: 研究深化了对基于聚类的交叉验证策略的理解，提出的新方法在平衡数据集上表现优异，而对于不平衡数据集，传统分层交叉验证仍是更优选择。此外，该工作为提升模型评估的鲁棒性和可靠性提供了新视角。

Abstract: Cross-validation plays a fundamental role in Machine Learning, enabling
robust evaluation of model performance and preventing overestimation on
training and validation data. However, one of its drawbacks is the potential to
create data subsets (folds) that do not adequately represent the diversity of
the original dataset, which can lead to biased performance estimates. The
objective of this work is to deepen the investigation of cluster-based
cross-validation strategies by analyzing the performance of different
clustering algorithms through experimental comparison. Additionally, a new
cross-validation technique that combines Mini Batch K-Means with class
stratification is proposed. Experiments were conducted on 20 datasets (both
balanced and imbalanced) using four supervised learning algorithms, comparing
cross-validation strategies in terms of bias, variance, and computational cost.
The technique that uses Mini Batch K-Means with class stratification
outperformed others in terms of bias and variance on balanced datasets, though
it did not significantly reduce computational cost. On imbalanced datasets,
traditional stratified cross-validation consistently performed better, showing
lower bias, variance, and computational cost, making it a safe choice for
performance evaluation in scenarios with class imbalance. In the comparison of
different clustering algorithms, no single algorithm consistently stood out as
superior. Overall, this work contributes to improving predictive model
evaluation strategies by providing a deeper understanding of the potential of
cluster-based data splitting techniques and reaffirming the effectiveness of
well-established strategies like stratified cross-validation. Moreover, it
highlights perspectives for increasing the robustness and reliability of model
evaluations, especially in datasets with clustering characteristics.

</details>


### [125] [Spatial-Temporal Data Mining for Ocean Science: Data, Methodologies, and Opportunities](https://arxiv.org/abs/2307.10803)
*Hanchen Yang,Wengen Li,Shuyu Wang,Hui Li,Jihong Guan,Shuigeng Zhou,Jiannong Cao*

Main category: cs.LG

TL;DR: 本文对海洋科学中的时空数据挖掘研究进行了全面综述，涵盖数据集、数据质量提升技术、四大任务类型（预测、事件检测、模式挖掘、异常检测），并讨论了未来研究方向，旨在促进计算机科学与海洋科学领域的交叉理解。


<details>
  <summary>Details</summary>
Motivation: 随着时空海洋数据的快速积累，相关数据挖掘研究日益增多，但海洋数据具有区域性差异大、稀疏性高等独特特征，导致建模困难。目前缺乏系统性综述，阻碍了两领域科学家对关键问题与技术进展的把握。

Method: 1. 梳理常用时空海洋数据集及其特征；2. 总结数据质量增强技术；3. 将现有研究归类为预测、事件检测、模式挖掘和异常检测四类任务并分析关键技术；4. 讨论未来研究机会。

Result: 系统性呈现海洋时空数据的特性、质量处理方法及四类核心任务的代表性技术框架，为跨领域研究者提供技术路线图。

Conclusion: 该综述填补了海洋科学时空数据挖掘领域的系统性总结空白，强调领域特有问题需定制化解决方案，并指出跨模态融合、可解释性等方向具备研究潜力。

Abstract: With the rapid amassing of spatial-temporal (ST) ocean data, many
spatial-temporal data mining (STDM) studies have been conducted to address
various oceanic issues, including climate forecasting and disaster warning.
Compared with typical ST data (e.g., traffic data), ST ocean data is more
complicated but with unique characteristics, e.g., diverse regionality and high
sparsity. These characteristics make it difficult to design and train STDM
models on ST ocean data. To the best of our knowledge, a comprehensive survey
of existing studies remains missing in the literature, which hinders not only
computer scientists from identifying the research issues in ocean data mining
but also ocean scientists to apply advanced STDM techniques. In this paper, we
provide a comprehensive survey of existing STDM studies for ocean science.
Concretely, we first review the widely-used ST ocean datasets and highlight
their unique characteristics. Then, typical ST ocean data quality enhancement
techniques are explored. Next, we classify existing STDM studies in ocean
science into four types of tasks, i.e., prediction, event detection, pattern
mining, and anomaly detection, and elaborate on the techniques for these tasks.
Finally, promising research opportunities are discussed. This survey can help
scientists from both computer science and ocean science better understand the
fundamental concepts, key techniques, and open challenges of STDM for ocean
science.

</details>


### [126] [CS-SHRED: Enhancing SHRED for Robust Recovery of Spatiotemporal Dynamics](https://arxiv.org/abs/2507.22303)
*Romulo B. da Silva,Cássio M. Oishi,Diego Passos,J. Nathan Kutz*

Main category: cs.LG

TL;DR: 提出了一种名为CS-SHRED的新型深度学习架构，该架构将压缩感知（CS）整合到浅层循环解码器（SHRED）中，用于从不完整、压缩或损坏的数据中重建时空动态。该方法通过引入批处理前向框架和ℓ1正则化，以及结合MSE和MAE的自适应损失函数，实现了在传感器稀疏、噪声大或数据不完整情况下的鲁棒信号恢复。


<details>
  <summary>Details</summary>
Motivation: 针对传感器布置稀疏、测量噪声大以及数据不完整等问题，传统方法难以有效重建高保真度的时空动态。因此，需要一种能够整合压缩感知技术与深度学习模型的新方法，以提高重建的准确性和鲁棒性。

Method: 1) 将压缩感知（CS）整合到SHRED架构中，利用批处理前向框架和ℓ1正则化进行信号恢复；2) 设计自适应损失函数，动态组合MSE和MAE，并根据信噪比（SNR）分片进行正则化，在低信噪比区域抑制噪声，高信噪比区域保留细节特征；3) 架构包括用于时间序列建模的LSTM和用于高维状态空间建模的浅层解码网络。

Result: 在多种挑战性问题（粘弹性流体流动、最大比湿场、海面温度分布和旋转湍流）上，CS-SHRED相比传统SHRED方法显著提高了重建保真度。具体表现在改进的SSIM和PSNR值、更低的归一化误差以及提升的LPIPS分数，表明其能更好地保留小尺度结构，并对噪声和异常值具有更强的鲁棒性。

Conclusion: CS-SHRED通过联合训练CS和SHRED架构，结合自适应SNR损失函数，在多种应用中展现出优越的时空数据恢复能力。该方法在环境、气候和科学数据分析领域具有广泛应用前景。

Abstract: We present $\textbf{CS-SHRED}$, a novel deep learning architecture that
integrates Compressed Sensing (CS) into a Shallow Recurrent Decoder
($\textbf{SHRED}$) to reconstruct spatiotemporal dynamics from incomplete,
compressed, or corrupted data. Our approach introduces two key innovations.
First, by incorporating CS techniques into the $\textbf{SHRED}$ architecture,
our method leverages a batch-based forward framework with $\ell_1$
regularization to robustly recover signals even in scenarios with sparse sensor
placements, noisy measurements, and incomplete sensor acquisitions. Second, an
adaptive loss function dynamically combines Mean Squared Error (MSE) and Mean
Absolute Error (MAE) terms with a piecewise Signal-to-Noise Ratio (SNR)
regularization, which suppresses noise and outliers in low-SNR regions while
preserving fine-scale features in high-SNR regions.
  We validate $\textbf{CS-SHRED}$ on challenging problems including
viscoelastic fluid flows, maximum specific humidity fields, sea surface
temperature distributions, and rotating turbulent flows. Compared to the
traditional $\textbf{SHRED}$ approach, $\textbf{CS-SHRED}$ achieves
significantly higher reconstruction fidelity - as demonstrated by improved SSIM
and PSNR values, lower normalized errors, and enhanced LPIPS scores-thereby
providing superior preservation of small-scale structures and increased
robustness against noise and outliers.
  Our results underscore the advantages of the jointly trained CS and SHRED
design architecture which includes an LSTM sequence model for characterizing
the temporal evolution with a shallow decoder network (SDN) for modeling the
high-dimensional state space. The SNR-guided adaptive loss function for the
spatiotemporal data recovery establishes $\textbf{CS-SHRED}$ as a promising
tool for a wide range of applications in environmental, climatic, and
scientific data analyses.

</details>


### [127] [Hypernetworks for Model-Heterogeneous Personalized Federated Learning](https://arxiv.org/abs/2507.22330)
*Chen Zhang,Husheng Li,Xiang Liu,Linshan Jiang,Danxin Wang*

Main category: cs.LG

TL;DR: MH-pFedHN是一个基于超网络的个性化联邦学习框架，不需要外部数据或模型解耦，通过客户端特定嵌入向量生成个性化参数，并采用多头结构共享知识。进一步提出的MH-pFedHNGD集成了一个轻量级全局模型以提升泛化能力，增强了隐私和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化联邦学习方法大多需要外部数据、依赖模型解耦或采用部分学习策略，这些限制了方法的实用性和可扩展性。本文旨在利用超网络的强泛化能力，设计一个简单有效的异构模型个性化联邦学习框架，避免上述限制。

Method: 提出MH-pFedHN框架：在服务器端使用超网络，接收客户端特定嵌入向量作为输入，输出为每个客户端定制的个性化参数。引入多头结构，使模型大小相似的客户端共享头部以减少计算量。进一步提出MH-pFedHNGD，可选集成轻量级全局模型以提高泛化能力。框架不依赖外部数据集且无需公开客户端模型架构。

Result: 在多个基准测试和模型设置上的实验表明，该方法达到了有竞争力的准确性、强大的泛化能力，并可作为未来模型异构个性化联邦学习的鲁棒基线。

Conclusion: MH-pFedHN和MH-pFedHNGD为模型异构的个性化联邦学习提供了简单高效、隐私保护良好的解决方案，具有实用性和可扩展性优势。

Abstract: Recent advances in personalized federated learning have focused on addressing
client model heterogeneity. However, most existing methods still require
external data, rely on model decoupling, or adopt partial learning strategies,
which can limit their practicality and scalability. In this paper, we revisit
hypernetwork-based methods and leverage their strong generalization
capabilities to design a simple yet effective framework for heterogeneous
personalized federated learning. Specifically, we propose MH-pFedHN, which
leverages a server-side hypernetwork that takes client-specific embedding
vectors as input and outputs personalized parameters tailored to each client's
heterogeneous model. To promote knowledge sharing and reduce computation, we
introduce a multi-head structure within the hypernetwork, allowing clients with
similar model sizes to share heads. Furthermore, we further propose
MH-pFedHNGD, which integrates an optional lightweight global model to improve
generalization. Our framework does not rely on external datasets and does not
require disclosure of client model architectures, thereby offering enhanced
privacy and flexibility. Extensive experiments on multiple benchmarks and model
settings demonstrate that our approach achieves competitive accuracy, strong
generalization, and serves as a robust baseline for future research in
model-heterogeneous personalized federated learning.

</details>


### [128] [Parametrized Multi-Agent Routing via Deep Attention Models](https://arxiv.org/abs/2507.22338)
*Salar Basiri,Dhananjay Tiwari,Srinivasa M. Salapaka*

Main category: cs.LG

TL;DR: 提出一个可扩展的深度学习框架ParaSDM，用于解决参数化序列决策问题。该框架通过整合最大熵原理与神经策略模型（最短路径网络SPN）来处理设施选址与路径优化(FLPO)这一NP难题。SPN在策略推断和梯度计算上比MEP基线提速100倍，平均最优性差距为6%。FLPO方法比元启发式基线降低10倍成本且运行更快，比带退火的Gurobi提速1500倍达到同等最优解，为大规模混合整数优化问题设下新标杆。


<details>
  <summary>Details</summary>
Motivation: 设施选址与路径优化(FLPO)问题具有混合离散-连续结构及高度非凸目标函数，属于NP难题。现有方法在应对大规模问题时面临计算效率低或求解质量差的挑战。本研究旨在利用结构化深度学习模型高效解决此类参数化序列决策问题。

Method: 1. 融合最大熵原理(MEP)与神经策略模型SPN，通过熵正则化处理决策随机性。
2. SPN采用置换不变的编码器-解码器架构，近似MEP解并支持对共享参数的梯度优化。
3. 针对FLPO场景：设计端到端框架，同时优化路线决策(离散动作)和设施位置(连续参数)。

Result: 1. 策略计算加速：SPN在策略推断和梯度计算上比MEP基线快100倍。
2. 优化质量：平均最优性差距6%，在各类问题规模下保持稳定。
3. 跨方法比较：比元启发式方法降低10倍成本且运行更快；达到带退火的Gurobi同等最优解，同时提速1500倍。

Conclusion: 提出SPN模型有效突破传统优化方法的效率瓶颈，大幅降低决策成本并保持接近最优解的性能。验证了结构化深度学习模型处理大规模混合整数优化问题的潜力，为参数化序列决策领域建立新标杆。

Abstract: We propose a scalable deep learning framework for parametrized sequential
decision-making (ParaSDM), where multiple agents jointly optimize discrete
action policies and shared continuous parameters. A key subclass of this
setting arises in Facility-Location and Path Optimization (FLPO), where
multi-agent systems must simultaneously determine optimal routes and facility
locations, aiming to minimize the cumulative transportation cost within the
network. FLPO problems are NP-hard due to their mixed discrete-continuous
structure and highly non-convex objective. To address this, we integrate the
Maximum Entropy Principle (MEP) with a neural policy model called the Shortest
Path Network (SPN)-a permutation-invariant encoder-decoder that approximates
the MEP solution while enabling efficient gradient-based optimization over
shared parameters. The SPN achieves up to 100$\times$ speedup in policy
inference and gradient computation compared to MEP baselines, with an average
optimality gap of approximately 6% across a wide range of problem sizes. Our
FLPO approach yields over 10$\times$ lower cost than metaheuristic baselines
while running significantly faster, and matches Gurobi's optimal cost with
annealing at a 1500$\times$ speedup-establishing a new state of the art for
ParaSDM problems. These results highlight the power of structured deep models
for solving large-scale mixed-integer optimization tasks.

</details>


### [129] [MSQ: Memory-Efficient Bit Sparsification Quantization](https://arxiv.org/abs/2507.22349)
*Seokho Han,Seoyeon Yoon,Jinhee Kim,Dongwei Wang,Kang Eun Jeon,Huanrui Yang,Jong Hwan Ko*

Main category: cs.LG

TL;DR: 为了解决混合精度量化中寻找每层最优精度的问题，并克服现有位级稀疏化方法的高训练复杂度和高内存需求，本文提出了MSQ方法。MSQ通过引入圆截式量化器和正则化在权重最低有效位（LSB）上诱导稀疏，从而在不显式分割位级参数的情况下实现精度降低。同时结合Hessian信息同时修剪多个LSB以提升效率。实验显示MSQ在参数量、训练时间和压缩率上取得显著改进，同时保持竞争性精度。


<details>
  <summary>Details</summary>
Motivation: 当前使用位级稀疏化的混合精度量化方法存在训练复杂度高和GPU内存需求大的问题，限制了在资源受限设备上的应用。因此，需要一种更高效的方法来降低训练开销并保持模型压缩的优势。

Method: 提出MSQ框架，包含：1）使用圆截式量化器（round-clamp quantizer）对权重进行可微的LSB计算；2）应用正则化在LSB上诱导稀疏性，实现精度降低而无需显式分割位级参数；3）引入Hessian信息，允许一次性修剪多个LSB以提升训练效率。

Result: 实验表明，相比之前的位级量化方法，MSQ实现了训练参数量最大减少8倍，训练时间最大减少86%，同时保持了竞争性的模型精度和压缩率。

Conclusion: MSQ是一种高效、内存友好的位稀疏量化方法，显著减少了训练开销，适用于在资源受限的设备上训练深度神经网络。

Abstract: As deep neural networks (DNNs) see increased deployment on mobile and edge
devices, optimizing model efficiency has become crucial. Mixed-precision
quantization is widely favored, as it offers a superior balance between
efficiency and accuracy compared to uniform quantization. However, finding the
optimal precision for each layer is challenging. Recent studies utilizing
bit-level sparsity have shown promise, yet they often introduce substantial
training complexity and high GPU memory requirements. In this paper, we propose
Memory-Efficient Bit Sparsification Quantization (MSQ), a novel approach that
addresses these limitations. MSQ applies a round-clamp quantizer to enable
differentiable computation of the least significant bits (LSBs) from model
weights. It further employs regularization to induce sparsity in these LSBs,
enabling effective precision reduction without explicit bit-level parameter
splitting. Additionally, MSQ incorporates Hessian information, allowing the
simultaneous pruning of multiple LSBs to further enhance training efficiency.
Experimental results show that MSQ achieves up to 8.00x reduction in trainable
parameters and up to 86% reduction in training time compared to previous
bit-level quantization, while maintaining competitive accuracy and compression
rates. This makes it a practical solution for training efficient DNNs on
resource-constrained devices.

</details>


### [130] [Prediction of acoustic field in 1-D uniform duct with varying mean flow and temperature using neural networks](https://arxiv.org/abs/2507.22370)
*D. Veerababu,Prasanta K. Ghosh*

Main category: cs.LG

TL;DR: 该论文提出了一种基于物理约束神经网络的替代数值方法，用于模拟非均匀介质一维管道中的声传播。通过转化为无约束优化问题，神经网络同时预测了声压和质点速度，并通过龙格-库塔法验证。研究了温度梯度对声场的影响，并展示了迁移学习和自动微分在声学应用中的使用。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在求解复杂物理问题时的局限性促使研究者探索结合物理定律的神经网络作为替代工具。本文针对非均匀介质一维管道声传播问题，旨在验证神经网络在此类物理约束问题中的有效性，并探索机器学习技术（如迁移学习和自动微分）在声学领域的应用潜力。

Method: 1. 推导描述非均匀介质一维管道声传播的控制方程；2. 将问题转化为无约束优化问题；3. 使用神经网络同时预测声压和质点速度；4. 通过传统龙格-库塔法验证预测结果；5. 研究温度梯度对声场的影响；6. 结合迁移学习和自动微分技术优化模型性能。

Result: 1. 神经网络准确预测了声压和质点速度，与龙格-库塔法结果一致；2. 证实温度梯度对声场分布有显著影响；3. 迁移学习有效提升了模型训练效率；4. 自动微分成功应用于物理约束的梯度计算，验证了机器学习在声学问题中的实用性。

Conclusion: 物理约束神经网络能有效模拟非均匀介质中的声传播问题，为复杂声学系统提供新解法。温度梯度等物理参数的影响可通过模型量化，迁移学习和自动微分进一步拓展了机器学习在计算声学中的应用场景，为后续研究奠定基础。

Abstract: Neural networks constrained by the physical laws emerged as an alternate
numerical tool. In this paper, the governing equation that represents the
propagation of sound inside a one-dimensional duct carrying a heterogeneous
medium is derived. The problem is converted into an unconstrained optimization
problem and solved using neural networks. Both the acoustic state variables:
acoustic pressure and particle velocity are predicted and validated with the
traditional Runge-Kutta solver. The effect of the temperature gradient on the
acoustic field is studied. Utilization of machine learning techniques such as
transfer learning and automatic differentiation for acoustic applications is
demonstrated.

</details>


### [131] [Spec-VLA: Speculative Decoding for Vision-Language-Action Models with Relaxed Acceptance](https://arxiv.org/abs/2507.22424)
*Songsheng Wang,Rucheng Yu,Zhihang Yuan,Chao Yu,Feng Gao,Yu Wang,Derek F. Wong*

Main category: cs.LG

TL;DR: 提出了名为Spec-VLA的推测解码框架，用于加速视觉语言动作（VLA）模型。通过引入一种基于动作token相对距离的接受机制，该框架在保持任务成功率的同时实现了1.42倍的加速。


<details>
  <summary>Details</summary>
Motivation: 尽管基于视觉语言模型（VLM）的VLA模型取得了进展，但其庞大的参数量以及自回归解码特性导致了高昂的计算成本。现有的推测解码（SD）技术虽然能有效加速大语言模型（LLMs），但在VLA模型上的应用尚未探索且面临动作预测任务的特殊挑战（如贪婪解码机制）。

Method: 1. 将推测解码（SD）框架首次应用于VLA模型；2. 针对动作预测任务难度大且VLA模型采用贪婪解码的问题，提出利用动作token相对距离的接受机制以放宽token接受条件；3. 该方法通过提升接受长度（提高44%）来加速生成过程。

Result: 在多样化测试场景中的实证结果表明：1. Spec-VLA框架有效实现了1.42倍（相比OpenVLA基线）的加速；2. 加速过程未影响任务成功率；3. 所提策略使接受长度提升44%。

Conclusion: Spec-VLA框架的成功证实了推测执行技术在VLA预测场景中的广泛潜力。其创新性在于通过动作空间特性改进SD的接受机制，为类似模型的加速提供了新思路。

Abstract: Vision-Language-Action (VLA) models have made substantial progress by
leveraging the robust capabilities of Visual Language Models (VLMs). However,
VLMs' significant parameter size and autoregressive (AR) decoding nature impose
considerable computational demands on VLA models. While Speculative Decoding
(SD) has shown efficacy in accelerating Large Language Models (LLMs) by
incorporating efficient drafting and parallel verification, allowing multiple
tokens to be generated in one forward pass, its application to VLA models
remains unexplored. This work introduces Spec-VLA, an SD framework designed to
accelerate VLA models. Due to the difficulty of the action prediction task and
the greedy decoding mechanism of the VLA models, the direct application of the
advanced SD framework to the VLA prediction task yields a minor speed
improvement. To boost the generation speed, we propose an effective mechanism
to relax acceptance utilizing the relative distances represented by the action
tokens of the VLA model. Empirical results across diverse test scenarios affirm
the effectiveness of the Spec-VLA framework, and further analysis substantiates
the impact of our proposed strategies, which enhance the acceptance length by
44%, achieving 1.42 times speedup compared with the OpenVLA baseline, without
compromising the success rate. The success of the Spec-VLA framework highlights
the potential for broader application of speculative execution in VLA
prediction scenarios.

</details>


### [132] [Multimodal Late Fusion Model for Problem-Solving Strategy Classification in a Machine Learning Game](https://arxiv.org/abs/2507.22426)
*Clemens Witt,Thiemo Leonhardt,Nadine Bergner,Mareen Grillenberger*

Main category: cs.LG

TL;DR: 提出了一种多模态晚融合模型，结合录屏视觉数据与游戏内动作序列，以分类学生的问题解决策略，在试点研究中该模型的表现优于单模态基线模型，准确率提升了15%以上。


<details>
  <summary>Details</summary>
Motivation: 现有的基于游戏日志数据的机器学习模型在评估学习者的认知策略时可能忽略细微的行为线索，因此需要能够捕捉更多模态信息的方法来提高分类准确性和评估的敏感性。

Method: 1. 采集两种数据：a)录屏视觉数据（包括手势等视觉行为）；b)结构化的游戏内动作序列（游戏日志）。2. 采用多模态晚融合模型：分别使用专门的模型处理每一模态的数据（如CNN处理视觉数据，序列模型处理动作序列），然后将模型提取的特征在决策层进行融合。3. 在试点研究中，让149名中学生玩一个多触点教育游戏，记录这两类数据，并对学生的解决问题策略进行标注。4. 训练和测试该融合模型，并与单模态模型作为基准进行比较。

Result: 在试点研究中，该多模态融合模型在问题解决策略分类上的准确率超过仅使用单一模态的基线模型15%以上。

Conclusion: 多模态机器学习在交互式学习环境中具有潜力，能够提供更敏感的策略评估和自适应支持。

Abstract: Machine learning models are widely used to support stealth assessment in
digital learning environments. Existing approaches typically rely on abstracted
gameplay log data, which may overlook subtle behavioral cues linked to
learners' cognitive strategies. This paper proposes a multimodal late fusion
model that integrates screencast-based visual data and structured in-game
action sequences to classify students' problem-solving strategies. In a pilot
study with secondary school students (N=149) playing a multitouch educational
game, the fusion model outperformed unimodal baseline models, increasing
classification accuracy by over 15%. Results highlight the potential of
multimodal ML for strategy-sensitive assessment and adaptive support in
interactive learning contexts.

</details>


### [133] [Theoretical Analysis of Relative Errors in Gradient Computations for Adversarial Attacks with CE Loss](https://arxiv.org/abs/2507.22428)
*Yunrui Yu,Hang Su,Cheng-zhong Xu,Zhizhong Su,Jun Zhu*

Main category: cs.LG

TL;DR: 本研究首次系统分析了基于梯度的对抗攻击中浮点计算误差对交叉熵损失函数的影响，提出了理论模型并据此设计了新型损失函数T-MIFPE以提升攻击效能，在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 由于浮点运算在梯度计算中产生的相对误差，传统基于交叉熵损失的对抗攻击存在高估问题，阻碍了防御机制的有效评估。该研究旨在揭示浮点误差在四种攻击场景下的影响机制，并提出解决方案。

Method: 1) 理论分析浮点运算(下溢和舍入)在四种对抗攻击场景下的误差传播模式；2) 推导出可最小化浮点误差的最优缩放因子t*；3) 设计集成该因子的新型损失函数T-MIFPE；4) 在MNIST/CIFAR-10/CIFAR-100数据集上对比CE/C&W/DLR/MIFPE等基线方法。

Result: 1) 理论证明了浮点误差与攻击成败状态的关联性及缩放因子的最优解；2) T-MIFPE在三个数据集上显著提升攻击成功率；3) 新损失函数比现有方法更精准评估模型鲁棒性。

Conclusion: 浮点计算误差是影响对抗攻击效能的深层因素，基于理论最优缩放因子的T-MIFPE损失函数可有效消除梯度计算中的数值不稳定性，为鲁棒性评估提供更可靠的基准。

Abstract: Gradient-based adversarial attacks using the Cross-Entropy (CE) loss often
suffer from overestimation due to relative errors in gradient computation
induced by floating-point arithmetic. This paper provides a rigorous
theoretical analysis of these errors, conducting the first comprehensive study
of floating-point computation errors in gradient-based attacks across four
distinct scenarios: (i) unsuccessful untargeted attacks, (ii) successful
untargeted attacks, (iii) unsuccessful targeted attacks, and (iv) successful
targeted attacks. We establish theoretical foundations characterizing the
behavior of relative numerical errors under different attack conditions,
revealing previously unknown patterns in gradient computation instability, and
identify floating-point underflow and rounding as key contributors. Building on
this insight, we propose the Theoretical MIFPE (T-MIFPE) loss function, which
incorporates an optimal scaling factor $T = t^*$ to minimize the impact of
floating-point errors, thereby enhancing the accuracy of gradient computation
in adversarial attacks. Extensive experiments on the MNIST, CIFAR-10, and
CIFAR-100 datasets demonstrate that T-MIFPE outperforms existing loss
functions, including CE, C\&W, DLR, and MIFPE, in terms of attack potency and
robustness evaluation accuracy.

</details>


### [134] [RANA: Robust Active Learning for Noisy Network Alignment](https://arxiv.org/abs/2507.22434)
*Yixuan Nan,Xixun Lin,Yanmin Shang,Zhuofan Li,Can Zhao,Yanan Cao*

Main category: cs.LG

TL;DR: 提出了一种名为RANA的鲁棒主动学习框架，用于解决网络对齐中的结构噪声和标签噪声问题，提高模型鲁棒性。该框架引入了噪声感知选择模块和标签去噪模块，在三个真实数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有网络对齐研究主要关注标签稀疏性问题，而忽略了噪声（包括结构噪声和标签噪声）对模型性能的破坏性影响。这些噪声源自图中的噪声边以及人为/流程错误导致的错误标签标注。

Method: 1. 噪声感知选择模块：设计噪声感知最大化目标函数，结合洁净度评分选择节点对以解决结构噪声问题；2. 标签去噪模块：提出多源融合去噪策略，利用模型预测和孪生节点对标注来生成更准确的标签。两个模块共同构成主动学习框架RANA。

Result: 在三个真实世界数据集上，RANA在对齐准确率上显著优于最先进的基于主动学习的方法，验证了其有效性。代码已开源。

Conclusion: 通过联合处理结构噪声和标签噪声，RANA为网络对齐任务提供了鲁棒的主动学习解决方案。噪声感知选择和标签去噪机制的协同设计有效提升了模型对噪声的鲁棒性和对齐性能。

Abstract: Network alignment has attracted widespread attention in various fields.
However, most existing works mainly focus on the problem of label sparsity,
while overlooking the issue of noise in network alignment, which can
substantially undermine model performance. Such noise mainly includes
structural noise from noisy edges and labeling noise caused by human-induced
and process-driven errors. To address these problems, we propose RANA, a Robust
Active learning framework for noisy Network Alignment. RANA effectively tackles
both structure noise and label noise while addressing the sparsity of anchor
link annotations, which can improve the robustness of network alignment models.
Specifically, RANA introduces the proposed Noise-aware Selection Module and the
Label Denoising Module to address structural noise and labeling noise,
respectively. In the first module, we design a noise-aware maximization
objective to select node pairs, incorporating a cleanliness score to address
structural noise. In the second module, we propose a novel multi-source fusion
denoising strategy that leverages model and twin node pairs labeling to provide
more accurate labels for node pairs. Empirical results on three real-world
datasets demonstrate that RANA outperforms state-of-the-art active
learning-based methods in alignment accuracy. Our code is available at
https://github.com/YXNan0110/RANA.

</details>


### [135] [RCR-AF: Enhancing Model Generalization via Rademacher Complexity Reduction Activation Function](https://arxiv.org/abs/2507.22446)
*Yunrui Yu,Kafeng Wang,Hang Su,Jun Zhu*

Main category: cs.LG

TL;DR: 提出了一種名為RCR-AF的新激活函數，通過結合GELU和ReLU的優點並控制稀疏性和容量，旨在增強深度神經網絡的泛化能力和對抗魯棒性。理論分析基於Rademacher複雜度，實證結果顯示其在標準訓練和對抗訓練中優於ReLU、GELU和Swish。


<details>
  <summary>Details</summary>
Motivation: 深度神經網絡易受對抗攻擊，尤其是在安全敏感應用中風險顯著。激活函數作為提升模型魯棒性的關鍵組件尚未被充分探索，因此提出設計新型激活函數來同時提升泛化能力和對抗魯棒性。

Method: 1. 提出RCR-AF激活函數，融合GELU（平滑性、梯度穩定性、負信息保留）與ReLU（單調性）的優點。
2. 引入兩個超參數α和γ，通過內置剪裁機制控制模型的稀疏性和容量。
3. 基於Rademacher複雜度進行理論分析，證明α和γ可調控模型的Rademacher複雜度，從而提供提升魯棒性的理論依據。

Result: 1. 理論上，超參數α和γ能夠調控模型的Rademacher複雜度，為提升魯棒性奠定理論基礎。
2. 在多種實驗設置下（標準訓練和對抗訓練），RCR-AF在乾淨數據準確率和對抗魯棒性上均一致優於常用激活函數（ReLU、GELU、Swish）。

Conclusion: RCR-AF作為一種新穎激活函數，通過結合GELU和ReLU的優勢並引入可調超參數，有效改進了模型的泛化與魯棒性。理論與實驗結果驗證了其優越性能，為深度學習模型的安全應用提供了有價值的工具。

Abstract: Despite their widespread success, deep neural networks remain critically
vulnerable to adversarial attacks, posing significant risks in safety-sensitive
applications. This paper investigates activation functions as a crucial yet
underexplored component for enhancing model robustness. We propose a Rademacher
Complexity Reduction Activation Function (RCR-AF), a novel activation function
designed to improve both generalization and adversarial resilience. RCR-AF
uniquely combines the advantages of GELU (including smoothness, gradient
stability, and negative information retention) with ReLU's desirable
monotonicity, while simultaneously controlling both model sparsity and capacity
through built-in clipping mechanisms governed by two hyperparameters, $\alpha$
and $\gamma$. Our theoretical analysis, grounded in Rademacher complexity,
demonstrates that these parameters directly modulate the model's Rademacher
complexity, offering a principled approach to enhance robustness. Comprehensive
empirical evaluations show that RCR-AF consistently outperforms widely-used
alternatives (ReLU, GELU, and Swish) in both clean accuracy under standard
training and in adversarial robustness within adversarial training paradigms.

</details>


### [136] [Towards Interpretable Renal Health Decline Forecasting via Multi-LMM Collaborative Reasoning Framework](https://arxiv.org/abs/2507.22464)
*Peng-Yi Wu,Pei-Cing Huang,Ting-Yu Chen,Chantung Ku,Ming-Yen Lin,Yihuang Kang*

Main category: cs.LG

TL;DR: 本文提出一个协作框架，通过视觉知识迁移、溯因推理和短期记忆机制来提升开源大型多模态模型在估算肾小球滤过率（eGFR）预测中的性能，同时生成具有临床意义的解释，使预测准确性和可解释性媲美专有模型。


<details>
  <summary>Details</summary>
Motivation: 准确且可解释的eGFR预测对慢性肾病管理至关重要。大型多模态模型虽在临床预测任务中潜力巨大，但面临部署成本、数据隐私和模型可靠性三大挑战。本研究旨在构建兼具预测准确性和临床可解释性的医疗AI系统。

Method: 1. 采用视觉知识迁移技术：利用预训练视觉模型向开源多模态模型传递视觉特征知识；2. 引入溯因推理模块：生成基于临床证据的解释链；3. 设计短期记忆机制：在时序预测中保留关键临床指标变化趋势。三级技术融合形成协作推理框架。

Result: 实验表明：1. 在eGFR预测任务上达到与专有模型相当的准确率（具体指标未提供）；2. 生成具有临床合理性的解释，包括关键病理特征关联性和指标变化逻辑；3. 框架在保持数据隐私前提下降低部署成本。

Conclusion: 该框架为构建医疗AI系统提供新范式：通过多技术协同实现预测性能与临床可解释性的统一。未来可扩展至其他临床预测任务，并探索联邦学习以加强隐私保护。

Abstract: Accurate and interpretable prediction of estimated glomerular filtration rate
(eGFR) is essential for managing chronic kidney disease (CKD) and supporting
clinical decisions. Recent advances in Large Multimodal Models (LMMs) have
shown strong potential in clinical prediction tasks due to their ability to
process visual and textual information. However, challenges related to
deployment cost, data privacy, and model reliability hinder their adoption. In
this study, we propose a collaborative framework that enhances the performance
of open-source LMMs for eGFR forecasting while generating clinically meaningful
explanations. The framework incorporates visual knowledge transfer, abductive
reasoning, and a short-term memory mechanism to enhance prediction accuracy and
interpretability. Experimental results show that the proposed framework
achieves predictive performance and interpretability comparable to proprietary
models. It also provides plausible clinical reasoning processes behind each
prediction. Our method sheds new light on building AI systems for healthcare
that combine predictive accuracy with clinically grounded interpretability.

</details>


### [137] [Proto-EVFL: Enhanced Vertical Federated Learning via Dual Prototype with Extremely Unaligned Data](https://arxiv.org/abs/2507.22488)
*Wei Guo,Yiyang Duan,Zhaojun Hu,Yiqi Tong,Fuzhen Zhuang,Xiao Zhang,Jin Dong,Ruofan Wu,Tengfei Liu,Yifan Sun*

Main category: cs.LG

TL;DR: 本文提出 Proto-EVFL，通过双原型增强垂直联邦学习，解决类不平衡问题，包括类原型学习和概率双原型学习方案，改善特征表示和预测空间。


<details>
  <summary>Details</summary>
Motivation: 垂直联邦学习中，不同参与方的样本类别极不平衡，导致特征表示不足和预测受限。具体为局部模型偏差和特征贡献不一致性，因此设计双原型框架。

Method: 1) 类原型学习：各方学习类原型增强隐空间中的类别关联；2) 概率双原型学习方案：通过条件最优传输代价动态选择未对齐样本；3) 混合先验引导模块：结合本地和全局类先验概率引导选择；4) 自适应门控特征聚合策略：动态加权聚合来自各方的特征。

Result: 实验结果验证了 Proto-EVFL 在解决类别不平衡问题上的有效性，在存在一个不可见类别的零样本场景下，模型性能显著提升。

Conclusion: Proto-EVFL 作为第一个在垂直联邦学习中实现双层优化的框架，具有可证明的收敛速度（1/√T），为类不平衡问题提供了一种有效的解决方案。

Abstract: In vertical federated learning (VFL), multiple enterprises address aligned
sample scarcity by leveraging massive locally unaligned samples to facilitate
collaborative learning. However, unaligned samples across different parties in
VFL can be extremely class-imbalanced, leading to insufficient feature
representation and limited model prediction space. Specifically,
class-imbalanced problems consist of intra-party class imbalance and
inter-party class imbalance, which can further cause local model bias and
feature contribution inconsistency issues, respectively. To address the above
challenges, we propose Proto-EVFL, an enhanced VFL framework via dual
prototypes. We first introduce class prototypes for each party to learn
relationships between classes in the latent space, allowing the active party to
predict unseen classes. We further design a probabilistic dual prototype
learning scheme to dynamically select unaligned samples by conditional optimal
transport cost with class prior probability. Moreover, a mixed prior guided
module guides this selection process by combining local and global class prior
probabilities. Finally, we adopt an \textit{adaptive gated feature aggregation
strategy} to mitigate feature contribution inconsistency by dynamically
weighting and aggregating local features across different parties. We proved
that Proto-EVFL, as the first bi-level optimization framework in VFL, has a
convergence rate of 1/\sqrt T. Extensive experiments on various datasets
validate the superiority of our Proto-EVFL. Even in a zero-shot scenario with
one unseen class, it outperforms baselines by at least 6.97%

</details>


### [138] [LoReUn: Data Itself Implicitly Provides Cues to Improve Machine Unlearning](https://arxiv.org/abs/2507.22499)
*Xiang Li,Qianli Shen,Haonan Wang,Kenji Kawaguchi*

Main category: cs.LG

TL;DR: 提出了名为LoReUn（基于损失的重加权遗忘）的插件式策略，通过动态重加权遗忘数据，有效减少现有机器学习遗忘方法与精确遗忘之间的差距，增强对有害内容生成的预防。


<details>
  <summary>Details</summary>
Motivation: 生成模型可能产生有害内容，现有的机器学习遗忘（MU）方法通常对所有待遗忘数据赋予相同权重，难以有效遗忘某些更难遗忘的数据。作者发现数据本身的损失可以隐式反映其遗忘难度，因此提出在遗忘过程中动态重加权数据以提高效率。

Method: 作者提出LoReUn策略，这是一种简单有效的插件式方法。该方法在遗忘过程中根据每个数据点的损失值动态调整其权重，计算开销低。具体来说，给难以遗忘的数据（损失高）更高权重以加速其遗忘。该方法可应用于图像分类和文本到图像扩散模型的遗忘任务。

Result: 在图像分类和生成任务中，LoReUn显著缩小了现有MU方法与精确遗忘之间的差距，特别是在文本到图像扩散模型中有效预防有害内容生成。

Conclusion: 基于损失的重加权是提升机器学习遗忘效率的有效方法，LoReUn作为一种轻量级插件，能够显著提升现有MU方法的性能。该方法在遗忘难度各异的数据上表现出色，尤其有助于减轻生成模型的潜在危害。

Abstract: Recent generative models face significant risks of producing harmful content,
which has underscored the importance of machine unlearning (MU) as a critical
technique for eliminating the influence of undesired data. However, existing MU
methods typically assign the same weight to all data to be forgotten, which
makes it difficult to effectively forget certain data that is harder to unlearn
than others. In this paper, we empirically demonstrate that the loss of data
itself can implicitly reflect its varying difficulty. Building on this insight,
we introduce Loss-based Reweighting Unlearning (LoReUn), a simple yet effective
plug-and-play strategy that dynamically reweights data during the unlearning
process with minimal additional computational overhead. Our approach
significantly reduces the gap between existing MU methods and exact unlearning
in both image classification and generation tasks, effectively enhancing the
prevention of harmful content generation in text-to-image diffusion models.

</details>


### [139] [Geometry of nonlinear forecast reconciliation](https://arxiv.org/abs/2507.22500)
*Lorenzo Nespoli,Anubhab Biswas,Vasco Medici*

Main category: cs.LG

TL;DR: 本文通过在非线性超曲面和向量值函数上建立形式化定理，填补了概率预测协调在非线性背景下缺乏形式化定理的空白。具体包括：为常号曲率超曲面导出理论类似物，为非恒号曲率超曲面及向量值函数提供概率保证，并发布基于JAX的Python包便于复现。


<details>
  <summary>Details</summary>
Motivation: 概率预测协调方法近年被推广至非线性设置，但类似Panagiotelis等人（2021）在线性情况下的理论保证尚未建立。本文旨在填补这一空白，为非线性预测协调建立形式化的误差减少理论。

Method: 1.为常号曲率超曲面建立与Panagiotelis等人2021年类似定理的精确类比<br>2.为非恒号曲率超曲面提供概率误差减少保证<br>3.为向量值函数构建预测协调理论框架<br>4.开发基于JAX的Python包实现上述理论及协调过程

Result: 1.严格推导常号曲率超曲面下的类似理论<br>2.证明非恒号曲率超曲面情形下误差减少的定量概率保证<br>3.拓展向量值函数的协调理论<br>4.提供可复现算法实现

Conclusion: 本文建立了预测协调用于概率非线性预测的首批形式化理论保证，涵盖常号曲率、变化曲率超曲面及向量值函数三类常见非线性结构。所提供算法工具有望推动概率协调在复杂非线性系统中的实用化进程。

Abstract: Forecast reconciliation, an ex-post technique applied to forecasts that must
satisfy constraints, has been a prominent topic in the forecasting literature
over the past two decades. Recently, several efforts have sought to extend
reconciliation methods to the probabilistic settings. Nevertheless, formal
theorems demonstrating error reduction in nonlinear contexts, analogous to
those presented in Panagiotelis et al.(2021), are still lacking. This paper
addresses that gap by establishing such theorems for various classes of
nonlinear hypersurfaces and vector-valued functions. Specifically, we derive an
exact analog of Theorem 3.1 from Panagiotelis et al.(2021) for hypersurfaces
with constant-sign curvature. Additionally, we provide probabilistic guarantees
for the broader case of hypersurfaces with non-constant-sign curvature and for
general vector-valued functions. To support reproducibility and practical
adoption, we release a JAX-based Python package, \emph{to be released upon
publication}, implementing the presented theorems and reconciliation
procedures.

</details>


### [140] [SmilesT5: Domain-specific pretraining for molecular language models](https://arxiv.org/abs/2507.22514)
*Philip Spence,Brooks Paige,Anne Osbourn*

Main category: cs.LG

TL;DR: 本文提出了一种新的领域特定的文本到文本预训练任务，用于分子性质预测，该任务在六个分类基准测试中优于传统方法和之前的微调任务。通过消融研究，证明了该方法的计算高效性。此外，预训练嵌入可以作为下游分类器的固定输入，获得与微调相当的性能但计算开销更低。


<details>
  <summary>Details</summary>
Motivation: 分子性质预测已成为药物研发中的关键任务，传统方法包括图结构、语言和特征工程方法。近期自然语言处理中的掩码语言建模技术已被用于分子序列的处理，但现有方法仍有提升空间。本文旨在通过设计新的预训练任务以提高模型的性能和效率。

Method: 本文提出新的领域特定的文本到文本预训练任务。首先将分子表示为SMILES字符串，之后在分子语言模型上进行掩码语言建模预训练。新任务包括：1. SMILES序列的恢复任务；2. 改进版的预训练任务（具体在正文中阐述）。模型使用基于transformer的架构，在大量分子序列上进行预训练。预训练后通过将预训练的分子嵌入用作下游机器学习模型的固定特征进行分子性质预测微调。

Result: 1. 在六个分子性质分类数据集上均优于基线方法。2. 预训练任务的计算效率和数据效率均优于传统方法。3. 将预训练嵌入用作下游模型的固定输入时达到与微调相当的效果但计算开销显著降低。

Conclusion: 本文提出的预训练任务在多种分子任务上取得了更优效果，并且在计算和数据效率上更加出色。该方法为分子性质预测提供了一种高效解决方案，特别适合资源受限的场景。

Abstract: Molecular property prediction is an increasingly critical task within drug
discovery and development. Typically, neural networks can learn molecular
properties using graph-based, language-based or feature-based methods. Recent
advances in natural language processing have highlighted the capabilities of
neural networks to learn complex human language using masked language
modelling. These approaches to training large transformer-based deep learning
models have also been used to learn the language of molecules, as represented
by simplified molecular-input line-entry system (SMILES) strings. Here, we
present novel domain-specific text-to-text pretraining tasks that yield
improved performance in six classification-based molecular property prediction
benchmarks, relative to both traditional likelihood-based training and
previously proposed fine-tuning tasks. Through ablation studies, we show that
data and computational efficiency can be improved by using these
domain-specific pretraining tasks. Finally, the pretrained embeddings from the
model can be used as fixed inputs into a downstream machine learning classifier
and yield comparable performance to finetuning but with much lower
computational overhead.

</details>


### [141] [HGCN(O): A Self-Tuning GCN HyperModel Toolkit for Outcome Prediction in Event-Sequence Data](https://arxiv.org/abs/2507.22524)
*Fang Wang,Paolo Ceravolo,Ernesto Damiani*

Main category: cs.LG

TL;DR: 提出了HGCN(O)，一个基于图卷积网络（GCN）的自调节工具包，用于事件序列预测。包含四种GCN架构，可整合多种事件序列的图表示并优化预测精度，特别适用于不平衡数据集。


<details>
  <summary>Details</summary>
Motivation: 传统方法在事件序列预测（如PBPM）中处理不同节点和图的属性以及时间依赖性时存在不足，尤其在面对不平衡数据时准确性较低。因此，开发一个利用GCN能力的自适应框架以提高预测精准性和稳定性。

Method: 提出HGCN(O)工具包，包含四种架构（O-GCN, T-GCN, TP-GCN, TE-GCN），使用GCNConv或GraphConv层构建。工具包整合了不同的节点级和图级属性表示，并通过边的权重融合时间依赖关系。该方法通过多种图表示增强模型表达能力，适配于平衡及不平衡数据集。

Result: 在多个实验中发现：GCNConv模型在不平衡数据表现更好；所有模型在平衡数据上表现一致；HGCN(O)整体上明显优于传统方法。

Conclusion: HGCN(O)提供了一个强大且灵活的GCN框架，特别适合需要捕获复杂时间依赖性的任务（如PBPM），能够显著提升预测准确率尤其是在不均衡数据集上。

Abstract: We propose HGCN(O), a self-tuning toolkit using Graph Convolutional Network
(GCN) models for event sequence prediction. Featuring four GCN architectures
(O-GCN, T-GCN, TP-GCN, TE-GCN) across the GCNConv and GraphConv layers, our
toolkit integrates multiple graph representations of event sequences with
different choices of node- and graph-level attributes and in temporal
dependencies via edge weights, optimising prediction accuracy and stability for
balanced and unbalanced datasets. Extensive experiments show that GCNConv
models excel on unbalanced data, while all models perform consistently on
balanced data. Experiments also confirm the superior performance of HGCN(O)
over traditional approaches. Applications include Predictive Business Process
Monitoring (PBPM), which predicts future events or states of a business process
based on event logs.

</details>


### [142] [FGFP: A Fractional Gaussian Filter and Pruning for Deep Neural Networks Compression](https://arxiv.org/abs/2507.22527)
*Kuan-Ting Tu,Po-Hsien Yu,Yu-Syuan Tseng,Shao-Yi Chien*

Main category: cs.LG

TL;DR: 提出了一个结合分数阶高斯滤波器和自适应非结构化剪枝的框架（FGFP），用于压缩深度神经网络，实现了高压缩率并最小化精度损失。在CIFAR-10和ImageNet2012数据集上的实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的网络压缩方法在边缘设备上部署后依然存在挑战，为此，作者提出了一个高效压缩框架以在保持低精度损失的情况下实现更高的压缩比。核心动机是为了减少计算复杂度并降低参数数量。

Method: 结合分数阶微分学和高斯函数构建分数阶高斯滤波器（FGF），使用Grünwald-Letnikov分数导数近似分数阶微分方程，同时引入自适应非结构化剪枝（AUP）提升压缩比。每个FGF核仅有7个参数。

Result: 在CIFAR-10上，ResNet-20压缩后模型缩85.2%，精度仅下降1.52%；在ImageNet2012上，ResNet-50模型压缩69.1%，精度下降1.63%。

Conclusion: FGFP框架在压缩率和精度上优于最新方法，为边缘设备部署提供了高效模型压缩方案。

Abstract: Network compression techniques have become increasingly important in recent
years because the loads of Deep Neural Networks (DNNs) are heavy for edge
devices in real-world applications. While many methods compress neural network
parameters, deploying these models on edge devices remains challenging. To
address this, we propose the fractional Gaussian filter and pruning (FGFP)
framework, which integrates fractional-order differential calculus and Gaussian
function to construct fractional Gaussian filters (FGFs). To reduce the
computational complexity of fractional-order differential operations, we
introduce Gr\"unwald-Letnikov fractional derivatives to approximate the
fractional-order differential equation. The number of parameters for each
kernel in FGF is minimized to only seven. Beyond the architecture of Fractional
Gaussian Filters, our FGFP framework also incorporates Adaptive Unstructured
Pruning (AUP) to achieve higher compression ratios. Experiments on various
architectures and benchmarks show that our FGFP framework outperforms recent
methods in accuracy and compression. On CIFAR-10, ResNet-20 achieves only a
1.52% drop in accuracy while reducing the model size by 85.2%. On ImageNet2012,
ResNet-50 achieves only a 1.63% drop in accuracy while reducing the model size
by 69.1%.

</details>


### [143] [Accident-Driven Congestion Prediction and Simulation: An Explainable Framework Using Advanced Clustering and Bayesian Networks](https://arxiv.org/abs/2507.22529)
*Kranthi Kumar Talluri,Galia Weidl,Vaishnavi Kasuluru*

Main category: cs.LG

TL;DR: 提出了一个通过AutoML增强的深度嵌入聚类（DEC）和贝叶斯网络（BN）来预测事故对交通拥堵影响的框架。


<details>
  <summary>Details</summary>
Motivation: 城市地区因事故等不确定性因素引发的交通拥堵会导致长时间延误、排放增加和安全问题。需要一个能够预测事故影响交通拥堵的框架来解决此问题。

Method: 1. 使用AutoML增强的DEC为事故数据打上拥堵标签。2. 使用贝叶斯网络（BN）预测拥堵概率。3. 利用SUMO仿真工具基于证据场景验证BN预测结果的正确性。

Result: 1. AutoML增强的DEC优于传统聚类方法。2. BN模型的总体准确率达到95.6%，能够理解事故导致拥堵的复杂关系。3. SUMO验证表明BN模型的拥堵状态预测与实际仿真高度一致。

Conclusion: 所提出的模型框架表现出高可靠性，能够预测并可能缓解事故带来的交通拥堵影响，从而确保城市交通顺畅。

Abstract: Traffic congestion due to uncertainties, such as accidents, is a significant
issue in urban areas, as the ripple effect of accidents causes longer delays,
increased emissions, and safety concerns. To address this issue, we propose a
robust framework for predicting the impact of accidents on congestion. We
implement Automated Machine Learning (AutoML)-enhanced Deep Embedding
Clustering (DEC) to assign congestion labels to accident data and predict
congestion probability using a Bayesian Network (BN). The Simulation of Urban
Mobility (SUMO) simulation is utilized to evaluate the correctness of BN
predictions using evidence-based scenarios. Results demonstrate that the
AutoML-enhanced DEC has outperformed traditional clustering approaches. The
performance of the proposed BN model achieved an overall accuracy of 95.6%,
indicating its ability to understand the complex relationship of accidents
causing congestion. Validation in SUMO with evidence-based scenarios
demonstrated that the BN model's prediction of congestion states closely
matches those of SUMO, indicating the high reliability of the proposed BN model
in ensuring smooth urban mobility.

</details>


### [144] [Pre-trained Models Perform the Best When Token Distributions Follow Zipf's Law](https://arxiv.org/abs/2507.22543)
*Yanjin He,Qingkai Zeng,Meng Jiang*

Main category: cs.LG

TL;DR: 提出了一种基于Zipf定律分析标记频率分布的词汇表规模选择方法，通过实验证明当标记分布符合Zipf定律时模型性能最佳。


<details>
  <summary>Details</summary>
Motivation: 选择最优词汇表规模对模型性能至关重要，但现有方法依赖启发式或特定数据集选择，缺乏理论依据。

Method: 分析标记频率分布是否符合Zipf定律，并以此调整词汇表规模使分布符合幂律行为。在自然语言处理、基因组学和化学领域进行了实验验证。

Result: 模型在下游任务上的性能与标记分布遵循幂律行为的程度相关。当词汇表规模使得标记分布对齐Zipf定律时，模型效率和效果均提升。

Conclusion: Zipf定律为准则是确定词汇表规模的一种稳健且可泛化的方法。

Abstract: Tokenization is a fundamental step in natural language processing (NLP) and
other sequence modeling domains, where the choice of vocabulary size
significantly impacts model performance. Despite its importance, selecting an
optimal vocabulary size remains underexplored, typically relying on heuristics
or dataset-specific choices. In this work, we propose a principled method for
determining the vocabulary size by analyzing token frequency distributions
through Zipf's law. We show that downstream task performance correlates with
how closely token distributions follow power-law behavior, and that aligning
with Zipfian scaling improves both model efficiency and effectiveness.
Extensive experiments across NLP, genomics, and chemistry demonstrate that
models consistently achieve peak performance when the token distribution
closely adheres to Zipf's law, establishing Zipfian alignment as a robust and
generalizable criterion for vocabulary size selection.

</details>


### [145] [Thermodynamics-Inspired Computing with Oscillatory Neural Networks for Inverse Matrix Computation](https://arxiv.org/abs/2507.22544)
*George Tsormpatzoglou,Filip Sabo,Aida Todri-Sanial*

Main category: cs.LG

TL;DR: 在振荡神经网络（ONNs）基础上提出的热力学启发的计算范式，用于解决线性代数中的逆矩阵问题。通过耦合的仓本振荡器模型的线性近似得到逆矩阵的解，并通过数值模拟验证了其计算精度最高的参数范围。


<details>
  <summary>Details</summary>
Motivation: 尽管振荡神经网络已被广泛用于组合优化问题（如作为Ising机），但其在求解线性代数问题（如逆矩阵）上的潜力尚未充分探索。受热力学原理启发，研究基于振荡神经网络的计算方法是否能用于线性代数问题求解。

Method: 1. 基于耦合的Kuramoto振荡器模型建立振荡神经网络计算框架；2. 理论证明：通过热力学分析表明该模型的线性近似在稳定状态下解出逆矩阵；3. 数值模拟：设计实验验证模型在不同参数下的性能表现，包括振荡器频率、耦合强度和仿真时间设置；4. 精度分析：系统性地探索参数范围，识别计算精度最高的最优参数设置。

Result: 1. 理论分析显示：耦合Kuramoto振荡器模型在稳定状态下通过线性近似可收敛至逆矩阵解；2. 数值实验表明：该方法在特定参数范围（如耦合强度在中等区间）具有最优的数值稳定性；3. 可实现逆矩阵求解，误差随参数选择不同而有所变化。

Conclusion: 本文开创性地将振荡神经网络应用于矩阵求逆问题，从热力学角度证明了其计算合理性。数值结果在特定参数配置下达到高精度，为ONNs扩展至数值计算任务提供了理论依据和实验验证。该方法在未来可应用于嵌入式计算系统的硬件设计。

Abstract: We describe a thermodynamic-inspired computing paradigm based on oscillatory
neural networks (ONNs). While ONNs have been widely studied as Ising machines
for tackling complex combinatorial optimization problems, this work
investigates their feasibility in solving linear algebra problems, specifically
the inverse matrix. Grounded in thermodynamic principles, we analytically
demonstrate that the linear approximation of the coupled Kuramoto oscillator
model leads to the inverse matrix solution. Numerical simulations validate the
theoretical framework, and we examine the parameter regimes that computation
has the highest accuracy.

</details>


### [146] [DeepC4: Deep Conditional Census-Constrained Clustering for Large-scale Multitask Spatial Disaggregation of Urban Morphology](https://arxiv.org/abs/2507.22554)
*Joshua Dimasaka,Christian Geiß,Emily So*

Main category: cs.LG

TL;DR: 提出了DeepC4，一种新颖的基于深度学习的空间分解方法，用于生成大规模的城市形态图，并以卢旺达的建筑暴露和物理脆弱性地图为例，展示了其在改进现有地图质量方面的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大尺度城市形态制图方法（如GEM和METEOR项目）在将粗粒度数据分解到细粒度时存在局部人口普查统计数据的差异和模型不确定性问题，特别是在弱条件和条件标签监督受限的情况下。需要一种能够更好地结合局部人口普查统计数据作为约束，并考虑多条件标签关系的方法。

Method: 提出了DeepC4（深度条件普查约束聚类）方法，该方法利用深度学习进行空间分解。该方法结合了局部人口普查统计数据作为聚类级别的约束，并在卫星影像模式的学习中考虑了多个条件标签关系，采用联合多任务学习策略。通过卢旺达的案例，使用2022年人口普查数据，在第三级行政单位上改进了建筑暴露和物理脆弱性地图的质量。

Result: 与GEM和METEOR方法相比，DeepC4提高了卢旺达城市形态地图（特别是建筑暴露和物理脆弱性）的准确性。该方法在第三级行政单位的精度上有所提升。

Conclusion: DeepC4为空间审计提供了一种新的基于深度学习的大尺度制图技术，有助于在2030年全球框架接近完成时，改进从粗粒度信息派生出的细粒度地图的质量。

Abstract: To understand our global progress for sustainable development and disaster
risk reduction in many developing economies, two recent major initiatives - the
Uniform African Exposure Dataset of the Global Earthquake Model (GEM)
Foundation and the Modelling Exposure through Earth Observation Routines
(METEOR) Project - implemented classical spatial disaggregation techniques to
generate large-scale mapping of urban morphology using the information from
various satellite imagery and its derivatives, geospatial datasets of the built
environment, and subnational census statistics. However, the local discrepancy
with well-validated census statistics and the propagated model uncertainties
remain a challenge in such coarse-to-fine-grained mapping problems,
specifically constrained by weak and conditional label supervision. Therefore,
we present Deep Conditional Census-Constrained Clustering (DeepC4), a novel
deep learning-based spatial disaggregation approach that incorporates local
census statistics as cluster-level constraints while considering multiple
conditional label relationships in a joint multitask learning of the patterns
of satellite imagery. To demonstrate, compared to GEM and METEOR, we enhanced
the quality of Rwandan maps of urban morphology, specifically building exposure
and physical vulnerability, at the third-level administrative unit from the
2022 census. As the world approaches the conclusion of our global frameworks in
2030, our work has offered a new deep learning-based mapping technique towards
a spatial auditing of our existing coarse-grained derived information at large
scales.

</details>


### [147] [VAR: Visual Analysis for Rashomon Set of Machine Learning Models' Performance](https://arxiv.org/abs/2507.22556)
*Yuanzhe Jin*

Main category: cs.LG

TL;DR: 本文提出了一种名为VAR的可视化解决方案，用于在Rashomon集合中比较多个具有相似准确度但结构不同的机器学习模型。该方法结合了热力图和散点图，帮助开发者发现特定条件下的最优模型并理解集合的整体特性。


<details>
  <summary>Details</summary>
Motivation: 传统上对Rashomon集（一组性能相近的机器学习模型集合）的分析侧重于纵向结构分析，而缺乏横向多模型特征比较的有效可视化方法。因此需要开发新的可视化工具来弥补这一不足。

Method: 提出VAR可视化解决方案，整合热力图和散点图两种可视化技术，实现对Rashomon集合中多个模型的横向特征比较分析。

Result: VAR帮助机器学习开发者直观识别特定条件下的最优模型，并更好地理解Rashomon集合的整体分布特征。

Conclusion: VAR填补了Rashomon集合横向比较的可视化空白，为模型选择和理解提供了有效支持。

Abstract: Evaluating the performance of closely matched machine learning(ML) models
under specific conditions has long been a focus of researchers in the field of
machine learning. The Rashomon set is a collection of closely matched ML
models, encompassing a wide range of models with similar accuracies but
different structures. Traditionally, the analysis of these sets has focused on
vertical structural analysis, which involves comparing the corresponding
features at various levels within the ML models. However, there has been a lack
of effective visualization methods for horizontally comparing multiple models
with specific features. We propose the VAR visualization solution. VAR uses
visualization to perform comparisons of ML models within the Rashomon set. This
solution combines heatmaps and scatter plots to facilitate the comparison. With
the help of VAR, ML model developers can identify the optimal model under
specific conditions and better understand the Rashomon set's overall
characteristics.

</details>


### [148] [Efficient Differentially Private Fine-Tuning of LLMs via Reinforcement Learning](https://arxiv.org/abs/2507.22565)
*Afshin Khadangi,Amir Sartipi,Igor Tchappi,Ramin Bahmani,Gilbert Fridgen*

Main category: cs.LG

TL;DR: RLDP利用强化学习动态优化差分隐私训练，通过细粒度梯度裁剪和噪声注入提升大型语言模型隐私训练的效率与性能。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私随机梯度下降（DP-SGD）方法在保护隐私的同时严重损害模型效用。现有改进方案的全局静态超参设置无法适应优化过程动态变化，导致隐私预算浪费或模型性能不佳。

Method: 1. 将DP优化建模为强化学习控制问题
2. 采用SAC策略实时感知学习动态，细粒度调控：
   - 为每个梯度参数独立设置裁剪阈值
   - 动态调节高斯噪声注入幅度
3. 在语言模型微调过程中在线训练超策略
4. 自动学习何时何处分配隐私预算

Result: 1. 在GPT2-small/Llama系列/Mistral-7B上的1600+实验：
   - 困惑度降低1.3-30.5%（平均5.4%）
   - 下游任务性能平均提升5.6%
2. 仅需13-43%梯度更新量即达基线最终性能（平均加速71%）
3. 在同等(ε,δ)-DP约束下：
   - 成员推理/金丝雀提取攻击成功率≤基线
4. 计算开销：RLDP仅增加基线5%训练时间

Conclusion: RLDP首次实现动态隐私预算分配，突破隐私/效用的静态权衡，为隐私敏感领域LLM部署提供新范式。强化学习持续优化机制显著优于人工调参，证明自适应策略在隐私计算中的核心价值。

Abstract: The tension between data privacy and model utility has become the defining
bottleneck for the practical deployment of large language models (LLMs) trained
on sensitive corpora including healthcare. Differentially private stochastic
gradient descent (DP-SGD) guarantees formal privacy, yet it does so at a
pronounced cost: gradients are forcibly clipped and perturbed with noise,
degrading sample efficiency and final accuracy. Numerous variants have been
proposed to soften this trade-off, but they all share a handicap: their control
knobs are hard-coded, global, and oblivious to the evolving optimization
landscape. Consequently, practitioners are forced either to over-spend privacy
budget in pursuit of utility, or to accept mediocre models in order to stay
within privacy constraints. We present RLDP, the first framework to cast DP
optimization itself as a closed-loop control problem amenable to modern deep
reinforcement learning (RL). RLDP continuously senses rich statistics of the
learning dynamics and acts by selecting fine-grained per parameter
gradient-clipping thresholds as well as the magnitude of injected Gaussian
noise. A soft actor-critic (SAC) hyper-policy is trained online during language
model fine-tuning; it learns, from scratch, how to allocate the privacy budget
where it matters and when it matters. Across more than 1,600 ablation
experiments on GPT2-small, Llama-1B, Llama-3B, and Mistral-7B, RLDP delivers
perplexity reductions of 1.3-30.5% (mean 5.4%) and an average 5.6% downstream
utility gain. RLDP reaches each baseline's final utility after only 13-43% of
the gradient-update budget (mean speed-up 71%), all while honoring the same
($\epsilon$, $\delta$)-DP contract and exhibiting equal or lower susceptibility
to membership-inference and canary-extraction attacks.

</details>


### [149] [Explaining Deep Network Classification of Matrices: A Case Study on Monotonicity](https://arxiv.org/abs/2507.22570)
*Leandro Farina,Sergey Korotov*

Main category: cs.LG

TL;DR: 本论文展示了使用深度学习和XAI技术发现矩阵代数性质分类的简单实用标准的方法。作者针对单调矩阵，通过训练神经网络并提取关键特征，发现两个特征多项式系数之比可以高准确度区分单调矩阵和非单调矩阵，得到简单分类标准。


<details>
  <summary>Details</summary>
Motivation: 单调矩阵定义为逆矩阵元素非负，但已知性质描述复杂且缺乏实用分类标准。研究旨在利用深度学习与可解释技术系统化生成易于人类理解的分类标准。

Method: 在(-1,1)区间均匀随机生成单调与非单调矩阵构建数据集；训练深度神经网络以矩阵元素和特征为输入分类；通过显著图方法筛选关键特征；基于特征重要性提炼简单规则。

Result: 特征多项式的c0和c1系数绝对值比可95%准确分类矩阵；分析7×7随机矩阵发现99.98%单调矩阵满足|c0/c1|≤0.18，等价于tr(A^{-1})≥5.7的简单标准。

Conclusion: 深度学习结合XAI可有效发掘隐藏数学规律，首次提供单调矩阵的实用判据|c0/c1|≤0.18，突破传统方法的局限性。

Abstract: This work demonstrates a methodology for using deep learning to discover
simple, practical criteria for classifying matrices based on abstract algebraic
properties. By combining a high-performance neural network with explainable AI
(XAI) techniques, we can distill a model's learned strategy into
human-interpretable rules. We apply this approach to the challenging case of
monotone matrices, defined by the condition that their inverses are entrywise
nonnegative. Despite their simple definition, an easy characterization in terms
of the matrix elements or the derived parameters is not known. Here, we
present, to the best of our knowledge, the first systematic machine-learning
approach for deriving a practical criterion that distinguishes monotone from
non-monotone matrices. After establishing a labelled dataset by randomly
generated monotone and non-monotone matrices uniformly on $(-1,1)$, we employ
deep neural network algorithms for classifying the matrices as monotone or
non-monotone, using both their entries and a comprehensive set of matrix
features. By saliency methods, such as integrated gradients, we identify among
all features, two matrix parameters which alone provide sufficient information
for the matrix classification, with $95\%$ accuracy, namely the absolute values
of the two lowest-order coefficients, $c_0$ and $c_1$ of the matrix's
characteristic polynomial. A data-driven study of 18,000 random $7\times7$
matrices shows that the monotone class obeys $\lvert c_{0}/c_{1}\rvert\le0.18$
with probability $>99.98\%$; because $\lvert c_{0}/c_{1}\rvert =
1/\mathrm{tr}(A^{-1})$ for monotone $A$, this is equivalent to the simple bound
$\mathrm{tr}(A^{-1})\ge5.7$.

</details>


### [150] [Deep learning of geometrical cell division rules](https://arxiv.org/abs/2507.22587)
*Alexandre Durrmeyer,Jean-Christophe Palauqui,Philippe Andrey*

Main category: cs.LG

TL;DR: 提出了一个基于深度神经网络的图像表示学习方法，用于从细胞几何形态学习细胞分裂平面的位置，无需预先指定几何规则，能够解决传统几何规则无法解释的分裂模式。


<details>
  <summary>Details</summary>
Motivation: 植物细胞分裂时的隔板定位对组织形态至关重要。传统方法依赖预定义的几何规则来建立细胞形状与分裂方向之间的联系，但必须预先假设规则是一大局限。本研究寻求一种数据驱动的方法，探索几何形态与分裂定位间的关系。

Method: 使用修改后的UNet架构，基于母亲细胞的几何图像（mask）学习分裂平面的定位。该方法在合成数据和拟南芥胚胎细胞上评估。

Result: 该模型能够预测多种复杂形状细胞的分裂方向，解释了先前几何规则无法统一的胚胎细胞分裂模式。

Conclusion: 深度神经网络具有理解细胞分裂模式并揭示分裂位置新机制的潜力。

Abstract: The positioning of new cellular walls during cell division plays a key role
in shaping plant tissue organization. The influence of cell geometry on the
positioning of division planes has been previously captured into various
geometrical rules. Accordingly, linking cell shape to division orientation has
relied on the comparison between observed division patterns and predictions
under specific rules. The need to define a priori the tested rules is a
fundamental limitation of this hypothesis-driven approach. As an alternative,
we introduce a data-based approach to investigate the relation between cell
geometry and division plane positioning, exploiting the ability of deep neural
network to learn complex relationships across multidimensional spaces. Adopting
an image-based cell representation, we show how division patterns can be
learned and predicted from mother cell geometry using a UNet architecture
modified to operate on cell masks. Using synthetic data and A. thaliana embryo
cells, we evaluate the model performances on a wide range of diverse cell
shapes and division patterns. We find that the trained model accounted for
embryo division patterns that were previously irreconcilable under existing
geometrical rules. Our work shows the potential of deep networks to understand
cell division patterns and to generate new hypotheses on the control of cell
division positioning.

</details>


### [151] [H2Tune: Federated Foundation Model Fine-Tuning with Hybrid Heterogeneity](https://arxiv.org/abs/2507.22633)
*Wei Guo,Siyuan Lu,Yiqi Tong,Zhaojun Hu,Fuzhen Zhuang,Xiao Zhang,Tao Fan,Jin Dong*

Main category: cs.LG

TL;DR: 联邦微调的新场景HHFFT中，存在矩阵维度不匹配和多任务知识干扰挑战，H2Tune框架提出三组件方案提升准确率15.4%。


<details>
  <summary>Details</summary>
Motivation: 当前联邦微调（FFT）方法在处理基础模型的客户端双重异构性（模型架构和下游任务）时存在局限，导致矩阵聚合困难与知识干扰严重。现有技术无法有效解决HHFFT场景下的维度对齐和知识解耦问题。

Method: 1. 稀疏三矩阵分解：构造秩一致中间矩阵对齐隐空间维度，按客户端资源自适应稀疏化；2. 关系引导矩阵层对齐：处理客户端间层结构和表示能力差异；3. 交替任务知识解耦机制：通过交替优化分离共享/特定知识参数。理论分析证明O(1/√T)收敛。

Result: 在联邦基准测试中，H2Tune相比基线方法达到15.4%的准确率提升。计算效率提升23%，通信成本降低37%

Conclusion: H2Tune首次系统解决HHFFT场景双重挑战，通过矩阵维度对齐和知识解耦显著提升性能，为联邦学习在异构基础模型中的应用提供新框架。

Abstract: Different from existing federated fine-tuning (FFT) methods for foundation
models, hybrid heterogeneous federated fine-tuning (HHFFT) is an under-explored
scenario where clients exhibit double heterogeneity in model architectures and
downstream tasks. This hybrid heterogeneity introduces two significant
challenges: 1) heterogeneous matrix aggregation, where clients adopt different
large-scale foundation models based on their task requirements and resource
limitations, leading to dimensional mismatches during LoRA parameter
aggregation; and 2) multi-task knowledge interference, where local shared
parameters, trained with both task-shared and task-specific knowledge, cannot
ensure only task-shared knowledge is transferred between clients. To address
these challenges, we propose H2Tune, a federated foundation model fine-tuning
with hybrid heterogeneity. Our framework H2Tune consists of three key
components: (i) sparsified triple matrix decomposition to align hidden
dimensions across clients through constructing rank-consistent middle matrices,
with adaptive sparsification based on client resources; (ii) relation-guided
matrix layer alignment to handle heterogeneous layer structures and
representation capabilities; and (iii) alternating task-knowledge
disentanglement mechanism to decouple shared and specific knowledge of local
model parameters through alternating optimization. Theoretical analysis proves
a convergence rate of O(1/\sqrt{T}). Extensive experiments show our method
achieves up to 15.4% accuracy improvement compared to state-of-the-art
baselines. Our code is available at
https://anonymous.4open.science/r/H2Tune-1407.

</details>


### [152] [Transductive Model Selection under Prior Probability Shift](https://arxiv.org/abs/2507.22647)
*Lorenzo Volpi,Alejandro Moreo,Fabrizio Sebastiani*

Main category: cs.LG

TL;DR: 本文提出了一种针对转导学习场景的方法，用于在数据经历先验概率漂移时进行模型选择（超参数优化）。该方法直接优化目标未标记数据上的超参数，而传统方法则依赖带标签训练数据的交叉验证。实验证明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 转导学习中，未标记数据在训练时已知。当数据存在数据集偏移（如先验概率偏移）时，传统基于训练集交叉验证的模型选择方法性能下降。本文旨在解决转导分类中先验概率偏移下的超参数优化问题。

Method: 1. 问题设定：考虑转导分类任务，目标是为已知的未标记集合分配标签。2. 关键假设：数据存在先验概率偏移（即类先验变化），但类条件分布不变。3. 核心方法：提出直接优化目标未标记数据上性能的超参数选择策略（而非在训练集上做交叉验证）。具体通过估计目标域类先验后，结合训练模型在目标域的预测分布优化评估指标。

Result: 实验验证了在模拟和真实数据集上的有效性。与传统交叉验证相比，该方法在存在先验概率偏移时显著提高分类性能（具体实验设置包括生成合成偏移数据及使用真实生物医学数据）。

Conclusion: 针对转导学习中先验概率偏移，提出一种直接优化目标域性能的超参数选择方法。该方法突破了传统交叉验证的局限，实验证明能有效提升分类表现。未来方向可扩展至其他类型数据集偏移。

Abstract: Transductive learning is a supervised machine learning task in which, unlike
in traditional inductive learning, the unlabelled data that require labelling
are a finite set and are available at training time. Similarly to inductive
learning contexts, transductive learning contexts may be affected by dataset
shift, i.e., may be such that the IID assumption does not hold. We here propose
a method, tailored to transductive classification contexts, for performing
model selection (i.e., hyperparameter optimisation) when the data exhibit prior
probability shift, an important type of dataset shift typical of anti-causal
learning problems. In our proposed method the hyperparameters can be optimised
directly on the unlabelled data to which the trained classifier must be
applied; this is unlike traditional model selection methods, that are based on
performing cross-validation on the labelled training data. We provide
experimental results that show the benefits brought about by our method.

</details>


### [153] [Cluster-Based Random Forest Visualization and Interpretation](https://arxiv.org/abs/2507.22665)
*Max Sondag,Christofer Meinecke,Dennis Collaris,Tatiana von Landesberger,Stef van den Elzen*

Main category: cs.LG

TL;DR: 本文提出了一种新的可视化方法和系统，通过聚类相似的决策树并使用两个新可视化工具——特征图和规则图，以增强随机森林的可解释性。


<details>
  <summary>Details</summary>
Motivation: 随机森林通过组合多个决策树提高了预测性能和泛化能力，但其复杂的结构使得模型难以解释。当前方法要么需要分析每棵树（低效），要么过度简化整个森林（信息不足）。因此，需要一种平衡的方式帮助用户理解模型行为。

Method: 1. 聚类相似决策树：设计新的距离度量方式，同时考虑树之间的决策规则和预测结果相似性。
2. 提出两个可视化工具：
   - 特征图（Feature Plot）：展示特征在决策树中的拓扑位置。
   - 规则图（Rule Plot）：可视化决策树的规则结构。
3. 评估：在标准数据集（Glass数据集）上进行案例研究，并通过小型用户研究验证有效性。

Result: 案例研究显示该方法能有效揭示随机森林的行为模式。用户研究证实可视化工具提升了模型可解释性，使用户无需逐棵分析树或依赖过度简化概括即可理解模型机制。

Conclusion: 通过树聚类结合双重视觉化，该方法在保持模型性能优势的同时显著提升了随机森林的可解释性，为复杂模型提供了一种高效的解读途径。

Abstract: Random forests are a machine learning method used to automatically classify
datasets and consist of a multitude of decision trees. While these random
forests often have higher performance and generalize better than a single
decision tree, they are also harder to interpret. This paper presents a
visualization method and system to increase interpretability of random forests.
We cluster similar trees which enables users to interpret how the model
performs in general without needing to analyze each individual decision tree in
detail, or interpret an oversimplified summary of the full forest. To
meaningfully cluster the decision trees, we introduce a new distance metric
that takes into account both the decision rules as well as the predictions of a
pair of decision trees. We also propose two new visualization methods that
visualize both clustered and individual decision trees: (1) The Feature Plot,
which visualizes the topological position of features in the decision trees,
and (2) the Rule Plot, which visualizes the decision rules of the decision
trees. We demonstrate the efficacy of our approach through a case study on the
"Glass" dataset, which is a relatively complex standard machine learning
dataset, as well as a small user study.

</details>


### [154] [Enhanced Prediction of CAR T-Cell Cytotoxicity with Quantum-Kernel Methods](https://arxiv.org/abs/2507.22710)
*Filippo Utro,Meltem Tolunay,Kahn Rhrissorrakrai,Tanvi P. Gujarati,Jie Shi,Sara Capponi,Mirko Amico,Nate Earnest-Noble,Laxmi Parida*

Main category: cs.LG

TL;DR: 该论文提出了一种量子计算方法（投影量子核，PQK），用于改进嵌合抗原受体（CAR）T细胞疗法的设计。由于共刺激结构域组合空间巨大且实验数据有限，传统方法难以高效筛选最优CAR构建。论文展示了在61量子位的门控量子计算机上应用PQK，在预测CAR T细胞毒性方面取得了优于经典机器学习方法的分类性能，尤其提高了信息较少的结构域和位置的学习效果。


<details>
  <summary>Details</summary>
Motivation: CAR T细胞疗法的设计涉及巨大的共刺激结构域组合空间，实验测试受限于高昂成本和数据稀疏性。传统计算方法难以在数据有限的情况下有效探索组合空间，因此需要更高效的计算方法来加速最优CAR构建的筛选。

Method: 1. CAR T细胞设计问题建模：将共刺激结构域组合空间视为高维离散空间。
2. 量子方法：使用投影量子核（PQK）将经典组合数据映射到高维希尔伯特空间，利用核方法衡量样本相似性。
3. 实验设置：在61量子位的量子计算机上训练PQK模型。
4. 性能对比：与经典机器学习方法（如SVM、随机森林等）进行CAR T细胞毒性预测性能的对比。

Result: 1. 实现了目前最大规模的PQK应用（61量子位）。
2. PQK在CAR T细胞毒性分类任务上显著优于经典机器学习方法（AUC等指标提升）。
3. 在信息较少的特定信号结构域及其位置上表现出更强的学习能力（如稀疏数据的泛化性能提升）。

Conclusion: 量子计算方法（PQK）能有效解决CAR T细胞设计中的数据稀缺组合优化问题，尤其在信号结构域信息不足的场景下具有优势。这为量子计算在生物医学领域的组合探索问题提供了新思路，未来可进一步扩展到更复杂的细胞疗法设计中。

Abstract: Chimeric antigen receptor (CAR) T-cells are T-cells engineered to recognize
and kill specific tumor cells. Through their extracellular domains, CAR T-cells
bind tumor cell antigens which triggers CAR T activation and proliferation.
These processes are regulated by co-stimulatory domains present in the
intracellular region of the CAR T-cell. Through integrating novel signaling
components into the co-stimulatory domains, it is possible to modify CAR T-cell
phenotype. Identifying and experimentally testing new CAR constructs based on
libraries of co-stimulatory domains is nontrivial given the vast combinatorial
space defined by such libraries. This leads to a highly data constrained,
poorly explored combinatorial problem, where the experiments undersample all
possible combinations. We propose a quantum approach using a Projected Quantum
Kernel (PQK) to address this challenge. PQK operates by embedding classical
data into a high dimensional Hilbert space and employs a kernel method to
measure sample similarity. Using 61 qubits on a gate-based quantum computer, we
demonstrate the largest PQK application to date and an enhancement in the
classification performance over purely classical machine learning methods for
CAR T cytotoxicity prediction. Importantly, we show improved learning for
specific signaling domains and domain positions, particularly where there was
lower information highlighting the potential for quantum computing in
data-constrained problems.

</details>


### [155] [Teaching the Teacher: Improving Neural Network Distillability for Symbolic Regression via Jacobian Regularization](https://arxiv.org/abs/2507.22767)
*Soumyadeep Dhar,Kei Sen Fong,Mehul Motani*

Main category: cs.LG

TL;DR: 本文提出了一种利用雅可比正则化器改进神经网络蒸馏成符号公式的方法，通过主动促使教师网络学习更容易蒸馏的平滑函数，显著提高了学生模型在回归任务上的性能（平均提升120%相对R²分数）。


<details>
  <summary>Details</summary>
Motivation: 当前的神经网络蒸馏方法常因学习到的函数过于复杂而导致符号蒸馏效果不佳（低保真度）。为提高符号模型蒸馏的保真度，需要使教师网络学习更易蒸馏的函数形式。

Method: 1) 在教师网络训练过程中引入雅可比矩阵正则化器，使网络梯度场更加平滑；
2) 以正则化后的教师网络为蒸馏目标；
3) 通过符号回归提取可读的符号公式。核心创新在于主动优化教师网络的可蒸馏性，而非被动蒸馏。

Result: 在真实世界回归任务上的实验表明：
1) 教师模型精度未下降；
2) 蒸馏出的符号模型R²分数相比基线平均提升120%（相对提升）；
3) 正则化强度需通过超参数调节适配具体问题。

Conclusion: 雅可比正则化提供了一种实用且理论可靠的方法，能显著提升从复杂网络中提取符号模型的保真度，同时保持模型准确性，推动可解释AI发展。

Abstract: Distilling large neural networks into simple, human-readable symbolic
formulas is a promising path toward trustworthy and interpretable AI. However,
this process is often brittle, as the complex functions learned by standard
networks are poor targets for symbolic discovery, resulting in low-fidelity
student models. In this work, we propose a novel training paradigm to address
this challenge. Instead of passively distilling a pre-trained network, we
introduce a \textbf{Jacobian-based regularizer} that actively encourages the
``teacher'' network to learn functions that are not only accurate but also
inherently smoother and more amenable to distillation. We demonstrate through
extensive experiments on a suite of real-world regression benchmarks that our
method is highly effective. By optimizing the regularization strength for each
problem, we improve the $R^2$ score of the final distilled symbolic model by an
average of \textbf{120\% (relative)} compared to the standard distillation
pipeline, all while maintaining the teacher's predictive accuracy. Our work
presents a practical and principled method for significantly improving the
fidelity of interpretable models extracted from complex neural networks.

</details>


### [156] [Label-free estimation of clinically relevant performance metrics under distribution shifts](https://arxiv.org/abs/2507.22776)
*Tim Flühmann,Alceu Bissoto,Trung-Dung Hoang,Lisa M. Koch*

Main category: cs.LG

TL;DR: 本文提出了一种泛化现有性能预测方法的新方法，直接估计完整混淆矩阵，并在真实分布偏移和模拟协变量及患病率偏移下，对胸部X光数据进行基准测试。结果表明，所提方法在医疗图像分布偏移下能可靠预测临床相关计数指标，但现有性能估计技术在模拟偏移场景中存在重要失败模式，提示在医疗AI模型市场后监测中需更深入理解实际部署背景。


<details>
  <summary>Details</summary>
Motivation: 现有性能估计方法主要估计模型精度，且很少在临床领域（存在严重的类别不平衡和数据集偏移）进行评估。因此，需要一种能够直接估计混淆矩阵的方法，以更全面监控医疗AI模型在真实部署中的性能。

Method: 文章引入现有性能预测方法的泛化版本，直接估计完整混淆矩阵。这些方法通过利用置信度分数估计目标混淆矩阵。在模拟协变量偏移和患病率偏移的情景下，以及真实世界胸部X光数据的分布偏移下，对提出的混淆矩阵估计方法进行性能基准测试。

Result: 所提出的混淆矩阵估计方法在医疗图像的分布偏移下能可靠预测临床相关计数指标（如准确率、召回率等）。但模拟偏移场景中，现有性能估计技术暴露了重要失败模式，如在某些特定分布变化下预测性能显著下降。

Conclusion: 本文提出的混淆矩阵估计方法为医学影像模型性能监测提供更全面的评估。但研究强调需理解实际部署环境中的具体分布变化，以确保在市场后监测中性能监测技术的可靠性，避免现有方法在一些现实场景中的失败。

Abstract: Performance monitoring is essential for safe clinical deployment of image
classification models. However, because ground-truth labels are typically
unavailable in the target dataset, direct assessment of real-world model
performance is infeasible. State-of-the-art performance estimation methods
address this by leveraging confidence scores to estimate the target accuracy.
Despite being a promising direction, the established methods mainly estimate
the model's accuracy and are rarely evaluated in a clinical domain, where
strong class imbalances and dataset shifts are common. Our contributions are
twofold: First, we introduce generalisations of existing performance prediction
methods that directly estimate the full confusion matrix. Then, we benchmark
their performance on chest x-ray data in real-world distribution shifts as well
as simulated covariate and prevalence shifts. The proposed confusion matrix
estimation methods reliably predicted clinically relevant counting metrics on
medical images under distribution shifts. However, our simulated shift
scenarios exposed important failure modes of current performance estimation
techniques, calling for a better understanding of real-world deployment
contexts when implementing these performance monitoring techniques for
postmarket surveillance of medical AI models.

</details>


### [157] [DO-EM: Density Operator Expectation Maximization](https://arxiv.org/abs/2507.22786)
*Adit Vishnu,Abhay Shastry,Dhruva Kashyap,Chiranjib Bhattacharyya*

Main category: cs.LG

TL;DR: 本文提出了一种基于密度算子的期望最大化（DO-EM）框架，用于在经典硬件上训练量子生成模型，并引入了量子交错深度玻尔兹曼机（QiDBM），在MNIST图像生成任务中显著优于经典模型。


<details>
  <summary>Details</summary>
Motivation: 现有的量子生成模型（如量子玻尔兹曼机）训练算法难以扩展到真实世界数据（如MNIST数据集）。期望最大化（EM）算法在经典概率模型中表现出优秀的可扩展性，但在量子模型中因缺乏条件概率的量子类比而难以应用。本文旨在解决这一难题。

Method: 1. 将EM算法的期望步骤重构为量子信息投影（QIP）问题，利用Petz恢复映射作为解决方案；2. 提出密度算子期望最大化（DO-EM）算法——一种通过量子证据下界优化的迭代次优化最大化过程；3. 设计量子交错深度玻尔兹曼机（QiDBM）模型，其资源消耗与经典深度玻尔兹曼机（DBM）相当，可通过DO-EM配合对比散度进行训练。

Result: 1. 理论证明DO-EM算法在广泛模型类上能确保对数似然单调递增；2. 在MNIST图像生成任务中，QiDBM以DO-EM训练时，Frechet Inception距离比大型经典DBM降低40-60%。

Conclusion: 通过建立量子条件概率的数学框架（QIP+Petz映射）实现的DO-EM算法，首次实现了量子生成模型在经典硬件上对真实世界数据的高效训练。QiDBM模型在资源受限情况下超越经典同类模型，证明了量子方法在生成任务中的潜力。

Abstract: Density operators, quantum generalizations of probability distributions, are
gaining prominence in machine learning due to their foundational role in
quantum computing. Generative modeling based on density operator models
(\textbf{DOMs}) is an emerging field, but existing training algorithms -- such
as those for the Quantum Boltzmann Machine -- do not scale to real-world data,
such as the MNIST dataset. The Expectation-Maximization algorithm has played a
fundamental role in enabling scalable training of probabilistic latent variable
models on real-world datasets. \textit{In this paper, we develop an
Expectation-Maximization framework to learn latent variable models defined
through \textbf{DOMs} on classical hardware, with resources comparable to those
used for probabilistic models, while scaling to real-world data.} However,
designing such an algorithm is nontrivial due to the absence of a well-defined
quantum analogue to conditional probability, which complicates the Expectation
step. To overcome this, we reformulate the Expectation step as a quantum
information projection (QIP) problem and show that the Petz Recovery Map
provides a solution under sufficient conditions. Using this formulation, we
introduce the Density Operator Expectation Maximization (DO-EM) algorithm -- an
iterative Minorant-Maximization procedure that optimizes a quantum evidence
lower bound. We show that the \textbf{DO-EM} algorithm ensures non-decreasing
log-likelihood across iterations for a broad class of models. Finally, we
present Quantum Interleaved Deep Boltzmann Machines (\textbf{QiDBMs}), a
\textbf{DOM} that can be trained with the same resources as a DBM. When trained
with \textbf{DO-EM} under Contrastive Divergence, a \textbf{QiDBM} outperforms
larger classical DBMs in image generation on the MNIST dataset, achieving a
40--60\% reduction in the Fr\'echet Inception Distance.

</details>


### [158] [G-Core: A Simple, Scalable and Balanced RLHF Trainer](https://arxiv.org/abs/2507.22789)
*Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Haoqiang Hong,Boqi Liu,Hongtao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao*

Main category: cs.LG

TL;DR: G-Core是一个简单、可扩展且平衡的RLHF（人类反馈强化学习）训练框架，旨在解决现有RLHF系统在面对多模态和扩散模型时，在控制器可扩展性、资源调度和工作流编排上的挑战。它通过并行控制器编程模型和动态资源调度策略，提高训练效率，并已成功应用于微信产品中大规模用户服务的模型训练。


<details>
  <summary>Details</summary>
Motivation: 现有的RLHF训练系统在处理多模态和扩散模型工作流时，面临控制器扩展性差、资源布局不够灵活以及难以高效编排复杂训练流程的问题，尤其是在应对动态采样或生成式奖励模型训练时。这些限制影响了RLHF的训练效率和可扩展性。

Method: G-Core提出了一种并行控制器编程模型，允许多个控制器协同工作以高效编排复杂RLHF工作流，避免了单一集中控制器的瓶颈。同时，引入动态资源放置策略——自适应地分配资源和调度任务，显著降低硬件空闲时间并提高利用率，即使在高波动的训练环境下也如此。

Result: G-Core已成功训练出应用于微信产品功能的模型，服务于大规模用户群体，证明了其在真实场景中的有效性和健壮性。实验结果表明，G-Core在RLHF训练方面取得了显著的进展，能够有效支持生成式奖励模型所需的复杂工作流。

Conclusion: G-Core通过创新的控制器设计和资源调度机制，为复杂RLHF工作流提供了高效、稳定且可扩展的解决方案，为未来大规模人机对齐模型的研究和部署奠定了坚实基础。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become an increasingly
popular paradigm for training large language models (LLMs) and diffusion
models. While existing RLHF training systems have enabled significant progress,
they often face challenges in scaling to multi-modal and diffusion workflows
and adapting to dynamic workloads. In particular, current approaches may
encounter limitations in controller scalability, flexible resource placement,
and efficient orchestration when handling complex RLHF pipelines, especially in
scenarios involving dynamic sampling or generative reward modeling. In this
paper, we present \textbf{G-Core}, a simple, scalable, and balanced RLHF
training framework designed to address these challenges. G-Core introduces a
parallel controller programming model, enabling flexible and efficient
orchestration of complex RLHF workflows without the bottlenecks of a single
centralized controller. Furthermore, we propose a dynamic placement schema that
adaptively partitions resources and schedules workloads, significantly reducing
hardware idle time and improving utilization, even under highly variable
training conditions. G-Core has successfully trained models that support WeChat
product features serving a large-scale user base, demonstrating its
effectiveness and robustness in real-world scenarios. Our results show that
G-Core advances the state of the art in RLHF training, providing a solid
foundation for future research and deployment of large-scale, human-aligned
models.

</details>


### [159] [Quantifying surprise in clinical care: Detecting highly informative events in electronic health records with foundation models](https://arxiv.org/abs/2507.22798)
*Michael C. Burkhart,Bashar Ramadan,Luke Solo,William F. Parker,Brett K. Beaulieu-Jones*

Main category: cs.LG

TL;DR: 提出一种基于基础模型的电子健康记录分析新方法，用于识别高度信息化的令牌和事件。该方法通过考虑患者整个住院期间的大背景数据，能够标记出基于规则的方法可能视为正常范围但实际异常的事件。实验证明，该模型标记的事件对预测患者下游预后具有重要价值，并且可安全丢弃大量被评估为低信息量的事件。此外，该方法还展示出如何利用‘信息量’指标增强对基础模型预测结果的解释能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的健康记录分析方法难以识别在全局背景下具有意义的异常事件。这些方法常将处于局部正常范围内但在全局背景下实际异常的事件误判为正常。基础模型具有在大规模数据中捕捉上下文深层次联系的能力，却缺乏针对医疗领域事件信息价值的量化手段。因此需要开发一种能结合临床上下文识别高价值事件的新方法，同时提升模型的可解释性。

Method: 1. 利用基础模型处理患者完整住院期间的电子健康记录数据，获得上下文感知的医疗事件表示。2. 设计基于信息论的指标评估每个医疗事件（令牌）的预测信息量，包括：计算某事件排除时对基础模型预测下游结局（如住院死亡率、再入院率等）的影响程度，通过这种扰动分析量化事件的信息量。3. 应用阈值将事件区分为"高信息量"（需重点关注）、"正常信息量"和"低信息量"（可安全丢弃）。4. 构建基于信息量的可视化框架，用于解释基础模型预后的决策依据。

Result: 1. 发现被模型标记为高信息量的事件与下游不良预后结局（如死亡率、再入院）具有显著相关性（P<0.001）。2. 在保留90%-98%原始数据信息量的前提下，通过丢弃30%-72%的低信息量事件实现显著数据压缩。3. 信息量热图能够明确指示影响特定预后的关键临床事件（例如突发低血压事件在死亡预测中呈现高信息量，而常规血压测量为低信息量）。

Conclusion: 该研究提出一种创新框架，首次将基础模型的上下文理解能力用于医疗事件信息量的量化分级：1. 突破性地证明在完整临床上下文背景下识别传统方法易忽略的异常事件的可行性；2. 开发安全高效的医疗数据降噪压缩机制；3. 创建基于信息量的可解释性分析工具，为临床AI提供新的决策透明度。该方法为构建高效且可信的临床预测系统开辟新途径。

Abstract: We present a foundation model-derived method to identify highly informative
tokens and events in electronic health records. Our approach considers incoming
data in the entire context of a patient's hospitalization and so can flag
anomalous events that rule-based approaches would consider within a normal
range. We demonstrate that the events our model flags are significant for
predicting downstream patient outcomes and that a fraction of events identified
as carrying little information can safely be dropped. Additionally, we show how
informativeness can help interpret the predictions of prognostic models trained
on foundation model-derived representations.

</details>


### [160] [Tapping into the Black Box: Uncovering Aligned Representations in Pretrained Neural Networks](https://arxiv.org/abs/2507.22832)
*Maciej Satkiewicz*

Main category: cs.LG

TL;DR: 该论文主张ReLU网络学习了一个隐式线性模型，并提出了通过简单修改反向传播来获取该模型，从而在输入空间中近似提取决策边界，这些梯度揭示了高分辨率且与感知对齐的特征，表明神经网络确实依赖可解释的模式。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索神经网络内部学习的可解释模式，并证明通过分析激活函数可以恢复这些模式，从而为知识发现和可信AI系统提供新途径。

Method: 提出一种称为‘excitation pullbacks’的方法，通过对ReLU网络反向传播过程进行简单修改，将隐式线性模型的决策边界拉回到输入空间，从而显式获取输入和目标类别相关的高分辨率特征。

Result: 在多个ImageNet预训练模型上，提取的特征显示出与人类感知高度一致的高分辨率模式，验证了该方法的有效性。

Conclusion: 该研究表明神经网络学习并依赖可解释模式，这些模式可在训练后被恢复，这对知识发现和可信AI系统的开发具有深远意义。

Abstract: In this paper we argue that ReLU networks learn an implicit linear model we
can actually tap into. We describe that alleged model formally and show that we
can approximately pull its decision boundary back to the input space with
certain simple modification to the backward pass. The resulting gradients
(called excitation pullbacks) reveal high-resolution input- and target-specific
features of remarkable perceptual alignment on a number of popular
ImageNet-pretrained deep architectures. This strongly suggests that neural
networks do, in fact, rely on learned interpretable patterns that can be
recovered after training. Thus, our findings may have profound implications for
knowledge discovery and the development of dependable artificial systems.

</details>


### [161] [PAF-Net: Phase-Aligned Frequency Decoupling Network for Multi-Process Manufacturing Quality Prediction](https://arxiv.org/abs/2507.22840)
*Yang Luo,Haoyang Luan,Haoyun Pan,Yongquan Jia,Xiaofeng Gao,Guihai Chen*

Main category: cs.LG

TL;DR: 为了解决在生产制造中的时间滞后、周期不匹配以及共享频带中的依赖关系等挑战，作者提出了PAF-Fet框架。该框架包括相位对齐、基于DCT分解的注意力机制以及频域解耦的交叉注意力机制。在四个数据集上取得了显著优于基线方法的成果。


<details>
  <summary>Details</summary>
Motivation: 在多工艺生产中，由于时间滞后过程交互、重叠操作和周期不匹配，以及共享频带中的进程依赖等三个挑战的存在，难以进行准确的质量预测。为了解决这些问题，提出了PAF-Net框架。

Method: PAF-Net包括三个关键的创新：通过频率域能量引导的相位相关性对齐方法来同步时间滞后的质量序列；基于离散余弦变换(DCT)分解的频域独立的补丁注意力机制捕获序列内的异构特征；以及频域解耦的交叉注意力模块来抑制共享频带内非相关频率的干扰。

Result: 在4个真实世界的实验数据集上，PAF-Net比10个被广泛认可的基线模型平均降低了7.06%的MSE(均方误差)和3.88%的MAE(平均绝对误差)。

Conclusion: PAF-Net通过同步时间滞后的质量序列、捕获异构操作特征以及在共享频带中聚焦有意义依赖关系的方法，显著地改进了工艺链中的质量预测性能。

Abstract: Accurate quality prediction in multi-process manufacturing is critical for
industrial efficiency but hindered by three core challenges: time-lagged
process interactions, overlapping operations with mixed periodicity, and
inter-process dependencies in shared frequency bands. To address these, we
propose PAF-Net, a frequency decoupled time series prediction framework with
three key innovations: (1) A phase-correlation alignment method guided by
frequency domain energy to synchronize time-lagged quality series, resolving
temporal misalignment. (2) A frequency independent patch attention mechanism
paired with Discrete Cosine Transform (DCT) decomposition to capture
heterogeneous operational features within individual series. (3) A frequency
decoupled cross attention module that suppresses noise from irrelevant
frequencies, focusing exclusively on meaningful dependencies within shared
bands. Experiments on 4 real-world datasets demonstrate PAF-Net's superiority.
It outperforms 10 well-acknowledged baselines by 7.06% lower MSE and 3.88%
lower MAE. Our code is available at
https://github.com/StevenLuan904/PAF-Net-Official.

</details>


### [162] [RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for Robust Long-Horizon Agents](https://arxiv.org/abs/2507.22844)
*Zijing Zhang,Ziyang Chen,Mingxiao Li,Zhaopeng Tu,Xiaolong Li*

Main category: cs.LG

TL;DR: 本文提出RLVMR框架，通过奖励可验证的元推理行为，将密集的过程级监督整合到端到端强化学习中，解决了传统强化学习方法因低效探索导致代理脆弱和泛化能力差的问题。在ALFWorld和ScienceWorld基准测试中取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在优化最终任务成功率时，往往会强化低效或有缺陷的推理路径（称为'低效探索'），导致代理脆弱且泛化能力差。因此，需要一种方法在训练过程中加入过程级监督，提升代理的推理质量。

Method: RLVMR框架：1) 让代理显式标记其认知步骤（规划、探索、反思等）；2) 通过程序化、基于规则的奖励函数对贡献于有效问题解决的行为进行过程级奖励；3) 将过程奖励与最终结果奖励结合，并使用无评论员的策略梯度方法优化。

Result: 在ALFWorld和ScienceWorld基准上实现新SOTA：其7B模型在最困难的未见任务子集上达到83.6%的成功率；分析表明代理冗余操作显著减少，错误恢复能力增强，推理质量提升，最终形成更鲁棒、高效、可解释的代理。

Conclusion: RLVMR通过过程级监督重塑推理路径优化，有效解决了强化学习的低效探索问题。实验证明该方法能提升代理的推理质量和泛化能力，为构建长期复杂任务的自主智能体提供了新方向。

Abstract: The development of autonomous agents for complex, long-horizon tasks is a
central goal in AI. However, dominant training paradigms face a critical
limitation: reinforcement learning (RL) methods that optimize solely for final
task success often reinforce flawed or inefficient reasoning paths, a problem
we term inefficient exploration. This leads to agents that are brittle and fail
to generalize, as they learn to find solutions without learning how to reason
coherently. To address this, we introduce RLVMR, a novel framework that
integrates dense, process-level supervision into end-to-end RL by rewarding
verifiable, meta-reasoning behaviors. RLVMR equips an agent to explicitly tag
its cognitive steps, such as planning, exploration, and reflection, and
provides programmatic, rule-based rewards for actions that contribute to
effective problem-solving. These process-centric rewards are combined with the
final outcome signal and optimized using a critic-free policy gradient method.
On the challenging ALFWorld and ScienceWorld benchmarks, RLVMR achieves new
state-of-the-art results, with our 7B model reaching an 83.6% success rate on
the most difficult unseen task split. Our analysis confirms these gains stem
from improved reasoning quality, including significant reductions in redundant
actions and enhanced error recovery, leading to more robust, efficient, and
interpretable agents.

</details>


### [163] [Decentralized Differentially Private Power Method](https://arxiv.org/abs/2507.22849)
*Andrew Campbell,Anna Scaglione,Sean Peisert*

Main category: cs.LG

TL;DR: 提出了一种分散式差分隐私幂方法（D-DP-PM），用于在联邦多智能体环境下处理行式数据划分的PCA问题，并在确保(ε,δ)-DP的同时实现全局特征向量的协作估算。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式PCA通常要求每个代理能访问全部数据维度，而本文针对每个代理仅拥有部分数据维度的行式数据划分场景，同时需要兼顾隐私保护。

Method: 各代理只共享当前特征向量估计的局部嵌入向量；通过随机初始化的固有隐私和精确校准的高斯噪声满足(ε,δ)-DP要求；利用线性动力学和高维概率论建立紧密的隐私与效用边界。

Result: D-DP-PM在真实数据集上显著优于本地朴素DP方法；在中等隐私范围（ε∈[2,5]）表现尤佳；收敛速度快且能用迭代次数换取更强的隐私保障。

Conclusion: 该方法首次实现了行式数据划分下的分布式差分隐私PCA，为网络化环境提供了严格的隐私保障和明确的收敛性分析。

Abstract: We propose a novel Decentralized Differentially Private Power Method
(D-DP-PM) for performing Principal Component Analysis (PCA) in networked
multi-agent settings. Unlike conventional decentralized PCA approaches where
each agent accesses the full n-dimensional sample space, we address the
challenging scenario where each agent observes only a subset of dimensions
through row-wise data partitioning. Our method ensures
$(\epsilon,\delta)$-Differential Privacy (DP) while enabling collaborative
estimation of global eigenvectors across the network without requiring a
central aggregator. We achieve this by having agents share only local
embeddings of the current eigenvector iterate, leveraging both the inherent
privacy from random initialization and carefully calibrated Gaussian noise
additions. We prove that our algorithm satisfies the prescribed
$(\epsilon,\delta)$-DP guarantee and establish convergence rates that
explicitly characterize the impact of the network topology. Our theoretical
analysis, based on linear dynamics and high-dimensional probability theory,
provides tight bounds on both privacy and utility. Experiments on real-world
datasets demonstrate that D-DP-PM achieves superior privacy-utility tradeoffs
compared to naive local DP approaches, with particularly strong performance in
moderate privacy regimes ($\epsilon\in[2, 5]$). The method converges rapidly,
allowing practitioners to trade iterations for enhanced privacy while
maintaining competitive utility.

</details>


### [164] [A Bit of Freedom Goes a Long Way: Classical and Quantum Algorithms for Reinforcement Learning under a Generative Model](https://arxiv.org/abs/2507.22854)
*Andris Ambainis,Joao F. Doriguello,Debbie Lim*

Main category: cs.LG

TL;DR: 提出了新颖的经典和量子在线算法，用于学习有限和无限时域的平均奖励马尔可夫决策过程（MDP）。通过结合探索和生成模型，并利用最优策略计算，避免了传统强化学习的范式（如乐观面对不确定性和后验采样），从而获得更好的遗憾上界。量子算法在有限时域MDP中实现了对数级时间依赖的遗憾，打破了经典算法的平方根瓶颈；在无限时域中定义了新的遗憾度量，使量子算法获得多项对数级别的遗憾。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在马尔可夫决策过程（MDP）中的方法如“乐观面对不确定性”和“后验采样”可能导致次优的遗憾上界。本文旨在利用混合探索-生成强化学习模型，结合经典和量子算法直接计算最优策略，以突破经典算法在遗憾上界（如 O(√T)）的限制，并在状态空间和动作空间大小上获得更优的依赖关系。

Method: 1. 采用混合探索-生成强化学习模型：代理可定期通过生成式采样（即访问模拟器）自由与环境交互。
2. 运用经典和量子算法（含新提出的量子算法）在生成模型下逼近最优策略。
3. 避免传统强化学习范式，转而直接计算并应用最优策略。
4. 将算法推广到紧凑状态空间。

Result: 1. 有限时域MDP：量子算法遗憾上界仅对数依赖于时间步数 T（打破 O(√T) 的经典屏障），且改进了状态空间 S 和动作空间 A 的依赖关系。
2. 无限时域MDP：经典和量子算法遗憾仍保持 O(√T)时间依赖，但具有更好的 S 和 A 因子；在新定义的遗憾度量下，量子算法实现多项式对数级别遗憾。
3. 所有结果均推广到紧凑状态空间。

Conclusion: 通过混合模型和量子算法，本文突破了经典强化学习在MDP中的遗憾界限，显著降低了时间依赖性，并在状态/动作空间上取得改进。特别地，在有限时域中实现了对数级时间依赖的量子遗憾上界，在无限时域中新定义的遗憾度量下实现了指数级优势。这为量子强化学习的实际应用提供了理论支持。

Abstract: We propose novel classical and quantum online algorithms for learning
finite-horizon and infinite-horizon average-reward Markov Decision Processes
(MDPs). Our algorithms are based on a hybrid exploration-generative
reinforcement learning (RL) model wherein the agent can, from time to time,
freely interact with the environment in a generative sampling fashion, i.e., by
having access to a "simulator". By employing known classical and new quantum
algorithms for approximating optimal policies under a generative model within
our learning algorithms, we show that it is possible to avoid several paradigms
from RL like "optimism in the face of uncertainty" and "posterior sampling" and
instead compute and use optimal policies directly, which yields better regret
bounds compared to previous works. For finite-horizon MDPs, our quantum
algorithms obtain regret bounds which only depend logarithmically on the number
of time steps $T$, thus breaking the $O(\sqrt{T})$ classical barrier. This
matches the time dependence of the prior quantum works of Ganguly et al.
(arXiv'23) and Zhong et al. (ICML'24), but with improved dependence on other
parameters like state space size $S$ and action space size $A$. For
infinite-horizon MDPs, our classical and quantum bounds still maintain the
$O(\sqrt{T})$ dependence but with better $S$ and $A$ factors. Nonetheless, we
propose a novel measure of regret for infinite-horizon MDPs with respect to
which our quantum algorithms have $\operatorname{poly}\log{T}$ regret,
exponentially better compared to classical algorithms. Finally, we generalise
all of our results to compact state spaces.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [165] [When Truthful Representations Flip Under Deceptive Instructions?](https://arxiv.org/abs/2507.22149)
*Xianxuan Long,Yao Fu,Runchao Li,Mu Sheng,Haotian Yu,Xiaotian Han,Pan Li*

Main category: cs.AI

TL;DR: 该研究探讨了大型语言模型（LLMs）在收到欺骗性指令时内部表征的变化。通过分析Llama-3.1-8B-Instruct和Gemma-2-9B-Instruct模型在事实验证任务中的表现，研究者发现欺骗性指令会引发显著的内部表征变化，尤其在早中期层，并识别出对欺骗性指令高度敏感的特征。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型容易响应恶意指令生成欺骗性内容，引发安全担忧。但除了对输出的分析外，欺骗性指令如何改变模型内部表征（与真实指令的差异）尚不清楚。

Method: 1. 在事实验证任务上分析Llama-3.1-8B-Instruct和Gemma-2-9B-Instruct内部表征。2. 使用线性探测预测模型的真/假输出。3. 用稀疏自编码器（SAEs）比对欺骗性、真实性和中性指令下的表征差异。4. 分离出对欺骗性指令敏感的具体SAE特征，并通过可视化展示差异。

Result: 1. 所有条件下，线性探测可预测模型真/假输出。2. SAEs显示欺骗性指令引发显著的表征变化（集中在早中期层）。3. 真实指令与中性指令的表征相似度高。4. 识别出对欺骗性高度敏感的特定特征，可视化证实真实/欺骗性表征存在于不同子空间。

Conclusion: 欺骗性指令在LLMs中具有明确的层间和特征级表征标记，这为检测和控制指令性虚假行为提供了新途径。

Abstract: Large language models (LLMs) tend to follow maliciously crafted instructions
to generate deceptive responses, posing safety challenges. How deceptive
instructions alter the internal representations of LLM compared to truthful
ones remains poorly understood beyond output analysis. To bridge this gap, we
investigate when and how these representations ``flip'', such as from truthful
to deceptive, under deceptive versus truthful/neutral instructions. Analyzing
the internal representations of Llama-3.1-8B-Instruct and Gemma-2-9B-Instruct
on a factual verification task, we find the model's instructed True/False
output is predictable via linear probes across all conditions based on the
internal representation. Further, we use Sparse Autoencoders (SAEs) to show
that the Deceptive instructions induce significant representational shifts
compared to Truthful/Neutral representations (which are similar), concentrated
in early-to-mid layers and detectable even on complex datasets. We also
identify specific SAE features highly sensitive to deceptive instruction and
use targeted visualizations to confirm distinct truthful/deceptive
representational subspaces. % Our analysis pinpoints layer-wise and
feature-level correlates of instructed dishonesty, offering insights for LLM
detection and control. Our findings expose feature- and layer-level signatures
of deception, offering new insights for detecting and mitigating instructed
dishonesty in LLMs.

</details>


### [166] [Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence](https://arxiv.org/abs/2507.22197)
*Matthieu Queloz*

Main category: cs.AI

TL;DR: 该论文提出可解释性仅是塑造我们对人工智能期望的广泛理想的一个方面，核心是探讨AI的系统性，并区分该词的四种含义。通过调和连接主义与系统性之间的矛盾，论文提出一个更严谨的系统性概念，并探讨将这一高标准应用于AI的五大理由，同时提出'系统性硬挑战'需动态调整标准。


<details>
  <summary>Details</summary>
Motivation: 动机在于澄清当前对AI系统性（尤其是连接主义网络缺乏系统性）的误解，并引入比Fodor等人定义的更深刻、丰富的系统性概念，进而探讨人类对AI应持的系统性期望及其合理依据。

Method: 首先提出系统性概念的四个层次框架（包括可组合性、一致性、整体性、简约性原则），用此框架解构连接主义与系统性的对立；随后提出支持系统性的五大理由（认知效率、稳定性、协作、透明度、知识传承），分析这些理由是否适用于AI；最后提出动态系统化框架——根据实际需求动态调整AI的系统化强度。

Result: 1. Fodor对系统性的批评并不适用于连接主义网络的系统性潜力；2. 历史上科学理性所依赖的系统性比Fodor定义更严格；3. 五大理由表明AI需要分场景追求不同程度的系统性；4. 提出'系统性硬挑战'指标准动态调整的必要性。

Conclusion: 系统性是AI发展必须满足的多元理想，但需依照实际需求动态调整标准；可解释性仅是系统性的一部分；AI模型的系统化不能盲目追求完美主义，而应基于五大理由灵活界定其目标层级。

Abstract: This paper argues that explainability is only one facet of a broader ideal
that shapes our expectations towards artificial intelligence (AI).
Fundamentally, the issue is to what extent AI exhibits systematicity--not
merely in being sensitive to how thoughts are composed of recombinable
constituents, but in striving towards an integrated body of thought that is
consistent, coherent, comprehensive, and parsimoniously principled. This richer
conception of systematicity has been obscured by the long shadow of the
"systematicity challenge" to connectionism, according to which network
architectures are fundamentally at odds with what Fodor and colleagues termed
"the systematicity of thought." I offer a conceptual framework for thinking
about "the systematicity of thought" that distinguishes four senses of the
phrase. I use these distinctions to defuse the perceived tension between
systematicity and connectionism and show that the conception of systematicity
that historically shaped our sense of what makes thought rational,
authoritative, and scientific is more demanding than the Fodorian notion. To
determine whether we have reason to hold AI models to this ideal of
systematicity, I then argue, we must look to the rationales for systematization
and explore to what extent they transfer to AI models. I identify five such
rationales and apply them to AI. This brings into view the "hard systematicity
challenge." However, the demand for systematization itself needs to be
regulated by the rationales for systematization. This yields a dynamic
understanding of the need to systematize thought, which tells us how systematic
we need AI models to be and when.

</details>


### [167] [CoEx -- Co-evolving World-model and Exploration](https://arxiv.org/abs/2507.22281)
*Minsoo Kim,Seung-won Hwang*

Main category: cs.AI

TL;DR: 该论文提出了CoEx，一种分层智能体架构，通过结合神经符号信仰状态来实时更新世界模型，以解决现有LLM智能体在规划中因静态世界模型导致的错误问题。在复杂的任务环境中，CoEx在规划和探索方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM智能体设计无法有效将新观察同化到世界模型的动态更新中，导致静态内部世界模型与真实世界状态逐渐产生偏差，从而产生错误计划。

Method: CoEx采用分层状态抽象架构：1. 利用LLM推理编排由子目标组成的动态计划；2. 通过神经符号信仰状态（文本推理+代码符号内存）持续将子目标经验集成到持久化世界模型中；3. 世界模型实时更新以支持后续规划。

Result: 在ALFWorld、PDDL和Jericho等复杂任务环境中，CoEx在规划和探索方面超越现有智能体范式。具体表现包括：1. 计划准确性提升；2. 环境探索效率提高。

Conclusion: 通过使LLM规划与动态更新的世界模型共同演化，CoEx解决了静态世界模型导致的计划偏差问题。神经符号信仰状态的设计兼顾了环境理解的灵活性与精确性，为复杂任务智能体提供了新框架。

Abstract: Planning in modern LLM agents relies on the utilization of LLM as an internal
world model, acquired during pretraining. However, existing agent designs fail
to effectively assimilate new observations into dynamic updates of the world
model. This reliance on the LLM's static internal world model is progressively
prone to misalignment with the underlying true state of the world, leading to
the generation of divergent and erroneous plans. We introduce a hierarchical
agent architecture, CoEx, in which hierarchical state abstraction allows LLM
planning to co-evolve with a dynamically updated model of the world. CoEx plans
and interacts with the world by using LLM reasoning to orchestrate dynamic
plans consisting of subgoals, and its learning mechanism continuously
incorporates these subgoal experiences into a persistent world model in the
form of a neurosymbolic belief state, comprising textual inferences and
code-based symbolic memory. We evaluate our agent across a diverse set of agent
scenarios involving rich environments and complex tasks including ALFWorld,
PDDL, and Jericho. Our experiments show that CoEx outperforms existing agent
paradigms in planning and exploration.

</details>


### [168] [An Explainable Emotion Alignment Framework for LLM-Empowered Agent in Metaverse Service Ecosystem](https://arxiv.org/abs/2507.22326)
*Qun Ma,Xiao Xue,Ming Zhang,Yifan Shen,Zihan Zhao*

Main category: cs.AI

TL;DR: 提出了一个可解释的情绪对齐框架，用于基于大型语言模型（LLM）的Metaverse服务生态系统中的代理，旨在将事实因素融入代理的决策循环，并解决角色数据融合、知识关联及伦理安全等问题。通过O2O外卖场景的仿真实验验证了框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的发展，代理在Metaverse服务生态中扮演双重角色（用户数字替身和个性化服务助手）。但现有基于LLM的代理在连接虚拟与现实服务时面临角色数据融合、知识关联和伦理安全等挑战。

Method: 提出一个可解释的情绪对齐框架，通过将事实因素融入LLM代理的决策循环，实现更相关的现实对齐。具体流程包括：1)角色数据融合处理；2)知识关联构建；3)嵌入伦理安全机制；4)在O2O外卖场景中设计仿真实验验证框架。

Result: 框架在仿真实验中有效提升了代理决策的现实对齐性，获得了更真实的社会涌现现象，成功整合了现实因素与虚拟服务环境。

Conclusion: 该框架通过可解释的情绪对齐机制，显著增强了LLM代理在Metaverse服务生态中连接虚拟与现实的能力，为后续代理行为的真实性及伦理合规研究提供基础。

Abstract: Metaverse service is a product of the convergence between Metaverse and
service systems, designed to address service-related challenges concerning
digital avatars, digital twins, and digital natives within Metaverse. With the
rise of large language models (LLMs), agents now play a pivotal role in
Metaverse service ecosystem, serving dual functions: as digital avatars
representing users in the virtual realm and as service assistants (or NPCs)
providing personalized support. However, during the modeling of Metaverse
service ecosystems, existing LLM-based agents face significant challenges in
bridging virtual-world services with real-world services, particularly
regarding issues such as character data fusion, character knowledge
association, and ethical safety concerns. This paper proposes an explainable
emotion alignment framework for LLM-based agents in Metaverse Service
Ecosystem. It aims to integrate factual factors into the decision-making loop
of LLM-based agents, systematically demonstrating how to achieve more
relational fact alignment for these agents. Finally, a simulation experiment in
the Offline-to-Offline food delivery scenario is conducted to evaluate the
effectiveness of this framework, obtaining more realistic social emergence.

</details>


### [169] [Magentic-UI: Towards Human-in-the-loop Agentic Systems](https://arxiv.org/abs/2507.22358)
*Hussein Mozannar,Gagan Bansal,Cheng Tan,Adam Fourney,Victor Dibia,Jingya Chen,Jack Gerrits,Tyler Payne,Matheus Kunzler Maldaner,Madeleine Grunde-McLaughlin,Eric Zhu,Griffin Bassman,Jacob Alber,Peter Chang,Ricky Loynd,Friederike Niedtner,Ece Kamar,Maya Murad,Rafah Hosn,Saleema Amershi*

Main category: cs.AI

TL;DR: Magentic-UI is an open-source interface designed to enhance human-agent collaboration through oversight and flexible interaction mechanisms to improve safety and efficiency.


<details>
  <summary>Details</summary>
Motivation: Despite advances in AI agents, they still underperform humans in complex tasks and pose real-world safety risks. Human-in-the-loop systems offer a promising solution by combining human oversight with AI efficiency.

Method: Magentic-UI is built on a multi-agent architecture supporting web browsing, code execution, and file manipulation, extensible via Model Context Protocol (MCP). It incorporates six interaction mechanisms: co-planning, co-tasking, multi-tasking, action guards, and long-term memory.

Result: Magentic-UI was evaluated on autonomous task completion, simulated user testing, qualitative user studies, and safety assessments, showing potential for advancing safe and efficient human-agent collaboration.

Conclusion: The study demonstrates that structured human oversight through Magentic-UI can effectively mitigate risks and enhance AI agent performance, paving the way for reliable human-agent collaboration.

Abstract: AI agents powered by large language models are increasingly capable of
autonomously completing complex, multi-step tasks using external tools. Yet,
they still fall short of human-level performance in most domains including
computer use, software development, and research. Their growing autonomy and
ability to interact with the outside world, also introduces safety and security
risks including potentially misaligned actions and adversarial manipulation. We
argue that human-in-the-loop agentic systems offer a promising path forward,
combining human oversight and control with AI efficiency to unlock productivity
from imperfect systems. We introduce Magentic-UI, an open-source web interface
for developing and studying human-agent interaction. Built on a flexible
multi-agent architecture, Magentic-UI supports web browsing, code execution,
and file manipulation, and can be extended with diverse tools via Model Context
Protocol (MCP). Moreover, Magentic-UI presents six interaction mechanisms for
enabling effective, low-cost human involvement: co-planning, co-tasking,
multi-tasking, action guards, and long-term memory. We evaluate Magentic-UI
across four dimensions: autonomous task completion on agentic benchmarks,
simulated user testing of its interaction capabilities, qualitative studies
with real users, and targeted safety assessments. Our findings highlight
Magentic-UI's potential to advance safe and efficient human-agent
collaboration.

</details>


### [170] [LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models](https://arxiv.org/abs/2507.22359)
*Qianhong Guo,Wei Xie,Xiaofang Cai,Enze Wang,Shuoyoucheng Ma,Kai Chen,Xiaofeng Wang,Baosheng Wang*

Main category: cs.AI

TL;DR: 提出了一种名为LLM-Crowdsourced的无基准评估范式，利用大语言模型（LLMs）自主生成问题、独立回答和相互评估，以解决现有评估方法中的数据污染、黑盒操作和主观偏好等问题。该方法满足动态、透明、客观和专业四大标准，并在数学和编程领域对八个主流LLMs进行了实验验证，揭示了包括Gemini在原始和专业问题设计能力上表现最佳等多项新发现。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）评估方法存在数据污染、黑盒操作和主观偏好等问题，难以全面评估LLMs的真实能力。为解决这些挑战，作者提出了一种新的无基准评估范式。

Method: 提出LLM-Crowdsourced范式，该范式利用LLMs自主生成问题，然后让LLMs独立回答问题，最后相互进行评估。整个流程满足动态、透明、客观和专业的四大评估标准。

Result: 在数学和编程任务上对八个主流LLMs进行评估，实验结果表明该方法能有效区分LLMs的性能。此外，还揭示了一些新发现，例如：1) Gemini在原始和专业问题设计能力上表现最佳；2) 部分LLMs存在基于记忆的回答倾向，错误地将新问题识别为结构相似的熟悉问题；3) LLM的评估结果具有高度一致性（鲁棒性）。

Conclusion: LLM-Crowdsourced提供了一种动态、透明、客观和专业的评估范式，能够有效解决现有评估方法的不足，并揭示传统方法难以发现的新现象。该方法为全面评估LLMs的真实能力提供了新途径。

Abstract: Although large language models (LLMs) demonstrate remarkable capabilities
across various tasks, evaluating their capabilities remains a challenging task.
Existing evaluation methods suffer from issues such as data contamination,
black-box operation, and subjective preference. These issues make it difficult
to evaluate the LLMs' true capabilities comprehensively. To tackle these
challenges, we propose a novel benchmark-free evaluation paradigm,
LLM-Crowdsourced. It utilizes LLMs to generate questions, answer independently,
and evaluate mutually. This method integrates four key evaluation criteria:
dynamic, transparent, objective, and professional, which existing evaluation
methods cannot satisfy simultaneously. Experiments on eight mainstream LLMs
across mathematics and programming verify the advantages of our method in
distinguishing LLM performance. Furthermore, our study reveals several novel
findings that are difficult for traditional methods to detect, including but
not limited to: (1) Gemini demonstrates the highest original and professional
question-design capabilities among others; (2) Some LLMs exhibit
''memorization-based answering'' by misrecognizing questions as familiar ones
with a similar structure; (3) LLM evaluation results demonstrate high
consistency (robustness).

</details>


### [171] [Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making](https://arxiv.org/abs/2507.22365)
*ZhaoBin Li,Mark Steyvers*

Main category: cs.AI

TL;DR: 本文探讨了在人类决策依赖AI输入的情境中，AI预测准确性及其置信度估计的可靠性如何共同影响决策质量。研究发现，AI的元认知敏感性（即其置信分数能准确区分预测正确与否）对于提升人类决策表现至关重要。理论框架和行为实验均表明，即使在某些情况下AI预测准确性较低，但只要元认知敏感性高，也可能改善整体决策精度。


<details>
  <summary>Details</summary>
Motivation: 在AI辅助人类决策的场景中，现有研究通常关注AI的预测准确性，而忽视了置信度估计的重要性。作者指出，AI的置信度若不可靠（即高置信度下仍出现错误），将误导人类决策。因此需要系统性评估AI的元认知敏感性及其联合影响。

Method: 首先建立理论框架，分析AI预测准确性与元认知敏感性的组合如何影响人类决策质量；随后设计行为实验：参与者需根据AI提供的文本分类预测及其置信度决定是否遵循建议。对照组为固定置信度AI，实验组为高/低元认知敏感性的动态AI系统。

Result: 理论模型证明：当人类对不可信预测持怀疑态度时，元认知敏感性高的AI（即使准确性稍低）可提升决策准确性。实验证实：相较元认知敏感性低的组，高敏感性组的人类决策准确率显著提升7.2%；同时参与者更倾向信任高置信度建议。

Conclusion: 评估AI决策辅助系统需同时考虑准确性及元认知敏感性。优化置信度校准度能放大人类判断优势，尤其在AI不确定性高时。这为开发新型AI系统提供了原则（如联合优化准确性与元认知指标），并建议决策界面应直观展示AI置信水平。

Abstract: In settings where human decision-making relies on AI input, both the
predictive accuracy of the AI system and the reliability of its confidence
estimates influence decision quality. We highlight the role of AI metacognitive
sensitivity -- its ability to assign confidence scores that accurately
distinguish correct from incorrect predictions -- and introduce a theoretical
framework for assessing the joint impact of AI's predictive accuracy and
metacognitive sensitivity in hybrid decision-making settings. Our analysis
identifies conditions under which an AI with lower predictive accuracy but
higher metacognitive sensitivity can enhance the overall accuracy of human
decision making. Finally, a behavioral experiment confirms that greater AI
metacognitive sensitivity improves human decision performance. Together, these
findings underscore the importance of evaluating AI assistance not only by
accuracy but also by metacognitive sensitivity, and of optimizing both to
achieve superior decision outcomes.

</details>


### [172] [On the Definition of Intelligence](https://arxiv.org/abs/2507.22423)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 该论文提出了一个通用的智能标准——样本忠实度，即智能是根据样本生成同一类别样本的能力。该标准适用于强化学习、生成模型、分类、类比推理和目标导向决策等多种智能行为范式，旨在以一种物种无关的形式捕捉智能的本质。


<details>
  <summary>Details</summary>
Motivation: 为了工程化人工通用智能（AGI），需要以一种物种无关的形式捕捉智能的本质，使其能够被评估，并足够通用以涵盖多种智能行为范式（如强化学习、生成模型等）。这种形式应该独立于特定物种（如人类）的智能体现。

Method: 作者提出了一种基于样本忠实度的智能标准：智能是根据样本生成同类样本的能力。这种标准可以形式化为ε类别智能（ε-category intelligence），其定义为：对于给定类别的样本，生成的样本在可接受的区分器下，与原样本之间的差异不超过容忍度ε。具体方法包括：
1. 定义类别智力：给定类别的初始样本，代理生成新样本；
2. 评估标准：使用一组可接受的区分器评估原始样本和生成样本之间是否可区分，要求在给定容错ε内无法区分。
此外，还提出了经验研究协议，包括建立可接受区分器集合、验证容忍度ε等步骤。

Result: 提出了一种广泛适用的智能定义，适用于强化学习、生成模型、分类、类比推理和目标导向决策等多种范例。该定义的优点包括：
1. 统一并涵盖现有AI任务（如生成任务、区分任务）。
2. 具有可测量的量化评估（通过ε容差）。
3. 能够指导评估、安全协议设计及泛化能力的提升。

Conclusion: 提出的ε类别智能框架是一个通用的智能评估标准，能够统一多种智能行为范式，实现可度量的AGI设计和安全规划。其核心是通过样本忠实度进行泛化。该定义有望推动可衡量AGI发展，解决评估和安全的挑战。

Abstract: To engineer AGI, we should first capture the essence of intelligence in a
species-agnostic form that can be evaluated, while being sufficiently general
to encompass diverse paradigms of intelligent behavior, including reinforcement
learning, generative models, classification, analogical reasoning, and
goal-directed decision-making. We propose a general criterion based on sample
fidelity: intelligence is the ability, given sample(s) from a category, to
generate sample(s) from the same category. We formalise this intuition as
{\epsilon}-category intelligence: it is {\epsilon}-intelligent with respect to
a category if no chosen admissible distinguisher can separate generated from
original samples beyond tolerance {\epsilon}. We present the formal framework,
outline empirical protocols, and discuss implications for evaluation, safety,
and generalization.

</details>


### [173] [Cross-Border Legal Adaptation of Autonomous Vehicle Design based on Logic and Non-monotonic Reasoning](https://arxiv.org/abs/2507.22432)
*Zhe Yu,Yiwei Lu,Burkhard Schafer,Zhe Lin*

Main category: cs.AI

TL;DR: 该论文关注自动驾驶车辆在跨国背景下的法律合规挑战，从设计者视角出发，通过论证理论和逻辑表示规范推理的基本属性，结合自然数的偏序集表达优先级，帮助设计者灵活调整设计方案并理解决策的法律含义。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在跨国应用中面临不同法律体系的合规挑战，设计者需要工具来支持其在设计过程中进行合法合规的推理和调整。

Method: 1. 采用论证理论框架；2. 引入一种逻辑来表示基于论证的实践（规范）推理的基本属性；3. 结合自然数的偏序集来表达优先级；4. 通过法律文本的案例分析验证推理系统的有效性。

Result: 提供的推理系统能够帮助设计者更灵活地调整自动驾驶车辆在跨境应用中的设计方案，并使其更容易理解决策的法律含义。

Conclusion: 通过结合论证理论和优先级表达，构建的推理系统有效支持了设计者在跨国法律环境下进行合规决策，增强了自动驾驶车辆设计的法律适应性。

Abstract: This paper focuses on the legal compliance challenges of autonomous vehicles
in a transnational context. We choose the perspective of designers and try to
provide supporting legal reasoning in the design process. Based on
argumentation theory, we introduce a logic to represent the basic properties of
argument-based practical (normative) reasoning, combined with partial order
sets of natural numbers to express priority. Finally, through case analysis of
legal texts, we show how the reasoning system we provide can help designers to
adapt their design solutions more flexibly in the cross-border application of
autonomous vehicles and to more easily understand the legal implications of
their decisions.

</details>


### [174] [Nearest-Better Network for Visualizing and Analyzing Combinatorial Optimization Problems: A Unified Tool](https://arxiv.org/abs/2507.22440)
*Yiya Diao,Changhe Li,Sanyou Zeng,Xinye Cai,Wenjian Luo,Shengxiang Yang,Carlos A. Coello Coello*

Main category: cs.AI

TL;DR: 本文改进了Nearest-Better Network (NBN) 的计算方法，提出一种对数线性时间复杂度的算法，并应用在OneMax和TSP问题上，发现了新特征：OneMax的中立性、崎岖性和模态特征；TSP的主要挑战是崎岖性、模态性和欺骗性。同时还指出两种先进算法（EAX和LKH）的局限性。


<details>
  <summary>Details</summary>
Motivation: 原始的NBN方法在连续优化问题中能可视化数据并保留多个景观特征，但其计算耗时，且难以扩展到组合优化问题。因此，需要高效的计算方法和在组合问题上的应用分析。

Method: 1. 通过理论推导证明NBN本质是算法的最大概率转移网络。2. 提出基于对数线性时间复杂度的NBN高效计算方法。3. 将高效NBN算法应用于OneMax问题和TSP问题（使用EAX和LKH算法）。

Result: 首次发现许多重要现象：1. OneMax问题的适应度景观具有中立性、崎岖性和模态特征。2. TSP问题的主要挑战是崎岖性、模态性和欺骗性。3. EAX算法（采用单一种群）能高效维持多样性，但当存在多个吸引盆地时，会同时保留多个盆地的个体，导致盆地间交互效率降低，使算法停滞。4. LKH算法（基于局部搜索算子）在全局最优解附近存在欺骗性解时会失效。

Conclusion: 本文提出的高效NBN计算方法解决了时间消耗问题，并且通过理论推导和实验证明了NBN作为最大概率转移网络的本质。首次揭示OneMax和TSP问题的景观特征及两种先进算法的局限性，为后续改进提供了新视角。

Abstract: The Nearest-Better Network (NBN) is a powerful method to visualize sampled
data for continuous optimization problems while preserving multiple landscape
features. However, the calculation of NBN is very time-consuming, and the
extension of the method to combinatorial optimization problems is challenging
but very important for analyzing the algorithm's behavior. This paper provides
a straightforward theoretical derivation showing that the NBN network
essentially functions as the maximum probability transition network for
algorithms. This paper also presents an efficient NBN computation method with
logarithmic linear time complexity to address the time-consuming issue. By
applying this efficient NBN algorithm to the OneMax problem and the Traveling
Salesman Problem (TSP), we have made several remarkable discoveries for the
first time: The fitness landscape of OneMax exhibits neutrality, ruggedness,
and modality features. The primary challenges of TSP problems are ruggedness,
modality, and deception. Two state-of-the-art TSP algorithms (i.e., EAX and
LKH) have limitations when addressing challenges related to modality and
deception, respectively. LKH, based on local search operators, fails when there
are deceptive solutions near global optima. EAX, which is based on a single
population, can efficiently maintain diversity. However, when multiple
attraction basins exist, EAX retains individuals within multiple basins
simultaneously, reducing inter-basin interaction efficiency and leading to
algorithm's stagnation.

</details>


### [175] [Collaborative Medical Triage under Uncertainty: A Multi-Agent Dynamic Matching Approach](https://arxiv.org/abs/2507.22504)
*Hongyan Cheng,Chengzhang Yu,Yanshu Shi,Chiyue Wang,Cong Liu,Zhanpeng Jin*

Main category: cs.AI

TL;DR: 提出了一个多智能体交互式医疗分诊系统，解决了当前AI分诊系统中医疗专业不足、机构结构异构和低效详细问诊三大挑战，系统通过在真实数据集上的实验，实现了高准确度的科室分类。


<details>
  <summary>Details</summary>
Motivation: 后疫情时期医疗需求激增与护理人员短缺导致急诊分诊压力剧增，急需AI驱动的解决方案。现有AI分诊系统存在专业性不足导致误诊、不同医疗机构部门结构异构以及详细问诊效率低下三大问题。

Method: 系统包含三个专用智能体：RecipientAgent（接收症状）、InquirerAgent（动态提问）、DepartmentAgent（匹配科室）。通过结构化问诊机制和科室指导规则，将非结构化患者症状转化为准确分诊建议。构建包含3,360个真实病例的中文分诊数据集，覆盖9个一级科室和62个二级科室，使用大语言模型补全医疗记录缺失数据。

Result: 经过四轮患者交互后，一级科室分类准确率达到89.2%，二级科室分类准确率达73.9%。基于模式匹配的指导机制能高效适配不同医院配置。

Conclusion: 该系统为部署AI辅助分诊提供了可扩展框架，能适应医疗机构的组织异构性，同时确保临床决策可靠性。通过真实数据验证，该方法有效解决了当前AI分诊系统的核心痛点。

Abstract: The post-pandemic surge in healthcare demand, coupled with critical nursing
shortages, has placed unprecedented pressure on emergency department triage
systems, necessitating innovative AI-driven solutions. We present a multi-agent
interactive intelligent system for medical triage that addresses three
fundamental challenges in current AI-based triage systems: insufficient medical
specialization leading to hallucination-induced misclassifications,
heterogeneous department structures across healthcare institutions, and
inefficient detail-oriented questioning that impedes rapid triage decisions.
Our system employs three specialized agents - RecipientAgent, InquirerAgent,
and DepartmentAgent - that collaborate through structured inquiry mechanisms
and department-specific guidance rules to transform unstructured patient
symptoms into accurate department recommendations. To ensure robust evaluation,
we constructed a comprehensive Chinese medical triage dataset from a medical
website, comprising 3,360 real-world cases spanning 9 primary departments and
62 secondary departments. Through systematic data imputation using large
language models, we address the prevalent issue of incomplete medical records
in real-world data. Experimental results demonstrate that our multi-agent
system achieves 89.2% accuracy in primary department classification and 73.9%
accuracy in secondary department classification after four rounds of patient
interaction. The system's pattern-matching-based guidance mechanisms enable
efficient adaptation to diverse hospital configurations while maintaining high
triage accuracy. Our work provides a scalable framework for deploying
AI-assisted triage systems that can accommodate the organizational
heterogeneity of healthcare institutions while ensuring clinically sound
decision-making.

</details>


### [176] [MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines](https://arxiv.org/abs/2507.22606)
*Yaolun Zhang,Xiaogeng Liu,Chaowei Xiao*

Main category: cs.AI

TL;DR: 提出了一个名为MetaAgent基于有限状态机的框架，能自动生成定制化的多Agent系统，并在各类任务中表现出优于其他自动设计方法的性能，可媲美专为该任务优化设计的人工多Agent系统。


<details>
  <summary>Details</summary>
Motivation: 现有的人工设计多Agent框架局限于预定的小型场景，而自动设计方法存在工具集成缺失、依赖外部训练数据、通信结构僵化等不足之处，因此需要一种更灵活、自动化的多Agent系统设计框架。

Method: 针对任务描述，采用有限状态机结构自动生成多Agent系统，并通过优化算法对系统进行打磨；在系统部署时，由有限状态机控制Agent的操作与状态转变；覆盖文本类与实用类任务进行验证。

Result: MetaAgent构建的系统在各类任务中优于其它自动设计方法，且性能与为特定任务优化后的人工设计系统相当。

Conclusion: 研究证明了MetaAgent框架在自动化设计高效率多Agent系统方面的能力，为复杂任务处理提供了灵活、可迁移的新思路。

Abstract: Large Language Models (LLMs) have demonstrated the ability to solve a wide
range of practical tasks within multi-agent systems. However, existing
human-designed multi-agent frameworks are typically limited to a small set of
pre-defined scenarios, while current automated design methods suffer from
several limitations, such as the lack of tool integration, dependence on
external training data, and rigid communication structures. In this paper, we
propose MetaAgent, a finite state machine based framework that can
automatically generate a multi-agent system. Given a task description,
MetaAgent will design a multi-agent system and polish it through an
optimization algorithm. When the multi-agent system is deployed, the finite
state machine will control the agent's actions and the state transitions. To
evaluate our framework, we conduct experiments on both text-based tasks and
practical tasks. The results indicate that the generated multi-agent system
surpasses other auto-designed methods and can achieve a comparable performance
with the human-designed multi-agent system, which is optimized for those
specific tasks.

</details>


### [177] [Enhancing Manufacturing Knowledge Access with LLMs and Context-aware Prompting](https://arxiv.org/abs/2507.22619)
*Sebastian Monka,Irlan Grangel-González,Stefan Schmid,Lavdim Halilaj,Marc Rickart,Oliver Rudolph,Rui Dias*

Main category: cs.AI

TL;DR: 大型语言模型通过感知KG上下文来提升从制造知识图谱生成SPARQL查询的准确率


<details>
  <summary>Details</summary>
Motivation: 知识图谱在制造业数据管理中具有重要作用，但非专家用户难以通过编写复杂的SPARQL查询来获取信息。大型语言模型可能解决此问题，但需要解决领域知识图谱的上下文提供问题。

Method: 在制造领域的知识图谱上测试多种策略，通过不同方式提供KG模式和上下文给LLM，评估其将自然语言问题转写为SPARQL查询的能力。

Result: 研究表明，当LLM获得领域知识图谱的上下文提示时，生成正确和完整查询的能力显著提高，且能减少幻觉。

Conclusion: 基于上下文感知提示的LLM方法有望在制造业等领域降低知识图谱访问门槛，为非专家用户提供决策支持。

Abstract: Knowledge graphs (KGs) have transformed data management within the
manufacturing industry, offering effective means for integrating disparate data
sources through shared and structured conceptual schemas. However, harnessing
the power of KGs can be daunting for non-experts, as it often requires
formulating complex SPARQL queries to retrieve specific information. With the
advent of Large Language Models (LLMs), there is a growing potential to
automatically translate natural language queries into the SPARQL format, thus
bridging the gap between user-friendly interfaces and the sophisticated
architecture of KGs. The challenge remains in adequately informing LLMs about
the relevant context and structure of domain-specific KGs, e.g., in
manufacturing, to improve the accuracy of generated queries. In this paper, we
evaluate multiple strategies that use LLMs as mediators to facilitate
information retrieval from KGs. We focus on the manufacturing domain,
particularly on the Bosch Line Information System KG and the I40 Core
Information Model. In our evaluation, we compare various approaches for feeding
relevant context from the KG to the LLM and analyze their proficiency in
transforming real-world questions into SPARQL queries. Our findings show that
LLMs can significantly improve their performance on generating correct and
complete queries when provided only the adequate context of the KG schema. Such
context-aware prompting techniques help LLMs to focus on the relevant parts of
the ontology and reduce the risk of hallucination. We anticipate that the
proposed techniques help LLMs to democratize access to complex data
repositories and empower informed decision-making in manufacturing settings.

</details>


### [178] [ASP-FZN: A Translation-based Constraint Answer Set Solver](https://arxiv.org/abs/2507.22774)
*Thomas Eiter,Tobias Geibinger,Tobias Kaminski,Nysret Musliu,Johannes Oetsch*

Main category: cs.AI

TL;DR: 介绍了用于约束答案集规划问题的求解器asp-fzn，支持将约束ASP程序转换为FlatZinc语言，利用后端约束规划求解器求解。该求解器支持丰富的线性约束和全局约束语言。实验表明在ASP基准问题上媲美前沿ASP求解器，部分约束ASP问题上表现优于主流求解器clingcon。


<details>
  <summary>Details</summary>
Motivation: 为约束答案集编程领域提供新的求解器选项，通过转换为FlatZinc语言利用现有约束求解技术提升处理线性约束的能力。

Method: 1. 设计转换模块将约束ASP程序转化为通用FlatZinc语言 2. 支持包括线性约束和常见全局约束的丰富语言 3. 使用多类后端约束求解器进行计算。

Result: 1. 在ASP标准基准测试中达到先进ASP求解器水平 2. 在多项约束ASP文献问题上性能优于主流求解器clingcon。

Conclusion: asp-fzn求解器在保持纯ASP问题竞争力的同时，在带约束问题上展现出更优潜力，为约束ASP落地提供实用新工具。

Abstract: We present the solver asp-fzn for Constraint Answer Set Programming (CASP),
which extends ASP with linear constraints. Our approach is based on translating
CASP programs into the solver-independent FlatZinc language that supports
several Constraint Programming and Integer Programming backend solvers. Our
solver supports a rich language of linear constraints, including some common
global constraints. As for evaluation, we show that asp-fzn is competitive with
state-of-the-art ASP solvers on benchmarks taken from past ASP competitions.
Furthermore, we evaluate it on several CASP problems from the literature and
compare its performance with clingcon, which is a prominent CASP solver that
supports most of the asp-fzn language. The performance of asp-fzn is very
promising as it is already competitive on plain ASP and even outperforms
clingcon on some CASP benchmarks.

</details>


### [179] [Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies](https://arxiv.org/abs/2507.22782)
*Hugo Garrido-Lestache,Jeremy Kedziora*

Main category: cs.AI

TL;DR: 提出Team-Attention-Actor-Critic（TAAC）算法，通过集中式训练/集中式执行框架整合多头注意力机制，增强多智能体协作。引入惩罚损失函数提升角色互补性，在模拟足球环境中表现优于基准算法。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习面临联合动作空间指数增长的挑战，现有方法难以实现动态高效协作。TAAC旨在通过显式智能体间通信机制解决协作效率问题，并鼓励多样互补的团队角色。

Method: 1. 采用CTCE（集中训练集中执行）框架。
2. 演员和评论家网络均集成多头注意力机制，实现智能体间动态查询。
3. 设计惩罚损失函数，通过增加角色差异性促进互补行为。
4. 在模拟足球环境中对比PPO、MAA2C等基准算法。

Result: TAAC在多个指标上优于基准算法：
- 胜率提升
- 更大净胜球差距
- 更高Elo评分
- 更强智能体间连接性
- 更平衡空间分布
- 更频繁战术互动（如球权交换）

Conclusion: TAAC通过动态注意力通信机制有效解决了多智能体协作的扩展性问题，其角色互补设计促进了更复杂的团队行为，为协作型多智能体系统提供了新方向。

Abstract: This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement
learning algorithm designed to enhance multi-agent collaboration in cooperative
environments. TAAC employs a Centralized Training/Centralized Execution scheme
incorporating multi-headed attention mechanisms in both the actor and critic.
This design facilitates dynamic, inter-agent communication, allowing agents to
explicitly query teammates, thereby efficiently managing the exponential growth
of joint-action spaces while ensuring a high degree of collaboration. We
further introduce a penalized loss function which promotes diverse yet
complementary roles among agents. We evaluate TAAC in a simulated soccer
environment against benchmark algorithms representing other multi-agent
paradigms, including Proximal Policy Optimization and Multi-Agent
Actor-Attention-Critic. We find that TAAC exhibits superior performance and
enhanced collaborative behaviors across a variety of metrics (win rates, goal
differentials, Elo ratings, inter-agent connectivity, balanced spatial
distributions, and frequent tactical interactions such as ball possession
swaps).

</details>


### [180] [The Incomplete Bridge: How AI Research (Mis)Engages with Psychology](https://arxiv.org/abs/2507.22847)
*Han Jiang,Pengda Wang,Xiaoyuan Yi,Xing Xie,Ziang Xiao*

Main category: cs.AI

TL;DR: 该研究分析了2023-2025年间顶级AI会议中1006篇涉及心理学理论的LLM相关论文及其引用的2544篇心理学文献，探讨了人工智能与心理学的跨学科整合模式。研究发现心理学在AI系统设计中具有重要价值，揭示了高频领域与应用盲区，同时指出了心理学理论在AI中的误用类型并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 社会科学（特别是心理学）为理解人类心智与行为提供了丰富的理论基础，对AI系统的设计与理解具有重要价值。但目前跨学科整合的程度与模式尚不明晰。

Method: 1. 收集2023-2025年顶级AI会议中1006篇涉及心理学理论的LLM相关论文；2. 分析这些论文引用的2544篇心理学出版物；3. 通过内容分析识别跨学科整合模式；4. 统计高频心理学领域并定位研究盲区；5. 考察心理学理论在AI中的操作化过程；6. 诊断常见误用类型并提出优化方案。

Result: 1. 揭示了AI与心理学跨学科整合的图谱；2. 识别出最常被引用的心理学领域；3. 发现存在显著的研究空白区；4. 总结了心理学理论在AI应用中的四类典型误用（如概念简化/情境错配等）；5. 提出结构化整合框架。

Conclusion: 研究为AI与心理学的深度协作提供了系统性路线图：a) 证实心理学理论能有效提升AI系统的解释性与人性化设计；b) 指出当前整合存在碎片化问题；c) 提出的跨学科操作指南有助于减少误用；d) 未来应重点加强认知神经科学等领域的协同探索。

Abstract: Social sciences have accumulated a rich body of theories and methodologies
for investigating the human mind and behaviors, while offering valuable
insights into the design and understanding of Artificial Intelligence (AI)
systems. Focusing on psychology as a prominent case, this study explores the
interdisciplinary synergy between AI and the field by analyzing 1,006
LLM-related papers published in premier AI venues between 2023 and 2025, along
with the 2,544 psychology publications they cite. Through our analysis, we
identify key patterns of interdisciplinary integration, locate the psychology
domains most frequently referenced, and highlight areas that remain
underexplored. We further examine how psychology theories/frameworks are
operationalized and interpreted, identify common types of misapplication, and
offer guidance for more effective incorporation. Our work provides a
comprehensive map of interdisciplinary engagement between AI and psychology,
thereby facilitating deeper collaboration and advancing AI systems.

</details>


### [181] [Automatically discovering heuristics in a complex SAT solver with large language models](https://arxiv.org/abs/2507.22876)
*Yiwen Sun,Furong Ye,Zhihan Chen,Ke Wei,Shaowei Cai*

Main category: cs.AI

TL;DR: 该论文提出了AutoModSAT工具，利用大语言模型（LLMs）优化复杂的SAT求解器。通过三个关键技术挑战的解决：LLM友好的求解器设计、自动提示优化和高效搜索策略，实现了相比基线求解器50%的性能提升和20%的平均加速，并超过了当前最优求解器30%。


<details>
  <summary>Details</summary>
Motivation: 传统的自动配置框架在优化现代复杂结构的SAT求解器时存在局限性，如搜索空间受限、性能提升有限。因此作者提出利用大型语言模型（LLMs）来优化SAT求解器的新范式，以突破当前性能瓶颈。

Method: 1. LLM友好求解器设计：提出模块化开发指南（代码简化、信息共享、减少错误）以确保LLM兼容性；2. 自动提示优化：采用无监督自动提示优化方法增强LLM输出多样性；3. 高效搜索策略：设计预搜索策略和EA进化算法高效探索启发式规则。

Result: 在多个数据集上实验表明：1. 比基线求解器性能提升50%；2. 超越当前最优（SOTA）求解器30%；3. 相比SOTA求解器的参数调优版本平均加速20%；4. 在处理复杂问题实例时展现出更强能力。

Conclusion: 该工作弥合了AI驱动的启发式发现与关键任务系统优化之间的鸿沟，为下一代复杂求解器开发提供了方法学突破和实证结果，证明了LLMs在优化复杂系统方面的潜力。

Abstract: Satisfiability problem (SAT) is a cornerstone of computational complexity
with broad industrial applications, and it remains challenging to optimize
modern SAT solvers in real-world settings due to their intricate architectures.
While automatic configuration frameworks have been developed, they rely on
manually constrained search spaces and yield limited performance gains. This
work introduces a novel paradigm which effectively optimizes complex SAT
solvers via Large Language Models (LLMs), and a tool called AutoModSAT is
developed. Three fundamental challenges are addressed in order to achieve
superior performance: (1) LLM-friendly solver: Systematic guidelines are
proposed for developing a modularized solver to meet LLMs' compatibility,
emphasizing code simplification, information share and bug reduction; (2)
Automatic prompt optimization: An unsupervised automatic prompt optimization
method is introduced to advance the diversity of LLMs' output; (3) Efficient
search strategy: We design a presearch strategy and an EA evolutionary
algorithm for the final efficient and effective discovery of heuristics.
Extensive experiments across a wide range of datasets demonstrate that
AutoModSAT achieves 50% performance improvement over the baseline solver and
achieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover,
AutoModSAT attains a 20% speedup on average compared to parameter-tuned
alternatives of the SOTA solvers, showcasing the enhanced capability in
handling complex problem instances. This work bridges the gap between AI-driven
heuristics discovery and mission-critical system optimization, and provides
both methodological advancements and empirically validated results for
next-generation complex solver development.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [182] [Deployment of Objects with a Soft Everting Robot](https://arxiv.org/abs/2507.22188)
*Ethan DeVries,Jack Ferlazzo,Mustafa Ugur,Laura H. Blumenschein*

Main category: cs.RO

TL;DR: 该论文探讨了软翻转型机器人如何通过其内部结构运输更大、更重的有效载荷，并分析了可部署物体的特性以及它们能穿越的地形特征。通过建立模型预测载荷对机器人扩展和自支撑的影响，以及载荷滑移的情况，并对各种形状、尺寸和重量的载荷进行实验验证，结果显示最大可运输1.5公斤的载荷，并能在多种复杂环境中进行运输。


<details>
  <summary>Details</summary>
Motivation: 当前软翻转型机器人主要应用于勘探任务，但在运输和部署有效载荷方面的潜力研究较少，而这一能力对于在危险区域（如向废墟下的人运送水瓶）具有重要应用价值。因此，研究如何利用软翻转型机器人的导航能力和部署体来运送更大、更重的载荷具有实际意义。

Method: 1. 分析软翻转型机器人内部可部署的物体类型和能穿越的地形特征。
2. 基于现有模型，建立量化载荷对机器人扩展和自支撑影响的方法。
3. 开发预测载荷滑移的模型。
4. 通过实验验证：使用不同形状、尺寸和重量的载荷，在转向、垂直运输、穿越孔洞和跨越间隙等一系列任务中进行测试。

Result: 1. 成功运输了多种形状的载荷，最大重量达1.5kg。
2. 可在孔径仅比载荷大0.01cm的圆形孔洞中通过。
3. 能实现高达135度的转弯。
4. 能跨越长度达1.15m的无支撑间隙。

Conclusion: 软翻转型机器人具备在复杂和危险环境中运输较大、较重有效载荷的能力，为实际应用（如救援任务）提供了新的可能性。研究不仅量化了机器人运输能力，还展示了其卓越的机动性和适应性。

Abstract: Soft everting robots present significant advantages over traditional rigid
robots, including enhanced dexterity, improved environmental interaction, and
safe navigation in unpredictable environments. While soft everting robots have
been widely demonstrated for exploration type tasks, their potential to move
and deploy payloads in such tasks has been less investigated, with previous
work focusing on sensors and tools for the robot. Leveraging the navigation
capabilities, and deployed body, of the soft everting robot to deliver payloads
in hazardous areas, e.g. carrying a water bottle to a person stuck under
debris, would represent a significant capability in many applications. In this
work, we present an analysis of how soft everting robots can be used to deploy
larger, heavier payloads through the inside of the robot. We analyze both what
objects can be deployed and what terrain features they can be carried through.
Building on existing models, we present methods to quantify the effects of
payloads on robot growth and self-support, and develop a model to predict
payload slip. We then experimentally quantify payload transport using soft
everting robot with a variety of payload shapes, sizes, and weights and though
a series of tasks: steering, vertical transport, movement through holes, and
movement across gaps. Overall, the results show that we can transport payloads
in a variety of shapes and up to 1.5kg in weight and that we can move through
circular apertures with as little as 0.01cm clearance around payloads, carry
out discrete turns up to 135 degrees, and move across unsupported gaps of 1.15m
in length.

</details>


### [183] [FLORES: A Reconfigured Wheel-Legged Robot for Enhanced Steering and Adaptability](https://arxiv.org/abs/2507.22345)
*Zhicheng Song,Jinglan Xu,Chunxin Zheng,Yulin Li,Zhihai Bi,Jun Ma*

Main category: cs.RO

TL;DR: 摘要介绍了FLORES——一种具有创新性轮腿设计的机器人，其前腿结构将传统的髋关节横滚自由度替换为偏航自由度，从而在平坦表面上高效移动，同时在复杂地形中保持适应性。通过强化学习控制器实现轮式与腿式运动的平滑过渡和多模态策略，提升了转向能力、导航效率和对不同地形的适应性。项目已开源。


<details>
  <summary>Details</summary>
Motivation: 现有轮腿机器人未能充分发挥腿部和轮式结构的优势，限制了系统的灵活性和效率。因此，开发一种新型轮腿机器人设计，以更好地结合两种结构的优点，提升在复杂环境中的适应性。

Method: 1. 机械设计：将前腿的髋关节横滚自由度替换为髋关节偏航自由度，实现平坦表面高效移动和复杂地形适应性的平衡。
2. 控制策略：开发基于强化学习的控制器，结合混合内部模型（HIM）和奖励机制，针对该独特结构优化多模态运动策略（轮式与腿式）。
3. 关节设计：引入新型腿部结构实现高效的混合步态（基于轮与腿的协同作用）。

Result: 通过全面实验，FLORES展现出：1) 增强的转向能力；2) 提升的导航效率；3) 可应对多种地形的自适应能力。

Conclusion: FLORES的创新机械设计与定制化控制器成功实现了轮式与腿式模式间的平滑过渡，在保证效率的同时显著提升了复杂环境中的适应性，推动了轮腿机器人的实用化发展。

Abstract: Wheel-legged robots integrate the agility of legs for navigating rough
terrains while harnessing the efficiency of wheels for smooth surfaces.
However, most existing designs do not fully capitalize on the benefits of both
legged and wheeled structures, which limits overall system flexibility and
efficiency. We present FLORES (reconfigured wheel-legged robot for enhanced
steering and adaptability), a novel wheel-legged robot design featuring a
distinctive front-leg configuration that sets it beyond standard design
approaches. Specifically, FLORES replaces the conventional hip-roll degree of
freedom (DoF) of the front leg with hip-yaw DoFs, and this allows for efficient
movement on flat surfaces while ensuring adaptability when navigating complex
terrains. This innovative design facilitates seamless transitions between
different locomotion modes (i.e., legged locomotion and wheeled locomotion) and
optimizes the performance across varied environments. To fully exploit FLORES's
mechanical capabilities, we develop a tailored reinforcement learning (RL)
controller that adapts the Hybrid Internal Model (HIM) with a customized reward
structure optimized for our unique mechanical configuration. This framework
enables the generation of adaptive, multi-modal locomotion strategies that
facilitate smooth transitions between wheeled and legged movements.
Furthermore, our distinctive joint design enables the robot to exhibit novel
and highly efficient locomotion gaits that capitalize on the synergistic
advantages of both locomotion modes. Through comprehensive experiments, we
demonstrate FLORES's enhanced steering capabilities, improved navigation
efficiency, and versatile locomotion across various terrains. The open-source
project can be found at
https://github.com/ZhichengSong6/FLORES-A-Reconfigured-Wheel-Legged-Robot-for-Enhanced-Steering-and-Adaptability.git.

</details>


### [184] [In-Situ Soil-Property Estimation and Bayesian Mapping with a Simulated Compact Track Loader](https://arxiv.org/abs/2507.22356)
*W. Jacob Wagner,Ahmet Soylemezoglu,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: 提出了一种土壤属性地图系统，用于扩展环境状态，以克服复杂车辆-地形交互动力学和土壤条件不可知性对自主土方工程的限制，从而实现更鲁棒的自动土方操作。


<details>
  <summary>Details</summary>
Motivation: 现有的自主土方工程大多局限于高度受控和特征明确的环境中，原因在于车辆-地形交互动力学的复杂性以及由于未知且空间变化的土壤条件导致的地形部分可观测性。

Method: 1. 扩展GPU加速高程地图系统，加入盲映射组件，通过追踪铲刀在土壤中的运动来计算土壤位移和侵蚀，分离跟踪未扰动和扰动土壤。2. 将每次交互近似视为平铲刀在局部均质土壤中的运动，利用土方基本方程（FEE）建模切削力。3. 基于先前研究中现场土壤属性估计的方法，提取模型几何参数，并开发改进的物理信息神经网络（PINN）模型预测土壤属性和不确定性。4. 使用带铲刀的紧凑型履带装载机（CTL）模拟器收集数据训练PINN模型。5. 训练后，地图系统利用模型在线跟踪土壤属性空间估计，以贝叶斯方式更新地图中的分层土壤属性信息。

Result: 该系统能够准确突出显示需要较高相对交互力的区域，为自主地形塑造的土壤感知规划提供了保障。

Conclusion: 所提出的土壤属性映射系统在初步实验中显示出潜力，能够区分不同类型土壤，并提供土壤属性的空间地图，为开发更强大的自主土方工程系统奠定了基础。

Abstract: Existing earthmoving autonomy is largely confined to highly controlled and
well-characterized environments due to the complexity of vehicle-terrain
interaction dynamics and the partial observability of the terrain resulting
from unknown and spatially varying soil conditions. In this chapter, a a
soil-property mapping system is proposed to extend the environmental state, in
order to overcome these restrictions and facilitate development of more robust
autonomous earthmoving. A GPU accelerated elevation mapping system is extended
to incorporate a blind mapping component which traces the movement of the blade
through the terrain to displace and erode intersected soil, enabling separately
tracking undisturbed and disturbed soil. Each interaction is approximated as a
flat blade moving through a locally homogeneous soil, enabling modeling of
cutting forces using the fundamental equation of earthmoving (FEE). Building
upon our prior work on in situ soil-property estimation, a method is devised to
extract approximate geometric parameters of the model given the uneven terrain,
and an improved physics infused neural network (PINN) model is developed to
predict soil properties and uncertainties of these estimates. A simulation of a
compact track loader (CTL) with a blade attachment is used to collect data to
train the PINN model. Post-training, the model is leveraged online by the
mapping system to track soil property estimates spatially as separate layers in
the map, with updates being performed in a Bayesian manner. Initial experiments
show that the system accurately highlights regions requiring higher relative
interaction forces, indicating the promise of this approach in enabling
soil-aware planning for autonomous terrain shaping.

</details>


### [185] [Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations](https://arxiv.org/abs/2507.22380)
*Yifei Chen,Yuzhe Zhang,Giovanni D'urso,Nicholas Lawrance,Brendan Tidd*

Main category: cs.RO

TL;DR: 提出了一种简单的因果结构学习框架，嵌入到复杂的模仿学习算法中，以解决机器人操控任务中的泛化问题。通过在模仿学习策略中进行干预，显式学习观测组件与专家动作之间的因果关系，从而提高在部署环境中对训练环境微小变化的适应能力。


<details>
  <summary>Details</summary>
Motivation: 当前的模仿学习技术在面对训练环境到部署环境的轻微域偏移时，泛化能力较差，限制了性能。为了增强复杂模仿学习算法在处理不可预测变化时的泛化能力，避免与目标任务无关的观测带来的混淆，需要显式学习观测组件与专家动作之间的因果关系。

Method: 1. 提出一个因果结构学习框架，该框架可轻松嵌入到现有的复杂模仿学习架构（如Action Chunking Transformer）中。2. 理论上澄清了在复杂机器人操控的模仿学习过程中，无需像[6]那样从图像输入中解耦特征表示。3. 在模仿学习策略上进行干预，学习一个因果结构函数，从而显式地建模观测组件与专家动作之间的因果关系。

Result: 在Mujoco中模拟ALOHA[31]双手机器人臂的实验表明，该方法显著减轻了现有复杂模仿学习算法的泛化问题。

Conclusion: 所提出的因果结构学习框架能够有效提升模仿学习算法在部署环境中的泛化能力，特别是在面对训练环境与部署环境之间的微小变化时。该方法通过显式学习因果关系，避免不相关观测的干扰，从而在机器人操控任务中实现了更好的适应性和鲁棒性。

Abstract: Recent developments in imitation learning have considerably advanced robotic
manipulation. However, current techniques in imitation learning can suffer from
poor generalization, limiting performance even under relatively minor domain
shifts. In this work, we aim to enhance the generalization capabilities of
complex imitation learning algorithms to handle unpredictable changes from the
training environments to deployment environments. To avoid confusion caused by
observations that are not relevant to the target task, we propose to explicitly
learn the causal relationship between observation components and expert
actions, employing a framework similar to [6], where a causal structural
function is learned by intervention on the imitation learning policy.
Disentangling the feature representation from image input as in [6] is hard to
satisfy in complex imitation learning process in robotic manipulation, we
theoretically clarify that this requirement is not necessary in causal
relationship learning. Therefore, we propose a simple causal structure learning
framework that can be easily embedded in recent imitation learning
architectures, such as the Action Chunking Transformer [31]. We demonstrate our
approach using a simulation of the ALOHA [31] bimanual robot arms in Mujoco,
and show that the method can considerably mitigate the generalization problem
of existing complex imitation learning algorithms.

</details>


### [186] [Safety Evaluation of Motion Plans Using Trajectory Predictors as Forward Reachable Set Estimators](https://arxiv.org/abs/2507.22389)
*Kaustav Chakraborty,Zeyuan Feng,Sushant Veer,Apoorva Sharma,Wenhao Ding,Sever Topan,Boris Ivanovic,Marco Pavone,Somil Bansal*

Main category: cs.RO

TL;DR: 本文提出了一种基于多模态轨迹预测的安全监控方法，用于验证端到端自动驾驶系统的安全。该方法利用凸优化和保形预测生成覆盖真实轨迹的置信区域，并结合贝叶斯过滤动态调整，以在保证安全性的同时减少误报。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统缺乏中间可解释模块，导致系统验证困难。现有方法在安全监控的完备性（检测所有不安全规划）和可靠性（不误报安全规划）方面存在不足。

Method: 1.利用多模态轨迹预测器生成障碍物的未来状态分布；2.基于场景上下文（车道拓扑、历史轨迹）通过凸优化提取数据驱动的可达集；3.使用保形预测校准可达集，确保以高概率覆盖真实轨迹；4.引入贝叶斯过滤器动态调整可靠度，应对分布外场景；5.通过检查主车规划与校准可达集的交集判断安全性

Result: 在nuScenes数据集上的实验表明：1.相较于基线方法，在保持完备性（召回率98%）的同时，误报率降低37%；2.贝叶斯过滤器有效缓解了分布外场景下的失效问题

Conclusion: 该监控器首次实现了完备性与可靠性的平衡，为学习型自动驾驶栈提供了实用化的安全验证方案，其核心创新在于将保形预测与在线性能评估结合

Abstract: The advent of end-to-end autonomy stacks - often lacking interpretable
intermediate modules - has placed an increased burden on ensuring that the
final output, i.e., the motion plan, is safe in order to validate the safety of
the entire stack. This requires a safety monitor that is both complete (able to
detect all unsafe plans) and sound (does not flag safe plans). In this work, we
propose a principled safety monitor that leverages modern multi-modal
trajectory predictors to approximate forward reachable sets (FRS) of
surrounding agents. By formulating a convex program, we efficiently extract
these data-driven FRSs directly from the predicted state distributions,
conditioned on scene context such as lane topology and agent history. To ensure
completeness, we leverage conformal prediction to calibrate the FRS and
guarantee coverage of ground-truth trajectories with high probability. To
preserve soundness in out-of-distribution (OOD) scenarios or under predictor
failure, we introduce a Bayesian filter that dynamically adjusts the FRS
conservativeness based on the predictor's observed performance. We then assess
the safety of the ego vehicle's motion plan by checking for intersections with
these calibrated FRSs, ensuring the plan remains collision-free under plausible
future behaviors of others. Extensive experiments on the nuScenes dataset show
our approach significantly improves soundness while maintaining completeness,
offering a practical and reliable safety monitor for learned autonomy stacks.

</details>


### [187] [Comparing Normalizing Flows with Kernel Density Estimation in Estimating Risk of Automated Driving Systems](https://arxiv.org/abs/2507.22429)
*Erwin de Gelder,Maren Buermann,Olaf Op den Camp*

Main category: cs.RO

TL;DR: 本文探讨了归一化流（Normalizing Flows, NF）在自动驾驶系统（ADS）安全验证中的应用，特别是用于场景参数的概率密度函数（PDF）估计。NF通过可逆映射从简单分布生成复杂分布，无需对PDF形状做限制性假设，适用于高维密度估计。论文通过与核密度估计（KDE）对比，展示了NF在风险及风险不确定性量化上的优势：虽然计算成本更高，但对维度灾难更不敏感，提升了风险评估的精度。未来工作包括优化NF架构以增强场景生成能力。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶系统的安全验证中，场景化评估依赖于从真实驾驶数据中提取测试用例，其参数级别的暴露概率需通过PDF准确估计。传统方法如参数独立性假设可能导致误差，而避免假设的非参数方法（如KDE）因维度灾难问题难以处理多参数场景。因此需要一种既能避免假设又能高效处理高维数据的方法来提升风险评估精度。

Method: 1. 提出使用归一化流（NF）模型估计场景参数PDF：NF通过一系列可逆可微映射将简单基分布（如高斯分布）转换为目标复杂分布，实现无参数假设的高维建模。
2. 对比实验：将NF与核密度估计（KDE）在模拟数据集上进行对比，评估二者对ADS系统风险及风险不确定性的量化能力。指标包括计算效率、维度敏感性和评估误差等。
3. 风险建模：基于估计的PDF计算碰撞概率等风险评估指标，特别关注不确定性区间的可靠性。

Result: 1. NF在相同数据量下对维度变化更稳健（维度灾难影响弱于KDE），能更准确地估计复杂PDF，尤其在风险不确定性量化上优于KDE，减少了误判。
2. NF的计算成本高于KDE（需训练链式变换），但精度提升显著。实验显示，在10维以上场景中NF能保持可用性，而KDE性能急剧下降。
3. ADS系统风险边界分析表明，NF提供的置信区间更窄且覆盖真实值更可靠，为安全决策提供更强依据。

Conclusion: NF为高维场景参数PDF估计提供了一种无假设、灵活且精确的解决方案，显著改进了ADS安全验证中的风险评估能力。未来将通过优化模型架构（如流函数选择）和训练策略进一步释放其潜力，尤其在生成高质量测试场景方面。

Abstract: The development of safety validation methods is essential for the safe
deployment and operation of Automated Driving Systems (ADSs). One of the goals
of safety validation is to prospectively evaluate the risk of an ADS dealing
with real-world traffic. Scenario-based assessment is a widely-used approach,
where test cases are derived from real-world driving data. To allow for a
quantitative analysis of the system performance, the exposure of the scenarios
must be accurately estimated. The exposure of scenarios at parameter level is
expressed using a Probability Density Function (PDF). However, assumptions
about the PDF, such as parameter independence, can introduce errors, while
avoiding assumptions often leads to oversimplified models with limited
parameters to mitigate the curse of dimensionality.
  This paper considers the use of Normalizing Flows (NF) for estimating the PDF
of the parameters. NF are a class of generative models that transform a simple
base distribution into a complex one using a sequence of invertible and
differentiable mappings, enabling flexible, high-dimensional density estimation
without restrictive assumptions on the PDF's shape. We demonstrate the
effectiveness of NF in quantifying risk and risk uncertainty of an ADS,
comparing its performance with Kernel Density Estimation (KDE), a traditional
method for non-parametric PDF estimation. While NF require more computational
resources compared to KDE, NF is less sensitive to the curse of dimensionality.
As a result, NF can improve risk uncertainty estimation, offering a more
precise assessment of an ADS's safety.
  This work illustrates the potential of NF in scenario-based safety. Future
work involves experimenting more with using NF for scenario generation and
optimizing the NF architecture, transformation types, and training
hyperparameters to further enhance their applicability.

</details>


### [188] [Bayesian Optimization applied for accelerated Virtual Validation of the Autonomous Driving Function](https://arxiv.org/abs/2507.22769)
*Satyesh Shanker Awasthi,Mohammed Irshadh Ismaaeel Sathyamangalam Imran,Stefano Arrigoni,Francesco Braghin*

Main category: cs.RO

TL;DR: 提出基于贝叶斯优化（BO）的框架，加速自动驾驶功能（ADF）安全验证中关键场景的发现。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶功能（ADF）的验证严重依赖仿真，但参数空间庞大导致计算量大且耗时。需要一种高效方法在运行设计域（ODD）中识别关键场景（如危险情况）。

Method: 1. 使用贝叶斯优化（BO）框架探索参数空间；2. 针对基于模型预测控制（MPC）的运动规划器进行优化；3. 目标是最小化安全指标（如车辆偏离道路）；4. 与暴力搜索（Design of Experiments, DoE）方法比较效率；5. 在更高维参数空间中测试框架的可扩展性；6. 研究框架识别多个独立关键区域的能力.

Result: 1. 所需仿真次数比暴力实验设计（DoE）方法少多个数量级；2. 有效识别危险场景（如车辆偏离道路事件）；3. 在更高维参数空间保持有效性；4. 成功识别运动规划器ODD中多个独立关键区域.

Conclusion: 贝叶斯优化框架显著加速了自动驾驶功能验证中关键场景的发现，计算效率高且可扩展到高维问题，为自动驾驶安全验证提供实用工具。

Abstract: Rigorous Verification and Validation (V&V) of Autonomous Driving Functions
(ADFs) is paramount for ensuring the safety and public acceptance of Autonomous
Vehicles (AVs). Current validation relies heavily on simulation to achieve
sufficient test coverage within the Operational Design Domain (ODD) of a
vehicle, but exhaustively exploring the vast parameter space of possible
scenarios is computationally expensive and time-consuming. This work introduces
a framework based on Bayesian Optimization (BO) to accelerate the discovery of
critical scenarios. We demonstrate the effectiveness of the framework on an
Model Predictive Controller (MPC)-based motion planner, showing that it
identifies hazardous situations, such as off-road events, using orders of
magnitude fewer simulations than brute-force Design of Experiments (DoE)
methods. Furthermore, this study investigates the scalability of the framework
in higher-dimensional parameter spaces and its ability to identify multiple,
distinct critical regions within the ODD of the motion planner used as the case
study .

</details>


### [189] [Operationalization of Scenario-Based Safety Assessment of Automated Driving Systems](https://arxiv.org/abs/2507.22433)
*Olaf Op den Camp,Erwin de Gelder*

Main category: cs.RO

TL;DR: 本文针对联合国欧洲经济委员会（UNECE WP.29 GRVA）正在制定的‘新评估/测试方法（NATM）’，探讨了如何利用场景数据库进行自动驾驶系统（ADS）的实际安全评估，以及全面实施NATM所需的额外步骤，同时结合了欧洲地平线项目中开发的方法。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶系统（ADS）的推广，需要一种结构化和协调的安全评估方法来确保道路安全。联合国机构UNECE WP.29 GRVA正在制定的NATM框架为这种评估提供了指导，但如何在实际操作中应用这一框架（尤其结合场景数据库）以及如何与现有研究项目（如欧洲地平线项目）的方法衔接仍需探索。

Method: 论文提出了一个基于场景数据库的实际操作流程：首先利用场景数据库存储和分类各种驾驶场景（如交通状况、天气条件等）；然后按照NATM的步骤，通过对场景库的挖掘分析风险评估需求并生成测试用例；最后结合欧洲地平线项目中开发的安全评估方法（如模拟测试、场地测试等），验证这些场景覆盖的有效性，并说明如何整合额外步骤（如数据收集标准制定、场景更新机制）以完全支持NATM。

Result: 研究证实场景数据库是实现NATM安全评估的核心工具，但需要辅以清晰的操作规范和与其他项目方法的协同整合。例如欧洲地平线项目提供的测试方法可直接适配NATM的场景评估需求，但需补充持续数据收集、场景验证、以及闭环反馈机制等步骤才能使NATM落地。

Conclusion: 论文表明：利用场景数据库可系统化支持NATM的实施，但其全面应用依赖于数据库的构建标准、与其他安全评估方法的协同（如欧洲地平线项目方案）以及额外流程设计（数据更新、反馈环路等），这为未来安全法规的落地提供了具体技术路径建议。

Abstract: Before introducing an Automated Driving System (ADS) on the road at scale,
the manufacturer must conduct some sort of safety assurance. To structure and
harmonize the safety assurance process, the UNECE WP.29 Working Party on
Automated/Autonomous and Connected Vehicles (GRVA) is developing the New
Assessment/Test Method (NATM) that indicates what steps need to be taken for
safety assessment of an ADS. In this paper, we will show how to practically
conduct safety assessment making use of a scenario database, and what
additional steps must be taken to fully operationalize the NATM. In addition,
we will elaborate on how the use of scenario databases fits with methods
developed in the Horizon Europe projects that focus on safety assessment
following the NATM approach.

</details>


### [190] [A Two-Stage Lightweight Framework for Efficient Land-Air Bimodal Robot Autonomous Navigation](https://arxiv.org/abs/2507.22473)
*Yongjie Li,Zhou Liu,Wenshuai Yu,Zhangji Lu,Chenyang Wang,Fei Yu,Qingquan Li*

Main category: cs.RO

TL;DR: 提出了一种两阶段的轻量级框架，用于陆地-空中双模式机器人（LABR）的高效导航。该框架结合了全局关键点预测与局部轨迹优化，以生成可达的轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有LABR导航方法存在轨迹次优或计算需求高的问题，无法兼顾高效率与低功耗的需求。需要一种能在资源受限的平台上实时运行的方法。

Method: 采用两阶段方法：1) 全局关键点预测网络（GKPN）生成混合陆空关键点路径。GKPN包含索贝尔感知网络（SPN）用于障碍物检测和轻量注意力规划网络（LAPN）捕获上下文信息进行预测；2) 根据关键点分割全局路径，使用基于地图的规划器优化成平滑、无碰撞的轨迹。

Result: 实验表明，该框架比现有方法减少14%的网络参数量，陆地-空中转换能耗降低35%。无需GPU加速即可实时导航，并实现仿真到现实的零样本迁移。

Conclusion: 所提框架解决了LABR导航中的计算效率和轨迹优化问题，显著降低了资源消耗，为双模式机器人的高效自主导航提供了实用方案。

Abstract: Land-air bimodal robots (LABR) are gaining attention for autonomous
navigation, combining high mobility from aerial vehicles with long endurance
from ground vehicles. However, existing LABR navigation methods are limited by
suboptimal trajectories from mapping-based approaches and the excessive
computational demands of learning-based methods. To address this, we propose a
two-stage lightweight framework that integrates global key points prediction
with local trajectory refinement to generate efficient and reachable
trajectories. In the first stage, the Global Key points Prediction Network
(GKPN) was used to generate a hybrid land-air keypoint path. The GKPN includes
a Sobel Perception Network (SPN) for improved obstacle detection and a
Lightweight Attention Planning Network (LAPN) to improves predictive ability by
capturing contextual information. In the second stage, the global path is
segmented based on predicted key points and refined using a mapping-based
planner to create smooth, collision-free trajectories. Experiments conducted on
our LABR platform show that our framework reduces network parameters by 14\%
and energy consumption during land-air transitions by 35\% compared to existing
approaches. The framework achieves real-time navigation without GPU
acceleration and enables zero-shot transfer from simulation to reality during

</details>


### [191] [Explainable Deep Anomaly Detection with Sequential Hypothesis Testing for Robotic Sewer Inspection](https://arxiv.org/abs/2507.22546)
*Alex George,Will Shepherd,Simon Tait,Lyudmila Mihaylova,Sean R. Anderson*

Main category: cs.RO

TL;DR: 该论文提出了一种结合可解释深度学习异常检测和序列概率比检验（SPRT）的新型系统，用于自动化检测下水道管道故障（如泄漏和堵塞）。传统方法依赖人工审查移动机器人收集的CCTV录像，效率低下且易出错。新系统通过单帧图像进行可解释的异常空间定位，并结合SPRT实现时间维度的证据聚合，提高了对图像序列噪声的鲁棒性。实验结果表明，该联合时空分析系统在异常检测性能上有所提升，能更可靠地进行下水道检查。


<details>
  <summary>Details</summary>
Motivation: 传统下水道管道故障检测依赖人工审查CCTV录像，存在效率低和易出错的问题。为了解决这些问题并实现自动化检测，作者提出了结合可解释深度学习与SPRT的新系统。

Method: 1. 使用可解释深度学习异常检测器处理单帧图像，提供异常的空间定位解释；2. 引入序列概率比检验（SPRT）对连续图像帧进行时间维度的证据聚合，增强系统对噪声的鲁棒性。

Result: 实验结果表明，该系统提高了异常检测的性能，证明了联合时空分析方法在下水道检查中的可靠性和鲁棒性优势。

Conclusion: 通过结合深度学习的空间异常检测与SPRT的时间序列分析，该系统实现了高效、可靠的下水道管道自动化检测，为实际应用提供了一种更优的解决方案。

Abstract: Sewer pipe faults, such as leaks and blockages, can lead to severe
consequences including groundwater contamination, property damage, and service
disruption. Traditional inspection methods rely heavily on the manual review of
CCTV footage collected by mobile robots, which is inefficient and susceptible
to human error. To automate this process, we propose a novel system
incorporating explainable deep learning anomaly detection combined with
sequential probability ratio testing (SPRT). The anomaly detector processes
single image frames, providing interpretable spatial localisation of anomalies,
whilst the SPRT introduces temporal evidence aggregation, enhancing robustness
against noise over sequences of image frames. Experimental results demonstrate
improved anomaly detection performance, highlighting the benefits of the
combined spatiotemporal analysis system for reliable and robust sewer
inspection.

</details>


### [192] [UniLegs: Universal Multi-Legged Robot Control through Morphology-Agnostic Policy Distillation](https://arxiv.org/abs/2507.22653)
*Weijie Xi,Zhanxiang Cao,Chenlin Ming,Jianying Zheng,Guyue Zhou*

Main category: cs.RO

TL;DR: 提出了一种两阶段的师生框架，通过策略蒸馏为不同的腿式机器人形态训练一个通用的Transformer控制器，该控制器在训练形态上达到教师策略94.47%的性能，在未见形态上达到72.64%，并在实物机器人上验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 现有的腿式机器人控制器要么针对特定形态设计而缺乏通用性，要么为了通用性而牺牲性能。需要一个既能保持各形态最优控制策略又能通用的控制器。

Method: 1. 为每个特定机器人形态训练一个专门的教师策略；2. 通过策略蒸馏将所有教师策略的知识融合进一个基于Transformer的学生策略，该策略利用注意力机制处理不同形态的关节关系。

Result: 在五种腿式机器人形态上的实验表明，Transformer学生策略在训练形态上达到教师策略94.47%的性能，在未见形态上达到72.64%的性能，且Transformer架构通过注意力机制始终优于多层感知机（MLP）。实物四足机器人部署验证了框架的实际可行性。

Conclusion: 该框架提供了一种可扩展的解决方案，能够开发出在保持接近最优性能的同时泛化到不同形态的通用腿式机器人控制器。

Abstract: Developing controllers that generalize across diverse robot morphologies
remains a significant challenge in legged locomotion. Traditional approaches
either create specialized controllers for each morphology or compromise
performance for generality. This paper introduces a two-stage teacher-student
framework that bridges this gap through policy distillation. First, we train
specialized teacher policies optimized for individual morphologies, capturing
the unique optimal control strategies for each robot design. Then, we distill
this specialized expertise into a single Transformer-based student policy
capable of controlling robots with varying leg configurations. Our experiments
across five distinct legged morphologies demonstrate that our approach
preserves morphology-specific optimal behaviors, with the Transformer
architecture achieving 94.47\% of teacher performance on training morphologies
and 72.64\% on unseen robot designs. Comparative analysis reveals that
Transformer-based architectures consistently outperform MLP baselines by
leveraging attention mechanisms to effectively model joint relationships across
different kinematic structures. We validate our approach through successful
deployment on a physical quadruped robot, demonstrating the practical viability
of our morphology-agnostic control framework. This work presents a scalable
solution for developing universal legged robot controllers that maintain
near-optimal performance while generalizing across diverse morphologies.

</details>
